/shared/home/matevz.vidovic/Diplomska/Prototip/Delo/model_wrapper.py:111: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.model = torch.load(self.prev_model_path, map_location=torch.device(device))
unet_original_main.py do_log: True
Log file name: log_07_18-24-05_01-2025.log.
            Add print_log_file_name=False to file_handler_setup() to disable this printout.
min_resource_percentage.py do_log: False
model_wrapper.py do_log: True
training_wrapper.py do_log: True
helper_img_and_fig_tools.py do_log: False
conv_resource_calc.py do_log: False
pruner.py do_log: False
helper_model_vizualization.py do_log: False
training_support.py do_log: True
helper_model_eval_graphs.py do_log: False
losses.py do_log: False
Args: Namespace(ptd='./Data/vein_and_sclera_data', sd='unet_zsc_train', mti=200, mtti=1000000000.0, pruning_phase=False, ifn='IPAD_eq', ips=1000000000.0, tras=-1, tp=False, yaml='z_pipeline_unet/unet_original_zsc.yaml', ntibp=None, ptp=None, map=None)
YAML: {'batch_size': 2, 'learning_rate': 1e-05, 'num_of_dataloader_workers': 7, 'train_epoch_size_limit': 400, 'num_epochs_per_training_iteration': 1, 'cleanup_k': 3, 'dataset_option': 'aug_with_zero_out_sclera', 'optimizer_used': 'Adam', 'zero_out_non_sclera_on_predictions': False, 'loss_fn_name': 'MCDL', 'alphas': [], 'model': '64_2_6', 'input_width': 2048, 'input_height': 1024, 'input_channels': 3, 'output_channels': 2, 'num_train_iters_between_prunings': 10, 'max_auto_prunings': 70, 'proportion_to_prune': 0.01, 'prune_by_original_percent': True, 'num_filters_to_prune': -1, 'prune_n_kernels_at_once': 100, 'resource_name_to_prune_by': 'flops_num', 'importance_func': 'IPAD_eq'}
Validation phase: False
Namespace(ptd='./Data/vein_and_sclera_data', sd='unet_zsc_train', mti=200, mtti=1000000000.0, pruning_phase=False, ifn='IPAD_eq', ips=1000000000.0, tras=-1, tp=False, yaml='z_pipeline_unet/unet_original_zsc.yaml', ntibp=None, ptp=None, map=None)
Device: cuda
dataset_aug_with_zero_out_sclera.py do_log: False
img_augments.py do_log: False
path to file: ./Data/vein_and_sclera_data
summary for train
valid images: 89
summary for val
valid images: 27
summary for test
valid images: 12
train dataset len: 89
val dataset len: 27
test dataset len: 12
train dataloader num of batches: 45
val dataloader num of batches: 14
test dataloader num of batches: 6
Loaded model path:  ./unet_zsc_train/saved_model_wrapper/models/UNet_46_.pth
per-ex loss: 0.885662  [    2/   89]
per-ex loss: 0.867290  [    4/   89]
per-ex loss: 0.827420  [    6/   89]
per-ex loss: 0.749265  [    8/   89]
per-ex loss: 0.860850  [   10/   89]
per-ex loss: 0.864395  [   12/   89]
per-ex loss: 0.881116  [   14/   89]
per-ex loss: 0.882576  [   16/   89]
per-ex loss: 0.809683  [   18/   89]
per-ex loss: 0.669982  [   20/   89]
per-ex loss: 0.899489  [   22/   89]
per-ex loss: 0.791636  [   24/   89]
per-ex loss: 0.764902  [   26/   89]
per-ex loss: 0.904311  [   28/   89]
per-ex loss: 0.904497  [   30/   89]
per-ex loss: 0.772264  [   32/   89]
per-ex loss: 0.820747  [   34/   89]
per-ex loss: 0.851495  [   36/   89]
per-ex loss: 0.691218  [   38/   89]
per-ex loss: 0.877631  [   40/   89]
per-ex loss: 0.849833  [   42/   89]
per-ex loss: 0.946483  [   44/   89]
per-ex loss: 0.918618  [   46/   89]
per-ex loss: 0.846587  [   48/   89]
per-ex loss: 0.828269  [   50/   89]
per-ex loss: 0.725427  [   52/   89]
per-ex loss: 0.834087  [   54/   89]
per-ex loss: 0.721658  [   56/   89]
per-ex loss: 0.941000  [   58/   89]
per-ex loss: 0.817220  [   60/   89]
per-ex loss: 0.777094  [   62/   89]
per-ex loss: 0.874143  [   64/   89]
per-ex loss: 0.924334  [   66/   89]
per-ex loss: 0.743519  [   68/   89]
per-ex loss: 0.947704  [   70/   89]
per-ex loss: 0.858043  [   72/   89]
per-ex loss: 0.839363  [   74/   89]
per-ex loss: 0.853028  [   76/   89]
per-ex loss: 0.614702  [   78/   89]
per-ex loss: 0.788313  [   80/   89]
per-ex loss: 0.837035  [   82/   89]
per-ex loss: 0.715301  [   84/   89]
per-ex loss: 0.614652  [   86/   89]
per-ex loss: 0.936872  [   88/   89]
per-ex loss: 0.711402  [   89/   89]
Train Error: Avg loss: 0.82313585
validation Error: 
 Avg loss: 0.88931182 
 F1: 0.322751 
 Precision: 0.877078 
 Recall: 0.197763
 IoU: 0.192429

test Error: 
 Avg loss: 0.88415038 
 F1: 0.311637 
 Precision: 0.882701 
 Recall: 0.189221
 IoU: 0.184580

We have finished training iteration 47
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_45_.pth
per-ex loss: 0.811543  [    2/   89]
per-ex loss: 0.843258  [    4/   89]
per-ex loss: 0.779464  [    6/   89]
per-ex loss: 0.810521  [    8/   89]
per-ex loss: 0.862435  [   10/   89]
per-ex loss: 0.801797  [   12/   89]
per-ex loss: 0.687452  [   14/   89]
per-ex loss: 0.812508  [   16/   89]
per-ex loss: 0.743056  [   18/   89]
per-ex loss: 0.863548  [   20/   89]
per-ex loss: 0.872044  [   22/   89]
per-ex loss: 0.887978  [   24/   89]
per-ex loss: 0.705200  [   26/   89]
per-ex loss: 0.893888  [   28/   89]
per-ex loss: 0.847522  [   30/   89]
per-ex loss: 0.936387  [   32/   89]
per-ex loss: 0.765935  [   34/   89]
per-ex loss: 0.809053  [   36/   89]
per-ex loss: 0.888991  [   38/   89]
per-ex loss: 0.775263  [   40/   89]
per-ex loss: 0.804012  [   42/   89]
per-ex loss: 0.939484  [   44/   89]
per-ex loss: 0.859367  [   46/   89]
per-ex loss: 0.890302  [   48/   89]
per-ex loss: 0.861451  [   50/   89]
per-ex loss: 0.905894  [   52/   89]
per-ex loss: 0.918868  [   54/   89]
per-ex loss: 0.816223  [   56/   89]
per-ex loss: 0.705088  [   58/   89]
per-ex loss: 0.893611  [   60/   89]
per-ex loss: 0.593899  [   62/   89]
per-ex loss: 0.895706  [   64/   89]
per-ex loss: 0.784050  [   66/   89]
per-ex loss: 0.912903  [   68/   89]
per-ex loss: 0.813925  [   70/   89]
per-ex loss: 0.811287  [   72/   89]
per-ex loss: 0.908242  [   74/   89]
per-ex loss: 0.791676  [   76/   89]
per-ex loss: 0.860218  [   78/   89]
per-ex loss: 0.821063  [   80/   89]
per-ex loss: 0.827907  [   82/   89]
per-ex loss: 0.967647  [   84/   89]
per-ex loss: 0.830849  [   86/   89]
per-ex loss: 0.912789  [   88/   89]
per-ex loss: 0.984335  [   89/   89]
Train Error: Avg loss: 0.83796979
validation Error: 
 Avg loss: 0.89423252 
 F1: 0.325066 
 Precision: 0.882211 
 Recall: 0.199240
 IoU: 0.194077

test Error: 
 Avg loss: 0.88927399 
 F1: 0.308597 
 Precision: 0.900320 
 Recall: 0.186212
 IoU: 0.182450

We have finished training iteration 48
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_46_.pth
per-ex loss: 0.799967  [    2/   89]
per-ex loss: 0.842839  [    4/   89]
per-ex loss: 0.858384  [    6/   89]
per-ex loss: 0.675291  [    8/   89]
per-ex loss: 0.892196  [   10/   89]
per-ex loss: 0.896160  [   12/   89]
per-ex loss: 0.939634  [   14/   89]
per-ex loss: 0.926191  [   16/   89]
per-ex loss: 0.834484  [   18/   89]
per-ex loss: 0.854189  [   20/   89]
per-ex loss: 0.840494  [   22/   89]
per-ex loss: 0.835581  [   24/   89]
per-ex loss: 0.927700  [   26/   89]
per-ex loss: 0.854982  [   28/   89]
per-ex loss: 0.896189  [   30/   89]
per-ex loss: 0.793643  [   32/   89]
per-ex loss: 0.734888  [   34/   89]
per-ex loss: 0.871554  [   36/   89]
per-ex loss: 0.817880  [   38/   89]
per-ex loss: 0.842612  [   40/   89]
per-ex loss: 0.906362  [   42/   89]
per-ex loss: 0.886978  [   44/   89]
per-ex loss: 0.844075  [   46/   89]
per-ex loss: 0.817272  [   48/   89]
per-ex loss: 0.902848  [   50/   89]
per-ex loss: 0.775717  [   52/   89]
per-ex loss: 0.862706  [   54/   89]
per-ex loss: 0.802105  [   56/   89]
per-ex loss: 0.712984  [   58/   89]
per-ex loss: 0.785091  [   60/   89]
per-ex loss: 0.844283  [   62/   89]
per-ex loss: 0.824343  [   64/   89]
per-ex loss: 0.662044  [   66/   89]
per-ex loss: 0.793892  [   68/   89]
per-ex loss: 0.926611  [   70/   89]
per-ex loss: 0.813206  [   72/   89]
per-ex loss: 0.725500  [   74/   89]
per-ex loss: 0.918147  [   76/   89]
per-ex loss: 0.907154  [   78/   89]
per-ex loss: 0.930665  [   80/   89]
per-ex loss: 0.950498  [   82/   89]
per-ex loss: 0.774162  [   84/   89]
per-ex loss: 0.724252  [   86/   89]
per-ex loss: 0.876105  [   88/   89]
per-ex loss: 0.960374  [   89/   89]
Train Error: Avg loss: 0.84138294
validation Error: 
 Avg loss: 0.89335909 
 F1: 0.339994 
 Precision: 0.864717 
 Recall: 0.211595
 IoU: 0.204815

test Error: 
 Avg loss: 0.88570207 
 F1: 0.332629 
 Precision: 0.877078 
 Recall: 0.205231
 IoU: 0.199493

We have finished training iteration 49
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_47_.pth
per-ex loss: 0.713865  [    2/   89]
per-ex loss: 0.663924  [    4/   89]
per-ex loss: 0.857075  [    6/   89]
per-ex loss: 0.843362  [    8/   89]
per-ex loss: 0.854400  [   10/   89]
per-ex loss: 0.892325  [   12/   89]
per-ex loss: 0.911461  [   14/   89]
per-ex loss: 0.814063  [   16/   89]
per-ex loss: 0.766473  [   18/   89]
per-ex loss: 0.717098  [   20/   89]
per-ex loss: 0.875417  [   22/   89]
per-ex loss: 0.850772  [   24/   89]
per-ex loss: 0.869705  [   26/   89]
per-ex loss: 0.761515  [   28/   89]
per-ex loss: 0.860485  [   30/   89]
per-ex loss: 0.814142  [   32/   89]
per-ex loss: 0.806739  [   34/   89]
per-ex loss: 0.833612  [   36/   89]
per-ex loss: 0.802416  [   38/   89]
per-ex loss: 0.913888  [   40/   89]
per-ex loss: 0.788943  [   42/   89]
per-ex loss: 0.892280  [   44/   89]
per-ex loss: 0.753282  [   46/   89]
per-ex loss: 0.884763  [   48/   89]
per-ex loss: 0.752190  [   50/   89]
per-ex loss: 0.862598  [   52/   89]
per-ex loss: 0.903759  [   54/   89]
per-ex loss: 0.886203  [   56/   89]
per-ex loss: 0.797049  [   58/   89]
per-ex loss: 0.885079  [   60/   89]
per-ex loss: 0.906286  [   62/   89]
per-ex loss: 0.923418  [   64/   89]
per-ex loss: 0.657501  [   66/   89]
per-ex loss: 0.696163  [   68/   89]
per-ex loss: 0.713224  [   70/   89]
per-ex loss: 0.795162  [   72/   89]
per-ex loss: 0.908677  [   74/   89]
per-ex loss: 0.843102  [   76/   89]
per-ex loss: 0.785663  [   78/   89]
per-ex loss: 0.856243  [   80/   89]
per-ex loss: 0.967732  [   82/   89]
per-ex loss: 0.855986  [   84/   89]
per-ex loss: 0.773948  [   86/   89]
per-ex loss: 0.844736  [   88/   89]
per-ex loss: 0.629663  [   89/   89]
Train Error: Avg loss: 0.82191976
validation Error: 
 Avg loss: 0.87961944 
 F1: 0.335597 
 Precision: 0.874829 
 Recall: 0.207622
 IoU: 0.201632

test Error: 
 Avg loss: 0.87840483 
 F1: 0.326313 
 Precision: 0.887287 
 Recall: 0.199918
 IoU: 0.194967

We have finished training iteration 50
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_48_.pth
per-ex loss: 0.846540  [    2/   89]
per-ex loss: 0.944681  [    4/   89]
per-ex loss: 0.706855  [    6/   89]
per-ex loss: 0.863108  [    8/   89]
per-ex loss: 0.843875  [   10/   89]
per-ex loss: 0.894681  [   12/   89]
per-ex loss: 0.898566  [   14/   89]
per-ex loss: 0.806823  [   16/   89]
per-ex loss: 0.851664  [   18/   89]
per-ex loss: 0.895719  [   20/   89]
per-ex loss: 0.784531  [   22/   89]
per-ex loss: 0.624909  [   24/   89]
per-ex loss: 0.756530  [   26/   89]
per-ex loss: 0.854966  [   28/   89]
per-ex loss: 0.880466  [   30/   89]
per-ex loss: 0.804103  [   32/   89]
per-ex loss: 0.841122  [   34/   89]
per-ex loss: 0.744442  [   36/   89]
per-ex loss: 0.899099  [   38/   89]
per-ex loss: 0.695942  [   40/   89]
per-ex loss: 0.892006  [   42/   89]
per-ex loss: 0.768206  [   44/   89]
per-ex loss: 0.682123  [   46/   89]
per-ex loss: 0.878758  [   48/   89]
per-ex loss: 0.927195  [   50/   89]
per-ex loss: 0.866239  [   52/   89]
per-ex loss: 0.817608  [   54/   89]
per-ex loss: 0.780252  [   56/   89]
per-ex loss: 0.955440  [   58/   89]
per-ex loss: 0.728649  [   60/   89]
per-ex loss: 0.815893  [   62/   89]
per-ex loss: 0.928258  [   64/   89]
per-ex loss: 0.805633  [   66/   89]
per-ex loss: 0.639031  [   68/   89]
per-ex loss: 0.877890  [   70/   89]
per-ex loss: 0.716018  [   72/   89]
per-ex loss: 0.924188  [   74/   89]
per-ex loss: 0.749413  [   76/   89]
per-ex loss: 0.882508  [   78/   89]
per-ex loss: 0.911385  [   80/   89]
per-ex loss: 0.787836  [   82/   89]
per-ex loss: 0.832429  [   84/   89]
per-ex loss: 0.908381  [   86/   89]
per-ex loss: 0.806559  [   88/   89]
per-ex loss: 0.666115  [   89/   89]
Train Error: Avg loss: 0.82192522
validation Error: 
 Avg loss: 0.88563508 
 F1: 0.364083 
 Precision: 0.840703 
 Recall: 0.232354
 IoU: 0.222556

test Error: 
 Avg loss: 0.87780578 
 F1: 0.357834 
 Precision: 0.843636 
 Recall: 0.227074
 IoU: 0.217904

We have finished training iteration 51
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_49_.pth
per-ex loss: 0.814435  [    2/   89]
per-ex loss: 0.966149  [    4/   89]
per-ex loss: 0.912714  [    6/   89]
per-ex loss: 0.812439  [    8/   89]
per-ex loss: 0.786991  [   10/   89]
per-ex loss: 0.918269  [   12/   89]
per-ex loss: 0.918243  [   14/   89]
per-ex loss: 0.842095  [   16/   89]
per-ex loss: 0.782726  [   18/   89]
per-ex loss: 0.862276  [   20/   89]
per-ex loss: 0.764114  [   22/   89]
per-ex loss: 0.887261  [   24/   89]
per-ex loss: 0.778204  [   26/   89]
per-ex loss: 0.682978  [   28/   89]
per-ex loss: 0.709798  [   30/   89]
per-ex loss: 0.845992  [   32/   89]
per-ex loss: 0.857364  [   34/   89]
per-ex loss: 0.885817  [   36/   89]
per-ex loss: 0.587445  [   38/   89]
per-ex loss: 0.891000  [   40/   89]
per-ex loss: 0.871967  [   42/   89]
per-ex loss: 0.890134  [   44/   89]
per-ex loss: 0.830019  [   46/   89]
per-ex loss: 0.855547  [   48/   89]
per-ex loss: 0.857009  [   50/   89]
per-ex loss: 0.962848  [   52/   89]
per-ex loss: 0.966679  [   54/   89]
per-ex loss: 0.863060  [   56/   89]
per-ex loss: 0.690655  [   58/   89]
per-ex loss: 0.808434  [   60/   89]
per-ex loss: 0.823927  [   62/   89]
per-ex loss: 0.682479  [   64/   89]
per-ex loss: 0.847696  [   66/   89]
per-ex loss: 0.936148  [   68/   89]
per-ex loss: 0.818003  [   70/   89]
per-ex loss: 0.938918  [   72/   89]
per-ex loss: 0.773554  [   74/   89]
per-ex loss: 0.795639  [   76/   89]
per-ex loss: 0.867799  [   78/   89]
per-ex loss: 0.851960  [   80/   89]
per-ex loss: 0.794685  [   82/   89]
per-ex loss: 0.786583  [   84/   89]
per-ex loss: 0.782043  [   86/   89]
per-ex loss: 0.729758  [   88/   89]
per-ex loss: 0.851870  [   89/   89]
Train Error: Avg loss: 0.83074945
validation Error: 
 Avg loss: 0.88756047 
 F1: 0.406060 
 Precision: 0.768816 
 Recall: 0.275887
 IoU: 0.254753

test Error: 
 Avg loss: 0.87808979 
 F1: 0.410954 
 Precision: 0.781618 
 Recall: 0.278759
 IoU: 0.258617

We have finished training iteration 52
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_50_.pth
per-ex loss: 0.753273  [    2/   89]
per-ex loss: 0.820198  [    4/   89]
per-ex loss: 0.903456  [    6/   89]
per-ex loss: 0.691583  [    8/   89]
per-ex loss: 0.894277  [   10/   89]
per-ex loss: 0.873641  [   12/   89]
per-ex loss: 0.902336  [   14/   89]
per-ex loss: 0.815606  [   16/   89]
per-ex loss: 0.929287  [   18/   89]
per-ex loss: 0.916823  [   20/   89]
per-ex loss: 0.877551  [   22/   89]
per-ex loss: 0.929634  [   24/   89]
per-ex loss: 0.836707  [   26/   89]
per-ex loss: 0.609025  [   28/   89]
per-ex loss: 0.765419  [   30/   89]
per-ex loss: 0.838060  [   32/   89]
per-ex loss: 0.897530  [   34/   89]
per-ex loss: 0.721723  [   36/   89]
per-ex loss: 0.827093  [   38/   89]
per-ex loss: 0.830688  [   40/   89]
per-ex loss: 0.734858  [   42/   89]
per-ex loss: 0.795739  [   44/   89]
per-ex loss: 0.945587  [   46/   89]
per-ex loss: 0.828428  [   48/   89]
per-ex loss: 0.857641  [   50/   89]
per-ex loss: 0.658048  [   52/   89]
per-ex loss: 0.893776  [   54/   89]
per-ex loss: 0.904688  [   56/   89]
per-ex loss: 0.798423  [   58/   89]
per-ex loss: 0.721453  [   60/   89]
per-ex loss: 0.868661  [   62/   89]
per-ex loss: 0.738756  [   64/   89]
per-ex loss: 0.919839  [   66/   89]
per-ex loss: 0.800794  [   68/   89]
per-ex loss: 0.850764  [   70/   89]
per-ex loss: 0.729248  [   72/   89]
per-ex loss: 0.668556  [   74/   89]
per-ex loss: 0.887641  [   76/   89]
per-ex loss: 0.891243  [   78/   89]
per-ex loss: 0.926530  [   80/   89]
per-ex loss: 0.908917  [   82/   89]
per-ex loss: 0.867685  [   84/   89]
per-ex loss: 0.642170  [   86/   89]
per-ex loss: 0.899300  [   88/   89]
per-ex loss: 0.837800  [   89/   89]
Train Error: Avg loss: 0.82689902
validation Error: 
 Avg loss: 0.88542355 
 F1: 0.364917 
 Precision: 0.837275 
 Recall: 0.233299
 IoU: 0.223180

test Error: 
 Avg loss: 0.87769583 
 F1: 0.366000 
 Precision: 0.847628 
 Recall: 0.233388
 IoU: 0.223990

We have finished training iteration 53
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_51_.pth
per-ex loss: 0.737454  [    2/   89]
per-ex loss: 0.785451  [    4/   89]
per-ex loss: 0.951074  [    6/   89]
per-ex loss: 0.837997  [    8/   89]
per-ex loss: 0.834026  [   10/   89]
per-ex loss: 0.883687  [   12/   89]
per-ex loss: 0.877905  [   14/   89]
per-ex loss: 0.663239  [   16/   89]
per-ex loss: 0.847001  [   18/   89]
per-ex loss: 0.824328  [   20/   89]
per-ex loss: 0.708257  [   22/   89]
per-ex loss: 0.634135  [   24/   89]
per-ex loss: 0.876605  [   26/   89]
per-ex loss: 0.786915  [   28/   89]
per-ex loss: 0.879753  [   30/   89]
per-ex loss: 0.820222  [   32/   89]
per-ex loss: 0.908273  [   34/   89]
per-ex loss: 0.833691  [   36/   89]
per-ex loss: 0.832963  [   38/   89]
per-ex loss: 0.796800  [   40/   89]
per-ex loss: 0.867280  [   42/   89]
per-ex loss: 0.774706  [   44/   89]
per-ex loss: 0.849551  [   46/   89]
per-ex loss: 0.909415  [   48/   89]
per-ex loss: 0.802962  [   50/   89]
per-ex loss: 0.874191  [   52/   89]
per-ex loss: 0.934684  [   54/   89]
per-ex loss: 0.917584  [   56/   89]
per-ex loss: 0.874037  [   58/   89]
per-ex loss: 0.747074  [   60/   89]
per-ex loss: 0.732208  [   62/   89]
per-ex loss: 0.782717  [   64/   89]
per-ex loss: 0.753893  [   66/   89]
per-ex loss: 0.839894  [   68/   89]
per-ex loss: 0.847554  [   70/   89]
per-ex loss: 0.829794  [   72/   89]
per-ex loss: 0.835670  [   74/   89]
per-ex loss: 0.814064  [   76/   89]
per-ex loss: 0.811038  [   78/   89]
per-ex loss: 0.624085  [   80/   89]
per-ex loss: 0.897203  [   82/   89]
per-ex loss: 0.912026  [   84/   89]
per-ex loss: 0.808031  [   86/   89]
per-ex loss: 0.812043  [   88/   89]
per-ex loss: 0.921334  [   89/   89]
Train Error: Avg loss: 0.82428473
validation Error: 
 Avg loss: 0.88350224 
 F1: 0.377919 
 Precision: 0.820169 
 Recall: 0.245527
 IoU: 0.232984

test Error: 
 Avg loss: 0.87761917 
 F1: 0.384551 
 Precision: 0.823774 
 Recall: 0.250819
 IoU: 0.238046

We have finished training iteration 54
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_52_.pth
per-ex loss: 0.905165  [    2/   89]
per-ex loss: 0.830864  [    4/   89]
per-ex loss: 0.913365  [    6/   89]
per-ex loss: 0.890955  [    8/   89]
per-ex loss: 0.940068  [   10/   89]
per-ex loss: 0.825737  [   12/   89]
per-ex loss: 0.807312  [   14/   89]
per-ex loss: 0.654500  [   16/   89]
per-ex loss: 0.643432  [   18/   89]
per-ex loss: 0.759045  [   20/   89]
per-ex loss: 0.818992  [   22/   89]
per-ex loss: 0.923270  [   24/   89]
per-ex loss: 0.812254  [   26/   89]
per-ex loss: 0.816736  [   28/   89]
per-ex loss: 0.881209  [   30/   89]
per-ex loss: 0.793984  [   32/   89]
per-ex loss: 0.655013  [   34/   89]
per-ex loss: 0.788702  [   36/   89]
per-ex loss: 0.907315  [   38/   89]
per-ex loss: 0.890263  [   40/   89]
per-ex loss: 0.667336  [   42/   89]
per-ex loss: 0.811770  [   44/   89]
per-ex loss: 0.756405  [   46/   89]
per-ex loss: 0.803801  [   48/   89]
per-ex loss: 0.848308  [   50/   89]
per-ex loss: 0.898888  [   52/   89]
per-ex loss: 0.848184  [   54/   89]
per-ex loss: 0.808208  [   56/   89]
per-ex loss: 0.849772  [   58/   89]
per-ex loss: 0.842886  [   60/   89]
per-ex loss: 0.895015  [   62/   89]
per-ex loss: 0.815520  [   64/   89]
per-ex loss: 0.860850  [   66/   89]
per-ex loss: 0.896104  [   68/   89]
per-ex loss: 0.901143  [   70/   89]
per-ex loss: 0.844325  [   72/   89]
per-ex loss: 0.797986  [   74/   89]
per-ex loss: 0.906242  [   76/   89]
per-ex loss: 0.808412  [   78/   89]
per-ex loss: 0.800403  [   80/   89]
per-ex loss: 0.862539  [   82/   89]
per-ex loss: 0.741510  [   84/   89]
per-ex loss: 0.851999  [   86/   89]
per-ex loss: 0.827605  [   88/   89]
per-ex loss: 0.814840  [   89/   89]
Train Error: Avg loss: 0.82707184
validation Error: 
 Avg loss: 0.88341364 
 F1: 0.375234 
 Precision: 0.828349 
 Recall: 0.242555
 IoU: 0.230947

test Error: 
 Avg loss: 0.87624620 
 F1: 0.373044 
 Precision: 0.830564 
 Recall: 0.240541
 IoU: 0.229290

We have finished training iteration 55
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_53_.pth
per-ex loss: 0.823329  [    2/   89]
per-ex loss: 0.926944  [    4/   89]
per-ex loss: 0.842311  [    6/   89]
per-ex loss: 0.749555  [    8/   89]
per-ex loss: 0.752576  [   10/   89]
per-ex loss: 0.804353  [   12/   89]
per-ex loss: 0.851599  [   14/   89]
per-ex loss: 0.866848  [   16/   89]
per-ex loss: 0.831129  [   18/   89]
per-ex loss: 0.680572  [   20/   89]
per-ex loss: 0.947532  [   22/   89]
per-ex loss: 0.714447  [   24/   89]
per-ex loss: 0.904923  [   26/   89]
per-ex loss: 0.757468  [   28/   89]
per-ex loss: 0.858931  [   30/   89]
per-ex loss: 0.892387  [   32/   89]
per-ex loss: 0.898263  [   34/   89]
per-ex loss: 0.784972  [   36/   89]
per-ex loss: 0.739935  [   38/   89]
per-ex loss: 0.720540  [   40/   89]
per-ex loss: 0.892867  [   42/   89]
per-ex loss: 0.911450  [   44/   89]
per-ex loss: 0.895604  [   46/   89]
per-ex loss: 0.817763  [   48/   89]
per-ex loss: 0.952221  [   50/   89]
per-ex loss: 0.900817  [   52/   89]
per-ex loss: 0.916978  [   54/   89]
per-ex loss: 0.741337  [   56/   89]
per-ex loss: 0.772483  [   58/   89]
per-ex loss: 0.707957  [   60/   89]
per-ex loss: 0.832508  [   62/   89]
per-ex loss: 0.900349  [   64/   89]
per-ex loss: 0.763141  [   66/   89]
per-ex loss: 0.787956  [   68/   89]
per-ex loss: 0.871612  [   70/   89]
per-ex loss: 0.741768  [   72/   89]
per-ex loss: 0.907706  [   74/   89]
per-ex loss: 0.760141  [   76/   89]
per-ex loss: 0.719955  [   78/   89]
per-ex loss: 0.774420  [   80/   89]
per-ex loss: 0.795536  [   82/   89]
per-ex loss: 0.864823  [   84/   89]
per-ex loss: 0.635713  [   86/   89]
per-ex loss: 0.918025  [   88/   89]
per-ex loss: 0.860328  [   89/   89]
Train Error: Avg loss: 0.82204598
validation Error: 
 Avg loss: 0.87974221 
 F1: 0.346854 
 Precision: 0.858081 
 Recall: 0.217357
 IoU: 0.209814

test Error: 
 Avg loss: 0.87309959 
 F1: 0.347232 
 Precision: 0.854400 
 Recall: 0.217892
 IoU: 0.210091

We have finished training iteration 56
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_54_.pth
per-ex loss: 0.843270  [    2/   89]
per-ex loss: 0.677626  [    4/   89]
per-ex loss: 0.841569  [    6/   89]
per-ex loss: 0.892409  [    8/   89]
per-ex loss: 0.812329  [   10/   89]
per-ex loss: 0.848875  [   12/   89]
per-ex loss: 0.842348  [   14/   89]
per-ex loss: 0.821479  [   16/   89]
per-ex loss: 0.813514  [   18/   89]
per-ex loss: 0.801802  [   20/   89]
per-ex loss: 0.722006  [   22/   89]
per-ex loss: 0.902920  [   24/   89]
per-ex loss: 0.817028  [   26/   89]
per-ex loss: 0.772070  [   28/   89]
per-ex loss: 0.835624  [   30/   89]
per-ex loss: 0.725541  [   32/   89]
per-ex loss: 0.695594  [   34/   89]
per-ex loss: 0.787177  [   36/   89]
per-ex loss: 0.822863  [   38/   89]
per-ex loss: 0.824802  [   40/   89]
per-ex loss: 0.858800  [   42/   89]
per-ex loss: 0.919091  [   44/   89]
per-ex loss: 0.915654  [   46/   89]
per-ex loss: 0.873042  [   48/   89]
per-ex loss: 0.839583  [   50/   89]
per-ex loss: 0.781000  [   52/   89]
per-ex loss: 0.852574  [   54/   89]
per-ex loss: 0.915747  [   56/   89]
per-ex loss: 0.765054  [   58/   89]
per-ex loss: 0.837613  [   60/   89]
per-ex loss: 0.909787  [   62/   89]
per-ex loss: 0.805479  [   64/   89]
per-ex loss: 0.759190  [   66/   89]
per-ex loss: 0.848564  [   68/   89]
per-ex loss: 0.793116  [   70/   89]
per-ex loss: 0.679040  [   72/   89]
per-ex loss: 0.671593  [   74/   89]
per-ex loss: 0.834004  [   76/   89]
per-ex loss: 0.939224  [   78/   89]
per-ex loss: 0.893683  [   80/   89]
per-ex loss: 0.937299  [   82/   89]
per-ex loss: 0.804125  [   84/   89]
per-ex loss: 0.724550  [   86/   89]
per-ex loss: 0.686151  [   88/   89]
per-ex loss: 0.715635  [   89/   89]
Train Error: Avg loss: 0.81467652
validation Error: 
 Avg loss: 0.87562815 
 F1: 0.351113 
 Precision: 0.860107 
 Recall: 0.220579
 IoU: 0.212940

test Error: 
 Avg loss: 0.87060266 
 F1: 0.343036 
 Precision: 0.870922 
 Recall: 0.213580
 IoU: 0.207027

We have finished training iteration 57
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_55_.pth
per-ex loss: 0.792629  [    2/   89]
per-ex loss: 0.920904  [    4/   89]
per-ex loss: 0.835645  [    6/   89]
per-ex loss: 0.739070  [    8/   89]
per-ex loss: 0.893324  [   10/   89]
per-ex loss: 0.789653  [   12/   89]
per-ex loss: 0.722642  [   14/   89]
per-ex loss: 0.875350  [   16/   89]
per-ex loss: 0.831038  [   18/   89]
per-ex loss: 0.858755  [   20/   89]
per-ex loss: 0.817144  [   22/   89]
per-ex loss: 0.747087  [   24/   89]
per-ex loss: 0.794093  [   26/   89]
per-ex loss: 0.909153  [   28/   89]
per-ex loss: 0.815053  [   30/   89]
per-ex loss: 0.804365  [   32/   89]
per-ex loss: 0.794638  [   34/   89]
per-ex loss: 0.920242  [   36/   89]
per-ex loss: 0.908141  [   38/   89]
per-ex loss: 0.678389  [   40/   89]
per-ex loss: 0.812500  [   42/   89]
per-ex loss: 0.847786  [   44/   89]
per-ex loss: 0.833745  [   46/   89]
per-ex loss: 0.903468  [   48/   89]
per-ex loss: 0.851353  [   50/   89]
per-ex loss: 0.813773  [   52/   89]
per-ex loss: 0.940441  [   54/   89]
per-ex loss: 0.912063  [   56/   89]
per-ex loss: 0.914049  [   58/   89]
per-ex loss: 0.828317  [   60/   89]
per-ex loss: 0.795005  [   62/   89]
per-ex loss: 0.851112  [   64/   89]
per-ex loss: 0.885610  [   66/   89]
per-ex loss: 0.902204  [   68/   89]
per-ex loss: 0.851617  [   70/   89]
per-ex loss: 0.746268  [   72/   89]
per-ex loss: 0.648963  [   74/   89]
per-ex loss: 0.728968  [   76/   89]
per-ex loss: 0.856658  [   78/   89]
per-ex loss: 0.866515  [   80/   89]
per-ex loss: 0.664187  [   82/   89]
per-ex loss: 0.628220  [   84/   89]
per-ex loss: 0.736747  [   86/   89]
per-ex loss: 0.858697  [   88/   89]
per-ex loss: 0.739738  [   89/   89]
Train Error: Avg loss: 0.81922931
validation Error: 
 Avg loss: 0.87632203 
 F1: 0.361568 
 Precision: 0.849573 
 Recall: 0.229653
 IoU: 0.220679

test Error: 
 Avg loss: 0.86610637 
 F1: 0.357585 
 Precision: 0.859756 
 Recall: 0.225736
 IoU: 0.217719

We have finished training iteration 58
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_56_.pth
per-ex loss: 0.842811  [    2/   89]
per-ex loss: 0.697526  [    4/   89]
per-ex loss: 0.827497  [    6/   89]
per-ex loss: 0.858863  [    8/   89]
per-ex loss: 0.905945  [   10/   89]
per-ex loss: 0.783133  [   12/   89]
per-ex loss: 0.723925  [   14/   89]
per-ex loss: 0.715676  [   16/   89]
per-ex loss: 0.894994  [   18/   89]
per-ex loss: 0.929467  [   20/   89]
per-ex loss: 0.792896  [   22/   89]
per-ex loss: 0.795574  [   24/   89]
per-ex loss: 0.887959  [   26/   89]
per-ex loss: 0.818768  [   28/   89]
per-ex loss: 0.713995  [   30/   89]
per-ex loss: 0.769437  [   32/   89]
per-ex loss: 0.828138  [   34/   89]
per-ex loss: 0.821219  [   36/   89]
per-ex loss: 0.736545  [   38/   89]
per-ex loss: 0.842570  [   40/   89]
per-ex loss: 0.901085  [   42/   89]
per-ex loss: 0.668251  [   44/   89]
per-ex loss: 0.686417  [   46/   89]
per-ex loss: 0.664495  [   48/   89]
per-ex loss: 0.880366  [   50/   89]
per-ex loss: 0.780293  [   52/   89]
per-ex loss: 0.905936  [   54/   89]
per-ex loss: 0.742010  [   56/   89]
per-ex loss: 0.873615  [   58/   89]
per-ex loss: 0.691167  [   60/   89]
per-ex loss: 0.747587  [   62/   89]
per-ex loss: 0.870731  [   64/   89]
per-ex loss: 0.828676  [   66/   89]
per-ex loss: 0.711670  [   68/   89]
per-ex loss: 0.767812  [   70/   89]
per-ex loss: 0.939561  [   72/   89]
per-ex loss: 0.819295  [   74/   89]
per-ex loss: 0.855423  [   76/   89]
per-ex loss: 0.945959  [   78/   89]
per-ex loss: 0.872726  [   80/   89]
per-ex loss: 0.821441  [   82/   89]
per-ex loss: 0.819070  [   84/   89]
per-ex loss: 0.831785  [   86/   89]
per-ex loss: 0.894748  [   88/   89]
per-ex loss: 0.915438  [   89/   89]
Train Error: Avg loss: 0.81383324
validation Error: 
 Avg loss: 0.87233681 
 F1: 0.367414 
 Precision: 0.845864 
 Recall: 0.234674
 IoU: 0.225050

test Error: 
 Avg loss: 0.86908829 
 F1: 0.369388 
 Precision: 0.846837 
 Recall: 0.236211
 IoU: 0.226533

We have finished training iteration 59
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_57_.pth
per-ex loss: 0.817212  [    2/   89]
per-ex loss: 0.900084  [    4/   89]
per-ex loss: 0.755300  [    6/   89]
per-ex loss: 0.870019  [    8/   89]
per-ex loss: 0.860622  [   10/   89]
per-ex loss: 0.641450  [   12/   89]
per-ex loss: 0.825036  [   14/   89]
per-ex loss: 0.677118  [   16/   89]
per-ex loss: 0.821586  [   18/   89]
per-ex loss: 0.606441  [   20/   89]
per-ex loss: 0.707370  [   22/   89]
per-ex loss: 0.812835  [   24/   89]
per-ex loss: 0.933102  [   26/   89]
per-ex loss: 0.577105  [   28/   89]
per-ex loss: 0.904097  [   30/   89]
per-ex loss: 0.711051  [   32/   89]
per-ex loss: 0.875397  [   34/   89]
per-ex loss: 0.778356  [   36/   89]
per-ex loss: 0.894948  [   38/   89]
per-ex loss: 0.825674  [   40/   89]
per-ex loss: 0.861160  [   42/   89]
per-ex loss: 0.883247  [   44/   89]
per-ex loss: 0.788364  [   46/   89]
per-ex loss: 0.766156  [   48/   89]
per-ex loss: 0.890194  [   50/   89]
per-ex loss: 0.912185  [   52/   89]
per-ex loss: 0.763366  [   54/   89]
per-ex loss: 0.841411  [   56/   89]
per-ex loss: 0.675065  [   58/   89]
per-ex loss: 0.922651  [   60/   89]
per-ex loss: 0.742265  [   62/   89]
per-ex loss: 0.862992  [   64/   89]
per-ex loss: 0.862717  [   66/   89]
per-ex loss: 0.877713  [   68/   89]
per-ex loss: 0.736686  [   70/   89]
per-ex loss: 0.894086  [   72/   89]
per-ex loss: 0.825267  [   74/   89]
per-ex loss: 0.819033  [   76/   89]
per-ex loss: 0.921668  [   78/   89]
per-ex loss: 0.630866  [   80/   89]
per-ex loss: 0.818583  [   82/   89]
per-ex loss: 0.927584  [   84/   89]
per-ex loss: 0.763234  [   86/   89]
per-ex loss: 0.893441  [   88/   89]
per-ex loss: 0.949697  [   89/   89]
Train Error: Avg loss: 0.81387633
validation Error: 
 Avg loss: 0.87372267 
 F1: 0.404773 
 Precision: 0.795354 
 Recall: 0.271463
 IoU: 0.253740

test Error: 
 Avg loss: 0.86712244 
 F1: 0.402626 
 Precision: 0.797978 
 Recall: 0.269235
 IoU: 0.252055

We have finished training iteration 60
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_58_.pth
per-ex loss: 0.780725  [    2/   89]
per-ex loss: 0.925089  [    4/   89]
per-ex loss: 0.837345  [    6/   89]
per-ex loss: 0.865125  [    8/   89]
per-ex loss: 0.779827  [   10/   89]
per-ex loss: 0.721548  [   12/   89]
per-ex loss: 0.755760  [   14/   89]
per-ex loss: 0.696926  [   16/   89]
per-ex loss: 0.854072  [   18/   89]
per-ex loss: 0.842954  [   20/   89]
per-ex loss: 0.791756  [   22/   89]
per-ex loss: 0.823056  [   24/   89]
per-ex loss: 0.877513  [   26/   89]
per-ex loss: 0.810743  [   28/   89]
per-ex loss: 0.727054  [   30/   89]
per-ex loss: 0.843007  [   32/   89]
per-ex loss: 0.892837  [   34/   89]
per-ex loss: 0.796999  [   36/   89]
per-ex loss: 0.932584  [   38/   89]
per-ex loss: 0.813868  [   40/   89]
per-ex loss: 0.719888  [   42/   89]
per-ex loss: 0.917497  [   44/   89]
per-ex loss: 0.798154  [   46/   89]
per-ex loss: 0.694801  [   48/   89]
per-ex loss: 0.891418  [   50/   89]
per-ex loss: 0.766447  [   52/   89]
per-ex loss: 0.865819  [   54/   89]
per-ex loss: 0.805306  [   56/   89]
per-ex loss: 0.816230  [   58/   89]
per-ex loss: 0.910952  [   60/   89]
per-ex loss: 0.764710  [   62/   89]
per-ex loss: 0.874995  [   64/   89]
per-ex loss: 0.873427  [   66/   89]
per-ex loss: 0.868086  [   68/   89]
per-ex loss: 0.890255  [   70/   89]
per-ex loss: 0.793656  [   72/   89]
per-ex loss: 0.824922  [   74/   89]
per-ex loss: 0.660053  [   76/   89]
per-ex loss: 0.796161  [   78/   89]
per-ex loss: 0.907184  [   80/   89]
per-ex loss: 0.803158  [   82/   89]
per-ex loss: 0.905360  [   84/   89]
per-ex loss: 0.948054  [   86/   89]
per-ex loss: 0.786964  [   88/   89]
per-ex loss: 0.602566  [   89/   89]
Train Error: Avg loss: 0.81899669
validation Error: 
 Avg loss: 0.87084383 
 F1: 0.375056 
 Precision: 0.847522 
 Recall: 0.240812
 IoU: 0.230812

test Error: 
 Avg loss: 0.86291709 
 F1: 0.373936 
 Precision: 0.851349 
 Recall: 0.239584
 IoU: 0.229964

We have finished training iteration 61
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_59_.pth
per-ex loss: 0.802210  [    2/   89]
per-ex loss: 0.659751  [    4/   89]
per-ex loss: 0.700153  [    6/   89]
per-ex loss: 0.873381  [    8/   89]
per-ex loss: 0.811694  [   10/   89]
per-ex loss: 0.872477  [   12/   89]
per-ex loss: 0.709608  [   14/   89]
per-ex loss: 0.823527  [   16/   89]
per-ex loss: 0.764728  [   18/   89]
per-ex loss: 0.682191  [   20/   89]
per-ex loss: 0.800680  [   22/   89]
per-ex loss: 0.808686  [   24/   89]
per-ex loss: 0.881628  [   26/   89]
per-ex loss: 0.752889  [   28/   89]
per-ex loss: 0.833635  [   30/   89]
per-ex loss: 0.814987  [   32/   89]
per-ex loss: 0.867866  [   34/   89]
per-ex loss: 0.762203  [   36/   89]
per-ex loss: 0.927670  [   38/   89]
per-ex loss: 0.917069  [   40/   89]
per-ex loss: 0.780733  [   42/   89]
per-ex loss: 0.768821  [   44/   89]
per-ex loss: 0.888387  [   46/   89]
per-ex loss: 0.836449  [   48/   89]
per-ex loss: 0.883252  [   50/   89]
per-ex loss: 0.731629  [   52/   89]
per-ex loss: 0.735144  [   54/   89]
per-ex loss: 0.814164  [   56/   89]
per-ex loss: 0.674783  [   58/   89]
per-ex loss: 0.789476  [   60/   89]
per-ex loss: 0.842058  [   62/   89]
per-ex loss: 0.837161  [   64/   89]
per-ex loss: 0.949500  [   66/   89]
per-ex loss: 0.760258  [   68/   89]
per-ex loss: 0.879999  [   70/   89]
per-ex loss: 0.756927  [   72/   89]
per-ex loss: 0.802940  [   74/   89]
per-ex loss: 0.690239  [   76/   89]
per-ex loss: 0.849085  [   78/   89]
per-ex loss: 0.864348  [   80/   89]
per-ex loss: 0.817862  [   82/   89]
per-ex loss: 0.947531  [   84/   89]
per-ex loss: 0.883188  [   86/   89]
per-ex loss: 0.835626  [   88/   89]
per-ex loss: 0.862575  [   89/   89]
Train Error: Avg loss: 0.81220375
validation Error: 
 Avg loss: 0.86839980 
 F1: 0.403959 
 Precision: 0.799040 
 Recall: 0.270307
 IoU: 0.253100

test Error: 
 Avg loss: 0.86616037 
 F1: 0.400277 
 Precision: 0.812253 
 Recall: 0.265576
 IoU: 0.250216

We have finished training iteration 62
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_60_.pth
per-ex loss: 0.857167  [    2/   89]
per-ex loss: 0.966974  [    4/   89]
per-ex loss: 0.709366  [    6/   89]
per-ex loss: 0.917114  [    8/   89]
per-ex loss: 0.930126  [   10/   89]
per-ex loss: 0.910677  [   12/   89]
per-ex loss: 0.783997  [   14/   89]
per-ex loss: 0.861731  [   16/   89]
per-ex loss: 0.887386  [   18/   89]
per-ex loss: 0.853296  [   20/   89]
per-ex loss: 0.882754  [   22/   89]
per-ex loss: 0.870232  [   24/   89]
per-ex loss: 0.821836  [   26/   89]
per-ex loss: 0.799979  [   28/   89]
per-ex loss: 0.692353  [   30/   89]
per-ex loss: 0.724517  [   32/   89]
per-ex loss: 0.797191  [   34/   89]
per-ex loss: 0.895721  [   36/   89]
per-ex loss: 0.750455  [   38/   89]
per-ex loss: 0.716355  [   40/   89]
per-ex loss: 0.757229  [   42/   89]
per-ex loss: 0.849512  [   44/   89]
per-ex loss: 0.858747  [   46/   89]
per-ex loss: 0.741173  [   48/   89]
per-ex loss: 0.810190  [   50/   89]
per-ex loss: 0.701113  [   52/   89]
per-ex loss: 0.751691  [   54/   89]
per-ex loss: 0.714188  [   56/   89]
per-ex loss: 0.905802  [   58/   89]
per-ex loss: 0.762221  [   60/   89]
per-ex loss: 0.849509  [   62/   89]
per-ex loss: 0.728639  [   64/   89]
per-ex loss: 0.822520  [   66/   89]
per-ex loss: 0.899354  [   68/   89]
per-ex loss: 0.836534  [   70/   89]
per-ex loss: 0.853178  [   72/   89]
per-ex loss: 0.734775  [   74/   89]
per-ex loss: 0.831140  [   76/   89]
per-ex loss: 0.841331  [   78/   89]
per-ex loss: 0.863510  [   80/   89]
per-ex loss: 0.703790  [   82/   89]
per-ex loss: 0.928264  [   84/   89]
per-ex loss: 0.798988  [   86/   89]
per-ex loss: 0.703180  [   88/   89]
per-ex loss: 0.560037  [   89/   89]
Train Error: Avg loss: 0.80968543
validation Error: 
 Avg loss: 0.86846333 
 F1: 0.383158 
 Precision: 0.834672 
 Recall: 0.248651
 IoU: 0.236979

test Error: 
 Avg loss: 0.85994001 
 F1: 0.378910 
 Precision: 0.846998 
 Recall: 0.244042
 IoU: 0.233738

We have finished training iteration 63
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_61_.pth
per-ex loss: 0.774555  [    2/   89]
per-ex loss: 0.803859  [    4/   89]
per-ex loss: 0.854121  [    6/   89]
per-ex loss: 0.931828  [    8/   89]
per-ex loss: 0.860121  [   10/   89]
per-ex loss: 0.749395  [   12/   89]
per-ex loss: 0.822243  [   14/   89]
per-ex loss: 0.804870  [   16/   89]
per-ex loss: 0.712805  [   18/   89]
per-ex loss: 0.770793  [   20/   89]
per-ex loss: 0.808408  [   22/   89]
per-ex loss: 0.829529  [   24/   89]
per-ex loss: 0.708565  [   26/   89]
per-ex loss: 0.889474  [   28/   89]
per-ex loss: 0.901888  [   30/   89]
per-ex loss: 0.784983  [   32/   89]
per-ex loss: 0.770606  [   34/   89]
per-ex loss: 0.658900  [   36/   89]
per-ex loss: 0.929114  [   38/   89]
per-ex loss: 0.777622  [   40/   89]
per-ex loss: 0.787662  [   42/   89]
per-ex loss: 0.674477  [   44/   89]
per-ex loss: 0.800707  [   46/   89]
per-ex loss: 0.760574  [   48/   89]
per-ex loss: 0.828898  [   50/   89]
per-ex loss: 0.758628  [   52/   89]
per-ex loss: 0.855122  [   54/   89]
per-ex loss: 0.850119  [   56/   89]
per-ex loss: 0.848300  [   58/   89]
per-ex loss: 0.861408  [   60/   89]
per-ex loss: 0.681262  [   62/   89]
per-ex loss: 0.946695  [   64/   89]
per-ex loss: 0.906471  [   66/   89]
per-ex loss: 0.856898  [   68/   89]
per-ex loss: 0.933413  [   70/   89]
per-ex loss: 0.789422  [   72/   89]
per-ex loss: 0.735612  [   74/   89]
per-ex loss: 0.765258  [   76/   89]
per-ex loss: 0.857862  [   78/   89]
per-ex loss: 0.599204  [   80/   89]
per-ex loss: 0.904790  [   82/   89]
per-ex loss: 0.823335  [   84/   89]
per-ex loss: 0.878644  [   86/   89]
per-ex loss: 0.922950  [   88/   89]
per-ex loss: 0.771118  [   89/   89]
Train Error: Avg loss: 0.81205573
validation Error: 
 Avg loss: 0.86522871 
 F1: 0.418952 
 Precision: 0.776797 
 Recall: 0.286823
 IoU: 0.264984

test Error: 
 Avg loss: 0.86017430 
 F1: 0.419695 
 Precision: 0.780306 
 Recall: 0.287041
 IoU: 0.265578

We have finished training iteration 64
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_62_.pth
per-ex loss: 0.937109  [    2/   89]
per-ex loss: 0.747821  [    4/   89]
per-ex loss: 0.748766  [    6/   89]
per-ex loss: 0.908751  [    8/   89]
per-ex loss: 0.829368  [   10/   89]
per-ex loss: 0.756200  [   12/   89]
per-ex loss: 0.828107  [   14/   89]
per-ex loss: 0.705124  [   16/   89]
per-ex loss: 0.809110  [   18/   89]
per-ex loss: 0.725399  [   20/   89]
per-ex loss: 0.738510  [   22/   89]
per-ex loss: 0.881084  [   24/   89]
per-ex loss: 0.854382  [   26/   89]
per-ex loss: 0.823761  [   28/   89]
per-ex loss: 0.853126  [   30/   89]
per-ex loss: 0.901844  [   32/   89]
per-ex loss: 0.846222  [   34/   89]
per-ex loss: 0.660583  [   36/   89]
per-ex loss: 0.837483  [   38/   89]
per-ex loss: 0.831753  [   40/   89]
per-ex loss: 0.633579  [   42/   89]
per-ex loss: 0.854848  [   44/   89]
per-ex loss: 0.853149  [   46/   89]
per-ex loss: 0.973170  [   48/   89]
per-ex loss: 0.869590  [   50/   89]
per-ex loss: 0.738033  [   52/   89]
per-ex loss: 0.884248  [   54/   89]
per-ex loss: 0.844853  [   56/   89]
per-ex loss: 0.862816  [   58/   89]
per-ex loss: 0.759140  [   60/   89]
per-ex loss: 0.955249  [   62/   89]
per-ex loss: 0.747808  [   64/   89]
per-ex loss: 0.650048  [   66/   89]
per-ex loss: 0.803077  [   68/   89]
per-ex loss: 0.682953  [   70/   89]
per-ex loss: 0.732049  [   72/   89]
per-ex loss: 0.752348  [   74/   89]
per-ex loss: 0.930338  [   76/   89]
per-ex loss: 0.830114  [   78/   89]
per-ex loss: 0.797137  [   80/   89]
per-ex loss: 0.760702  [   82/   89]
per-ex loss: 0.911263  [   84/   89]
per-ex loss: 0.779148  [   86/   89]
per-ex loss: 0.840395  [   88/   89]
per-ex loss: 0.762564  [   89/   89]
Train Error: Avg loss: 0.80962498
validation Error: 
 Avg loss: 0.86773964 
 F1: 0.364399 
 Precision: 0.851029 
 Recall: 0.231833
 IoU: 0.222792

test Error: 
 Avg loss: 0.85977378 
 F1: 0.357617 
 Precision: 0.861072 
 Recall: 0.225671
 IoU: 0.217743

We have finished training iteration 65
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_63_.pth
Error in cropping the image to the non-zero values in the fourth channel. Returned the original image.
per-ex loss: 0.862351  [    2/   89]
per-ex loss: 0.906925  [    4/   89]
per-ex loss: 0.802235  [    6/   89]
per-ex loss: 0.696443  [    8/   89]
per-ex loss: 0.806265  [   10/   89]
per-ex loss: 0.880330  [   12/   89]
per-ex loss: 0.839317  [   14/   89]
per-ex loss: 0.898186  [   16/   89]
per-ex loss: 0.868178  [   18/   89]
per-ex loss: 0.918816  [   20/   89]
per-ex loss: 0.836172  [   22/   89]
per-ex loss: 0.853869  [   24/   89]
per-ex loss: 0.750765  [   26/   89]
per-ex loss: 0.788903  [   28/   89]
per-ex loss: 0.663601  [   30/   89]
per-ex loss: 0.817396  [   32/   89]
per-ex loss: 0.800750  [   34/   89]
per-ex loss: 0.743212  [   36/   89]
per-ex loss: 0.807329  [   38/   89]
per-ex loss: 0.797491  [   40/   89]
per-ex loss: 0.692203  [   42/   89]
per-ex loss: 0.887775  [   44/   89]
per-ex loss: 0.776591  [   46/   89]
per-ex loss: 0.784299  [   48/   89]
per-ex loss: 0.888739  [   50/   89]
per-ex loss: 0.860172  [   52/   89]
per-ex loss: 0.607555  [   54/   89]
per-ex loss: 0.870000  [   56/   89]
per-ex loss: 0.903626  [   58/   89]
per-ex loss: 0.881963  [   60/   89]
per-ex loss: 0.823392  [   62/   89]
per-ex loss: 0.890235  [   64/   89]
per-ex loss: 0.673513  [   66/   89]
per-ex loss: 0.624619  [   68/   89]
per-ex loss: 0.879150  [   70/   89]
per-ex loss: 0.715225  [   72/   89]
per-ex loss: 0.881969  [   74/   89]
per-ex loss: 0.639009  [   76/   89]
per-ex loss: 0.831147  [   78/   89]
per-ex loss: 0.962159  [   80/   89]
per-ex loss: 0.766445  [   82/   89]
per-ex loss: 0.709125  [   84/   89]
per-ex loss: 0.742399  [   86/   89]
per-ex loss: 0.786374  [   88/   89]
per-ex loss: 0.726940  [   89/   89]
Train Error: Avg loss: 0.80318134
validation Error: 
 Avg loss: 0.86207855 
 F1: 0.378642 
 Precision: 0.811625 
 Recall: 0.246917
 IoU: 0.233534

test Error: 
 Avg loss: 0.85130500 
 F1: 0.391196 
 Precision: 0.820447 
 Recall: 0.256827
 IoU: 0.243160

We have finished training iteration 66
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_64_.pth
per-ex loss: 0.879855  [    2/   89]
per-ex loss: 0.839193  [    4/   89]
per-ex loss: 0.847534  [    6/   89]
per-ex loss: 0.927651  [    8/   89]
per-ex loss: 0.821923  [   10/   89]
per-ex loss: 0.599663  [   12/   89]
per-ex loss: 0.861681  [   14/   89]
per-ex loss: 0.801946  [   16/   89]
per-ex loss: 0.611671  [   18/   89]
per-ex loss: 0.814767  [   20/   89]
per-ex loss: 0.736142  [   22/   89]
per-ex loss: 0.842155  [   24/   89]
per-ex loss: 0.837614  [   26/   89]
per-ex loss: 0.740045  [   28/   89]
per-ex loss: 0.925008  [   30/   89]
per-ex loss: 0.816981  [   32/   89]
per-ex loss: 0.924438  [   34/   89]
per-ex loss: 0.913238  [   36/   89]
per-ex loss: 0.867178  [   38/   89]
per-ex loss: 0.854308  [   40/   89]
per-ex loss: 0.700763  [   42/   89]
per-ex loss: 0.794463  [   44/   89]
per-ex loss: 0.837772  [   46/   89]
per-ex loss: 0.754364  [   48/   89]
per-ex loss: 0.771250  [   50/   89]
per-ex loss: 0.778070  [   52/   89]
per-ex loss: 0.833957  [   54/   89]
per-ex loss: 0.920171  [   56/   89]
per-ex loss: 0.856155  [   58/   89]
per-ex loss: 0.701084  [   60/   89]
per-ex loss: 0.924329  [   62/   89]
per-ex loss: 0.693795  [   64/   89]
per-ex loss: 0.782891  [   66/   89]
per-ex loss: 0.920617  [   68/   89]
per-ex loss: 0.866122  [   70/   89]
per-ex loss: 0.877317  [   72/   89]
per-ex loss: 0.742133  [   74/   89]
per-ex loss: 0.748404  [   76/   89]
per-ex loss: 0.873036  [   78/   89]
per-ex loss: 0.724969  [   80/   89]
per-ex loss: 0.860342  [   82/   89]
per-ex loss: 0.804296  [   84/   89]
per-ex loss: 0.758944  [   86/   89]
per-ex loss: 0.862067  [   88/   89]
per-ex loss: 0.714882  [   89/   89]
Train Error: Avg loss: 0.81255968
validation Error: 
 Avg loss: 0.86157358 
 F1: 0.383503 
 Precision: 0.837862 
 Recall: 0.248659
 IoU: 0.237243

test Error: 
 Avg loss: 0.85718281 
 F1: 0.385617 
 Precision: 0.816394 
 Recall: 0.252424
 IoU: 0.238864

We have finished training iteration 67
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_65_.pth
Error in cropping the image to the non-zero values in the fourth channel. Returned the original image.
per-ex loss: 0.794033  [    2/   89]
per-ex loss: 0.586462  [    4/   89]
per-ex loss: 0.835079  [    6/   89]
per-ex loss: 0.632451  [    8/   89]
per-ex loss: 0.873408  [   10/   89]
per-ex loss: 0.810024  [   12/   89]
per-ex loss: 0.810400  [   14/   89]
per-ex loss: 0.835572  [   16/   89]
per-ex loss: 0.781521  [   18/   89]
per-ex loss: 0.846524  [   20/   89]
per-ex loss: 0.728533  [   22/   89]
per-ex loss: 0.816002  [   24/   89]
per-ex loss: 0.861026  [   26/   89]
per-ex loss: 0.840666  [   28/   89]
per-ex loss: 0.720598  [   30/   89]
per-ex loss: 0.824428  [   32/   89]
per-ex loss: 0.827322  [   34/   89]
per-ex loss: 0.680160  [   36/   89]
per-ex loss: 0.834958  [   38/   89]
per-ex loss: 0.805532  [   40/   89]
per-ex loss: 0.705620  [   42/   89]
per-ex loss: 0.697948  [   44/   89]
per-ex loss: 0.803917  [   46/   89]
per-ex loss: 0.768755  [   48/   89]
per-ex loss: 0.871708  [   50/   89]
per-ex loss: 0.892839  [   52/   89]
per-ex loss: 0.556476  [   54/   89]
per-ex loss: 0.880141  [   56/   89]
per-ex loss: 0.949846  [   58/   89]
per-ex loss: 0.778261  [   60/   89]
per-ex loss: 0.632735  [   62/   89]
per-ex loss: 0.823162  [   64/   89]
per-ex loss: 0.717036  [   66/   89]
per-ex loss: 0.794122  [   68/   89]
per-ex loss: 0.870705  [   70/   89]
per-ex loss: 0.798071  [   72/   89]
per-ex loss: 0.752288  [   74/   89]
per-ex loss: 0.769624  [   76/   89]
per-ex loss: 0.919481  [   78/   89]
per-ex loss: 0.756027  [   80/   89]
per-ex loss: 0.849436  [   82/   89]
per-ex loss: 0.829749  [   84/   89]
per-ex loss: 0.860753  [   86/   89]
per-ex loss: 0.725832  [   88/   89]
per-ex loss: 0.742567  [   89/   89]
Train Error: Avg loss: 0.78870667
validation Error: 
 Avg loss: 0.86792342 
 F1: 0.407035 
 Precision: 0.778025 
 Recall: 0.275613
 IoU: 0.255521

test Error: 
 Avg loss: 0.85655941 
 F1: 0.405429 
 Precision: 0.766792 
 Recall: 0.275565
 IoU: 0.254256

We have finished training iteration 68
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_66_.pth
per-ex loss: 0.720791  [    2/   89]
per-ex loss: 0.748902  [    4/   89]
per-ex loss: 0.719546  [    6/   89]
per-ex loss: 0.892511  [    8/   89]
per-ex loss: 0.711761  [   10/   89]
per-ex loss: 0.780202  [   12/   89]
per-ex loss: 0.663940  [   14/   89]
per-ex loss: 0.772340  [   16/   89]
per-ex loss: 0.873736  [   18/   89]
per-ex loss: 0.874980  [   20/   89]
per-ex loss: 0.720376  [   22/   89]
per-ex loss: 0.658582  [   24/   89]
per-ex loss: 0.773422  [   26/   89]
per-ex loss: 0.809818  [   28/   89]
per-ex loss: 0.787628  [   30/   89]
per-ex loss: 0.713960  [   32/   89]
per-ex loss: 0.790823  [   34/   89]
per-ex loss: 0.870477  [   36/   89]
per-ex loss: 0.900038  [   38/   89]
per-ex loss: 0.826764  [   40/   89]
per-ex loss: 0.859892  [   42/   89]
per-ex loss: 0.889240  [   44/   89]
per-ex loss: 0.739552  [   46/   89]
per-ex loss: 0.813026  [   48/   89]
per-ex loss: 0.683090  [   50/   89]
per-ex loss: 0.758447  [   52/   89]
per-ex loss: 0.905867  [   54/   89]
per-ex loss: 0.796709  [   56/   89]
per-ex loss: 0.792153  [   58/   89]
per-ex loss: 0.844222  [   60/   89]
per-ex loss: 0.818914  [   62/   89]
per-ex loss: 0.910383  [   64/   89]
per-ex loss: 0.766756  [   66/   89]
per-ex loss: 0.583303  [   68/   89]
per-ex loss: 0.749458  [   70/   89]
per-ex loss: 0.887296  [   72/   89]
per-ex loss: 0.931469  [   74/   89]
per-ex loss: 0.741374  [   76/   89]
per-ex loss: 0.673010  [   78/   89]
per-ex loss: 0.862188  [   80/   89]
per-ex loss: 0.699160  [   82/   89]
per-ex loss: 0.750915  [   84/   89]
per-ex loss: 0.800026  [   86/   89]
per-ex loss: 0.830745  [   88/   89]
per-ex loss: 0.917772  [   89/   89]
Train Error: Avg loss: 0.79145701
validation Error: 
 Avg loss: 0.85986102 
 F1: 0.418661 
 Precision: 0.786795 
 Recall: 0.285212
 IoU: 0.264751

test Error: 
 Avg loss: 0.84808290 
 F1: 0.431236 
 Precision: 0.780337 
 Recall: 0.297944
 IoU: 0.274889

We have finished training iteration 69
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_67_.pth
per-ex loss: 0.793791  [    2/   89]
per-ex loss: 0.730573  [    4/   89]
per-ex loss: 0.849470  [    6/   89]
per-ex loss: 0.825399  [    8/   89]
per-ex loss: 0.781790  [   10/   89]
per-ex loss: 0.793723  [   12/   89]
per-ex loss: 0.889626  [   14/   89]
per-ex loss: 0.726344  [   16/   89]
per-ex loss: 0.816738  [   18/   89]
per-ex loss: 0.830237  [   20/   89]
per-ex loss: 0.778965  [   22/   89]
per-ex loss: 0.904465  [   24/   89]
per-ex loss: 0.920897  [   26/   89]
per-ex loss: 0.847391  [   28/   89]
per-ex loss: 0.864289  [   30/   89]
per-ex loss: 0.923034  [   32/   89]
per-ex loss: 0.757294  [   34/   89]
per-ex loss: 0.797768  [   36/   89]
per-ex loss: 0.860909  [   38/   89]
per-ex loss: 0.812863  [   40/   89]
per-ex loss: 0.783573  [   42/   89]
per-ex loss: 0.861041  [   44/   89]
per-ex loss: 0.705025  [   46/   89]
per-ex loss: 0.800827  [   48/   89]
per-ex loss: 0.765730  [   50/   89]
per-ex loss: 0.860666  [   52/   89]
per-ex loss: 0.636361  [   54/   89]
per-ex loss: 0.644316  [   56/   89]
per-ex loss: 0.711977  [   58/   89]
per-ex loss: 0.709367  [   60/   89]
per-ex loss: 0.872616  [   62/   89]
per-ex loss: 0.795227  [   64/   89]
per-ex loss: 0.880629  [   66/   89]
per-ex loss: 0.751707  [   68/   89]
per-ex loss: 0.610607  [   70/   89]
per-ex loss: 0.896632  [   72/   89]
per-ex loss: 0.797543  [   74/   89]
per-ex loss: 0.850801  [   76/   89]
per-ex loss: 0.841996  [   78/   89]
per-ex loss: 0.758630  [   80/   89]
per-ex loss: 0.811699  [   82/   89]
per-ex loss: 0.854783  [   84/   89]
per-ex loss: 0.760576  [   86/   89]
per-ex loss: 0.783123  [   88/   89]
per-ex loss: 0.865831  [   89/   89]
Train Error: Avg loss: 0.80259663
validation Error: 
 Avg loss: 0.85952148 
 F1: 0.443529 
 Precision: 0.747214 
 Recall: 0.315359
 IoU: 0.284958

test Error: 
 Avg loss: 0.84956076 
 F1: 0.456257 
 Precision: 0.754375 
 Recall: 0.327022
 IoU: 0.295552

We have finished training iteration 70
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_68_.pth
per-ex loss: 0.703137  [    2/   89]
per-ex loss: 0.692253  [    4/   89]
per-ex loss: 0.742652  [    6/   89]
per-ex loss: 0.893973  [    8/   89]
per-ex loss: 0.769510  [   10/   89]
per-ex loss: 0.919314  [   12/   89]
per-ex loss: 0.857365  [   14/   89]
per-ex loss: 0.688698  [   16/   89]
per-ex loss: 0.597869  [   18/   89]
per-ex loss: 0.854573  [   20/   89]
per-ex loss: 0.790824  [   22/   89]
per-ex loss: 0.657703  [   24/   89]
per-ex loss: 0.919000  [   26/   89]
per-ex loss: 0.694258  [   28/   89]
per-ex loss: 0.816192  [   30/   89]
per-ex loss: 0.781196  [   32/   89]
per-ex loss: 0.859085  [   34/   89]
per-ex loss: 0.783509  [   36/   89]
per-ex loss: 0.961726  [   38/   89]
per-ex loss: 0.742531  [   40/   89]
per-ex loss: 0.851764  [   42/   89]
per-ex loss: 0.849269  [   44/   89]
per-ex loss: 0.882100  [   46/   89]
per-ex loss: 0.831734  [   48/   89]
per-ex loss: 0.933644  [   50/   89]
per-ex loss: 0.828669  [   52/   89]
per-ex loss: 0.782507  [   54/   89]
per-ex loss: 0.784047  [   56/   89]
per-ex loss: 0.841568  [   58/   89]
per-ex loss: 0.935247  [   60/   89]
per-ex loss: 0.772484  [   62/   89]
per-ex loss: 0.822534  [   64/   89]
per-ex loss: 0.744974  [   66/   89]
per-ex loss: 0.858089  [   68/   89]
per-ex loss: 0.780891  [   70/   89]
per-ex loss: 0.637417  [   72/   89]
per-ex loss: 0.668955  [   74/   89]
per-ex loss: 0.719164  [   76/   89]
per-ex loss: 0.802721  [   78/   89]
per-ex loss: 0.841235  [   80/   89]
per-ex loss: 0.902067  [   82/   89]
per-ex loss: 0.729276  [   84/   89]
per-ex loss: 0.832445  [   86/   89]
per-ex loss: 0.658437  [   88/   89]
per-ex loss: 0.716201  [   89/   89]
Train Error: Avg loss: 0.79406233
validation Error: 
 Avg loss: 0.85415388 
 F1: 0.422543 
 Precision: 0.736613 
 Recall: 0.296236
 IoU: 0.267863

test Error: 
 Avg loss: 0.85173485 
 F1: 0.427386 
 Precision: 0.729787 
 Recall: 0.302174
 IoU: 0.271768

We have finished training iteration 71
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_69_.pth
per-ex loss: 0.838963  [    2/   89]
per-ex loss: 0.784384  [    4/   89]
per-ex loss: 0.816616  [    6/   89]
per-ex loss: 0.915468  [    8/   89]
per-ex loss: 0.736869  [   10/   89]
per-ex loss: 0.913125  [   12/   89]
per-ex loss: 0.697757  [   14/   89]
per-ex loss: 0.917208  [   16/   89]
per-ex loss: 0.792680  [   18/   89]
per-ex loss: 0.689478  [   20/   89]
per-ex loss: 0.926469  [   22/   89]
per-ex loss: 0.811854  [   24/   89]
per-ex loss: 0.701706  [   26/   89]
per-ex loss: 0.769297  [   28/   89]
per-ex loss: 0.818986  [   30/   89]
per-ex loss: 0.900753  [   32/   89]
per-ex loss: 0.703535  [   34/   89]
per-ex loss: 0.843251  [   36/   89]
per-ex loss: 0.882605  [   38/   89]
per-ex loss: 0.761882  [   40/   89]
per-ex loss: 0.763500  [   42/   89]
per-ex loss: 0.795136  [   44/   89]
per-ex loss: 0.644999  [   46/   89]
per-ex loss: 0.781957  [   48/   89]
per-ex loss: 0.862762  [   50/   89]
per-ex loss: 0.822979  [   52/   89]
per-ex loss: 0.683535  [   54/   89]
per-ex loss: 0.902542  [   56/   89]
per-ex loss: 0.835966  [   58/   89]
per-ex loss: 0.701831  [   60/   89]
per-ex loss: 0.702861  [   62/   89]
per-ex loss: 0.691403  [   64/   89]
per-ex loss: 0.683427  [   66/   89]
per-ex loss: 0.808947  [   68/   89]
per-ex loss: 0.766509  [   70/   89]
per-ex loss: 0.866418  [   72/   89]
per-ex loss: 0.701986  [   74/   89]
per-ex loss: 0.770457  [   76/   89]
per-ex loss: 0.865383  [   78/   89]
per-ex loss: 0.818581  [   80/   89]
per-ex loss: 0.810441  [   82/   89]
per-ex loss: 0.690551  [   84/   89]
per-ex loss: 0.772542  [   86/   89]
per-ex loss: 0.884534  [   88/   89]
per-ex loss: 0.743649  [   89/   89]
Train Error: Avg loss: 0.79101739
validation Error: 
 Avg loss: 0.85172717 
 F1: 0.421366 
 Precision: 0.782725 
 Recall: 0.288277
 IoU: 0.266918

test Error: 
 Avg loss: 0.84459704 
 F1: 0.427870 
 Precision: 0.791704 
 Recall: 0.293150
 IoU: 0.272159

We have finished training iteration 72
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_70_.pth
Error in cropping the image to the non-zero values in the fourth channel. Returned the original image.
per-ex loss: 0.863184  [    2/   89]
per-ex loss: 0.848844  [    4/   89]
per-ex loss: 0.904848  [    6/   89]
per-ex loss: 0.839346  [    8/   89]
per-ex loss: 0.641228  [   10/   89]
per-ex loss: 0.746354  [   12/   89]
per-ex loss: 0.812275  [   14/   89]
per-ex loss: 0.790772  [   16/   89]
per-ex loss: 0.933756  [   18/   89]
per-ex loss: 0.751903  [   20/   89]
per-ex loss: 0.833433  [   22/   89]
per-ex loss: 0.791179  [   24/   89]
per-ex loss: 0.928359  [   26/   89]
per-ex loss: 0.701421  [   28/   89]
per-ex loss: 0.695133  [   30/   89]
per-ex loss: 0.651026  [   32/   89]
per-ex loss: 0.831541  [   34/   89]
per-ex loss: 0.786450  [   36/   89]
per-ex loss: 0.869611  [   38/   89]
per-ex loss: 0.692787  [   40/   89]
per-ex loss: 0.748475  [   42/   89]
per-ex loss: 0.681257  [   44/   89]
per-ex loss: 0.671401  [   46/   89]
per-ex loss: 0.865293  [   48/   89]
per-ex loss: 0.754260  [   50/   89]
per-ex loss: 0.696958  [   52/   89]
per-ex loss: 0.791222  [   54/   89]
per-ex loss: 0.876756  [   56/   89]
per-ex loss: 0.605781  [   58/   89]
per-ex loss: 0.835341  [   60/   89]
per-ex loss: 0.784528  [   62/   89]
per-ex loss: 0.654877  [   64/   89]
per-ex loss: 0.834421  [   66/   89]
per-ex loss: 0.753246  [   68/   89]
per-ex loss: 0.892499  [   70/   89]
per-ex loss: 0.707318  [   72/   89]
per-ex loss: 0.858794  [   74/   89]
per-ex loss: 0.653214  [   76/   89]
per-ex loss: 0.787672  [   78/   89]
per-ex loss: 0.759562  [   80/   89]
per-ex loss: 0.814407  [   82/   89]
per-ex loss: 0.773576  [   84/   89]
per-ex loss: 0.829518  [   86/   89]
per-ex loss: 0.905066  [   88/   89]
per-ex loss: 0.795657  [   89/   89]
Train Error: Avg loss: 0.78321225
validation Error: 
 Avg loss: 0.85342178 
 F1: 0.402431 
 Precision: 0.815699 
 Recall: 0.267104
 IoU: 0.251902

test Error: 
 Avg loss: 0.84492801 
 F1: 0.395600 
 Precision: 0.841017 
 Recall: 0.258627
 IoU: 0.246572

We have finished training iteration 73
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_71_.pth
per-ex loss: 0.877412  [    2/   89]
per-ex loss: 0.727330  [    4/   89]
per-ex loss: 0.878877  [    6/   89]
per-ex loss: 0.893836  [    8/   89]
per-ex loss: 0.740816  [   10/   89]
per-ex loss: 0.867423  [   12/   89]
per-ex loss: 0.859087  [   14/   89]
per-ex loss: 0.727282  [   16/   89]
per-ex loss: 0.726689  [   18/   89]
per-ex loss: 0.896562  [   20/   89]
per-ex loss: 0.881718  [   22/   89]
per-ex loss: 0.799207  [   24/   89]
per-ex loss: 0.772033  [   26/   89]
per-ex loss: 0.734778  [   28/   89]
per-ex loss: 0.829207  [   30/   89]
per-ex loss: 0.723216  [   32/   89]
per-ex loss: 0.613875  [   34/   89]
per-ex loss: 0.665283  [   36/   89]
per-ex loss: 0.744072  [   38/   89]
per-ex loss: 0.919299  [   40/   89]
per-ex loss: 0.886431  [   42/   89]
per-ex loss: 0.804270  [   44/   89]
per-ex loss: 0.669596  [   46/   89]
per-ex loss: 0.694291  [   48/   89]
per-ex loss: 0.871853  [   50/   89]
per-ex loss: 0.864466  [   52/   89]
per-ex loss: 0.682197  [   54/   89]
per-ex loss: 0.774235  [   56/   89]
per-ex loss: 0.721500  [   58/   89]
per-ex loss: 0.741675  [   60/   89]
per-ex loss: 0.822037  [   62/   89]
per-ex loss: 0.724766  [   64/   89]
per-ex loss: 0.880356  [   66/   89]
per-ex loss: 0.859019  [   68/   89]
per-ex loss: 0.607422  [   70/   89]
per-ex loss: 0.828012  [   72/   89]
per-ex loss: 0.720421  [   74/   89]
per-ex loss: 0.805460  [   76/   89]
per-ex loss: 0.749043  [   78/   89]
per-ex loss: 0.823141  [   80/   89]
per-ex loss: 0.751760  [   82/   89]
per-ex loss: 0.567137  [   84/   89]
per-ex loss: 0.867068  [   86/   89]
per-ex loss: 0.620066  [   88/   89]
per-ex loss: 0.663416  [   89/   89]
Train Error: Avg loss: 0.77505865
validation Error: 
 Avg loss: 0.84473514 
 F1: 0.375434 
 Precision: 0.847817 
 Recall: 0.241099
 IoU: 0.231098

test Error: 
 Avg loss: 0.84289858 
 F1: 0.379485 
 Precision: 0.861090 
 Recall: 0.243369
 IoU: 0.234176

We have finished training iteration 74
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_72_.pth
per-ex loss: 0.673302  [    2/   89]
per-ex loss: 0.785662  [    4/   89]
per-ex loss: 0.877900  [    6/   89]
per-ex loss: 0.834866  [    8/   89]
per-ex loss: 0.831788  [   10/   89]
per-ex loss: 0.833075  [   12/   89]
per-ex loss: 0.804565  [   14/   89]
per-ex loss: 0.649699  [   16/   89]
per-ex loss: 0.851285  [   18/   89]
per-ex loss: 0.622354  [   20/   89]
per-ex loss: 0.790365  [   22/   89]
per-ex loss: 0.910006  [   24/   89]
per-ex loss: 0.824963  [   26/   89]
per-ex loss: 0.740584  [   28/   89]
per-ex loss: 0.821875  [   30/   89]
per-ex loss: 0.823273  [   32/   89]
per-ex loss: 0.848812  [   34/   89]
per-ex loss: 0.712768  [   36/   89]
per-ex loss: 0.750181  [   38/   89]
per-ex loss: 0.925081  [   40/   89]
per-ex loss: 0.932478  [   42/   89]
per-ex loss: 0.716337  [   44/   89]
per-ex loss: 0.777241  [   46/   89]
per-ex loss: 0.800313  [   48/   89]
per-ex loss: 0.745966  [   50/   89]
per-ex loss: 0.650338  [   52/   89]
per-ex loss: 0.804881  [   54/   89]
per-ex loss: 0.607079  [   56/   89]
per-ex loss: 0.803888  [   58/   89]
per-ex loss: 0.862689  [   60/   89]
per-ex loss: 0.847553  [   62/   89]
per-ex loss: 0.824557  [   64/   89]
per-ex loss: 0.854712  [   66/   89]
per-ex loss: 0.700344  [   68/   89]
per-ex loss: 0.569795  [   70/   89]
per-ex loss: 0.824840  [   72/   89]
per-ex loss: 0.873134  [   74/   89]
per-ex loss: 0.691280  [   76/   89]
per-ex loss: 0.867114  [   78/   89]
per-ex loss: 0.802425  [   80/   89]
per-ex loss: 0.787955  [   82/   89]
per-ex loss: 0.865297  [   84/   89]
per-ex loss: 0.846269  [   86/   89]
per-ex loss: 0.850060  [   88/   89]
per-ex loss: 0.735066  [   89/   89]
Train Error: Avg loss: 0.79008925
validation Error: 
 Avg loss: 0.84693236 
 F1: 0.412128 
 Precision: 0.811751 
 Recall: 0.276170
 IoU: 0.259547

test Error: 
 Avg loss: 0.84034427 
 F1: 0.413817 
 Precision: 0.823411 
 Recall: 0.276351
 IoU: 0.260889

We have finished training iteration 75
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_73_.pth
per-ex loss: 0.616918  [    2/   89]
per-ex loss: 0.748251  [    4/   89]
per-ex loss: 0.820578  [    6/   89]
per-ex loss: 0.698929  [    8/   89]
per-ex loss: 0.883433  [   10/   89]
per-ex loss: 0.781408  [   12/   89]
per-ex loss: 0.689553  [   14/   89]
per-ex loss: 0.869952  [   16/   89]
per-ex loss: 0.879511  [   18/   89]
per-ex loss: 0.876563  [   20/   89]
per-ex loss: 0.599277  [   22/   89]
per-ex loss: 0.814905  [   24/   89]
per-ex loss: 0.681231  [   26/   89]
per-ex loss: 0.799319  [   28/   89]
per-ex loss: 0.846443  [   30/   89]
per-ex loss: 0.493081  [   32/   89]
per-ex loss: 0.828349  [   34/   89]
per-ex loss: 0.836763  [   36/   89]
per-ex loss: 0.738514  [   38/   89]
per-ex loss: 0.734066  [   40/   89]
per-ex loss: 0.814580  [   42/   89]
per-ex loss: 0.906483  [   44/   89]
per-ex loss: 0.830725  [   46/   89]
per-ex loss: 0.921750  [   48/   89]
per-ex loss: 0.812014  [   50/   89]
per-ex loss: 0.676106  [   52/   89]
per-ex loss: 0.646292  [   54/   89]
per-ex loss: 0.750782  [   56/   89]
per-ex loss: 0.684057  [   58/   89]
per-ex loss: 0.727265  [   60/   89]
per-ex loss: 0.711718  [   62/   89]
per-ex loss: 0.833576  [   64/   89]
per-ex loss: 0.663832  [   66/   89]
per-ex loss: 0.916017  [   68/   89]
per-ex loss: 0.766087  [   70/   89]
per-ex loss: 0.731798  [   72/   89]
per-ex loss: 0.752316  [   74/   89]
per-ex loss: 0.785857  [   76/   89]
per-ex loss: 0.718168  [   78/   89]
per-ex loss: 0.813966  [   80/   89]
per-ex loss: 0.900569  [   82/   89]
per-ex loss: 0.901666  [   84/   89]
per-ex loss: 0.941472  [   86/   89]
per-ex loss: 0.791779  [   88/   89]
per-ex loss: 0.814020  [   89/   89]
Train Error: Avg loss: 0.77888749
validation Error: 
 Avg loss: 0.84472614 
 F1: 0.420721 
 Precision: 0.801274 
 Recall: 0.285247
 IoU: 0.266400

test Error: 
 Avg loss: 0.84030667 
 F1: 0.428606 
 Precision: 0.808860 
 Recall: 0.291547
 IoU: 0.272755

We have finished training iteration 76
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_74_.pth
per-ex loss: 0.657306  [    2/   89]
per-ex loss: 0.832412  [    4/   89]
per-ex loss: 0.640232  [    6/   89]
per-ex loss: 0.883170  [    8/   89]
per-ex loss: 0.735163  [   10/   89]
per-ex loss: 0.855335  [   12/   89]
per-ex loss: 0.865064  [   14/   89]
per-ex loss: 0.759540  [   16/   89]
per-ex loss: 0.614767  [   18/   89]
per-ex loss: 0.696290  [   20/   89]
per-ex loss: 0.945878  [   22/   89]
per-ex loss: 0.894623  [   24/   89]
per-ex loss: 0.816457  [   26/   89]
per-ex loss: 0.789257  [   28/   89]
per-ex loss: 0.807772  [   30/   89]
per-ex loss: 0.872857  [   32/   89]
per-ex loss: 0.716096  [   34/   89]
per-ex loss: 0.709835  [   36/   89]
per-ex loss: 0.779392  [   38/   89]
per-ex loss: 0.725425  [   40/   89]
per-ex loss: 0.585401  [   42/   89]
per-ex loss: 0.768192  [   44/   89]
per-ex loss: 0.617534  [   46/   89]
per-ex loss: 0.829185  [   48/   89]
per-ex loss: 0.876847  [   50/   89]
per-ex loss: 0.923238  [   52/   89]
per-ex loss: 0.598082  [   54/   89]
per-ex loss: 0.723010  [   56/   89]
per-ex loss: 0.868266  [   58/   89]
per-ex loss: 0.786077  [   60/   89]
per-ex loss: 0.777774  [   62/   89]
per-ex loss: 0.645091  [   64/   89]
per-ex loss: 0.730797  [   66/   89]
per-ex loss: 0.773395  [   68/   89]
per-ex loss: 0.710697  [   70/   89]
per-ex loss: 0.871161  [   72/   89]
per-ex loss: 0.893611  [   74/   89]
per-ex loss: 0.878181  [   76/   89]
per-ex loss: 0.879605  [   78/   89]
per-ex loss: 0.744512  [   80/   89]
per-ex loss: 0.766891  [   82/   89]
per-ex loss: 0.761286  [   84/   89]
per-ex loss: 0.599185  [   86/   89]
per-ex loss: 0.744378  [   88/   89]
per-ex loss: 0.674167  [   89/   89]
Train Error: Avg loss: 0.76940964
validation Error: 
 Avg loss: 0.84365800 
 F1: 0.365006 
 Precision: 0.870772 
 Recall: 0.230896
 IoU: 0.223246

test Error: 
 Avg loss: 0.84058780 
 F1: 0.358110 
 Precision: 0.865777 
 Recall: 0.225742
 IoU: 0.218109

We have finished training iteration 77
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_75_.pth
per-ex loss: 0.823179  [    2/   89]
per-ex loss: 0.793417  [    4/   89]
per-ex loss: 0.806786  [    6/   89]
per-ex loss: 0.711194  [    8/   89]
per-ex loss: 0.808129  [   10/   89]
per-ex loss: 0.870557  [   12/   89]
per-ex loss: 0.753420  [   14/   89]
per-ex loss: 0.796590  [   16/   89]
per-ex loss: 0.895627  [   18/   89]
per-ex loss: 0.910726  [   20/   89]
per-ex loss: 0.720403  [   22/   89]
per-ex loss: 0.839684  [   24/   89]
per-ex loss: 0.695506  [   26/   89]
per-ex loss: 0.624024  [   28/   89]
per-ex loss: 0.737015  [   30/   89]
per-ex loss: 0.748940  [   32/   89]
per-ex loss: 0.738879  [   34/   89]
per-ex loss: 0.905900  [   36/   89]
per-ex loss: 0.664516  [   38/   89]
per-ex loss: 0.863244  [   40/   89]
per-ex loss: 0.774817  [   42/   89]
per-ex loss: 0.693948  [   44/   89]
per-ex loss: 0.829329  [   46/   89]
per-ex loss: 0.846850  [   48/   89]
per-ex loss: 0.816600  [   50/   89]
per-ex loss: 0.910948  [   52/   89]
per-ex loss: 0.752890  [   54/   89]
per-ex loss: 0.666828  [   56/   89]
per-ex loss: 0.753452  [   58/   89]
per-ex loss: 0.812733  [   60/   89]
per-ex loss: 0.742597  [   62/   89]
per-ex loss: 0.853049  [   64/   89]
per-ex loss: 0.716375  [   66/   89]
per-ex loss: 0.578817  [   68/   89]
per-ex loss: 0.711276  [   70/   89]
per-ex loss: 0.809441  [   72/   89]
per-ex loss: 0.822954  [   74/   89]
per-ex loss: 0.804192  [   76/   89]
per-ex loss: 0.765482  [   78/   89]
per-ex loss: 0.791023  [   80/   89]
per-ex loss: 0.833862  [   82/   89]
per-ex loss: 0.784213  [   84/   89]
per-ex loss: 0.808571  [   86/   89]
per-ex loss: 0.747557  [   88/   89]
per-ex loss: 0.458244  [   89/   89]
Train Error: Avg loss: 0.77319527
validation Error: 
 Avg loss: 0.84374039 
 F1: 0.425382 
 Precision: 0.789101 
 Recall: 0.291173
 IoU: 0.270150

test Error: 
 Avg loss: 0.83113800 
 F1: 0.429987 
 Precision: 0.816927 
 Recall: 0.291783
 IoU: 0.273875

We have finished training iteration 78
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_76_.pth
per-ex loss: 0.684961  [    2/   89]
per-ex loss: 0.778806  [    4/   89]
per-ex loss: 0.841778  [    6/   89]
per-ex loss: 0.727609  [    8/   89]
per-ex loss: 0.805006  [   10/   89]
per-ex loss: 0.748618  [   12/   89]
per-ex loss: 0.780894  [   14/   89]
per-ex loss: 0.797588  [   16/   89]
per-ex loss: 0.842640  [   18/   89]
per-ex loss: 0.790843  [   20/   89]
per-ex loss: 0.822768  [   22/   89]
per-ex loss: 0.584175  [   24/   89]
per-ex loss: 0.855928  [   26/   89]
per-ex loss: 0.822556  [   28/   89]
per-ex loss: 0.870805  [   30/   89]
per-ex loss: 0.811814  [   32/   89]
per-ex loss: 0.648109  [   34/   89]
per-ex loss: 0.602595  [   36/   89]
per-ex loss: 0.806633  [   38/   89]
per-ex loss: 0.656536  [   40/   89]
per-ex loss: 0.823213  [   42/   89]
per-ex loss: 0.782168  [   44/   89]
per-ex loss: 0.723796  [   46/   89]
per-ex loss: 0.821412  [   48/   89]
per-ex loss: 0.752864  [   50/   89]
per-ex loss: 0.612763  [   52/   89]
per-ex loss: 0.616408  [   54/   89]
per-ex loss: 0.832126  [   56/   89]
per-ex loss: 0.645479  [   58/   89]
per-ex loss: 0.790671  [   60/   89]
per-ex loss: 0.795929  [   62/   89]
per-ex loss: 0.828074  [   64/   89]
per-ex loss: 0.660779  [   66/   89]
per-ex loss: 0.796388  [   68/   89]
per-ex loss: 0.856374  [   70/   89]
per-ex loss: 0.822244  [   72/   89]
per-ex loss: 0.822618  [   74/   89]
per-ex loss: 0.889357  [   76/   89]
per-ex loss: 0.831540  [   78/   89]
per-ex loss: 0.838089  [   80/   89]
per-ex loss: 0.763969  [   82/   89]
per-ex loss: 0.689341  [   84/   89]
per-ex loss: 0.752341  [   86/   89]
per-ex loss: 0.643666  [   88/   89]
per-ex loss: 0.667192  [   89/   89]
Train Error: Avg loss: 0.76309925
validation Error: 
 Avg loss: 0.85055381 
 F1: 0.474676 
 Precision: 0.616431 
 Recall: 0.385928
 IoU: 0.311197

test Error: 
 Avg loss: 0.84426485 
 F1: 0.491383 
 Precision: 0.623593 
 Recall: 0.405427
 IoU: 0.325717

We have finished training iteration 79
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_77_.pth
per-ex loss: 0.821615  [    2/   89]
per-ex loss: 0.594702  [    4/   89]
per-ex loss: 0.783893  [    6/   89]
per-ex loss: 0.703587  [    8/   89]
per-ex loss: 0.842082  [   10/   89]
per-ex loss: 0.834037  [   12/   89]
per-ex loss: 0.683769  [   14/   89]
per-ex loss: 0.727834  [   16/   89]
per-ex loss: 0.731349  [   18/   89]
per-ex loss: 0.768548  [   20/   89]
per-ex loss: 0.754714  [   22/   89]
per-ex loss: 0.705851  [   24/   89]
per-ex loss: 0.820700  [   26/   89]
per-ex loss: 0.748854  [   28/   89]
per-ex loss: 0.830958  [   30/   89]
per-ex loss: 0.680056  [   32/   89]
per-ex loss: 0.807638  [   34/   89]
per-ex loss: 0.773250  [   36/   89]
per-ex loss: 0.907778  [   38/   89]
per-ex loss: 0.891964  [   40/   89]
per-ex loss: 0.700408  [   42/   89]
per-ex loss: 0.845534  [   44/   89]
per-ex loss: 0.634259  [   46/   89]
per-ex loss: 0.721994  [   48/   89]
per-ex loss: 0.588771  [   50/   89]
per-ex loss: 0.665363  [   52/   89]
per-ex loss: 0.706336  [   54/   89]
per-ex loss: 0.838325  [   56/   89]
per-ex loss: 0.909903  [   58/   89]
per-ex loss: 0.820023  [   60/   89]
per-ex loss: 0.855125  [   62/   89]
per-ex loss: 0.876503  [   64/   89]
per-ex loss: 0.903819  [   66/   89]
per-ex loss: 0.794080  [   68/   89]
per-ex loss: 0.797860  [   70/   89]
per-ex loss: 0.626568  [   72/   89]
per-ex loss: 0.724596  [   74/   89]
per-ex loss: 0.872845  [   76/   89]
per-ex loss: 0.815082  [   78/   89]
per-ex loss: 0.570703  [   80/   89]
per-ex loss: 0.846789  [   82/   89]
per-ex loss: 0.823731  [   84/   89]
per-ex loss: 0.770851  [   86/   89]
per-ex loss: 0.696773  [   88/   89]
per-ex loss: 0.799232  [   89/   89]
Train Error: Avg loss: 0.76930339
validation Error: 
 Avg loss: 0.83507158 
 F1: 0.409541 
 Precision: 0.811545 
 Recall: 0.273875
 IoU: 0.257499

test Error: 
 Avg loss: 0.83026417 
 F1: 0.415477 
 Precision: 0.837629 
 Recall: 0.276251
 IoU: 0.262210

We have finished training iteration 80
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_78_.pth
per-ex loss: 0.769704  [    2/   89]
per-ex loss: 0.661426  [    4/   89]
per-ex loss: 0.830341  [    6/   89]
per-ex loss: 0.790802  [    8/   89]
per-ex loss: 0.866354  [   10/   89]
per-ex loss: 0.826940  [   12/   89]
per-ex loss: 0.753491  [   14/   89]
per-ex loss: 0.783417  [   16/   89]
per-ex loss: 0.684919  [   18/   89]
per-ex loss: 0.613095  [   20/   89]
per-ex loss: 0.652647  [   22/   89]
per-ex loss: 0.799706  [   24/   89]
per-ex loss: 0.829610  [   26/   89]
per-ex loss: 0.850062  [   28/   89]
per-ex loss: 0.744140  [   30/   89]
per-ex loss: 0.888681  [   32/   89]
per-ex loss: 0.765183  [   34/   89]
per-ex loss: 0.672083  [   36/   89]
per-ex loss: 0.907047  [   38/   89]
per-ex loss: 0.717498  [   40/   89]
per-ex loss: 0.743639  [   42/   89]
per-ex loss: 0.826331  [   44/   89]
per-ex loss: 0.525074  [   46/   89]
per-ex loss: 0.842086  [   48/   89]
per-ex loss: 0.734020  [   50/   89]
per-ex loss: 0.806172  [   52/   89]
per-ex loss: 0.684631  [   54/   89]
per-ex loss: 0.626291  [   56/   89]
per-ex loss: 0.732456  [   58/   89]
per-ex loss: 0.834046  [   60/   89]
per-ex loss: 0.778890  [   62/   89]
per-ex loss: 0.869532  [   64/   89]
per-ex loss: 0.711849  [   66/   89]
per-ex loss: 0.933462  [   68/   89]
per-ex loss: 0.590049  [   70/   89]
per-ex loss: 0.858196  [   72/   89]
per-ex loss: 0.751657  [   74/   89]
per-ex loss: 0.865445  [   76/   89]
per-ex loss: 0.595414  [   78/   89]
per-ex loss: 0.925383  [   80/   89]
per-ex loss: 0.801099  [   82/   89]
per-ex loss: 0.863716  [   84/   89]
per-ex loss: 0.803560  [   86/   89]
per-ex loss: 0.590171  [   88/   89]
per-ex loss: 0.929158  [   89/   89]
Train Error: Avg loss: 0.76954387
validation Error: 
 Avg loss: 0.84247622 
 F1: 0.420751 
 Precision: 0.802789 
 Recall: 0.285083
 IoU: 0.266425

test Error: 
 Avg loss: 0.83113843 
 F1: 0.418600 
 Precision: 0.801034 
 Recall: 0.283331
 IoU: 0.264702

We have finished training iteration 81
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_79_.pth
per-ex loss: 0.712009  [    2/   89]
per-ex loss: 0.626600  [    4/   89]
per-ex loss: 0.862486  [    6/   89]
per-ex loss: 0.741385  [    8/   89]
per-ex loss: 0.680999  [   10/   89]
per-ex loss: 0.834037  [   12/   89]
per-ex loss: 0.885432  [   14/   89]
per-ex loss: 0.688487  [   16/   89]
per-ex loss: 0.950361  [   18/   89]
per-ex loss: 0.540850  [   20/   89]
per-ex loss: 0.795014  [   22/   89]
per-ex loss: 0.823618  [   24/   89]
per-ex loss: 0.763390  [   26/   89]
per-ex loss: 0.744498  [   28/   89]
per-ex loss: 0.847150  [   30/   89]
per-ex loss: 0.872091  [   32/   89]
per-ex loss: 0.716326  [   34/   89]
per-ex loss: 0.704070  [   36/   89]
per-ex loss: 0.819419  [   38/   89]
per-ex loss: 0.675781  [   40/   89]
per-ex loss: 0.638380  [   42/   89]
per-ex loss: 0.789471  [   44/   89]
per-ex loss: 0.741904  [   46/   89]
per-ex loss: 0.718831  [   48/   89]
per-ex loss: 0.630452  [   50/   89]
per-ex loss: 0.800466  [   52/   89]
per-ex loss: 0.803993  [   54/   89]
per-ex loss: 0.782807  [   56/   89]
per-ex loss: 0.730974  [   58/   89]
per-ex loss: 0.808504  [   60/   89]
per-ex loss: 0.645004  [   62/   89]
per-ex loss: 0.835159  [   64/   89]
per-ex loss: 0.846543  [   66/   89]
per-ex loss: 0.932793  [   68/   89]
per-ex loss: 0.778714  [   70/   89]
per-ex loss: 0.854212  [   72/   89]
per-ex loss: 0.651595  [   74/   89]
per-ex loss: 0.850309  [   76/   89]
per-ex loss: 0.613078  [   78/   89]
per-ex loss: 0.817565  [   80/   89]
per-ex loss: 0.783693  [   82/   89]
per-ex loss: 0.853857  [   84/   89]
per-ex loss: 0.789311  [   86/   89]
per-ex loss: 0.711934  [   88/   89]
per-ex loss: 0.703607  [   89/   89]
Train Error: Avg loss: 0.76438136
validation Error: 
 Avg loss: 0.83114672 
 F1: 0.400651 
 Precision: 0.826958 
 Recall: 0.264367
 IoU: 0.250509

test Error: 
 Avg loss: 0.82384961 
 F1: 0.409335 
 Precision: 0.841214 
 Recall: 0.270474
 IoU: 0.257336

We have finished training iteration 82
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_80_.pth
per-ex loss: 0.784554  [    2/   89]
per-ex loss: 0.815540  [    4/   89]
per-ex loss: 0.801435  [    6/   89]
per-ex loss: 0.676130  [    8/   89]
per-ex loss: 0.521657  [   10/   89]
per-ex loss: 0.584712  [   12/   89]
per-ex loss: 0.757329  [   14/   89]
per-ex loss: 0.841437  [   16/   89]
per-ex loss: 0.851057  [   18/   89]
per-ex loss: 0.723316  [   20/   89]
per-ex loss: 0.783221  [   22/   89]
per-ex loss: 0.758970  [   24/   89]
per-ex loss: 0.806593  [   26/   89]
per-ex loss: 0.778596  [   28/   89]
per-ex loss: 0.723895  [   30/   89]
per-ex loss: 0.778894  [   32/   89]
per-ex loss: 0.786793  [   34/   89]
per-ex loss: 0.768588  [   36/   89]
per-ex loss: 0.737501  [   38/   89]
per-ex loss: 0.677258  [   40/   89]
per-ex loss: 0.619450  [   42/   89]
per-ex loss: 0.916531  [   44/   89]
per-ex loss: 0.914523  [   46/   89]
per-ex loss: 0.825415  [   48/   89]
per-ex loss: 0.773959  [   50/   89]
per-ex loss: 0.818985  [   52/   89]
per-ex loss: 0.793353  [   54/   89]
per-ex loss: 0.571410  [   56/   89]
per-ex loss: 0.763905  [   58/   89]
per-ex loss: 0.626408  [   60/   89]
per-ex loss: 0.757817  [   62/   89]
per-ex loss: 0.852441  [   64/   89]
per-ex loss: 0.812692  [   66/   89]
per-ex loss: 0.801548  [   68/   89]
per-ex loss: 0.629453  [   70/   89]
per-ex loss: 0.827104  [   72/   89]
per-ex loss: 0.837455  [   74/   89]
per-ex loss: 0.920982  [   76/   89]
per-ex loss: 0.725105  [   78/   89]
per-ex loss: 0.864056  [   80/   89]
per-ex loss: 0.743380  [   82/   89]
per-ex loss: 0.768392  [   84/   89]
per-ex loss: 0.831551  [   86/   89]
per-ex loss: 0.706947  [   88/   89]
per-ex loss: 0.912685  [   89/   89]
Train Error: Avg loss: 0.76828940
validation Error: 
 Avg loss: 0.83560653 
 F1: 0.433416 
 Precision: 0.783683 
 Recall: 0.299537
 IoU: 0.276663

test Error: 
 Avg loss: 0.82223485 
 F1: 0.444382 
 Precision: 0.809949 
 Recall: 0.306186
 IoU: 0.285663

We have finished training iteration 83
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_81_.pth
per-ex loss: 0.891477  [    2/   89]
per-ex loss: 0.598084  [    4/   89]
per-ex loss: 0.733266  [    6/   89]
per-ex loss: 0.780993  [    8/   89]
per-ex loss: 0.864313  [   10/   89]
per-ex loss: 0.796176  [   12/   89]
per-ex loss: 0.926247  [   14/   89]
per-ex loss: 0.783289  [   16/   89]
per-ex loss: 0.828980  [   18/   89]
per-ex loss: 0.829112  [   20/   89]
per-ex loss: 0.759457  [   22/   89]
per-ex loss: 0.594302  [   24/   89]
per-ex loss: 0.911927  [   26/   89]
per-ex loss: 0.711239  [   28/   89]
per-ex loss: 0.793566  [   30/   89]
per-ex loss: 0.642583  [   32/   89]
per-ex loss: 0.877856  [   34/   89]
per-ex loss: 0.767224  [   36/   89]
per-ex loss: 0.632030  [   38/   89]
per-ex loss: 0.794912  [   40/   89]
per-ex loss: 0.764069  [   42/   89]
per-ex loss: 0.851521  [   44/   89]
per-ex loss: 0.656377  [   46/   89]
per-ex loss: 0.864017  [   48/   89]
per-ex loss: 0.748279  [   50/   89]
per-ex loss: 0.640617  [   52/   89]
per-ex loss: 0.751485  [   54/   89]
per-ex loss: 0.906897  [   56/   89]
per-ex loss: 0.556965  [   58/   89]
per-ex loss: 0.705128  [   60/   89]
per-ex loss: 0.899980  [   62/   89]
per-ex loss: 0.693897  [   64/   89]
per-ex loss: 0.918688  [   66/   89]
per-ex loss: 0.692093  [   68/   89]
per-ex loss: 0.849855  [   70/   89]
per-ex loss: 0.671329  [   72/   89]
per-ex loss: 0.789786  [   74/   89]
per-ex loss: 0.720365  [   76/   89]
per-ex loss: 0.625591  [   78/   89]
per-ex loss: 0.633586  [   80/   89]
per-ex loss: 0.632454  [   82/   89]
per-ex loss: 0.715885  [   84/   89]
per-ex loss: 0.803021  [   86/   89]
per-ex loss: 0.713996  [   88/   89]
per-ex loss: 0.617478  [   89/   89]
Train Error: Avg loss: 0.75423095
validation Error: 
 Avg loss: 0.82778848 
 F1: 0.439168 
 Precision: 0.777953 
 Recall: 0.305937
 IoU: 0.281368

test Error: 
 Avg loss: 0.81674485 
 F1: 0.452527 
 Precision: 0.785815 
 Recall: 0.317757
 IoU: 0.292430

We have finished training iteration 84
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_82_.pth
per-ex loss: 0.855865  [    2/   89]
per-ex loss: 0.798217  [    4/   89]
per-ex loss: 0.709042  [    6/   89]
per-ex loss: 0.754547  [    8/   89]
per-ex loss: 0.863885  [   10/   89]
per-ex loss: 0.800699  [   12/   89]
per-ex loss: 0.638741  [   14/   89]
per-ex loss: 0.870245  [   16/   89]
per-ex loss: 0.730848  [   18/   89]
per-ex loss: 0.829164  [   20/   89]
per-ex loss: 0.864968  [   22/   89]
per-ex loss: 0.512174  [   24/   89]
per-ex loss: 0.870166  [   26/   89]
per-ex loss: 0.793163  [   28/   89]
per-ex loss: 0.561794  [   30/   89]
per-ex loss: 0.652509  [   32/   89]
per-ex loss: 0.749374  [   34/   89]
per-ex loss: 0.682652  [   36/   89]
per-ex loss: 0.716187  [   38/   89]
per-ex loss: 0.808996  [   40/   89]
per-ex loss: 0.673433  [   42/   89]
per-ex loss: 0.785394  [   44/   89]
per-ex loss: 0.822851  [   46/   89]
per-ex loss: 0.872137  [   48/   89]
per-ex loss: 0.596785  [   50/   89]
per-ex loss: 0.770784  [   52/   89]
per-ex loss: 0.597627  [   54/   89]
per-ex loss: 0.731031  [   56/   89]
per-ex loss: 0.695670  [   58/   89]
per-ex loss: 0.699111  [   60/   89]
per-ex loss: 0.847067  [   62/   89]
per-ex loss: 0.787132  [   64/   89]
per-ex loss: 0.718082  [   66/   89]
per-ex loss: 0.728240  [   68/   89]
per-ex loss: 0.869619  [   70/   89]
per-ex loss: 0.833377  [   72/   89]
per-ex loss: 0.731889  [   74/   89]
per-ex loss: 0.935143  [   76/   89]
per-ex loss: 0.765873  [   78/   89]
per-ex loss: 0.723867  [   80/   89]
per-ex loss: 0.841361  [   82/   89]
per-ex loss: 0.875329  [   84/   89]
per-ex loss: 0.779841  [   86/   89]
per-ex loss: 0.786887  [   88/   89]
per-ex loss: 0.688762  [   89/   89]
Train Error: Avg loss: 0.76045618
validation Error: 
 Avg loss: 0.83217966 
 F1: 0.392063 
 Precision: 0.842408 
 Recall: 0.255484
 IoU: 0.243830

test Error: 
 Avg loss: 0.82336115 
 F1: 0.391092 
 Precision: 0.855192 
 Recall: 0.253514
 IoU: 0.243079

We have finished training iteration 85
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_83_.pth
per-ex loss: 0.891842  [    2/   89]
per-ex loss: 0.716361  [    4/   89]
per-ex loss: 0.902613  [    6/   89]
per-ex loss: 0.797279  [    8/   89]
per-ex loss: 0.750277  [   10/   89]
per-ex loss: 0.701906  [   12/   89]
per-ex loss: 0.694314  [   14/   89]
per-ex loss: 0.826413  [   16/   89]
per-ex loss: 0.826869  [   18/   89]
per-ex loss: 0.720798  [   20/   89]
per-ex loss: 0.542417  [   22/   89]
per-ex loss: 0.672406  [   24/   89]
per-ex loss: 0.779389  [   26/   89]
per-ex loss: 0.786790  [   28/   89]
per-ex loss: 0.872726  [   30/   89]
per-ex loss: 0.818229  [   32/   89]
per-ex loss: 0.787837  [   34/   89]
per-ex loss: 0.685561  [   36/   89]
per-ex loss: 0.548551  [   38/   89]
per-ex loss: 0.884689  [   40/   89]
per-ex loss: 0.743745  [   42/   89]
per-ex loss: 0.757396  [   44/   89]
per-ex loss: 0.662030  [   46/   89]
per-ex loss: 0.593522  [   48/   89]
per-ex loss: 0.831785  [   50/   89]
per-ex loss: 0.914576  [   52/   89]
per-ex loss: 0.566116  [   54/   89]
per-ex loss: 0.867509  [   56/   89]
per-ex loss: 0.640403  [   58/   89]
per-ex loss: 0.607507  [   60/   89]
per-ex loss: 0.730818  [   62/   89]
per-ex loss: 0.718528  [   64/   89]
per-ex loss: 0.717546  [   66/   89]
per-ex loss: 0.780552  [   68/   89]
per-ex loss: 0.695231  [   70/   89]
per-ex loss: 0.747961  [   72/   89]
per-ex loss: 0.819634  [   74/   89]
per-ex loss: 0.768336  [   76/   89]
per-ex loss: 0.624844  [   78/   89]
per-ex loss: 0.745128  [   80/   89]
per-ex loss: 0.808261  [   82/   89]
per-ex loss: 0.800099  [   84/   89]
per-ex loss: 0.819415  [   86/   89]
per-ex loss: 0.725112  [   88/   89]
per-ex loss: 0.868718  [   89/   89]
Train Error: Avg loss: 0.75026757
validation Error: 
 Avg loss: 0.82275100 
 F1: 0.430517 
 Precision: 0.786709 
 Recall: 0.296344
 IoU: 0.274305

test Error: 
 Avg loss: 0.81715084 
 F1: 0.438088 
 Precision: 0.795871 
 Recall: 0.302223
 IoU: 0.280482

We have finished training iteration 86
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_84_.pth
per-ex loss: 0.889178  [    2/   89]
per-ex loss: 0.742706  [    4/   89]
per-ex loss: 0.585635  [    6/   89]
per-ex loss: 0.655559  [    8/   89]
per-ex loss: 0.753023  [   10/   89]
per-ex loss: 0.867949  [   12/   89]
per-ex loss: 0.503355  [   14/   89]
per-ex loss: 0.772766  [   16/   89]
per-ex loss: 0.670198  [   18/   89]
per-ex loss: 0.703180  [   20/   89]
per-ex loss: 0.571635  [   22/   89]
per-ex loss: 0.775541  [   24/   89]
per-ex loss: 0.514115  [   26/   89]
per-ex loss: 0.687941  [   28/   89]
per-ex loss: 0.825445  [   30/   89]
per-ex loss: 0.730651  [   32/   89]
per-ex loss: 0.859127  [   34/   89]
per-ex loss: 0.744435  [   36/   89]
per-ex loss: 0.609942  [   38/   89]
per-ex loss: 0.830064  [   40/   89]
per-ex loss: 0.717932  [   42/   89]
per-ex loss: 0.877474  [   44/   89]
per-ex loss: 0.740823  [   46/   89]
per-ex loss: 0.859627  [   48/   89]
per-ex loss: 0.820938  [   50/   89]
per-ex loss: 0.857696  [   52/   89]
per-ex loss: 0.909222  [   54/   89]
per-ex loss: 0.826252  [   56/   89]
per-ex loss: 0.850987  [   58/   89]
per-ex loss: 0.889771  [   60/   89]
per-ex loss: 0.642344  [   62/   89]
per-ex loss: 0.747805  [   64/   89]
per-ex loss: 0.758537  [   66/   89]
per-ex loss: 0.794893  [   68/   89]
per-ex loss: 0.705054  [   70/   89]
per-ex loss: 0.703096  [   72/   89]
per-ex loss: 0.742853  [   74/   89]
per-ex loss: 0.794243  [   76/   89]
per-ex loss: 0.806299  [   78/   89]
per-ex loss: 0.864880  [   80/   89]
per-ex loss: 0.732682  [   82/   89]
per-ex loss: 0.719172  [   84/   89]
per-ex loss: 0.812201  [   86/   89]
per-ex loss: 0.614450  [   88/   89]
per-ex loss: 0.748698  [   89/   89]
Train Error: Avg loss: 0.75178610
validation Error: 
 Avg loss: 0.82643806 
 F1: 0.420822 
 Precision: 0.804576 
 Recall: 0.284923
 IoU: 0.266481

test Error: 
 Avg loss: 0.81583062 
 F1: 0.421159 
 Precision: 0.828093 
 Recall: 0.282390
 IoU: 0.266752

We have finished training iteration 87
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_85_.pth
per-ex loss: 0.714170  [    2/   89]
per-ex loss: 0.645824  [    4/   89]
per-ex loss: 0.727701  [    6/   89]
per-ex loss: 0.878057  [    8/   89]
per-ex loss: 0.701026  [   10/   89]
per-ex loss: 0.713286  [   12/   89]
per-ex loss: 0.852589  [   14/   89]
per-ex loss: 0.734319  [   16/   89]
per-ex loss: 0.892465  [   18/   89]
per-ex loss: 0.627415  [   20/   89]
per-ex loss: 0.775119  [   22/   89]
per-ex loss: 0.820914  [   24/   89]
per-ex loss: 0.800295  [   26/   89]
per-ex loss: 0.735829  [   28/   89]
per-ex loss: 0.716304  [   30/   89]
per-ex loss: 0.736095  [   32/   89]
per-ex loss: 0.756373  [   34/   89]
per-ex loss: 0.553273  [   36/   89]
per-ex loss: 0.674422  [   38/   89]
per-ex loss: 0.863490  [   40/   89]
per-ex loss: 0.850944  [   42/   89]
per-ex loss: 0.838157  [   44/   89]
per-ex loss: 0.781023  [   46/   89]
per-ex loss: 0.661844  [   48/   89]
per-ex loss: 0.855917  [   50/   89]
per-ex loss: 0.889854  [   52/   89]
per-ex loss: 0.840786  [   54/   89]
per-ex loss: 0.797457  [   56/   89]
per-ex loss: 0.671037  [   58/   89]
per-ex loss: 0.604624  [   60/   89]
per-ex loss: 0.674658  [   62/   89]
per-ex loss: 0.775022  [   64/   89]
per-ex loss: 0.534095  [   66/   89]
per-ex loss: 0.646228  [   68/   89]
per-ex loss: 0.664171  [   70/   89]
per-ex loss: 0.882710  [   72/   89]
per-ex loss: 0.852053  [   74/   89]
per-ex loss: 0.805661  [   76/   89]
per-ex loss: 0.804976  [   78/   89]
per-ex loss: 0.890909  [   80/   89]
per-ex loss: 0.680524  [   82/   89]
per-ex loss: 0.764218  [   84/   89]
per-ex loss: 0.742748  [   86/   89]
per-ex loss: 0.626583  [   88/   89]
per-ex loss: 0.717071  [   89/   89]
Train Error: Avg loss: 0.75049411
validation Error: 
 Avg loss: 0.81478136 
 F1: 0.445187 
 Precision: 0.762305 
 Recall: 0.314397
 IoU: 0.286328

test Error: 
 Avg loss: 0.81054203 
 F1: 0.455123 
 Precision: 0.768069 
 Recall: 0.323368
 IoU: 0.294602

We have finished training iteration 88
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_86_.pth
per-ex loss: 0.670590  [    2/   89]
per-ex loss: 0.891508  [    4/   89]
per-ex loss: 0.833981  [    6/   89]
per-ex loss: 0.806258  [    8/   89]
per-ex loss: 0.762249  [   10/   89]
per-ex loss: 0.671269  [   12/   89]
per-ex loss: 0.667817  [   14/   89]
per-ex loss: 0.738353  [   16/   89]
per-ex loss: 0.916464  [   18/   89]
per-ex loss: 0.916094  [   20/   89]
per-ex loss: 0.728955  [   22/   89]
per-ex loss: 0.686605  [   24/   89]
per-ex loss: 0.860726  [   26/   89]
per-ex loss: 0.824009  [   28/   89]
per-ex loss: 0.675311  [   30/   89]
per-ex loss: 0.704897  [   32/   89]
per-ex loss: 0.733466  [   34/   89]
per-ex loss: 0.868001  [   36/   89]
per-ex loss: 0.696068  [   38/   89]
per-ex loss: 0.695183  [   40/   89]
per-ex loss: 0.830130  [   42/   89]
per-ex loss: 0.679850  [   44/   89]
per-ex loss: 0.749059  [   46/   89]
per-ex loss: 0.638790  [   48/   89]
per-ex loss: 0.817478  [   50/   89]
per-ex loss: 0.832074  [   52/   89]
per-ex loss: 0.818469  [   54/   89]
per-ex loss: 0.827501  [   56/   89]
per-ex loss: 0.669253  [   58/   89]
per-ex loss: 0.626412  [   60/   89]
per-ex loss: 0.810457  [   62/   89]
per-ex loss: 0.632202  [   64/   89]
per-ex loss: 0.720996  [   66/   89]
per-ex loss: 0.606759  [   68/   89]
per-ex loss: 0.780814  [   70/   89]
per-ex loss: 0.587988  [   72/   89]
per-ex loss: 0.762616  [   74/   89]
per-ex loss: 0.768394  [   76/   89]
per-ex loss: 0.785228  [   78/   89]
per-ex loss: 0.815226  [   80/   89]
per-ex loss: 0.603408  [   82/   89]
per-ex loss: 0.756548  [   84/   89]
per-ex loss: 0.700609  [   86/   89]
per-ex loss: 0.833308  [   88/   89]
per-ex loss: 0.739807  [   89/   89]
Train Error: Avg loss: 0.74980406
validation Error: 
 Avg loss: 0.81486316 
 F1: 0.412742 
 Precision: 0.812888 
 Recall: 0.276590
 IoU: 0.260035

test Error: 
 Avg loss: 0.81203861 
 F1: 0.421437 
 Precision: 0.814159 
 Recall: 0.284300
 IoU: 0.266975

We have finished training iteration 89
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_87_.pth
per-ex loss: 0.747078  [    2/   89]
per-ex loss: 0.636618  [    4/   89]
per-ex loss: 0.876174  [    6/   89]
per-ex loss: 0.772091  [    8/   89]
per-ex loss: 0.529077  [   10/   89]
per-ex loss: 0.817235  [   12/   89]
per-ex loss: 0.828115  [   14/   89]
per-ex loss: 0.729546  [   16/   89]
per-ex loss: 0.681839  [   18/   89]
per-ex loss: 0.808178  [   20/   89]
per-ex loss: 0.777205  [   22/   89]
per-ex loss: 0.704061  [   24/   89]
per-ex loss: 0.587903  [   26/   89]
per-ex loss: 0.783011  [   28/   89]
per-ex loss: 0.723966  [   30/   89]
per-ex loss: 0.533124  [   32/   89]
per-ex loss: 0.704356  [   34/   89]
per-ex loss: 0.807090  [   36/   89]
per-ex loss: 0.895476  [   38/   89]
per-ex loss: 0.838843  [   40/   89]
per-ex loss: 0.697966  [   42/   89]
per-ex loss: 0.541232  [   44/   89]
per-ex loss: 0.625369  [   46/   89]
per-ex loss: 0.778044  [   48/   89]
per-ex loss: 0.791606  [   50/   89]
per-ex loss: 0.683230  [   52/   89]
per-ex loss: 0.781256  [   54/   89]
per-ex loss: 0.835315  [   56/   89]
per-ex loss: 0.905328  [   58/   89]
per-ex loss: 0.712323  [   60/   89]
per-ex loss: 0.847687  [   62/   89]
per-ex loss: 0.788311  [   64/   89]
per-ex loss: 0.701802  [   66/   89]
per-ex loss: 0.655164  [   68/   89]
per-ex loss: 0.756864  [   70/   89]
per-ex loss: 0.751768  [   72/   89]
per-ex loss: 0.714525  [   74/   89]
per-ex loss: 0.869367  [   76/   89]
per-ex loss: 0.614867  [   78/   89]
per-ex loss: 0.606213  [   80/   89]
per-ex loss: 0.714015  [   82/   89]
per-ex loss: 0.856817  [   84/   89]
per-ex loss: 0.724143  [   86/   89]
per-ex loss: 0.581891  [   88/   89]
per-ex loss: 0.943205  [   89/   89]
Train Error: Avg loss: 0.73909538
validation Error: 
 Avg loss: 0.81377356 
 F1: 0.428170 
 Precision: 0.787702 
 Recall: 0.293986
 IoU: 0.272402

test Error: 
 Avg loss: 0.80520886 
 F1: 0.443876 
 Precision: 0.803868 
 Recall: 0.306581
 IoU: 0.285244

We have finished training iteration 90
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_88_.pth
per-ex loss: 0.610166  [    2/   89]
per-ex loss: 0.817599  [    4/   89]
per-ex loss: 0.819498  [    6/   89]
per-ex loss: 0.703457  [    8/   89]
per-ex loss: 0.726022  [   10/   89]
per-ex loss: 0.798688  [   12/   89]
per-ex loss: 0.748512  [   14/   89]
per-ex loss: 0.547829  [   16/   89]
per-ex loss: 0.606738  [   18/   89]
per-ex loss: 0.886733  [   20/   89]
per-ex loss: 0.799165  [   22/   89]
per-ex loss: 0.846064  [   24/   89]
per-ex loss: 0.646271  [   26/   89]
per-ex loss: 0.648719  [   28/   89]
per-ex loss: 0.719500  [   30/   89]
per-ex loss: 0.750297  [   32/   89]
per-ex loss: 0.815904  [   34/   89]
per-ex loss: 0.725619  [   36/   89]
per-ex loss: 0.684852  [   38/   89]
per-ex loss: 0.902674  [   40/   89]
per-ex loss: 0.815614  [   42/   89]
per-ex loss: 0.836451  [   44/   89]
per-ex loss: 0.858854  [   46/   89]
per-ex loss: 0.667294  [   48/   89]
per-ex loss: 0.848198  [   50/   89]
per-ex loss: 0.706922  [   52/   89]
per-ex loss: 0.852820  [   54/   89]
per-ex loss: 0.802561  [   56/   89]
per-ex loss: 0.874738  [   58/   89]
per-ex loss: 0.702390  [   60/   89]
per-ex loss: 0.761400  [   62/   89]
per-ex loss: 0.806302  [   64/   89]
per-ex loss: 0.809614  [   66/   89]
per-ex loss: 0.676058  [   68/   89]
per-ex loss: 0.729600  [   70/   89]
per-ex loss: 0.699714  [   72/   89]
per-ex loss: 0.831605  [   74/   89]
per-ex loss: 0.660734  [   76/   89]
per-ex loss: 0.588270  [   78/   89]
per-ex loss: 0.787512  [   80/   89]
per-ex loss: 0.750355  [   82/   89]
per-ex loss: 0.721248  [   84/   89]
per-ex loss: 0.747730  [   86/   89]
per-ex loss: 0.883350  [   88/   89]
per-ex loss: 0.903214  [   89/   89]
Train Error: Avg loss: 0.75837452
validation Error: 
 Avg loss: 0.81701171 
 F1: 0.416850 
 Precision: 0.812285 
 Recall: 0.280364
 IoU: 0.263304

test Error: 
 Avg loss: 0.80883422 
 F1: 0.423570 
 Precision: 0.841371 
 Recall: 0.283027
 IoU: 0.268689

We have finished training iteration 91
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_89_.pth
per-ex loss: 0.726822  [    2/   89]
per-ex loss: 0.836273  [    4/   89]
per-ex loss: 0.754952  [    6/   89]
per-ex loss: 0.718726  [    8/   89]
per-ex loss: 0.752541  [   10/   89]
per-ex loss: 0.728449  [   12/   89]
per-ex loss: 0.656856  [   14/   89]
per-ex loss: 0.676077  [   16/   89]
per-ex loss: 0.763444  [   18/   89]
per-ex loss: 0.766789  [   20/   89]
per-ex loss: 0.718145  [   22/   89]
per-ex loss: 0.663839  [   24/   89]
per-ex loss: 0.933590  [   26/   89]
per-ex loss: 0.894272  [   28/   89]
per-ex loss: 0.897070  [   30/   89]
per-ex loss: 0.620047  [   32/   89]
per-ex loss: 0.755205  [   34/   89]
per-ex loss: 0.856682  [   36/   89]
per-ex loss: 0.683274  [   38/   89]
per-ex loss: 0.633872  [   40/   89]
per-ex loss: 0.539021  [   42/   89]
per-ex loss: 0.700538  [   44/   89]
per-ex loss: 0.687910  [   46/   89]
per-ex loss: 0.779061  [   48/   89]
per-ex loss: 0.737261  [   50/   89]
per-ex loss: 0.880494  [   52/   89]
per-ex loss: 0.760585  [   54/   89]
per-ex loss: 0.574330  [   56/   89]
per-ex loss: 0.622026  [   58/   89]
per-ex loss: 0.925462  [   60/   89]
per-ex loss: 0.859575  [   62/   89]
per-ex loss: 0.628222  [   64/   89]
per-ex loss: 0.695757  [   66/   89]
per-ex loss: 0.841320  [   68/   89]
per-ex loss: 0.885107  [   70/   89]
per-ex loss: 0.734001  [   72/   89]
per-ex loss: 0.848024  [   74/   89]
per-ex loss: 0.874092  [   76/   89]
per-ex loss: 0.686999  [   78/   89]
per-ex loss: 0.731745  [   80/   89]
per-ex loss: 0.676393  [   82/   89]
per-ex loss: 0.641947  [   84/   89]
per-ex loss: 0.794484  [   86/   89]
per-ex loss: 0.773816  [   88/   89]
per-ex loss: 0.773852  [   89/   89]
Train Error: Avg loss: 0.74864331
validation Error: 
 Avg loss: 0.81808571 
 F1: 0.411223 
 Precision: 0.815332 
 Recall: 0.274949
 IoU: 0.258830

test Error: 
 Avg loss: 0.80922724 
 F1: 0.414593 
 Precision: 0.823511 
 Recall: 0.277032
 IoU: 0.261506

We have finished training iteration 92
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_90_.pth
Error in cropping the image to the non-zero values in the fourth channel. Returned the original image.
per-ex loss: 0.763472  [    2/   89]
per-ex loss: 0.795420  [    4/   89]
per-ex loss: 0.789665  [    6/   89]
per-ex loss: 0.578319  [    8/   89]
per-ex loss: 0.826975  [   10/   89]
per-ex loss: 0.742412  [   12/   89]
per-ex loss: 0.757217  [   14/   89]
per-ex loss: 0.701819  [   16/   89]
per-ex loss: 0.752648  [   18/   89]
per-ex loss: 0.686724  [   20/   89]
per-ex loss: 0.637455  [   22/   89]
per-ex loss: 0.821250  [   24/   89]
per-ex loss: 0.666816  [   26/   89]
per-ex loss: 0.619712  [   28/   89]
per-ex loss: 0.736093  [   30/   89]
per-ex loss: 0.887707  [   32/   89]
per-ex loss: 0.618711  [   34/   89]
per-ex loss: 0.725280  [   36/   89]
per-ex loss: 0.569655  [   38/   89]
per-ex loss: 0.850782  [   40/   89]
per-ex loss: 0.719137  [   42/   89]
per-ex loss: 0.714661  [   44/   89]
per-ex loss: 0.700205  [   46/   89]
per-ex loss: 0.783758  [   48/   89]
per-ex loss: 0.750612  [   50/   89]
per-ex loss: 0.707387  [   52/   89]
per-ex loss: 0.837227  [   54/   89]
per-ex loss: 0.640545  [   56/   89]
per-ex loss: 0.840817  [   58/   89]
per-ex loss: 0.856855  [   60/   89]
per-ex loss: 0.711360  [   62/   89]
per-ex loss: 0.744592  [   64/   89]
per-ex loss: 0.855693  [   66/   89]
per-ex loss: 0.730449  [   68/   89]
per-ex loss: 0.657516  [   70/   89]
per-ex loss: 0.655840  [   72/   89]
per-ex loss: 0.819854  [   74/   89]
per-ex loss: 0.873859  [   76/   89]
per-ex loss: 0.564784  [   78/   89]
per-ex loss: 0.867740  [   80/   89]
per-ex loss: 0.602435  [   82/   89]
per-ex loss: 0.639922  [   84/   89]
per-ex loss: 0.682165  [   86/   89]
per-ex loss: 0.672510  [   88/   89]
per-ex loss: 0.954789  [   89/   89]
Train Error: Avg loss: 0.73584101
validation Error: 
 Avg loss: 0.80689691 
 F1: 0.428899 
 Precision: 0.806036 
 Recall: 0.292188
 IoU: 0.272993

test Error: 
 Avg loss: 0.79667485 
 F1: 0.440550 
 Precision: 0.818838 
 Recall: 0.301338
 IoU: 0.282503

We have finished training iteration 93
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_91_.pth
Error in cropping the image to the non-zero values in the fourth channel. Returned the original image.
per-ex loss: 0.715409  [    2/   89]
per-ex loss: 0.766455  [    4/   89]
per-ex loss: 0.516398  [    6/   89]
per-ex loss: 0.595804  [    8/   89]
per-ex loss: 0.709573  [   10/   89]
per-ex loss: 0.760028  [   12/   89]
per-ex loss: 0.811456  [   14/   89]
per-ex loss: 0.780591  [   16/   89]
per-ex loss: 0.846330  [   18/   89]
per-ex loss: 0.745227  [   20/   89]
per-ex loss: 0.768298  [   22/   89]
per-ex loss: 0.614365  [   24/   89]
per-ex loss: 0.660410  [   26/   89]
per-ex loss: 0.736993  [   28/   89]
per-ex loss: 0.842754  [   30/   89]
per-ex loss: 0.764065  [   32/   89]
per-ex loss: 0.628370  [   34/   89]
per-ex loss: 0.874599  [   36/   89]
per-ex loss: 0.653354  [   38/   89]
per-ex loss: 0.686185  [   40/   89]
per-ex loss: 0.832354  [   42/   89]
per-ex loss: 0.760745  [   44/   89]
per-ex loss: 0.662220  [   46/   89]
per-ex loss: 0.766228  [   48/   89]
per-ex loss: 0.764976  [   50/   89]
per-ex loss: 0.683179  [   52/   89]
per-ex loss: 0.723942  [   54/   89]
per-ex loss: 0.809374  [   56/   89]
per-ex loss: 0.844161  [   58/   89]
per-ex loss: 0.626571  [   60/   89]
per-ex loss: 0.554231  [   62/   89]
per-ex loss: 0.730725  [   64/   89]
per-ex loss: 0.739756  [   66/   89]
per-ex loss: 0.688909  [   68/   89]
per-ex loss: 0.816199  [   70/   89]
per-ex loss: 0.690262  [   72/   89]
per-ex loss: 0.625030  [   74/   89]
per-ex loss: 0.832712  [   76/   89]
per-ex loss: 0.666504  [   78/   89]
per-ex loss: 0.706392  [   80/   89]
per-ex loss: 0.714611  [   82/   89]
per-ex loss: 0.763815  [   84/   89]
per-ex loss: 0.797759  [   86/   89]
per-ex loss: 0.729550  [   88/   89]
per-ex loss: 0.886196  [   89/   89]
Train Error: Avg loss: 0.73095703
validation Error: 
 Avg loss: 0.80728095 
 F1: 0.410330 
 Precision: 0.816667 
 Recall: 0.274000
 IoU: 0.258123

test Error: 
 Avg loss: 0.80367450 
 F1: 0.413352 
 Precision: 0.842298 
 Recall: 0.273878
 IoU: 0.260519

We have finished training iteration 94
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_92_.pth
per-ex loss: 0.748391  [    2/   89]
per-ex loss: 0.693472  [    4/   89]
per-ex loss: 0.678390  [    6/   89]
per-ex loss: 0.848500  [    8/   89]
per-ex loss: 0.772447  [   10/   89]
per-ex loss: 0.719598  [   12/   89]
per-ex loss: 0.716932  [   14/   89]
per-ex loss: 0.638800  [   16/   89]
per-ex loss: 0.603233  [   18/   89]
per-ex loss: 0.814259  [   20/   89]
per-ex loss: 0.773115  [   22/   89]
per-ex loss: 0.747990  [   24/   89]
per-ex loss: 0.851609  [   26/   89]
per-ex loss: 0.784362  [   28/   89]
per-ex loss: 0.705490  [   30/   89]
per-ex loss: 0.865432  [   32/   89]
per-ex loss: 0.698962  [   34/   89]
per-ex loss: 0.685739  [   36/   89]
per-ex loss: 0.914634  [   38/   89]
per-ex loss: 0.733558  [   40/   89]
per-ex loss: 0.864343  [   42/   89]
per-ex loss: 0.866955  [   44/   89]
per-ex loss: 0.726567  [   46/   89]
per-ex loss: 0.901173  [   48/   89]
per-ex loss: 0.602038  [   50/   89]
per-ex loss: 0.679542  [   52/   89]
per-ex loss: 0.629942  [   54/   89]
per-ex loss: 0.753427  [   56/   89]
per-ex loss: 0.703719  [   58/   89]
per-ex loss: 0.688004  [   60/   89]
per-ex loss: 0.701754  [   62/   89]
per-ex loss: 0.682945  [   64/   89]
per-ex loss: 0.899509  [   66/   89]
per-ex loss: 0.612141  [   68/   89]
per-ex loss: 0.601094  [   70/   89]
per-ex loss: 0.496794  [   72/   89]
per-ex loss: 0.763228  [   74/   89]
per-ex loss: 0.758989  [   76/   89]
per-ex loss: 0.630749  [   78/   89]
per-ex loss: 0.716414  [   80/   89]
per-ex loss: 0.836195  [   82/   89]
per-ex loss: 0.641182  [   84/   89]
per-ex loss: 0.600702  [   86/   89]
per-ex loss: 0.784266  [   88/   89]
per-ex loss: 0.857613  [   89/   89]
Train Error: Avg loss: 0.73320440
validation Error: 
 Avg loss: 0.80247495 
 F1: 0.430872 
 Precision: 0.791150 
 Recall: 0.296053
 IoU: 0.274593

test Error: 
 Avg loss: 0.79371660 
 F1: 0.442315 
 Precision: 0.811663 
 Recall: 0.303986
 IoU: 0.283957

We have finished training iteration 95
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_93_.pth
per-ex loss: 0.794911  [    2/   89]
per-ex loss: 0.706106  [    4/   89]
per-ex loss: 0.729583  [    6/   89]
per-ex loss: 0.727987  [    8/   89]
per-ex loss: 0.585580  [   10/   89]
per-ex loss: 0.838990  [   12/   89]
per-ex loss: 0.739743  [   14/   89]
per-ex loss: 0.537555  [   16/   89]
per-ex loss: 0.538604  [   18/   89]
per-ex loss: 0.879382  [   20/   89]
per-ex loss: 0.643951  [   22/   89]
per-ex loss: 0.830094  [   24/   89]
per-ex loss: 0.692530  [   26/   89]
per-ex loss: 0.797618  [   28/   89]
per-ex loss: 0.607209  [   30/   89]
per-ex loss: 0.677003  [   32/   89]
per-ex loss: 0.796921  [   34/   89]
per-ex loss: 0.765512  [   36/   89]
per-ex loss: 0.685130  [   38/   89]
per-ex loss: 0.875393  [   40/   89]
per-ex loss: 0.681707  [   42/   89]
per-ex loss: 0.651884  [   44/   89]
per-ex loss: 0.754642  [   46/   89]
per-ex loss: 0.869380  [   48/   89]
per-ex loss: 0.737690  [   50/   89]
per-ex loss: 0.819648  [   52/   89]
per-ex loss: 0.712148  [   54/   89]
per-ex loss: 0.794792  [   56/   89]
per-ex loss: 0.856257  [   58/   89]
per-ex loss: 0.534322  [   60/   89]
per-ex loss: 0.816071  [   62/   89]
per-ex loss: 0.654007  [   64/   89]
per-ex loss: 0.672037  [   66/   89]
per-ex loss: 0.723727  [   68/   89]
per-ex loss: 0.752786  [   70/   89]
per-ex loss: 0.675909  [   72/   89]
per-ex loss: 0.800376  [   74/   89]
per-ex loss: 0.769555  [   76/   89]
per-ex loss: 0.837417  [   78/   89]
per-ex loss: 0.585247  [   80/   89]
per-ex loss: 0.699870  [   82/   89]
per-ex loss: 0.738905  [   84/   89]
per-ex loss: 0.733193  [   86/   89]
per-ex loss: 0.613079  [   88/   89]
per-ex loss: 0.872371  [   89/   89]
Train Error: Avg loss: 0.72904052
validation Error: 
 Avg loss: 0.81151689 
 F1: 0.448335 
 Precision: 0.770322 
 Recall: 0.316176
 IoU: 0.288938

test Error: 
 Avg loss: 0.79874635 
 F1: 0.452949 
 Precision: 0.771947 
 Recall: 0.320504
 IoU: 0.292782

We have finished training iteration 96
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_94_.pth
Error in cropping the image to the non-zero values in the fourth channel. Returned the original image.
Error in cropping the image to the non-zero values in the fourth channel. Returned the original image.
per-ex loss: 0.814776  [    2/   89]
per-ex loss: 0.627294  [    4/   89]
per-ex loss: 0.763908  [    6/   89]
per-ex loss: 0.725802  [    8/   89]
per-ex loss: 0.641755  [   10/   89]
per-ex loss: 0.759589  [   12/   89]
per-ex loss: 0.536986  [   14/   89]
per-ex loss: 0.751441  [   16/   89]
per-ex loss: 0.654436  [   18/   89]
per-ex loss: 0.711424  [   20/   89]
per-ex loss: 0.846014  [   22/   89]
per-ex loss: 0.629808  [   24/   89]
per-ex loss: 0.785226  [   26/   89]
per-ex loss: 0.535552  [   28/   89]
per-ex loss: 0.878082  [   30/   89]
per-ex loss: 0.793804  [   32/   89]
per-ex loss: 0.710358  [   34/   89]
per-ex loss: 0.735188  [   36/   89]
per-ex loss: 0.858456  [   38/   89]
per-ex loss: 0.820718  [   40/   89]
per-ex loss: 0.853239  [   42/   89]
per-ex loss: 0.764599  [   44/   89]
per-ex loss: 0.883321  [   46/   89]
per-ex loss: 0.737516  [   48/   89]
per-ex loss: 0.926648  [   50/   89]
per-ex loss: 0.494887  [   52/   89]
per-ex loss: 0.679679  [   54/   89]
per-ex loss: 0.769083  [   56/   89]
per-ex loss: 0.732166  [   58/   89]
per-ex loss: 0.811914  [   60/   89]
per-ex loss: 0.648649  [   62/   89]
per-ex loss: 0.884987  [   64/   89]
per-ex loss: 0.656700  [   66/   89]
per-ex loss: 0.748456  [   68/   89]
per-ex loss: 0.673213  [   70/   89]
per-ex loss: 0.744522  [   72/   89]
per-ex loss: 0.809362  [   74/   89]
per-ex loss: 0.607113  [   76/   89]
per-ex loss: 0.778077  [   78/   89]
per-ex loss: 0.908736  [   80/   89]
per-ex loss: 0.609712  [   82/   89]
per-ex loss: 0.694262  [   84/   89]
per-ex loss: 0.814287  [   86/   89]
per-ex loss: 0.698091  [   88/   89]
per-ex loss: 0.628645  [   89/   89]
Train Error: Avg loss: 0.73641071
validation Error: 
 Avg loss: 0.79702227 
 F1: 0.427361 
 Precision: 0.805572 
 Recall: 0.290822
 IoU: 0.271747

test Error: 
 Avg loss: 0.78971820 
 F1: 0.440988 
 Precision: 0.820206 
 Recall: 0.301563
 IoU: 0.282864

We have finished training iteration 97
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_95_.pth
per-ex loss: 0.758843  [    2/   89]
per-ex loss: 0.526203  [    4/   89]
per-ex loss: 0.882120  [    6/   89]
per-ex loss: 0.807163  [    8/   89]
per-ex loss: 0.522553  [   10/   89]
per-ex loss: 0.868698  [   12/   89]
per-ex loss: 0.557327  [   14/   89]
per-ex loss: 0.798742  [   16/   89]
per-ex loss: 0.811399  [   18/   89]
per-ex loss: 0.587400  [   20/   89]
per-ex loss: 0.693604  [   22/   89]
per-ex loss: 0.735436  [   24/   89]
per-ex loss: 0.795901  [   26/   89]
per-ex loss: 0.664442  [   28/   89]
per-ex loss: 0.797202  [   30/   89]
per-ex loss: 0.793108  [   32/   89]
per-ex loss: 0.811441  [   34/   89]
per-ex loss: 0.663878  [   36/   89]
per-ex loss: 0.739085  [   38/   89]
per-ex loss: 0.712939  [   40/   89]
per-ex loss: 0.638143  [   42/   89]
per-ex loss: 0.553493  [   44/   89]
per-ex loss: 0.876927  [   46/   89]
per-ex loss: 0.852871  [   48/   89]
per-ex loss: 0.695182  [   50/   89]
per-ex loss: 0.756280  [   52/   89]
per-ex loss: 0.648862  [   54/   89]
per-ex loss: 0.753254  [   56/   89]
per-ex loss: 0.719840  [   58/   89]
per-ex loss: 0.596282  [   60/   89]
per-ex loss: 0.633800  [   62/   89]
per-ex loss: 0.679482  [   64/   89]
per-ex loss: 0.636616  [   66/   89]
per-ex loss: 0.611435  [   68/   89]
per-ex loss: 0.586910  [   70/   89]
per-ex loss: 0.763127  [   72/   89]
per-ex loss: 0.780084  [   74/   89]
per-ex loss: 0.782224  [   76/   89]
per-ex loss: 0.952419  [   78/   89]
per-ex loss: 0.904994  [   80/   89]
per-ex loss: 0.692608  [   82/   89]
per-ex loss: 0.756358  [   84/   89]
per-ex loss: 0.709655  [   86/   89]
per-ex loss: 0.684913  [   88/   89]
per-ex loss: 0.827770  [   89/   89]
Train Error: Avg loss: 0.72491136
validation Error: 
 Avg loss: 0.80214015 
 F1: 0.452482 
 Precision: 0.756301 
 Recall: 0.322805
 IoU: 0.292392

test Error: 
 Avg loss: 0.78774617 
 F1: 0.468585 
 Precision: 0.785470 
 Recall: 0.333885
 IoU: 0.305982

We have finished training iteration 98
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_96_.pth
per-ex loss: 0.589002  [    2/   89]
per-ex loss: 0.800061  [    4/   89]
per-ex loss: 0.575334  [    6/   89]
per-ex loss: 0.796528  [    8/   89]
per-ex loss: 0.780166  [   10/   89]
per-ex loss: 0.726728  [   12/   89]
per-ex loss: 0.811709  [   14/   89]
per-ex loss: 0.813897  [   16/   89]
per-ex loss: 0.793637  [   18/   89]
per-ex loss: 0.734854  [   20/   89]
per-ex loss: 0.621772  [   22/   89]
per-ex loss: 0.828555  [   24/   89]
per-ex loss: 0.529174  [   26/   89]
per-ex loss: 0.587296  [   28/   89]
per-ex loss: 0.643124  [   30/   89]
per-ex loss: 0.688836  [   32/   89]
per-ex loss: 0.768267  [   34/   89]
per-ex loss: 0.825790  [   36/   89]
per-ex loss: 0.884872  [   38/   89]
per-ex loss: 0.728454  [   40/   89]
per-ex loss: 0.530324  [   42/   89]
per-ex loss: 0.685055  [   44/   89]
per-ex loss: 0.791142  [   46/   89]
per-ex loss: 0.718637  [   48/   89]
per-ex loss: 0.762166  [   50/   89]
per-ex loss: 0.800992  [   52/   89]
per-ex loss: 0.666783  [   54/   89]
per-ex loss: 0.555140  [   56/   89]
per-ex loss: 0.798030  [   58/   89]
per-ex loss: 0.604012  [   60/   89]
per-ex loss: 0.737394  [   62/   89]
per-ex loss: 0.864167  [   64/   89]
per-ex loss: 0.732572  [   66/   89]
per-ex loss: 0.604629  [   68/   89]
per-ex loss: 0.820856  [   70/   89]
per-ex loss: 0.853389  [   72/   89]
per-ex loss: 0.760159  [   74/   89]
per-ex loss: 0.810278  [   76/   89]
per-ex loss: 0.691251  [   78/   89]
per-ex loss: 0.646291  [   80/   89]
per-ex loss: 0.662016  [   82/   89]
per-ex loss: 0.623743  [   84/   89]
per-ex loss: 0.635087  [   86/   89]
per-ex loss: 0.630796  [   88/   89]
per-ex loss: 0.800416  [   89/   89]
Train Error: Avg loss: 0.71807511
validation Error: 
 Avg loss: 0.79637929 
 F1: 0.412616 
 Precision: 0.815686 
 Recall: 0.276155
 IoU: 0.259935

test Error: 
 Avg loss: 0.78718189 
 F1: 0.422808 
 Precision: 0.837502 
 Recall: 0.282785
 IoU: 0.268076

We have finished training iteration 99
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_97_.pth
per-ex loss: 0.733948  [    2/   89]
per-ex loss: 0.747598  [    4/   89]
per-ex loss: 0.870100  [    6/   89]
per-ex loss: 0.721307  [    8/   89]
per-ex loss: 0.622992  [   10/   89]
per-ex loss: 0.622993  [   12/   89]
per-ex loss: 0.695206  [   14/   89]
per-ex loss: 0.751696  [   16/   89]
per-ex loss: 0.647518  [   18/   89]
per-ex loss: 0.645038  [   20/   89]
per-ex loss: 0.633116  [   22/   89]
per-ex loss: 0.905376  [   24/   89]
per-ex loss: 0.765422  [   26/   89]
per-ex loss: 0.718946  [   28/   89]
per-ex loss: 0.685693  [   30/   89]
per-ex loss: 0.754286  [   32/   89]
per-ex loss: 0.794787  [   34/   89]
per-ex loss: 0.738882  [   36/   89]
per-ex loss: 0.721906  [   38/   89]
per-ex loss: 0.662479  [   40/   89]
per-ex loss: 0.756723  [   42/   89]
per-ex loss: 0.785689  [   44/   89]
per-ex loss: 0.763870  [   46/   89]
per-ex loss: 0.672271  [   48/   89]
per-ex loss: 0.570351  [   50/   89]
per-ex loss: 0.749748  [   52/   89]
per-ex loss: 0.803987  [   54/   89]
per-ex loss: 0.770387  [   56/   89]
per-ex loss: 0.738985  [   58/   89]
per-ex loss: 0.752915  [   60/   89]
per-ex loss: 0.783890  [   62/   89]
per-ex loss: 0.789891  [   64/   89]
per-ex loss: 0.783347  [   66/   89]
per-ex loss: 0.665000  [   68/   89]
per-ex loss: 0.883684  [   70/   89]
per-ex loss: 0.893368  [   72/   89]
per-ex loss: 0.914451  [   74/   89]
per-ex loss: 0.826065  [   76/   89]
per-ex loss: 0.497510  [   78/   89]
per-ex loss: 0.651219  [   80/   89]
per-ex loss: 0.538354  [   82/   89]
per-ex loss: 0.847703  [   84/   89]
per-ex loss: 0.655528  [   86/   89]
per-ex loss: 0.582842  [   88/   89]
per-ex loss: 0.787755  [   89/   89]
Train Error: Avg loss: 0.73121826
validation Error: 
 Avg loss: 0.79016908 
 F1: 0.387277 
 Precision: 0.865088 
 Recall: 0.249481
 IoU: 0.240138

test Error: 
 Avg loss: 0.78935750 
 F1: 0.397838 
 Precision: 0.869895 
 Recall: 0.257891
 IoU: 0.248313

We have finished training iteration 100
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_98_.pth
per-ex loss: 0.694681  [    2/   89]
per-ex loss: 0.834598  [    4/   89]
per-ex loss: 0.493876  [    6/   89]
per-ex loss: 0.861387  [    8/   89]
per-ex loss: 0.537976  [   10/   89]
per-ex loss: 0.715271  [   12/   89]
per-ex loss: 0.803261  [   14/   89]
per-ex loss: 0.748750  [   16/   89]
per-ex loss: 0.792244  [   18/   89]
per-ex loss: 0.542547  [   20/   89]
per-ex loss: 0.782030  [   22/   89]
per-ex loss: 0.820730  [   24/   89]
per-ex loss: 0.889203  [   26/   89]
per-ex loss: 0.822590  [   28/   89]
per-ex loss: 0.774607  [   30/   89]
per-ex loss: 0.627611  [   32/   89]
per-ex loss: 0.698987  [   34/   89]
per-ex loss: 0.537324  [   36/   89]
per-ex loss: 0.603174  [   38/   89]
per-ex loss: 0.678572  [   40/   89]
per-ex loss: 0.715753  [   42/   89]
per-ex loss: 0.655044  [   44/   89]
per-ex loss: 0.666309  [   46/   89]
per-ex loss: 0.712025  [   48/   89]
per-ex loss: 0.852984  [   50/   89]
per-ex loss: 0.827946  [   52/   89]
per-ex loss: 0.722135  [   54/   89]
per-ex loss: 0.640320  [   56/   89]
per-ex loss: 0.621357  [   58/   89]
per-ex loss: 0.751256  [   60/   89]
per-ex loss: 0.629173  [   62/   89]
per-ex loss: 0.863095  [   64/   89]
per-ex loss: 0.871956  [   66/   89]
per-ex loss: 0.693970  [   68/   89]
per-ex loss: 0.715920  [   70/   89]
per-ex loss: 0.710431  [   72/   89]
per-ex loss: 0.698771  [   74/   89]
per-ex loss: 0.860477  [   76/   89]
per-ex loss: 0.754548  [   78/   89]
per-ex loss: 0.625154  [   80/   89]
per-ex loss: 0.650398  [   82/   89]
per-ex loss: 0.893188  [   84/   89]
per-ex loss: 0.648466  [   86/   89]
per-ex loss: 0.549093  [   88/   89]
per-ex loss: 0.659269  [   89/   89]
Train Error: Avg loss: 0.71663239
validation Error: 
 Avg loss: 0.79763640 
 F1: 0.455861 
 Precision: 0.743271 
 Recall: 0.328742
 IoU: 0.295220

test Error: 
 Avg loss: 0.78600630 
 F1: 0.461539 
 Precision: 0.759910 
 Recall: 0.331413
 IoU: 0.300000

We have finished training iteration 101
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_99_.pth
per-ex loss: 0.767573  [    2/   89]
per-ex loss: 0.818507  [    4/   89]
per-ex loss: 0.640934  [    6/   89]
per-ex loss: 0.682523  [    8/   89]
per-ex loss: 0.769175  [   10/   89]
per-ex loss: 0.769606  [   12/   89]
per-ex loss: 0.768767  [   14/   89]
per-ex loss: 0.607860  [   16/   89]
per-ex loss: 0.570187  [   18/   89]
per-ex loss: 0.660553  [   20/   89]
per-ex loss: 0.703789  [   22/   89]
per-ex loss: 0.488572  [   24/   89]
per-ex loss: 0.636664  [   26/   89]
per-ex loss: 0.819195  [   28/   89]
per-ex loss: 0.775842  [   30/   89]
per-ex loss: 0.783160  [   32/   89]
per-ex loss: 0.823625  [   34/   89]
per-ex loss: 0.688115  [   36/   89]
per-ex loss: 0.819745  [   38/   89]
per-ex loss: 0.743331  [   40/   89]
per-ex loss: 0.614473  [   42/   89]
per-ex loss: 0.750671  [   44/   89]
per-ex loss: 0.692848  [   46/   89]
per-ex loss: 0.781349  [   48/   89]
per-ex loss: 0.472179  [   50/   89]
per-ex loss: 0.751060  [   52/   89]
per-ex loss: 0.729228  [   54/   89]
per-ex loss: 0.752101  [   56/   89]
per-ex loss: 0.691272  [   58/   89]
per-ex loss: 0.638664  [   60/   89]
per-ex loss: 0.885316  [   62/   89]
per-ex loss: 0.747609  [   64/   89]
per-ex loss: 0.574450  [   66/   89]
per-ex loss: 0.795654  [   68/   89]
per-ex loss: 0.699592  [   70/   89]
per-ex loss: 0.660435  [   72/   89]
per-ex loss: 0.879623  [   74/   89]
per-ex loss: 0.629530  [   76/   89]
per-ex loss: 0.580698  [   78/   89]
per-ex loss: 0.580278  [   80/   89]
per-ex loss: 0.672775  [   82/   89]
per-ex loss: 0.537077  [   84/   89]
per-ex loss: 0.782021  [   86/   89]
per-ex loss: 0.689371  [   88/   89]
per-ex loss: 0.909333  [   89/   89]
Train Error: Avg loss: 0.70745181
validation Error: 
 Avg loss: 0.78327373 
 F1: 0.465868 
 Precision: 0.713557 
 Recall: 0.345826
 IoU: 0.303669

test Error: 
 Avg loss: 0.77858991 
 F1: 0.489979 
 Precision: 0.727653 
 Recall: 0.369340
 IoU: 0.324484

We have finished training iteration 102
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_100_.pth
per-ex loss: 0.793022  [    2/   89]
per-ex loss: 0.475956  [    4/   89]
per-ex loss: 0.758810  [    6/   89]
per-ex loss: 0.806285  [    8/   89]
per-ex loss: 0.925473  [   10/   89]
per-ex loss: 0.658846  [   12/   89]
per-ex loss: 0.622258  [   14/   89]
per-ex loss: 0.749545  [   16/   89]
per-ex loss: 0.554568  [   18/   89]
per-ex loss: 0.778233  [   20/   89]
per-ex loss: 0.568636  [   22/   89]
per-ex loss: 0.763462  [   24/   89]
per-ex loss: 0.765050  [   26/   89]
per-ex loss: 0.664856  [   28/   89]
per-ex loss: 0.836806  [   30/   89]
per-ex loss: 0.733468  [   32/   89]
per-ex loss: 0.659097  [   34/   89]
per-ex loss: 0.699014  [   36/   89]
per-ex loss: 0.807907  [   38/   89]
per-ex loss: 0.698633  [   40/   89]
per-ex loss: 0.512533  [   42/   89]
per-ex loss: 0.863442  [   44/   89]
per-ex loss: 0.744635  [   46/   89]
per-ex loss: 0.655535  [   48/   89]
per-ex loss: 0.678547  [   50/   89]
per-ex loss: 0.729703  [   52/   89]
per-ex loss: 0.697839  [   54/   89]
per-ex loss: 0.622147  [   56/   89]
per-ex loss: 0.802047  [   58/   89]
per-ex loss: 0.737585  [   60/   89]
per-ex loss: 0.630188  [   62/   89]
per-ex loss: 0.714060  [   64/   89]
per-ex loss: 0.694578  [   66/   89]
per-ex loss: 0.705138  [   68/   89]
per-ex loss: 0.782592  [   70/   89]
per-ex loss: 0.655340  [   72/   89]
per-ex loss: 0.717892  [   74/   89]
per-ex loss: 0.634650  [   76/   89]
per-ex loss: 0.753293  [   78/   89]
per-ex loss: 0.819235  [   80/   89]
per-ex loss: 0.655686  [   82/   89]
per-ex loss: 0.630332  [   84/   89]
per-ex loss: 0.816804  [   86/   89]
per-ex loss: 0.655187  [   88/   89]
per-ex loss: 0.619370  [   89/   89]
Train Error: Avg loss: 0.70773966
validation Error: 
 Avg loss: 0.80155585 
 F1: 0.367482 
 Precision: 0.877694 
 Recall: 0.232391
 IoU: 0.225101

test Error: 
 Avg loss: 0.79795045 
 F1: 0.359370 
 Precision: 0.888354 
 Recall: 0.225245
 IoU: 0.219044

We have finished training iteration 103
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_101_.pth
per-ex loss: 0.787243  [    2/   89]
per-ex loss: 0.701054  [    4/   89]
per-ex loss: 0.582507  [    6/   89]
per-ex loss: 0.499837  [    8/   89]
per-ex loss: 0.676909  [   10/   89]
per-ex loss: 0.458411  [   12/   89]
per-ex loss: 0.800870  [   14/   89]
per-ex loss: 0.659765  [   16/   89]
per-ex loss: 0.870637  [   18/   89]
per-ex loss: 0.843145  [   20/   89]
per-ex loss: 0.501400  [   22/   89]
per-ex loss: 0.630017  [   24/   89]
per-ex loss: 0.799180  [   26/   89]
per-ex loss: 0.808701  [   28/   89]
per-ex loss: 0.738737  [   30/   89]
per-ex loss: 0.755901  [   32/   89]
per-ex loss: 0.574108  [   34/   89]
per-ex loss: 0.811752  [   36/   89]
per-ex loss: 0.692041  [   38/   89]
per-ex loss: 0.849638  [   40/   89]
per-ex loss: 0.686904  [   42/   89]
per-ex loss: 0.725220  [   44/   89]
per-ex loss: 0.678632  [   46/   89]
per-ex loss: 0.665099  [   48/   89]
per-ex loss: 0.644923  [   50/   89]
per-ex loss: 0.820939  [   52/   89]
per-ex loss: 0.664468  [   54/   89]
per-ex loss: 0.774487  [   56/   89]
per-ex loss: 0.771230  [   58/   89]
per-ex loss: 0.839762  [   60/   89]
per-ex loss: 0.553563  [   62/   89]
per-ex loss: 0.713917  [   64/   89]
per-ex loss: 0.673548  [   66/   89]
per-ex loss: 0.691951  [   68/   89]
per-ex loss: 0.798900  [   70/   89]
per-ex loss: 0.883682  [   72/   89]
per-ex loss: 0.649905  [   74/   89]
per-ex loss: 0.685987  [   76/   89]
per-ex loss: 0.530465  [   78/   89]
per-ex loss: 0.761654  [   80/   89]
per-ex loss: 0.643817  [   82/   89]
per-ex loss: 0.788045  [   84/   89]
per-ex loss: 0.801886  [   86/   89]
per-ex loss: 0.618336  [   88/   89]
per-ex loss: 0.636547  [   89/   89]
Train Error: Avg loss: 0.70546043
validation Error: 
 Avg loss: 0.79492668 
 F1: 0.484521 
 Precision: 0.683369 
 Recall: 0.375312
 IoU: 0.319715

test Error: 
 Avg loss: 0.77833915 
 F1: 0.510371 
 Precision: 0.694451 
 Recall: 0.403431
 IoU: 0.342616

We have finished training iteration 104
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_102_.pth
per-ex loss: 0.599498  [    2/   89]
per-ex loss: 0.814482  [    4/   89]
per-ex loss: 0.760853  [    6/   89]
per-ex loss: 0.571091  [    8/   89]
per-ex loss: 0.801590  [   10/   89]
per-ex loss: 0.673694  [   12/   89]
per-ex loss: 0.669092  [   14/   89]
per-ex loss: 0.638976  [   16/   89]
per-ex loss: 0.477663  [   18/   89]
per-ex loss: 0.775552  [   20/   89]
per-ex loss: 0.827183  [   22/   89]
per-ex loss: 0.674568  [   24/   89]
per-ex loss: 0.685119  [   26/   89]
per-ex loss: 0.723728  [   28/   89]
per-ex loss: 0.820354  [   30/   89]
per-ex loss: 0.684993  [   32/   89]
per-ex loss: 0.639909  [   34/   89]
per-ex loss: 0.714263  [   36/   89]
per-ex loss: 0.718222  [   38/   89]
per-ex loss: 0.715206  [   40/   89]
per-ex loss: 0.494767  [   42/   89]
per-ex loss: 0.609945  [   44/   89]
per-ex loss: 0.867338  [   46/   89]
per-ex loss: 0.796647  [   48/   89]
per-ex loss: 0.702337  [   50/   89]
per-ex loss: 0.642170  [   52/   89]
per-ex loss: 0.679969  [   54/   89]
per-ex loss: 0.633025  [   56/   89]
per-ex loss: 0.759298  [   58/   89]
per-ex loss: 0.736170  [   60/   89]
per-ex loss: 0.776429  [   62/   89]
per-ex loss: 0.784982  [   64/   89]
per-ex loss: 0.731899  [   66/   89]
per-ex loss: 0.685320  [   68/   89]
per-ex loss: 0.643361  [   70/   89]
per-ex loss: 0.601394  [   72/   89]
per-ex loss: 0.712807  [   74/   89]
per-ex loss: 0.697974  [   76/   89]
per-ex loss: 0.815711  [   78/   89]
per-ex loss: 0.819212  [   80/   89]
per-ex loss: 0.630981  [   82/   89]
per-ex loss: 0.675848  [   84/   89]
per-ex loss: 0.812754  [   86/   89]
per-ex loss: 0.770696  [   88/   89]
per-ex loss: 0.803481  [   89/   89]
Train Error: Avg loss: 0.70823438
validation Error: 
 Avg loss: 0.78730496 
 F1: 0.466333 
 Precision: 0.731482 
 Recall: 0.342267
 IoU: 0.304064

test Error: 
 Avg loss: 0.77867440 
 F1: 0.472231 
 Precision: 0.724759 
 Recall: 0.350208
 IoU: 0.309099

We have finished training iteration 105
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_103_.pth
per-ex loss: 0.873303  [    2/   89]
per-ex loss: 0.778683  [    4/   89]
per-ex loss: 0.710042  [    6/   89]
per-ex loss: 0.659945  [    8/   89]
per-ex loss: 0.554551  [   10/   89]
per-ex loss: 0.641652  [   12/   89]
per-ex loss: 0.678829  [   14/   89]
per-ex loss: 0.692242  [   16/   89]
per-ex loss: 0.665627  [   18/   89]
per-ex loss: 0.636676  [   20/   89]
per-ex loss: 0.667877  [   22/   89]
per-ex loss: 0.883386  [   24/   89]
per-ex loss: 0.694499  [   26/   89]
per-ex loss: 0.765184  [   28/   89]
per-ex loss: 0.710825  [   30/   89]
per-ex loss: 0.667669  [   32/   89]
per-ex loss: 0.744871  [   34/   89]
per-ex loss: 0.560394  [   36/   89]
per-ex loss: 0.808924  [   38/   89]
per-ex loss: 0.704345  [   40/   89]
per-ex loss: 0.879057  [   42/   89]
per-ex loss: 0.664555  [   44/   89]
per-ex loss: 0.664152  [   46/   89]
per-ex loss: 0.737103  [   48/   89]
per-ex loss: 0.770972  [   50/   89]
per-ex loss: 0.823857  [   52/   89]
per-ex loss: 0.800712  [   54/   89]
per-ex loss: 0.654408  [   56/   89]
per-ex loss: 0.796627  [   58/   89]
per-ex loss: 0.697834  [   60/   89]
per-ex loss: 0.793394  [   62/   89]
per-ex loss: 0.895687  [   64/   89]
per-ex loss: 0.647060  [   66/   89]
per-ex loss: 0.782045  [   68/   89]
per-ex loss: 0.629946  [   70/   89]
per-ex loss: 0.608348  [   72/   89]
per-ex loss: 0.781901  [   74/   89]
per-ex loss: 0.599685  [   76/   89]
per-ex loss: 0.831700  [   78/   89]
per-ex loss: 0.490606  [   80/   89]
per-ex loss: 0.577955  [   82/   89]
per-ex loss: 0.648676  [   84/   89]
per-ex loss: 0.566252  [   86/   89]
per-ex loss: 0.686616  [   88/   89]
per-ex loss: 0.769351  [   89/   89]
Train Error: Avg loss: 0.70884495
validation Error: 
 Avg loss: 0.77638581 
 F1: 0.450037 
 Precision: 0.786474 
 Recall: 0.315201
 IoU: 0.290353

test Error: 
 Avg loss: 0.76663464 
 F1: 0.461303 
 Precision: 0.775528 
 Recall: 0.328288
 IoU: 0.299801

We have finished training iteration 106
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_104_.pth
per-ex loss: 0.770100  [    2/   89]
per-ex loss: 0.747183  [    4/   89]
per-ex loss: 0.641270  [    6/   89]
per-ex loss: 0.766170  [    8/   89]
per-ex loss: 0.743962  [   10/   89]
per-ex loss: 0.739684  [   12/   89]
per-ex loss: 0.831997  [   14/   89]
per-ex loss: 0.650240  [   16/   89]
per-ex loss: 0.552542  [   18/   89]
per-ex loss: 0.689090  [   20/   89]
per-ex loss: 0.691611  [   22/   89]
per-ex loss: 0.621892  [   24/   89]
per-ex loss: 0.703318  [   26/   89]
per-ex loss: 0.729189  [   28/   89]
per-ex loss: 0.793261  [   30/   89]
per-ex loss: 0.633072  [   32/   89]
per-ex loss: 0.568926  [   34/   89]
per-ex loss: 0.652430  [   36/   89]
per-ex loss: 0.753519  [   38/   89]
per-ex loss: 0.789724  [   40/   89]
per-ex loss: 0.609329  [   42/   89]
per-ex loss: 0.722969  [   44/   89]
per-ex loss: 0.733717  [   46/   89]
per-ex loss: 0.664198  [   48/   89]
per-ex loss: 0.719387  [   50/   89]
per-ex loss: 0.582824  [   52/   89]
per-ex loss: 0.693907  [   54/   89]
per-ex loss: 0.756530  [   56/   89]
per-ex loss: 0.676786  [   58/   89]
per-ex loss: 0.667859  [   60/   89]
per-ex loss: 0.610286  [   62/   89]
per-ex loss: 0.696903  [   64/   89]
per-ex loss: 0.524549  [   66/   89]
per-ex loss: 0.605739  [   68/   89]
per-ex loss: 0.682406  [   70/   89]
per-ex loss: 0.883812  [   72/   89]
per-ex loss: 0.607315  [   74/   89]
per-ex loss: 0.607057  [   76/   89]
per-ex loss: 0.526228  [   78/   89]
per-ex loss: 0.710811  [   80/   89]
per-ex loss: 0.703582  [   82/   89]
per-ex loss: 0.819350  [   84/   89]
per-ex loss: 0.564159  [   86/   89]
per-ex loss: 0.652359  [   88/   89]
per-ex loss: 0.759764  [   89/   89]
Train Error: Avg loss: 0.68557787
validation Error: 
 Avg loss: 0.77836327 
 F1: 0.493746 
 Precision: 0.687069 
 Recall: 0.385325
 IoU: 0.327797

test Error: 
 Avg loss: 0.76611524 
 F1: 0.523264 
 Precision: 0.697486 
 Recall: 0.418684
 IoU: 0.354339

We have finished training iteration 107
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_105_.pth
per-ex loss: 0.804924  [    2/   89]
per-ex loss: 0.723184  [    4/   89]
per-ex loss: 0.879889  [    6/   89]
per-ex loss: 0.739853  [    8/   89]
per-ex loss: 0.611456  [   10/   89]
per-ex loss: 0.543611  [   12/   89]
per-ex loss: 0.805569  [   14/   89]
per-ex loss: 0.508345  [   16/   89]
per-ex loss: 0.659651  [   18/   89]
per-ex loss: 0.533552  [   20/   89]
per-ex loss: 0.854122  [   22/   89]
per-ex loss: 0.874348  [   24/   89]
per-ex loss: 0.490440  [   26/   89]
per-ex loss: 0.769417  [   28/   89]
per-ex loss: 0.805788  [   30/   89]
per-ex loss: 0.683853  [   32/   89]
per-ex loss: 0.646261  [   34/   89]
per-ex loss: 0.504303  [   36/   89]
per-ex loss: 0.667231  [   38/   89]
per-ex loss: 0.828524  [   40/   89]
per-ex loss: 0.752147  [   42/   89]
per-ex loss: 0.657430  [   44/   89]
per-ex loss: 0.602787  [   46/   89]
per-ex loss: 0.753066  [   48/   89]
per-ex loss: 0.590229  [   50/   89]
per-ex loss: 0.790633  [   52/   89]
per-ex loss: 0.778342  [   54/   89]
per-ex loss: 0.763433  [   56/   89]
per-ex loss: 0.758694  [   58/   89]
per-ex loss: 0.570744  [   60/   89]
per-ex loss: 0.591344  [   62/   89]
per-ex loss: 0.690197  [   64/   89]
per-ex loss: 0.685677  [   66/   89]
per-ex loss: 0.498498  [   68/   89]
per-ex loss: 0.668608  [   70/   89]
per-ex loss: 0.663661  [   72/   89]
per-ex loss: 0.820790  [   74/   89]
per-ex loss: 0.541883  [   76/   89]
per-ex loss: 0.672183  [   78/   89]
per-ex loss: 0.820547  [   80/   89]
per-ex loss: 0.558672  [   82/   89]
per-ex loss: 0.697084  [   84/   89]
per-ex loss: 0.798719  [   86/   89]
per-ex loss: 0.763048  [   88/   89]
per-ex loss: 0.771036  [   89/   89]
Train Error: Avg loss: 0.69319489
validation Error: 
 Avg loss: 0.78334848 
 F1: 0.391370 
 Precision: 0.836712 
 Recall: 0.255421
 IoU: 0.243294

test Error: 
 Avg loss: 0.78060549 
 F1: 0.390849 
 Precision: 0.844965 
 Recall: 0.254221
 IoU: 0.242892

We have finished training iteration 108
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_106_.pth
per-ex loss: 0.831024  [    2/   89]
per-ex loss: 0.665173  [    4/   89]
per-ex loss: 0.874802  [    6/   89]
per-ex loss: 0.486636  [    8/   89]
per-ex loss: 0.731362  [   10/   89]
per-ex loss: 0.660070  [   12/   89]
per-ex loss: 0.623468  [   14/   89]
per-ex loss: 0.740695  [   16/   89]
per-ex loss: 0.658824  [   18/   89]
per-ex loss: 0.683917  [   20/   89]
per-ex loss: 0.735582  [   22/   89]
per-ex loss: 0.636288  [   24/   89]
per-ex loss: 0.597097  [   26/   89]
per-ex loss: 0.676862  [   28/   89]
per-ex loss: 0.807523  [   30/   89]
per-ex loss: 0.512079  [   32/   89]
per-ex loss: 0.649047  [   34/   89]
per-ex loss: 0.681867  [   36/   89]
per-ex loss: 0.747185  [   38/   89]
per-ex loss: 0.834447  [   40/   89]
per-ex loss: 0.815740  [   42/   89]
per-ex loss: 0.834812  [   44/   89]
per-ex loss: 0.566197  [   46/   89]
per-ex loss: 0.469858  [   48/   89]
per-ex loss: 0.685016  [   50/   89]
per-ex loss: 0.593990  [   52/   89]
per-ex loss: 0.800489  [   54/   89]
per-ex loss: 0.605112  [   56/   89]
per-ex loss: 0.659452  [   58/   89]
per-ex loss: 0.604883  [   60/   89]
per-ex loss: 0.656851  [   62/   89]
per-ex loss: 0.752841  [   64/   89]
per-ex loss: 0.537198  [   66/   89]
per-ex loss: 0.798571  [   68/   89]
per-ex loss: 0.616655  [   70/   89]
per-ex loss: 0.806256  [   72/   89]
per-ex loss: 0.706300  [   74/   89]
per-ex loss: 0.801970  [   76/   89]
per-ex loss: 0.789645  [   78/   89]
per-ex loss: 0.595041  [   80/   89]
per-ex loss: 0.792838  [   82/   89]
per-ex loss: 0.814692  [   84/   89]
per-ex loss: 0.679932  [   86/   89]
per-ex loss: 0.724459  [   88/   89]
per-ex loss: 0.767923  [   89/   89]
Train Error: Avg loss: 0.69579267
validation Error: 
 Avg loss: 0.77361184 
 F1: 0.480456 
 Precision: 0.708464 
 Recall: 0.363476
 IoU: 0.316184

test Error: 
 Avg loss: 0.76107305 
 F1: 0.499666 
 Precision: 0.723810 
 Recall: 0.381520
 IoU: 0.333037

We have finished training iteration 109
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_107_.pth
per-ex loss: 0.637158  [    2/   89]
per-ex loss: 0.513406  [    4/   89]
per-ex loss: 0.647269  [    6/   89]
per-ex loss: 0.682689  [    8/   89]
per-ex loss: 0.713686  [   10/   89]
per-ex loss: 0.706859  [   12/   89]
per-ex loss: 0.572907  [   14/   89]
per-ex loss: 0.789619  [   16/   89]
per-ex loss: 0.738413  [   18/   89]
per-ex loss: 0.895788  [   20/   89]
per-ex loss: 0.696202  [   22/   89]
per-ex loss: 0.741733  [   24/   89]
per-ex loss: 0.571436  [   26/   89]
per-ex loss: 0.848760  [   28/   89]
per-ex loss: 0.784462  [   30/   89]
per-ex loss: 0.799093  [   32/   89]
per-ex loss: 0.764057  [   34/   89]
per-ex loss: 0.556739  [   36/   89]
per-ex loss: 0.834620  [   38/   89]
per-ex loss: 0.546500  [   40/   89]
per-ex loss: 0.640998  [   42/   89]
per-ex loss: 0.603930  [   44/   89]
per-ex loss: 0.552938  [   46/   89]
per-ex loss: 0.619283  [   48/   89]
per-ex loss: 0.515357  [   50/   89]
per-ex loss: 0.519135  [   52/   89]
per-ex loss: 0.632006  [   54/   89]
per-ex loss: 0.727254  [   56/   89]
per-ex loss: 0.730270  [   58/   89]
per-ex loss: 0.732632  [   60/   89]
per-ex loss: 0.862419  [   62/   89]
per-ex loss: 0.522647  [   64/   89]
per-ex loss: 0.659319  [   66/   89]
per-ex loss: 0.887758  [   68/   89]
per-ex loss: 0.780906  [   70/   89]
per-ex loss: 0.499742  [   72/   89]
per-ex loss: 0.740015  [   74/   89]
per-ex loss: 0.681184  [   76/   89]
per-ex loss: 0.674785  [   78/   89]
per-ex loss: 0.575938  [   80/   89]
per-ex loss: 0.749347  [   82/   89]
per-ex loss: 0.679047  [   84/   89]
per-ex loss: 0.761099  [   86/   89]
per-ex loss: 0.687004  [   88/   89]
per-ex loss: 0.895564  [   89/   89]
Train Error: Avg loss: 0.68826607
validation Error: 
 Avg loss: 0.76523620 
 F1: 0.461501 
 Precision: 0.756552 
 Recall: 0.332016
 IoU: 0.299968

test Error: 
 Avg loss: 0.75825348 
 F1: 0.483381 
 Precision: 0.785242 
 Recall: 0.349158
 IoU: 0.318723

We have finished training iteration 110
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_108_.pth
per-ex loss: 0.854059  [    2/   89]
per-ex loss: 0.835889  [    4/   89]
per-ex loss: 0.669763  [    6/   89]
per-ex loss: 0.778672  [    8/   89]
per-ex loss: 0.626131  [   10/   89]
per-ex loss: 0.716192  [   12/   89]
per-ex loss: 0.716319  [   14/   89]
per-ex loss: 0.693614  [   16/   89]
per-ex loss: 0.706594  [   18/   89]
per-ex loss: 0.803304  [   20/   89]
per-ex loss: 0.736183  [   22/   89]
per-ex loss: 0.666728  [   24/   89]
per-ex loss: 0.867953  [   26/   89]
per-ex loss: 0.637890  [   28/   89]
per-ex loss: 0.863616  [   30/   89]
per-ex loss: 0.634407  [   32/   89]
per-ex loss: 0.600749  [   34/   89]
per-ex loss: 0.803598  [   36/   89]
per-ex loss: 0.683447  [   38/   89]
per-ex loss: 0.635294  [   40/   89]
per-ex loss: 0.646111  [   42/   89]
per-ex loss: 0.451792  [   44/   89]
per-ex loss: 0.797691  [   46/   89]
per-ex loss: 0.497702  [   48/   89]
per-ex loss: 0.509428  [   50/   89]
per-ex loss: 0.617282  [   52/   89]
per-ex loss: 0.696917  [   54/   89]
per-ex loss: 0.488007  [   56/   89]
per-ex loss: 0.638606  [   58/   89]
per-ex loss: 0.602527  [   60/   89]
per-ex loss: 0.844874  [   62/   89]
per-ex loss: 0.748175  [   64/   89]
per-ex loss: 0.630976  [   66/   89]
per-ex loss: 0.813323  [   68/   89]
per-ex loss: 0.668941  [   70/   89]
per-ex loss: 0.576853  [   72/   89]
per-ex loss: 0.598013  [   74/   89]
per-ex loss: 0.467777  [   76/   89]
per-ex loss: 0.806458  [   78/   89]
per-ex loss: 0.785821  [   80/   89]
per-ex loss: 0.761235  [   82/   89]
per-ex loss: 0.599097  [   84/   89]
per-ex loss: 0.763648  [   86/   89]
per-ex loss: 0.590737  [   88/   89]
per-ex loss: 0.863041  [   89/   89]
Train Error: Avg loss: 0.68878736
validation Error: 
 Avg loss: 0.78119912 
 F1: 0.413570 
 Precision: 0.813268 
 Recall: 0.277290
 IoU: 0.260692

test Error: 
 Avg loss: 0.77173764 
 F1: 0.409771 
 Precision: 0.820976 
 Recall: 0.273022
 IoU: 0.257680

We have finished training iteration 111
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_109_.pth
Error in cropping the image to the non-zero values in the fourth channel. Returned the original image.
per-ex loss: 0.655499  [    2/   89]
per-ex loss: 0.813529  [    4/   89]
per-ex loss: 0.645389  [    6/   89]
per-ex loss: 0.792684  [    8/   89]
per-ex loss: 0.575970  [   10/   89]
per-ex loss: 0.774822  [   12/   89]
per-ex loss: 0.668214  [   14/   89]
per-ex loss: 0.688026  [   16/   89]
per-ex loss: 0.645143  [   18/   89]
per-ex loss: 0.667266  [   20/   89]
per-ex loss: 0.826368  [   22/   89]
per-ex loss: 0.708567  [   24/   89]
per-ex loss: 0.882257  [   26/   89]
per-ex loss: 0.759704  [   28/   89]
per-ex loss: 0.598892  [   30/   89]
per-ex loss: 0.674522  [   32/   89]
per-ex loss: 0.604686  [   34/   89]
per-ex loss: 0.647318  [   36/   89]
per-ex loss: 0.783049  [   38/   89]
per-ex loss: 0.585774  [   40/   89]
per-ex loss: 0.744387  [   42/   89]
per-ex loss: 0.665942  [   44/   89]
per-ex loss: 0.586622  [   46/   89]
per-ex loss: 0.788557  [   48/   89]
per-ex loss: 0.838013  [   50/   89]
per-ex loss: 0.483301  [   52/   89]
per-ex loss: 0.676324  [   54/   89]
per-ex loss: 0.661184  [   56/   89]
per-ex loss: 0.776098  [   58/   89]
per-ex loss: 0.656113  [   60/   89]
per-ex loss: 0.525303  [   62/   89]
per-ex loss: 0.749302  [   64/   89]
per-ex loss: 0.638166  [   66/   89]
per-ex loss: 0.832598  [   68/   89]
per-ex loss: 0.720963  [   70/   89]
per-ex loss: 0.531571  [   72/   89]
per-ex loss: 0.783641  [   74/   89]
per-ex loss: 0.770161  [   76/   89]
per-ex loss: 0.640600  [   78/   89]
per-ex loss: 0.602984  [   80/   89]
per-ex loss: 0.582415  [   82/   89]
per-ex loss: 0.710652  [   84/   89]
per-ex loss: 0.741013  [   86/   89]
per-ex loss: 0.774469  [   88/   89]
per-ex loss: 0.676527  [   89/   89]
Train Error: Avg loss: 0.69232411
validation Error: 
 Avg loss: 0.76021355 
 F1: 0.459562 
 Precision: 0.760432 
 Recall: 0.329280
 IoU: 0.298332

test Error: 
 Avg loss: 0.76500891 
 F1: 0.460046 
 Precision: 0.726774 
 Recall: 0.336536
 IoU: 0.298740

We have finished training iteration 112
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_110_.pth
per-ex loss: 0.702806  [    2/   89]
per-ex loss: 0.771549  [    4/   89]
per-ex loss: 0.647977  [    6/   89]
per-ex loss: 0.696708  [    8/   89]
per-ex loss: 0.711036  [   10/   89]
per-ex loss: 0.702556  [   12/   89]
per-ex loss: 0.825314  [   14/   89]
per-ex loss: 0.856926  [   16/   89]
per-ex loss: 0.610697  [   18/   89]
per-ex loss: 0.680340  [   20/   89]
per-ex loss: 0.595558  [   22/   89]
per-ex loss: 0.710030  [   24/   89]
per-ex loss: 0.819530  [   26/   89]
per-ex loss: 0.782846  [   28/   89]
per-ex loss: 0.680660  [   30/   89]
per-ex loss: 0.724092  [   32/   89]
per-ex loss: 0.670222  [   34/   89]
per-ex loss: 0.646323  [   36/   89]
per-ex loss: 0.683489  [   38/   89]
per-ex loss: 0.801813  [   40/   89]
per-ex loss: 0.500633  [   42/   89]
per-ex loss: 0.632570  [   44/   89]
per-ex loss: 0.630102  [   46/   89]
per-ex loss: 0.723136  [   48/   89]
per-ex loss: 0.742172  [   50/   89]
per-ex loss: 0.662140  [   52/   89]
per-ex loss: 0.590738  [   54/   89]
per-ex loss: 0.644492  [   56/   89]
per-ex loss: 0.621632  [   58/   89]
per-ex loss: 0.727247  [   60/   89]
per-ex loss: 0.810926  [   62/   89]
per-ex loss: 0.581258  [   64/   89]
per-ex loss: 0.771501  [   66/   89]
per-ex loss: 0.711433  [   68/   89]
per-ex loss: 0.722250  [   70/   89]
per-ex loss: 0.548772  [   72/   89]
per-ex loss: 0.846440  [   74/   89]
per-ex loss: 0.760346  [   76/   89]
per-ex loss: 0.573579  [   78/   89]
per-ex loss: 0.638586  [   80/   89]
per-ex loss: 0.581652  [   82/   89]
per-ex loss: 0.670290  [   84/   89]
per-ex loss: 0.609711  [   86/   89]
per-ex loss: 0.643433  [   88/   89]
per-ex loss: 0.804395  [   89/   89]
Train Error: Avg loss: 0.69044233
validation Error: 
 Avg loss: 0.76424476 
 F1: 0.482696 
 Precision: 0.698114 
 Recall: 0.368872
 IoU: 0.318127

test Error: 
 Avg loss: 0.75036738 
 F1: 0.501256 
 Precision: 0.723264 
 Recall: 0.383530
 IoU: 0.334451

We have finished training iteration 113
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_111_.pth
per-ex loss: 0.583598  [    2/   89]
per-ex loss: 0.776986  [    4/   89]
per-ex loss: 0.849453  [    6/   89]
per-ex loss: 0.566139  [    8/   89]
per-ex loss: 0.816784  [   10/   89]
per-ex loss: 0.753821  [   12/   89]
per-ex loss: 0.748241  [   14/   89]
per-ex loss: 0.888188  [   16/   89]
per-ex loss: 0.787771  [   18/   89]
per-ex loss: 0.745060  [   20/   89]
per-ex loss: 0.723664  [   22/   89]
per-ex loss: 0.720687  [   24/   89]
per-ex loss: 0.568328  [   26/   89]
per-ex loss: 0.618002  [   28/   89]
per-ex loss: 0.606918  [   30/   89]
per-ex loss: 0.700270  [   32/   89]
per-ex loss: 0.747320  [   34/   89]
per-ex loss: 0.651489  [   36/   89]
per-ex loss: 0.786198  [   38/   89]
per-ex loss: 0.575325  [   40/   89]
per-ex loss: 0.803359  [   42/   89]
per-ex loss: 0.619622  [   44/   89]
per-ex loss: 0.798961  [   46/   89]
per-ex loss: 0.546463  [   48/   89]
per-ex loss: 0.448167  [   50/   89]
per-ex loss: 0.645588  [   52/   89]
per-ex loss: 0.555882  [   54/   89]
per-ex loss: 0.624386  [   56/   89]
per-ex loss: 0.600140  [   58/   89]
per-ex loss: 0.720527  [   60/   89]
per-ex loss: 0.710513  [   62/   89]
per-ex loss: 0.769697  [   64/   89]
per-ex loss: 0.567297  [   66/   89]
per-ex loss: 0.777577  [   68/   89]
per-ex loss: 0.603467  [   70/   89]
per-ex loss: 0.877911  [   72/   89]
per-ex loss: 0.615552  [   74/   89]
per-ex loss: 0.690721  [   76/   89]
per-ex loss: 0.593550  [   78/   89]
per-ex loss: 0.810313  [   80/   89]
per-ex loss: 0.738454  [   82/   89]
per-ex loss: 0.704761  [   84/   89]
per-ex loss: 0.706361  [   86/   89]
per-ex loss: 0.509482  [   88/   89]
per-ex loss: 0.994785  [   89/   89]
Train Error: Avg loss: 0.69439507
validation Error: 
 Avg loss: 0.76630508 
 F1: 0.446817 
 Precision: 0.749872 
 Recall: 0.318213
 IoU: 0.287678

test Error: 
 Avg loss: 0.76065533 
 F1: 0.459526 
 Precision: 0.758594 
 Recall: 0.329589
 IoU: 0.298302

We have finished training iteration 114
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_112_.pth
per-ex loss: 0.751369  [    2/   89]
per-ex loss: 0.642362  [    4/   89]
per-ex loss: 0.669963  [    6/   89]
per-ex loss: 0.714256  [    8/   89]
per-ex loss: 0.756480  [   10/   89]
per-ex loss: 0.818505  [   12/   89]
per-ex loss: 0.609537  [   14/   89]
per-ex loss: 0.743349  [   16/   89]
per-ex loss: 0.484892  [   18/   89]
per-ex loss: 0.573542  [   20/   89]
per-ex loss: 0.746280  [   22/   89]
per-ex loss: 0.579753  [   24/   89]
per-ex loss: 0.774821  [   26/   89]
per-ex loss: 0.652231  [   28/   89]
per-ex loss: 0.696526  [   30/   89]
per-ex loss: 0.775481  [   32/   89]
per-ex loss: 0.675301  [   34/   89]
per-ex loss: 0.652317  [   36/   89]
per-ex loss: 0.666708  [   38/   89]
per-ex loss: 0.832785  [   40/   89]
per-ex loss: 0.642191  [   42/   89]
per-ex loss: 0.560616  [   44/   89]
per-ex loss: 0.611084  [   46/   89]
per-ex loss: 0.727143  [   48/   89]
per-ex loss: 0.703520  [   50/   89]
per-ex loss: 0.714628  [   52/   89]
per-ex loss: 0.688644  [   54/   89]
per-ex loss: 0.860219  [   56/   89]
per-ex loss: 0.814899  [   58/   89]
per-ex loss: 0.741495  [   60/   89]
per-ex loss: 0.616551  [   62/   89]
per-ex loss: 0.533126  [   64/   89]
per-ex loss: 0.523503  [   66/   89]
per-ex loss: 0.601591  [   68/   89]
per-ex loss: 0.673158  [   70/   89]
per-ex loss: 0.853230  [   72/   89]
per-ex loss: 0.822206  [   74/   89]
per-ex loss: 0.622446  [   76/   89]
per-ex loss: 0.524704  [   78/   89]
per-ex loss: 0.652470  [   80/   89]
per-ex loss: 0.567942  [   82/   89]
per-ex loss: 0.526277  [   84/   89]
per-ex loss: 0.767863  [   86/   89]
per-ex loss: 0.531966  [   88/   89]
per-ex loss: 0.777943  [   89/   89]
Train Error: Avg loss: 0.67724166
validation Error: 
 Avg loss: 0.76110516 
 F1: 0.474545 
 Precision: 0.736665 
 Recall: 0.350006
 IoU: 0.311085

test Error: 
 Avg loss: 0.73682887 
 F1: 0.499134 
 Precision: 0.753134 
 Recall: 0.373252
 IoU: 0.332564

We have finished training iteration 115
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_113_.pth
per-ex loss: 0.765860  [    2/   89]
per-ex loss: 0.578461  [    4/   89]
per-ex loss: 0.737934  [    6/   89]
per-ex loss: 0.515087  [    8/   89]
per-ex loss: 0.489442  [   10/   89]
per-ex loss: 0.600798  [   12/   89]
per-ex loss: 0.628180  [   14/   89]
per-ex loss: 0.741672  [   16/   89]
per-ex loss: 0.485519  [   18/   89]
per-ex loss: 0.730053  [   20/   89]
per-ex loss: 0.760509  [   22/   89]
per-ex loss: 0.605047  [   24/   89]
per-ex loss: 0.768090  [   26/   89]
per-ex loss: 0.752736  [   28/   89]
per-ex loss: 0.571189  [   30/   89]
per-ex loss: 0.618742  [   32/   89]
per-ex loss: 0.780407  [   34/   89]
per-ex loss: 0.615508  [   36/   89]
per-ex loss: 0.782643  [   38/   89]
per-ex loss: 0.563826  [   40/   89]
per-ex loss: 0.652840  [   42/   89]
per-ex loss: 0.677517  [   44/   89]
per-ex loss: 0.538007  [   46/   89]
per-ex loss: 0.691331  [   48/   89]
per-ex loss: 0.892612  [   50/   89]
per-ex loss: 0.752727  [   52/   89]
per-ex loss: 0.810212  [   54/   89]
per-ex loss: 0.575640  [   56/   89]
per-ex loss: 0.677382  [   58/   89]
per-ex loss: 0.687338  [   60/   89]
per-ex loss: 0.544035  [   62/   89]
per-ex loss: 0.746309  [   64/   89]
per-ex loss: 0.761801  [   66/   89]
per-ex loss: 0.605624  [   68/   89]
per-ex loss: 0.701007  [   70/   89]
per-ex loss: 0.559757  [   72/   89]
per-ex loss: 0.864191  [   74/   89]
per-ex loss: 0.633348  [   76/   89]
per-ex loss: 0.690808  [   78/   89]
per-ex loss: 0.778932  [   80/   89]
per-ex loss: 0.773291  [   82/   89]
per-ex loss: 0.646968  [   84/   89]
per-ex loss: 0.754470  [   86/   89]
per-ex loss: 0.564585  [   88/   89]
per-ex loss: 0.540450  [   89/   89]
Train Error: Avg loss: 0.67139744
validation Error: 
 Avg loss: 0.77065850 
 F1: 0.504025 
 Precision: 0.643043 
 Recall: 0.414431
 IoU: 0.336921

test Error: 
 Avg loss: 0.74866186 
 F1: 0.530689 
 Precision: 0.658281 
 Recall: 0.444528
 IoU: 0.361183

We have finished training iteration 116
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_114_.pth
per-ex loss: 0.606934  [    2/   89]
per-ex loss: 0.868435  [    4/   89]
per-ex loss: 0.718936  [    6/   89]
per-ex loss: 0.555462  [    8/   89]
per-ex loss: 0.611560  [   10/   89]
per-ex loss: 0.611001  [   12/   89]
per-ex loss: 0.682519  [   14/   89]
per-ex loss: 0.577448  [   16/   89]
per-ex loss: 0.635419  [   18/   89]
per-ex loss: 0.751233  [   20/   89]
per-ex loss: 0.572786  [   22/   89]
per-ex loss: 0.645800  [   24/   89]
per-ex loss: 0.876146  [   26/   89]
per-ex loss: 0.693695  [   28/   89]
per-ex loss: 0.742784  [   30/   89]
per-ex loss: 0.773501  [   32/   89]
per-ex loss: 0.682486  [   34/   89]
per-ex loss: 0.682328  [   36/   89]
per-ex loss: 0.711149  [   38/   89]
per-ex loss: 0.738815  [   40/   89]
per-ex loss: 0.501122  [   42/   89]
per-ex loss: 0.726985  [   44/   89]
per-ex loss: 0.714507  [   46/   89]
per-ex loss: 0.548549  [   48/   89]
per-ex loss: 0.753653  [   50/   89]
per-ex loss: 0.581507  [   52/   89]
per-ex loss: 0.560721  [   54/   89]
per-ex loss: 0.612312  [   56/   89]
per-ex loss: 0.641587  [   58/   89]
per-ex loss: 0.776660  [   60/   89]
per-ex loss: 0.700966  [   62/   89]
per-ex loss: 0.563816  [   64/   89]
per-ex loss: 0.584065  [   66/   89]
per-ex loss: 0.676798  [   68/   89]
per-ex loss: 0.680549  [   70/   89]
per-ex loss: 0.737172  [   72/   89]
per-ex loss: 0.736038  [   74/   89]
per-ex loss: 0.581074  [   76/   89]
per-ex loss: 0.703721  [   78/   89]
per-ex loss: 0.517608  [   80/   89]
per-ex loss: 0.795385  [   82/   89]
per-ex loss: 0.770487  [   84/   89]
per-ex loss: 0.520858  [   86/   89]
per-ex loss: 0.819293  [   88/   89]
per-ex loss: 0.653728  [   89/   89]
Train Error: Avg loss: 0.67105775
validation Error: 
 Avg loss: 0.75144565 
 F1: 0.479588 
 Precision: 0.726935 
 Recall: 0.357832
 IoU: 0.315433

test Error: 
 Avg loss: 0.73402496 
 F1: 0.493318 
 Precision: 0.750974 
 Recall: 0.367299
 IoU: 0.327420

We have finished training iteration 117
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_115_.pth
per-ex loss: 0.762596  [    2/   89]
per-ex loss: 0.525530  [    4/   89]
per-ex loss: 0.625095  [    6/   89]
per-ex loss: 0.783129  [    8/   89]
per-ex loss: 0.743855  [   10/   89]
per-ex loss: 0.670709  [   12/   89]
per-ex loss: 0.535822  [   14/   89]
per-ex loss: 0.840778  [   16/   89]
per-ex loss: 0.833606  [   18/   89]
per-ex loss: 0.665988  [   20/   89]
per-ex loss: 0.649743  [   22/   89]
per-ex loss: 0.595573  [   24/   89]
per-ex loss: 0.661957  [   26/   89]
per-ex loss: 0.664692  [   28/   89]
per-ex loss: 0.515754  [   30/   89]
per-ex loss: 0.565477  [   32/   89]
per-ex loss: 0.508696  [   34/   89]
per-ex loss: 0.629595  [   36/   89]
per-ex loss: 0.646272  [   38/   89]
per-ex loss: 0.732305  [   40/   89]
per-ex loss: 0.653559  [   42/   89]
per-ex loss: 0.780518  [   44/   89]
per-ex loss: 0.825393  [   46/   89]
per-ex loss: 0.771737  [   48/   89]
per-ex loss: 0.785846  [   50/   89]
per-ex loss: 0.656130  [   52/   89]
per-ex loss: 0.506067  [   54/   89]
per-ex loss: 0.679976  [   56/   89]
per-ex loss: 0.786248  [   58/   89]
per-ex loss: 0.715662  [   60/   89]
per-ex loss: 0.739566  [   62/   89]
per-ex loss: 0.841188  [   64/   89]
per-ex loss: 0.700069  [   66/   89]
per-ex loss: 0.786676  [   68/   89]
per-ex loss: 0.610012  [   70/   89]
per-ex loss: 0.739047  [   72/   89]
per-ex loss: 0.546455  [   74/   89]
per-ex loss: 0.618152  [   76/   89]
per-ex loss: 0.556606  [   78/   89]
per-ex loss: 0.700096  [   80/   89]
per-ex loss: 0.663305  [   82/   89]
per-ex loss: 0.701210  [   84/   89]
per-ex loss: 0.717204  [   86/   89]
per-ex loss: 0.756035  [   88/   89]
per-ex loss: 0.755205  [   89/   89]
Train Error: Avg loss: 0.68331407
validation Error: 
 Avg loss: 0.76233126 
 F1: 0.467127 
 Precision: 0.749248 
 Recall: 0.339349
 IoU: 0.304739

test Error: 
 Avg loss: 0.74457149 
 F1: 0.483439 
 Precision: 0.769332 
 Recall: 0.352461
 IoU: 0.318774

We have finished training iteration 118
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_116_.pth
per-ex loss: 0.749313  [    2/   89]
per-ex loss: 0.571048  [    4/   89]
per-ex loss: 0.551328  [    6/   89]
per-ex loss: 0.693269  [    8/   89]
per-ex loss: 0.663393  [   10/   89]
per-ex loss: 0.811782  [   12/   89]
per-ex loss: 0.789286  [   14/   89]
per-ex loss: 0.567744  [   16/   89]
per-ex loss: 0.705628  [   18/   89]
per-ex loss: 0.512048  [   20/   89]
per-ex loss: 0.741821  [   22/   89]
per-ex loss: 0.584606  [   24/   89]
per-ex loss: 0.628429  [   26/   89]
per-ex loss: 0.619270  [   28/   89]
per-ex loss: 0.570596  [   30/   89]
per-ex loss: 0.628628  [   32/   89]
per-ex loss: 0.584078  [   34/   89]
per-ex loss: 0.830992  [   36/   89]
per-ex loss: 0.830750  [   38/   89]
per-ex loss: 0.802847  [   40/   89]
per-ex loss: 0.787734  [   42/   89]
per-ex loss: 0.678561  [   44/   89]
per-ex loss: 0.566765  [   46/   89]
per-ex loss: 0.524790  [   48/   89]
per-ex loss: 0.698032  [   50/   89]
per-ex loss: 0.712908  [   52/   89]
per-ex loss: 0.516472  [   54/   89]
per-ex loss: 0.655226  [   56/   89]
per-ex loss: 0.615928  [   58/   89]
per-ex loss: 0.700091  [   60/   89]
per-ex loss: 0.678190  [   62/   89]
per-ex loss: 0.497310  [   64/   89]
per-ex loss: 0.663773  [   66/   89]
per-ex loss: 0.854681  [   68/   89]
per-ex loss: 0.733920  [   70/   89]
per-ex loss: 0.679033  [   72/   89]
per-ex loss: 0.527377  [   74/   89]
per-ex loss: 0.538209  [   76/   89]
per-ex loss: 0.767717  [   78/   89]
per-ex loss: 0.689267  [   80/   89]
per-ex loss: 0.587652  [   82/   89]
per-ex loss: 0.822406  [   84/   89]
per-ex loss: 0.681730  [   86/   89]
per-ex loss: 0.720817  [   88/   89]
per-ex loss: 0.841772  [   89/   89]
Train Error: Avg loss: 0.67060472
validation Error: 
 Avg loss: 0.76242461 
 F1: 0.489368 
 Precision: 0.702515 
 Recall: 0.375454
 IoU: 0.323949

test Error: 
 Avg loss: 0.73693405 
 F1: 0.516322 
 Precision: 0.717615 
 Recall: 0.403218
 IoU: 0.348001

We have finished training iteration 119
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_117_.pth
per-ex loss: 0.784653  [    2/   89]
per-ex loss: 0.864477  [    4/   89]
per-ex loss: 0.516665  [    6/   89]
per-ex loss: 0.645939  [    8/   89]
per-ex loss: 0.536338  [   10/   89]
per-ex loss: 0.470355  [   12/   89]
per-ex loss: 0.746632  [   14/   89]
per-ex loss: 0.674886  [   16/   89]
per-ex loss: 0.559874  [   18/   89]
per-ex loss: 0.609534  [   20/   89]
per-ex loss: 0.522821  [   22/   89]
per-ex loss: 0.664516  [   24/   89]
per-ex loss: 0.679474  [   26/   89]
per-ex loss: 0.746025  [   28/   89]
per-ex loss: 0.705163  [   30/   89]
per-ex loss: 0.668277  [   32/   89]
per-ex loss: 0.762898  [   34/   89]
per-ex loss: 0.700177  [   36/   89]
per-ex loss: 0.875464  [   38/   89]
per-ex loss: 0.706994  [   40/   89]
per-ex loss: 0.704518  [   42/   89]
per-ex loss: 0.676819  [   44/   89]
per-ex loss: 0.520942  [   46/   89]
per-ex loss: 0.660784  [   48/   89]
per-ex loss: 0.684799  [   50/   89]
per-ex loss: 0.660204  [   52/   89]
per-ex loss: 0.685705  [   54/   89]
per-ex loss: 0.481745  [   56/   89]
per-ex loss: 0.637084  [   58/   89]
per-ex loss: 0.684582  [   60/   89]
per-ex loss: 0.604177  [   62/   89]
per-ex loss: 0.847816  [   64/   89]
per-ex loss: 0.687428  [   66/   89]
per-ex loss: 0.615666  [   68/   89]
per-ex loss: 0.737662  [   70/   89]
per-ex loss: 0.504931  [   72/   89]
per-ex loss: 0.599696  [   74/   89]
per-ex loss: 0.865070  [   76/   89]
per-ex loss: 0.746017  [   78/   89]
per-ex loss: 0.593332  [   80/   89]
per-ex loss: 0.727022  [   82/   89]
per-ex loss: 0.775808  [   84/   89]
per-ex loss: 0.720303  [   86/   89]
per-ex loss: 0.477675  [   88/   89]
per-ex loss: 0.617774  [   89/   89]
Train Error: Avg loss: 0.66574940
validation Error: 
 Avg loss: 0.75822354 
 F1: 0.501001 
 Precision: 0.672483 
 Recall: 0.399205
 IoU: 0.334224

test Error: 
 Avg loss: 0.73375160 
 F1: 0.526212 
 Precision: 0.693205 
 Recall: 0.424056
 IoU: 0.357047

We have finished training iteration 120
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_118_.pth
per-ex loss: 0.620090  [    2/   89]
per-ex loss: 0.836812  [    4/   89]
per-ex loss: 0.499627  [    6/   89]
per-ex loss: 0.599274  [    8/   89]
per-ex loss: 0.673424  [   10/   89]
per-ex loss: 0.781387  [   12/   89]
per-ex loss: 0.814357  [   14/   89]
per-ex loss: 0.516112  [   16/   89]
per-ex loss: 0.741609  [   18/   89]
per-ex loss: 0.485830  [   20/   89]
per-ex loss: 0.665394  [   22/   89]
per-ex loss: 0.798155  [   24/   89]
per-ex loss: 0.618515  [   26/   89]
per-ex loss: 0.631718  [   28/   89]
per-ex loss: 0.617788  [   30/   89]
per-ex loss: 0.673866  [   32/   89]
per-ex loss: 0.743502  [   34/   89]
per-ex loss: 0.523096  [   36/   89]
per-ex loss: 0.762916  [   38/   89]
per-ex loss: 0.601498  [   40/   89]
per-ex loss: 0.636865  [   42/   89]
per-ex loss: 0.703973  [   44/   89]
per-ex loss: 0.493222  [   46/   89]
per-ex loss: 0.728605  [   48/   89]
per-ex loss: 0.607485  [   50/   89]
per-ex loss: 0.674958  [   52/   89]
per-ex loss: 0.654556  [   54/   89]
per-ex loss: 0.524481  [   56/   89]
per-ex loss: 0.582723  [   58/   89]
per-ex loss: 0.484267  [   60/   89]
per-ex loss: 0.602902  [   62/   89]
per-ex loss: 0.522229  [   64/   89]
per-ex loss: 0.611086  [   66/   89]
per-ex loss: 0.786635  [   68/   89]
per-ex loss: 0.784155  [   70/   89]
per-ex loss: 0.537167  [   72/   89]
per-ex loss: 0.837819  [   74/   89]
per-ex loss: 0.740812  [   76/   89]
per-ex loss: 0.753932  [   78/   89]
per-ex loss: 0.668507  [   80/   89]
per-ex loss: 0.867844  [   82/   89]
per-ex loss: 0.695856  [   84/   89]
per-ex loss: 0.766970  [   86/   89]
per-ex loss: 0.800772  [   88/   89]
per-ex loss: 0.558349  [   89/   89]
Train Error: Avg loss: 0.66291427
validation Error: 
 Avg loss: 0.75841288 
 F1: 0.485742 
 Precision: 0.720857 
 Recall: 0.366277
 IoU: 0.320779

test Error: 
 Avg loss: 0.73822579 
 F1: 0.500965 
 Precision: 0.745102 
 Recall: 0.377330
 IoU: 0.334192

We have finished training iteration 121
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_119_.pth
per-ex loss: 0.800965  [    2/   89]
per-ex loss: 0.549363  [    4/   89]
per-ex loss: 0.817517  [    6/   89]
per-ex loss: 0.911462  [    8/   89]
per-ex loss: 0.814499  [   10/   89]
per-ex loss: 0.621888  [   12/   89]
per-ex loss: 0.657344  [   14/   89]
per-ex loss: 0.744072  [   16/   89]
per-ex loss: 0.856019  [   18/   89]
per-ex loss: 0.664204  [   20/   89]
per-ex loss: 0.524105  [   22/   89]
per-ex loss: 0.517424  [   24/   89]
per-ex loss: 0.658363  [   26/   89]
per-ex loss: 0.617306  [   28/   89]
per-ex loss: 0.725730  [   30/   89]
per-ex loss: 0.582479  [   32/   89]
per-ex loss: 0.610699  [   34/   89]
per-ex loss: 0.686563  [   36/   89]
per-ex loss: 0.633688  [   38/   89]
per-ex loss: 0.526635  [   40/   89]
per-ex loss: 0.644644  [   42/   89]
per-ex loss: 0.667335  [   44/   89]
per-ex loss: 0.817570  [   46/   89]
per-ex loss: 0.645355  [   48/   89]
per-ex loss: 0.767353  [   50/   89]
per-ex loss: 0.570748  [   52/   89]
per-ex loss: 0.638505  [   54/   89]
per-ex loss: 0.629548  [   56/   89]
per-ex loss: 0.730519  [   58/   89]
per-ex loss: 0.744953  [   60/   89]
per-ex loss: 0.623348  [   62/   89]
per-ex loss: 0.522017  [   64/   89]
per-ex loss: 0.553506  [   66/   89]
per-ex loss: 0.822709  [   68/   89]
per-ex loss: 0.689322  [   70/   89]
per-ex loss: 0.565836  [   72/   89]
per-ex loss: 0.526913  [   74/   89]
per-ex loss: 0.744589  [   76/   89]
per-ex loss: 0.476434  [   78/   89]
per-ex loss: 0.663622  [   80/   89]
per-ex loss: 0.747199  [   82/   89]
per-ex loss: 0.771329  [   84/   89]
per-ex loss: 0.908417  [   86/   89]
per-ex loss: 0.737171  [   88/   89]
per-ex loss: 0.800267  [   89/   89]
Train Error: Avg loss: 0.67843410
validation Error: 
 Avg loss: 0.73979373 
 F1: 0.473610 
 Precision: 0.739750 
 Recall: 0.348301
 IoU: 0.310281

test Error: 
 Avg loss: 0.73232783 
 F1: 0.496491 
 Precision: 0.730167 
 Recall: 0.376120
 IoU: 0.330221

We have finished training iteration 122
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_120_.pth
per-ex loss: 0.785943  [    2/   89]
per-ex loss: 0.785442  [    4/   89]
per-ex loss: 0.761900  [    6/   89]
per-ex loss: 0.625161  [    8/   89]
per-ex loss: 0.658960  [   10/   89]
per-ex loss: 0.783178  [   12/   89]
per-ex loss: 0.786881  [   14/   89]
per-ex loss: 0.587211  [   16/   89]
per-ex loss: 0.575756  [   18/   89]
per-ex loss: 0.574847  [   20/   89]
per-ex loss: 0.658013  [   22/   89]
per-ex loss: 0.705777  [   24/   89]
per-ex loss: 0.627173  [   26/   89]
per-ex loss: 0.652023  [   28/   89]
per-ex loss: 0.772130  [   30/   89]
per-ex loss: 0.592175  [   32/   89]
per-ex loss: 0.541940  [   34/   89]
per-ex loss: 0.704724  [   36/   89]
per-ex loss: 0.660367  [   38/   89]
per-ex loss: 0.546549  [   40/   89]
per-ex loss: 0.560162  [   42/   89]
per-ex loss: 0.792261  [   44/   89]
per-ex loss: 0.680145  [   46/   89]
per-ex loss: 0.588037  [   48/   89]
per-ex loss: 0.758801  [   50/   89]
per-ex loss: 0.664794  [   52/   89]
per-ex loss: 0.514359  [   54/   89]
per-ex loss: 0.804862  [   56/   89]
per-ex loss: 0.514654  [   58/   89]
per-ex loss: 0.870106  [   60/   89]
per-ex loss: 0.833532  [   62/   89]
per-ex loss: 0.663363  [   64/   89]
per-ex loss: 0.535812  [   66/   89]
per-ex loss: 0.496464  [   68/   89]
per-ex loss: 0.697227  [   70/   89]
per-ex loss: 0.620203  [   72/   89]
per-ex loss: 0.716487  [   74/   89]
per-ex loss: 0.860596  [   76/   89]
per-ex loss: 0.774831  [   78/   89]
per-ex loss: 0.804651  [   80/   89]
per-ex loss: 0.757792  [   82/   89]
per-ex loss: 0.641835  [   84/   89]
per-ex loss: 0.763463  [   86/   89]
per-ex loss: 0.647331  [   88/   89]
per-ex loss: 0.731263  [   89/   89]
Train Error: Avg loss: 0.68175966
validation Error: 
 Avg loss: 0.75012802 
 F1: 0.501151 
 Precision: 0.678438 
 Recall: 0.397324
 IoU: 0.334357

test Error: 
 Avg loss: 0.73538444 
 F1: 0.531241 
 Precision: 0.684238 
 Recall: 0.434162
 IoU: 0.361694

We have finished training iteration 123
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_121_.pth
per-ex loss: 0.659809  [    2/   89]
per-ex loss: 0.544357  [    4/   89]
per-ex loss: 0.754946  [    6/   89]
per-ex loss: 0.663486  [    8/   89]
per-ex loss: 0.797346  [   10/   89]
per-ex loss: 0.623183  [   12/   89]
per-ex loss: 0.672894  [   14/   89]
per-ex loss: 0.799254  [   16/   89]
per-ex loss: 0.631371  [   18/   89]
per-ex loss: 0.503894  [   20/   89]
per-ex loss: 0.823289  [   22/   89]
per-ex loss: 0.585552  [   24/   89]
per-ex loss: 0.698260  [   26/   89]
per-ex loss: 0.746662  [   28/   89]
per-ex loss: 0.571540  [   30/   89]
per-ex loss: 0.738678  [   32/   89]
per-ex loss: 0.676169  [   34/   89]
per-ex loss: 0.869728  [   36/   89]
per-ex loss: 0.617567  [   38/   89]
per-ex loss: 0.527019  [   40/   89]
per-ex loss: 0.756630  [   42/   89]
per-ex loss: 0.580049  [   44/   89]
per-ex loss: 0.613837  [   46/   89]
per-ex loss: 0.844869  [   48/   89]
per-ex loss: 0.661852  [   50/   89]
per-ex loss: 0.817962  [   52/   89]
per-ex loss: 0.711657  [   54/   89]
per-ex loss: 0.621309  [   56/   89]
per-ex loss: 0.574670  [   58/   89]
per-ex loss: 0.716716  [   60/   89]
per-ex loss: 0.657340  [   62/   89]
per-ex loss: 0.613951  [   64/   89]
per-ex loss: 0.593154  [   66/   89]
per-ex loss: 0.608218  [   68/   89]
per-ex loss: 0.569333  [   70/   89]
per-ex loss: 0.589038  [   72/   89]
per-ex loss: 0.683940  [   74/   89]
per-ex loss: 0.678764  [   76/   89]
per-ex loss: 0.701792  [   78/   89]
per-ex loss: 0.689156  [   80/   89]
per-ex loss: 0.521039  [   82/   89]
per-ex loss: 0.568369  [   84/   89]
per-ex loss: 0.617368  [   86/   89]
per-ex loss: 0.807867  [   88/   89]
per-ex loss: 0.845236  [   89/   89]
Train Error: Avg loss: 0.66998045
validation Error: 
 Avg loss: 0.75050928 
 F1: 0.439606 
 Precision: 0.809549 
 Recall: 0.301726
 IoU: 0.281728

test Error: 
 Avg loss: 0.73774122 
 F1: 0.450579 
 Precision: 0.809595 
 Recall: 0.312154
 IoU: 0.290805

We have finished training iteration 124
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_122_.pth
Error in cropping the image to the non-zero values in the fourth channel. Returned the original image.
per-ex loss: 0.564281  [    2/   89]
per-ex loss: 0.477537  [    4/   89]
per-ex loss: 0.581595  [    6/   89]
per-ex loss: 0.744690  [    8/   89]
per-ex loss: 0.625915  [   10/   89]
per-ex loss: 0.610714  [   12/   89]
per-ex loss: 0.783782  [   14/   89]
per-ex loss: 0.500104  [   16/   89]
per-ex loss: 0.694019  [   18/   89]
per-ex loss: 0.645679  [   20/   89]
per-ex loss: 0.703673  [   22/   89]
per-ex loss: 0.699576  [   24/   89]
per-ex loss: 0.441820  [   26/   89]
per-ex loss: 0.771699  [   28/   89]
per-ex loss: 0.663134  [   30/   89]
per-ex loss: 0.660549  [   32/   89]
per-ex loss: 0.670271  [   34/   89]
per-ex loss: 0.792001  [   36/   89]
per-ex loss: 0.512780  [   38/   89]
per-ex loss: 0.676292  [   40/   89]
per-ex loss: 0.830361  [   42/   89]
per-ex loss: 0.600952  [   44/   89]
per-ex loss: 0.768795  [   46/   89]
per-ex loss: 0.794489  [   48/   89]
per-ex loss: 0.634891  [   50/   89]
per-ex loss: 0.717137  [   52/   89]
per-ex loss: 0.631039  [   54/   89]
per-ex loss: 0.447073  [   56/   89]
per-ex loss: 0.688730  [   58/   89]
per-ex loss: 0.584341  [   60/   89]
per-ex loss: 0.592569  [   62/   89]
per-ex loss: 0.871711  [   64/   89]
per-ex loss: 0.621736  [   66/   89]
per-ex loss: 0.833709  [   68/   89]
per-ex loss: 0.785187  [   70/   89]
per-ex loss: 0.599625  [   72/   89]
per-ex loss: 0.538081  [   74/   89]
per-ex loss: 0.729512  [   76/   89]
per-ex loss: 0.628786  [   78/   89]
per-ex loss: 0.646690  [   80/   89]
per-ex loss: 0.678538  [   82/   89]
per-ex loss: 0.814339  [   84/   89]
per-ex loss: 0.653038  [   86/   89]
per-ex loss: 0.637439  [   88/   89]
per-ex loss: 0.602056  [   89/   89]
Train Error: Avg loss: 0.66113185
validation Error: 
 Avg loss: 0.73528267 
 F1: 0.471033 
 Precision: 0.754655 
 Recall: 0.342363
 IoU: 0.308073

test Error: 
 Avg loss: 0.72800893 
 F1: 0.481713 
 Precision: 0.753046 
 Recall: 0.354119
 IoU: 0.317274

We have finished training iteration 125
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_123_.pth
per-ex loss: 0.566745  [    2/   89]
per-ex loss: 0.749767  [    4/   89]
per-ex loss: 0.711617  [    6/   89]
per-ex loss: 0.485089  [    8/   89]
per-ex loss: 0.558030  [   10/   89]
per-ex loss: 0.606477  [   12/   89]
per-ex loss: 0.629769  [   14/   89]
per-ex loss: 0.503806  [   16/   89]
per-ex loss: 0.569393  [   18/   89]
per-ex loss: 0.493622  [   20/   89]
per-ex loss: 0.743198  [   22/   89]
per-ex loss: 0.619284  [   24/   89]
per-ex loss: 0.688180  [   26/   89]
per-ex loss: 0.791628  [   28/   89]
per-ex loss: 0.676388  [   30/   89]
per-ex loss: 0.861694  [   32/   89]
per-ex loss: 0.812345  [   34/   89]
per-ex loss: 0.645225  [   36/   89]
per-ex loss: 0.476174  [   38/   89]
per-ex loss: 0.791478  [   40/   89]
per-ex loss: 0.683941  [   42/   89]
per-ex loss: 0.612975  [   44/   89]
per-ex loss: 0.749949  [   46/   89]
per-ex loss: 0.491047  [   48/   89]
per-ex loss: 0.616383  [   50/   89]
per-ex loss: 0.503443  [   52/   89]
per-ex loss: 0.666798  [   54/   89]
per-ex loss: 0.521171  [   56/   89]
per-ex loss: 0.768912  [   58/   89]
per-ex loss: 0.699685  [   60/   89]
per-ex loss: 0.762277  [   62/   89]
per-ex loss: 0.714363  [   64/   89]
per-ex loss: 0.630580  [   66/   89]
per-ex loss: 0.686874  [   68/   89]
per-ex loss: 0.812948  [   70/   89]
per-ex loss: 0.527660  [   72/   89]
per-ex loss: 0.632784  [   74/   89]
per-ex loss: 0.805583  [   76/   89]
per-ex loss: 0.489143  [   78/   89]
per-ex loss: 0.613200  [   80/   89]
per-ex loss: 0.583279  [   82/   89]
per-ex loss: 0.716742  [   84/   89]
per-ex loss: 0.555443  [   86/   89]
per-ex loss: 0.612477  [   88/   89]
per-ex loss: 0.749445  [   89/   89]
Train Error: Avg loss: 0.64860027
validation Error: 
 Avg loss: 0.72614433 
 F1: 0.483034 
 Precision: 0.738486 
 Recall: 0.358889
 IoU: 0.318421

test Error: 
 Avg loss: 0.71387196 
 F1: 0.508012 
 Precision: 0.756645 
 Recall: 0.382367
 IoU: 0.340494

We have finished training iteration 126
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_124_.pth
per-ex loss: 0.626748  [    2/   89]
per-ex loss: 0.749957  [    4/   89]
per-ex loss: 0.837446  [    6/   89]
per-ex loss: 0.703579  [    8/   89]
per-ex loss: 0.823475  [   10/   89]
per-ex loss: 0.485792  [   12/   89]
per-ex loss: 0.648069  [   14/   89]
per-ex loss: 0.670031  [   16/   89]
per-ex loss: 0.652294  [   18/   89]
per-ex loss: 0.800262  [   20/   89]
per-ex loss: 0.659724  [   22/   89]
per-ex loss: 0.834784  [   24/   89]
per-ex loss: 0.502615  [   26/   89]
per-ex loss: 0.557798  [   28/   89]
per-ex loss: 0.665877  [   30/   89]
per-ex loss: 0.762100  [   32/   89]
per-ex loss: 0.687507  [   34/   89]
per-ex loss: 0.704291  [   36/   89]
per-ex loss: 0.748487  [   38/   89]
per-ex loss: 0.516328  [   40/   89]
per-ex loss: 0.616658  [   42/   89]
per-ex loss: 0.489054  [   44/   89]
per-ex loss: 0.671192  [   46/   89]
per-ex loss: 0.603371  [   48/   89]
per-ex loss: 0.446937  [   50/   89]
per-ex loss: 0.757029  [   52/   89]
per-ex loss: 0.606587  [   54/   89]
per-ex loss: 0.474405  [   56/   89]
per-ex loss: 0.537800  [   58/   89]
per-ex loss: 0.782738  [   60/   89]
per-ex loss: 0.804054  [   62/   89]
per-ex loss: 0.550470  [   64/   89]
per-ex loss: 0.583149  [   66/   89]
per-ex loss: 0.444377  [   68/   89]
per-ex loss: 0.712423  [   70/   89]
per-ex loss: 0.543111  [   72/   89]
per-ex loss: 0.699826  [   74/   89]
per-ex loss: 0.672426  [   76/   89]
per-ex loss: 0.614509  [   78/   89]
per-ex loss: 0.659249  [   80/   89]
per-ex loss: 0.648374  [   82/   89]
per-ex loss: 0.628868  [   84/   89]
per-ex loss: 0.601258  [   86/   89]
per-ex loss: 0.503210  [   88/   89]
per-ex loss: 0.629780  [   89/   89]
Train Error: Avg loss: 0.64262261
validation Error: 
 Avg loss: 0.72774612 
 F1: 0.481932 
 Precision: 0.732629 
 Recall: 0.359065
 IoU: 0.317464

test Error: 
 Avg loss: 0.71903694 
 F1: 0.493022 
 Precision: 0.748460 
 Recall: 0.367574
 IoU: 0.327159

We have finished training iteration 127
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_125_.pth
per-ex loss: 0.588242  [    2/   89]
per-ex loss: 0.677948  [    4/   89]
per-ex loss: 0.502652  [    6/   89]
per-ex loss: 0.481353  [    8/   89]
per-ex loss: 0.796985  [   10/   89]
per-ex loss: 0.607098  [   12/   89]
per-ex loss: 0.742215  [   14/   89]
per-ex loss: 0.713963  [   16/   89]
per-ex loss: 0.891610  [   18/   89]
per-ex loss: 0.697713  [   20/   89]
per-ex loss: 0.571466  [   22/   89]
per-ex loss: 0.746749  [   24/   89]
per-ex loss: 0.814841  [   26/   89]
per-ex loss: 0.649867  [   28/   89]
per-ex loss: 0.560384  [   30/   89]
per-ex loss: 0.745910  [   32/   89]
per-ex loss: 0.652327  [   34/   89]
per-ex loss: 0.635341  [   36/   89]
per-ex loss: 0.511505  [   38/   89]
per-ex loss: 0.560098  [   40/   89]
per-ex loss: 0.678567  [   42/   89]
per-ex loss: 0.670534  [   44/   89]
per-ex loss: 0.515075  [   46/   89]
per-ex loss: 0.617797  [   48/   89]
per-ex loss: 0.567315  [   50/   89]
per-ex loss: 0.622949  [   52/   89]
per-ex loss: 0.657041  [   54/   89]
per-ex loss: 0.688807  [   56/   89]
per-ex loss: 0.611818  [   58/   89]
per-ex loss: 0.573228  [   60/   89]
per-ex loss: 0.836794  [   62/   89]
per-ex loss: 0.772567  [   64/   89]
per-ex loss: 0.608497  [   66/   89]
per-ex loss: 0.698510  [   68/   89]
per-ex loss: 0.767014  [   70/   89]
per-ex loss: 0.661115  [   72/   89]
per-ex loss: 0.620947  [   74/   89]
per-ex loss: 0.615296  [   76/   89]
per-ex loss: 0.714260  [   78/   89]
per-ex loss: 0.654863  [   80/   89]
per-ex loss: 0.693130  [   82/   89]
per-ex loss: 0.870463  [   84/   89]
per-ex loss: 0.435227  [   86/   89]
per-ex loss: 0.588453  [   88/   89]
per-ex loss: 0.541716  [   89/   89]
Train Error: Avg loss: 0.65400563
validation Error: 
 Avg loss: 0.73576977 
 F1: 0.488577 
 Precision: 0.727973 
 Recall: 0.367668
 IoU: 0.323256

test Error: 
 Avg loss: 0.71174087 
 F1: 0.517733 
 Precision: 0.735899 
 Recall: 0.399343
 IoU: 0.349284

We have finished training iteration 128
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_126_.pth
per-ex loss: 0.819664  [    2/   89]
per-ex loss: 0.651741  [    4/   89]
per-ex loss: 0.766910  [    6/   89]
per-ex loss: 0.631651  [    8/   89]
per-ex loss: 0.497697  [   10/   89]
per-ex loss: 0.576533  [   12/   89]
per-ex loss: 0.663100  [   14/   89]
per-ex loss: 0.757637  [   16/   89]
per-ex loss: 0.618145  [   18/   89]
per-ex loss: 0.511379  [   20/   89]
per-ex loss: 0.746456  [   22/   89]
per-ex loss: 0.668934  [   24/   89]
per-ex loss: 0.636120  [   26/   89]
per-ex loss: 0.840611  [   28/   89]
per-ex loss: 0.486472  [   30/   89]
per-ex loss: 0.495221  [   32/   89]
per-ex loss: 0.744839  [   34/   89]
per-ex loss: 0.682789  [   36/   89]
per-ex loss: 0.517421  [   38/   89]
per-ex loss: 0.650266  [   40/   89]
per-ex loss: 0.638808  [   42/   89]
per-ex loss: 0.614541  [   44/   89]
per-ex loss: 0.518986  [   46/   89]
per-ex loss: 0.501660  [   48/   89]
per-ex loss: 0.608003  [   50/   89]
per-ex loss: 0.640631  [   52/   89]
per-ex loss: 0.540619  [   54/   89]
per-ex loss: 0.760648  [   56/   89]
per-ex loss: 0.568783  [   58/   89]
per-ex loss: 0.576444  [   60/   89]
per-ex loss: 0.759910  [   62/   89]
per-ex loss: 0.566013  [   64/   89]
per-ex loss: 0.737271  [   66/   89]
per-ex loss: 0.529723  [   68/   89]
per-ex loss: 0.532915  [   70/   89]
per-ex loss: 0.883776  [   72/   89]
per-ex loss: 0.639977  [   74/   89]
per-ex loss: 0.643153  [   76/   89]
per-ex loss: 0.781747  [   78/   89]
per-ex loss: 0.490712  [   80/   89]
per-ex loss: 0.671972  [   82/   89]
per-ex loss: 0.680878  [   84/   89]
per-ex loss: 0.600857  [   86/   89]
per-ex loss: 0.619017  [   88/   89]
per-ex loss: 0.770758  [   89/   89]
Train Error: Avg loss: 0.64091973
validation Error: 
 Avg loss: 0.73698280 
 F1: 0.501025 
 Precision: 0.678696 
 Recall: 0.397077
 IoU: 0.334245

test Error: 
 Avg loss: 0.71922076 
 F1: 0.529925 
 Precision: 0.678275 
 Recall: 0.434822
 IoU: 0.360474

We have finished training iteration 129
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_127_.pth
Error in cropping the image to the non-zero values in the fourth channel. Returned the original image.
per-ex loss: 0.658146  [    2/   89]
per-ex loss: 0.581828  [    4/   89]
per-ex loss: 0.663733  [    6/   89]
per-ex loss: 0.759001  [    8/   89]
per-ex loss: 0.692727  [   10/   89]
per-ex loss: 0.574391  [   12/   89]
per-ex loss: 0.478970  [   14/   89]
per-ex loss: 0.587087  [   16/   89]
per-ex loss: 0.856560  [   18/   89]
per-ex loss: 0.757938  [   20/   89]
per-ex loss: 0.687256  [   22/   89]
per-ex loss: 0.641865  [   24/   89]
per-ex loss: 0.781372  [   26/   89]
per-ex loss: 0.712428  [   28/   89]
per-ex loss: 0.516971  [   30/   89]
per-ex loss: 0.491993  [   32/   89]
per-ex loss: 0.606564  [   34/   89]
per-ex loss: 0.785897  [   36/   89]
per-ex loss: 0.587529  [   38/   89]
per-ex loss: 0.566396  [   40/   89]
per-ex loss: 0.700200  [   42/   89]
per-ex loss: 0.837511  [   44/   89]
per-ex loss: 0.449553  [   46/   89]
per-ex loss: 0.672885  [   48/   89]
per-ex loss: 0.724986  [   50/   89]
per-ex loss: 0.556059  [   52/   89]
per-ex loss: 0.745166  [   54/   89]
per-ex loss: 0.533571  [   56/   89]
per-ex loss: 0.639097  [   58/   89]
per-ex loss: 0.573713  [   60/   89]
per-ex loss: 0.644464  [   62/   89]
per-ex loss: 0.743355  [   64/   89]
per-ex loss: 0.572369  [   66/   89]
per-ex loss: 0.907960  [   68/   89]
per-ex loss: 0.596771  [   70/   89]
per-ex loss: 0.592118  [   72/   89]
per-ex loss: 0.576792  [   74/   89]
per-ex loss: 0.603220  [   76/   89]
per-ex loss: 0.512123  [   78/   89]
per-ex loss: 0.585275  [   80/   89]
per-ex loss: 0.647496  [   82/   89]
per-ex loss: 0.587255  [   84/   89]
per-ex loss: 0.526819  [   86/   89]
per-ex loss: 0.595545  [   88/   89]
per-ex loss: 0.816401  [   89/   89]
Train Error: Avg loss: 0.64287458
validation Error: 
 Avg loss: 0.73843680 
 F1: 0.472383 
 Precision: 0.683221 
 Recall: 0.360985
 IoU: 0.309228

test Error: 
 Avg loss: 0.72074138 
 F1: 0.478614 
 Precision: 0.720404 
 Recall: 0.358342
 IoU: 0.314590

We have finished training iteration 130
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_128_.pth
per-ex loss: 0.654776  [    2/   89]
per-ex loss: 0.677827  [    4/   89]
per-ex loss: 0.781139  [    6/   89]
per-ex loss: 0.553165  [    8/   89]
per-ex loss: 0.792980  [   10/   89]
per-ex loss: 0.732607  [   12/   89]
per-ex loss: 0.671323  [   14/   89]
per-ex loss: 0.697044  [   16/   89]
per-ex loss: 0.708762  [   18/   89]
per-ex loss: 0.511517  [   20/   89]
per-ex loss: 0.449794  [   22/   89]
per-ex loss: 0.826360  [   24/   89]
per-ex loss: 0.500458  [   26/   89]
per-ex loss: 0.681226  [   28/   89]
per-ex loss: 0.701267  [   30/   89]
per-ex loss: 0.550353  [   32/   89]
per-ex loss: 0.566494  [   34/   89]
per-ex loss: 0.811497  [   36/   89]
per-ex loss: 0.615887  [   38/   89]
per-ex loss: 0.803109  [   40/   89]
per-ex loss: 0.590133  [   42/   89]
per-ex loss: 0.526549  [   44/   89]
per-ex loss: 0.623388  [   46/   89]
per-ex loss: 0.856372  [   48/   89]
per-ex loss: 0.801696  [   50/   89]
per-ex loss: 0.485078  [   52/   89]
per-ex loss: 0.681917  [   54/   89]
per-ex loss: 0.605520  [   56/   89]
per-ex loss: 0.838810  [   58/   89]
per-ex loss: 0.716065  [   60/   89]
per-ex loss: 0.520364  [   62/   89]
per-ex loss: 0.603947  [   64/   89]
per-ex loss: 0.689323  [   66/   89]
per-ex loss: 0.600084  [   68/   89]
per-ex loss: 0.539297  [   70/   89]
per-ex loss: 0.812093  [   72/   89]
per-ex loss: 0.567726  [   74/   89]
per-ex loss: 0.591352  [   76/   89]
per-ex loss: 0.676013  [   78/   89]
per-ex loss: 0.473186  [   80/   89]
per-ex loss: 0.717777  [   82/   89]
per-ex loss: 0.532407  [   84/   89]
per-ex loss: 0.587032  [   86/   89]
per-ex loss: 0.488589  [   88/   89]
per-ex loss: 0.669321  [   89/   89]
Train Error: Avg loss: 0.64625822
validation Error: 
 Avg loss: 0.72386966 
 F1: 0.463401 
 Precision: 0.759529 
 Recall: 0.333410
 IoU: 0.301575

test Error: 
 Avg loss: 0.70660355 
 F1: 0.478683 
 Precision: 0.778251 
 Recall: 0.345638
 IoU: 0.314650

We have finished training iteration 131
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_129_.pth
per-ex loss: 0.487213  [    2/   89]
per-ex loss: 0.511844  [    4/   89]
per-ex loss: 0.590765  [    6/   89]
per-ex loss: 0.674040  [    8/   89]
per-ex loss: 0.444229  [   10/   89]
per-ex loss: 0.585973  [   12/   89]
per-ex loss: 0.666937  [   14/   89]
per-ex loss: 0.588485  [   16/   89]
per-ex loss: 0.460742  [   18/   89]
per-ex loss: 0.678225  [   20/   89]
per-ex loss: 0.613884  [   22/   89]
per-ex loss: 0.502510  [   24/   89]
per-ex loss: 0.511434  [   26/   89]
per-ex loss: 0.642659  [   28/   89]
per-ex loss: 0.857422  [   30/   89]
per-ex loss: 0.654251  [   32/   89]
per-ex loss: 0.762436  [   34/   89]
per-ex loss: 0.658908  [   36/   89]
per-ex loss: 0.691309  [   38/   89]
per-ex loss: 0.762108  [   40/   89]
per-ex loss: 0.461204  [   42/   89]
per-ex loss: 0.710629  [   44/   89]
per-ex loss: 0.723702  [   46/   89]
per-ex loss: 0.458351  [   48/   89]
per-ex loss: 0.816574  [   50/   89]
per-ex loss: 0.769874  [   52/   89]
per-ex loss: 0.699163  [   54/   89]
per-ex loss: 0.631590  [   56/   89]
per-ex loss: 0.752627  [   58/   89]
per-ex loss: 0.750953  [   60/   89]
per-ex loss: 0.696783  [   62/   89]
per-ex loss: 0.620230  [   64/   89]
per-ex loss: 0.640854  [   66/   89]
per-ex loss: 0.653875  [   68/   89]
per-ex loss: 0.535858  [   70/   89]
per-ex loss: 0.775596  [   72/   89]
per-ex loss: 0.755010  [   74/   89]
per-ex loss: 0.783151  [   76/   89]
per-ex loss: 0.593519  [   78/   89]
per-ex loss: 0.632344  [   80/   89]
per-ex loss: 0.613827  [   82/   89]
per-ex loss: 0.761966  [   84/   89]
per-ex loss: 0.460376  [   86/   89]
per-ex loss: 0.502187  [   88/   89]
per-ex loss: 0.588179  [   89/   89]
Train Error: Avg loss: 0.63852881
validation Error: 
 Avg loss: 0.73148640 
 F1: 0.471184 
 Precision: 0.767936 
 Recall: 0.339855
 IoU: 0.308202

test Error: 
 Avg loss: 0.71462142 
 F1: 0.472945 
 Precision: 0.770801 
 Recall: 0.341125
 IoU: 0.309710

We have finished training iteration 132
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_130_.pth
per-ex loss: 0.616599  [    2/   89]
per-ex loss: 0.687961  [    4/   89]
per-ex loss: 0.538949  [    6/   89]
per-ex loss: 0.658405  [    8/   89]
per-ex loss: 0.679211  [   10/   89]
per-ex loss: 0.595646  [   12/   89]
per-ex loss: 0.588028  [   14/   89]
per-ex loss: 0.538310  [   16/   89]
per-ex loss: 0.768586  [   18/   89]
per-ex loss: 0.647072  [   20/   89]
per-ex loss: 0.713096  [   22/   89]
per-ex loss: 0.710233  [   24/   89]
per-ex loss: 0.691401  [   26/   89]
per-ex loss: 0.760636  [   28/   89]
per-ex loss: 0.765991  [   30/   89]
per-ex loss: 0.606398  [   32/   89]
per-ex loss: 0.551851  [   34/   89]
per-ex loss: 0.608001  [   36/   89]
per-ex loss: 0.831019  [   38/   89]
per-ex loss: 0.557481  [   40/   89]
per-ex loss: 0.464864  [   42/   89]
per-ex loss: 0.600250  [   44/   89]
per-ex loss: 0.725384  [   46/   89]
per-ex loss: 0.604722  [   48/   89]
per-ex loss: 0.504476  [   50/   89]
per-ex loss: 0.611349  [   52/   89]
per-ex loss: 0.748582  [   54/   89]
per-ex loss: 0.571953  [   56/   89]
per-ex loss: 0.690706  [   58/   89]
per-ex loss: 0.690620  [   60/   89]
per-ex loss: 0.508974  [   62/   89]
per-ex loss: 0.466263  [   64/   89]
per-ex loss: 0.689609  [   66/   89]
per-ex loss: 0.707249  [   68/   89]
per-ex loss: 0.513900  [   70/   89]
per-ex loss: 0.685404  [   72/   89]
per-ex loss: 0.800845  [   74/   89]
per-ex loss: 0.523686  [   76/   89]
per-ex loss: 0.601397  [   78/   89]
per-ex loss: 0.761535  [   80/   89]
per-ex loss: 0.687624  [   82/   89]
per-ex loss: 0.709835  [   84/   89]
per-ex loss: 0.708515  [   86/   89]
per-ex loss: 0.728945  [   88/   89]
per-ex loss: 0.516818  [   89/   89]
Train Error: Avg loss: 0.64307508
validation Error: 
 Avg loss: 0.72689299 
 F1: 0.494534 
 Precision: 0.685675 
 Recall: 0.386728
 IoU: 0.328492

test Error: 
 Avg loss: 0.70468841 
 F1: 0.515754 
 Precision: 0.700730 
 Recall: 0.408042
 IoU: 0.347486

We have finished training iteration 133
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_131_.pth
per-ex loss: 0.601427  [    2/   89]
per-ex loss: 0.766749  [    4/   89]
per-ex loss: 0.584630  [    6/   89]
per-ex loss: 0.491929  [    8/   89]
per-ex loss: 0.643751  [   10/   89]
per-ex loss: 0.666288  [   12/   89]
per-ex loss: 0.528270  [   14/   89]
per-ex loss: 0.576525  [   16/   89]
per-ex loss: 0.657032  [   18/   89]
per-ex loss: 0.681647  [   20/   89]
per-ex loss: 0.639502  [   22/   89]
per-ex loss: 0.807270  [   24/   89]
per-ex loss: 0.673025  [   26/   89]
per-ex loss: 0.578603  [   28/   89]
per-ex loss: 0.827044  [   30/   89]
per-ex loss: 0.813033  [   32/   89]
per-ex loss: 0.789943  [   34/   89]
per-ex loss: 0.570659  [   36/   89]
per-ex loss: 0.714986  [   38/   89]
per-ex loss: 0.593206  [   40/   89]
per-ex loss: 0.475013  [   42/   89]
per-ex loss: 0.521429  [   44/   89]
per-ex loss: 0.608389  [   46/   89]
per-ex loss: 0.530306  [   48/   89]
per-ex loss: 0.613052  [   50/   89]
per-ex loss: 0.623414  [   52/   89]
per-ex loss: 0.583758  [   54/   89]
per-ex loss: 0.724292  [   56/   89]
per-ex loss: 0.529756  [   58/   89]
per-ex loss: 0.498474  [   60/   89]
per-ex loss: 0.726168  [   62/   89]
per-ex loss: 0.471920  [   64/   89]
per-ex loss: 0.571479  [   66/   89]
per-ex loss: 0.435462  [   68/   89]
per-ex loss: 0.456536  [   70/   89]
per-ex loss: 0.862271  [   72/   89]
per-ex loss: 0.738038  [   74/   89]
per-ex loss: 0.740894  [   76/   89]
per-ex loss: 0.590084  [   78/   89]
per-ex loss: 0.586851  [   80/   89]
per-ex loss: 0.701864  [   82/   89]
per-ex loss: 0.721818  [   84/   89]
per-ex loss: 0.765965  [   86/   89]
per-ex loss: 0.569966  [   88/   89]
per-ex loss: 0.506862  [   89/   89]
Train Error: Avg loss: 0.63021289
validation Error: 
 Avg loss: 0.72598306 
 F1: 0.505525 
 Precision: 0.637627 
 Recall: 0.418766
 IoU: 0.338263

test Error: 
 Avg loss: 0.69999684 
 F1: 0.535864 
 Precision: 0.680190 
 Recall: 0.442065
 IoU: 0.365993

We have finished training iteration 134
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_132_.pth
per-ex loss: 0.719273  [    2/   89]
per-ex loss: 0.681783  [    4/   89]
per-ex loss: 0.746928  [    6/   89]
per-ex loss: 0.531818  [    8/   89]
per-ex loss: 0.677275  [   10/   89]
per-ex loss: 0.573870  [   12/   89]
per-ex loss: 0.568105  [   14/   89]
per-ex loss: 0.422222  [   16/   89]
per-ex loss: 0.636219  [   18/   89]
per-ex loss: 0.481248  [   20/   89]
per-ex loss: 0.622046  [   22/   89]
per-ex loss: 0.564559  [   24/   89]
per-ex loss: 0.668480  [   26/   89]
per-ex loss: 0.706001  [   28/   89]
per-ex loss: 0.513477  [   30/   89]
per-ex loss: 0.495079  [   32/   89]
per-ex loss: 0.595194  [   34/   89]
per-ex loss: 0.487418  [   36/   89]
per-ex loss: 0.458244  [   38/   89]
per-ex loss: 0.495485  [   40/   89]
per-ex loss: 0.650937  [   42/   89]
per-ex loss: 0.692582  [   44/   89]
per-ex loss: 0.564735  [   46/   89]
per-ex loss: 0.774615  [   48/   89]
per-ex loss: 0.520577  [   50/   89]
per-ex loss: 0.618445  [   52/   89]
per-ex loss: 0.745916  [   54/   89]
per-ex loss: 0.589489  [   56/   89]
per-ex loss: 0.501490  [   58/   89]
per-ex loss: 0.804418  [   60/   89]
per-ex loss: 0.601988  [   62/   89]
per-ex loss: 0.543948  [   64/   89]
per-ex loss: 0.592561  [   66/   89]
per-ex loss: 0.708984  [   68/   89]
per-ex loss: 0.555398  [   70/   89]
per-ex loss: 0.807091  [   72/   89]
per-ex loss: 0.523259  [   74/   89]
per-ex loss: 0.809934  [   76/   89]
per-ex loss: 0.776428  [   78/   89]
per-ex loss: 0.665640  [   80/   89]
per-ex loss: 0.631801  [   82/   89]
per-ex loss: 0.685714  [   84/   89]
per-ex loss: 0.667183  [   86/   89]
per-ex loss: 0.588793  [   88/   89]
per-ex loss: 0.762200  [   89/   89]
Train Error: Avg loss: 0.62286337
validation Error: 
 Avg loss: 0.72012115 
 F1: 0.490951 
 Precision: 0.690814 
 Recall: 0.380785
 IoU: 0.325338

test Error: 
 Avg loss: 0.71104479 
 F1: 0.490867 
 Precision: 0.714935 
 Recall: 0.373735
 IoU: 0.325264

We have finished training iteration 135
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_133_.pth
per-ex loss: 0.522014  [    2/   89]
per-ex loss: 0.597358  [    4/   89]
per-ex loss: 0.450686  [    6/   89]
per-ex loss: 0.630317  [    8/   89]
per-ex loss: 0.494369  [   10/   89]
per-ex loss: 0.552856  [   12/   89]
per-ex loss: 0.602117  [   14/   89]
per-ex loss: 0.698126  [   16/   89]
per-ex loss: 0.589389  [   18/   89]
per-ex loss: 0.727712  [   20/   89]
per-ex loss: 0.645735  [   22/   89]
per-ex loss: 0.533992  [   24/   89]
per-ex loss: 0.740991  [   26/   89]
per-ex loss: 0.785030  [   28/   89]
per-ex loss: 0.507283  [   30/   89]
per-ex loss: 0.685679  [   32/   89]
per-ex loss: 0.874010  [   34/   89]
per-ex loss: 0.597107  [   36/   89]
per-ex loss: 0.520711  [   38/   89]
per-ex loss: 0.657145  [   40/   89]
per-ex loss: 0.664198  [   42/   89]
per-ex loss: 0.655547  [   44/   89]
per-ex loss: 0.542532  [   46/   89]
per-ex loss: 0.516416  [   48/   89]
per-ex loss: 0.718200  [   50/   89]
per-ex loss: 0.718406  [   52/   89]
per-ex loss: 0.714181  [   54/   89]
per-ex loss: 0.642226  [   56/   89]
per-ex loss: 0.676838  [   58/   89]
per-ex loss: 0.499544  [   60/   89]
per-ex loss: 0.507908  [   62/   89]
per-ex loss: 0.611346  [   64/   89]
per-ex loss: 0.648881  [   66/   89]
per-ex loss: 0.815619  [   68/   89]
per-ex loss: 0.732195  [   70/   89]
per-ex loss: 0.686126  [   72/   89]
per-ex loss: 0.791054  [   74/   89]
per-ex loss: 0.686555  [   76/   89]
per-ex loss: 0.496505  [   78/   89]
per-ex loss: 0.711972  [   80/   89]
per-ex loss: 0.517102  [   82/   89]
per-ex loss: 0.743706  [   84/   89]
per-ex loss: 0.592557  [   86/   89]
per-ex loss: 0.467109  [   88/   89]
per-ex loss: 0.583428  [   89/   89]
Train Error: Avg loss: 0.63006183
validation Error: 
 Avg loss: 0.73069384 
 F1: 0.420741 
 Precision: 0.811258 
 Recall: 0.284021
 IoU: 0.266416

test Error: 
 Avg loss: 0.72218736 
 F1: 0.425466 
 Precision: 0.803837 
 Recall: 0.289293
 IoU: 0.270217

We have finished training iteration 136
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_134_.pth
per-ex loss: 0.670153  [    2/   89]
per-ex loss: 0.678294  [    4/   89]
per-ex loss: 0.566096  [    6/   89]
per-ex loss: 0.658943  [    8/   89]
per-ex loss: 0.781823  [   10/   89]
per-ex loss: 0.605025  [   12/   89]
per-ex loss: 0.566627  [   14/   89]
per-ex loss: 0.856697  [   16/   89]
per-ex loss: 0.625348  [   18/   89]
per-ex loss: 0.445201  [   20/   89]
per-ex loss: 0.608161  [   22/   89]
per-ex loss: 0.552950  [   24/   89]
per-ex loss: 0.692248  [   26/   89]
per-ex loss: 0.732254  [   28/   89]
per-ex loss: 0.669594  [   30/   89]
per-ex loss: 0.622079  [   32/   89]
per-ex loss: 0.675313  [   34/   89]
per-ex loss: 0.829780  [   36/   89]
per-ex loss: 0.549360  [   38/   89]
per-ex loss: 0.480053  [   40/   89]
per-ex loss: 0.695833  [   42/   89]
per-ex loss: 0.635530  [   44/   89]
per-ex loss: 0.750623  [   46/   89]
per-ex loss: 0.604164  [   48/   89]
per-ex loss: 0.748749  [   50/   89]
per-ex loss: 0.593100  [   52/   89]
per-ex loss: 0.634621  [   54/   89]
per-ex loss: 0.554013  [   56/   89]
per-ex loss: 0.676148  [   58/   89]
per-ex loss: 0.408946  [   60/   89]
per-ex loss: 0.478245  [   62/   89]
per-ex loss: 0.611987  [   64/   89]
per-ex loss: 0.567649  [   66/   89]
per-ex loss: 0.608911  [   68/   89]
per-ex loss: 0.501767  [   70/   89]
per-ex loss: 0.720632  [   72/   89]
per-ex loss: 0.754965  [   74/   89]
per-ex loss: 0.471149  [   76/   89]
per-ex loss: 0.650761  [   78/   89]
per-ex loss: 0.574043  [   80/   89]
per-ex loss: 0.634168  [   82/   89]
per-ex loss: 0.603646  [   84/   89]
per-ex loss: 0.488866  [   86/   89]
per-ex loss: 0.691133  [   88/   89]
per-ex loss: 0.692579  [   89/   89]
Train Error: Avg loss: 0.62707174
validation Error: 
 Avg loss: 0.71051877 
 F1: 0.505393 
 Precision: 0.646877 
 Recall: 0.414692
 IoU: 0.338144

test Error: 
 Avg loss: 0.68951091 
 F1: 0.539190 
 Precision: 0.658246 
 Recall: 0.456605
 IoU: 0.369104

We have finished training iteration 137
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_135_.pth
per-ex loss: 0.458379  [    2/   89]
per-ex loss: 0.520681  [    4/   89]
per-ex loss: 0.783227  [    6/   89]
per-ex loss: 0.683629  [    8/   89]
per-ex loss: 0.529705  [   10/   89]
per-ex loss: 0.533589  [   12/   89]
per-ex loss: 0.493022  [   14/   89]
per-ex loss: 0.530305  [   16/   89]
per-ex loss: 0.729222  [   18/   89]
per-ex loss: 0.747169  [   20/   89]
per-ex loss: 0.734597  [   22/   89]
per-ex loss: 0.546357  [   24/   89]
per-ex loss: 0.731133  [   26/   89]
per-ex loss: 0.695874  [   28/   89]
per-ex loss: 0.675666  [   30/   89]
per-ex loss: 0.664721  [   32/   89]
per-ex loss: 0.703830  [   34/   89]
per-ex loss: 0.527632  [   36/   89]
per-ex loss: 0.518963  [   38/   89]
per-ex loss: 0.711193  [   40/   89]
per-ex loss: 0.631902  [   42/   89]
per-ex loss: 0.462323  [   44/   89]
per-ex loss: 0.558872  [   46/   89]
per-ex loss: 0.585270  [   48/   89]
per-ex loss: 0.460754  [   50/   89]
per-ex loss: 0.593094  [   52/   89]
per-ex loss: 0.800825  [   54/   89]
per-ex loss: 0.524205  [   56/   89]
per-ex loss: 0.712941  [   58/   89]
per-ex loss: 0.686101  [   60/   89]
per-ex loss: 0.559172  [   62/   89]
per-ex loss: 0.626971  [   64/   89]
per-ex loss: 0.553632  [   66/   89]
per-ex loss: 0.561958  [   68/   89]
per-ex loss: 0.473524  [   70/   89]
per-ex loss: 0.753088  [   72/   89]
per-ex loss: 0.698074  [   74/   89]
per-ex loss: 0.679192  [   76/   89]
per-ex loss: 0.726605  [   78/   89]
per-ex loss: 0.775830  [   80/   89]
per-ex loss: 0.516053  [   82/   89]
per-ex loss: 0.648230  [   84/   89]
per-ex loss: 0.810931  [   86/   89]
per-ex loss: 0.441769  [   88/   89]
per-ex loss: 0.746301  [   89/   89]
Train Error: Avg loss: 0.62458907
validation Error: 
 Avg loss: 0.70656783 
 F1: 0.496165 
 Precision: 0.704713 
 Recall: 0.382863
 IoU: 0.329933

test Error: 
 Avg loss: 0.68930460 
 F1: 0.522415 
 Precision: 0.724877 
 Recall: 0.408358
 IoU: 0.353560

We have finished training iteration 138
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_136_.pth
per-ex loss: 0.649292  [    2/   89]
per-ex loss: 0.714431  [    4/   89]
per-ex loss: 0.579771  [    6/   89]
per-ex loss: 0.449992  [    8/   89]
per-ex loss: 0.615432  [   10/   89]
per-ex loss: 0.550326  [   12/   89]
per-ex loss: 0.623291  [   14/   89]
per-ex loss: 0.497036  [   16/   89]
per-ex loss: 0.654731  [   18/   89]
per-ex loss: 0.701696  [   20/   89]
per-ex loss: 0.516638  [   22/   89]
per-ex loss: 0.657030  [   24/   89]
per-ex loss: 0.671981  [   26/   89]
per-ex loss: 0.644886  [   28/   89]
per-ex loss: 0.636526  [   30/   89]
per-ex loss: 0.565804  [   32/   89]
per-ex loss: 0.547153  [   34/   89]
per-ex loss: 0.637626  [   36/   89]
per-ex loss: 0.651231  [   38/   89]
per-ex loss: 0.589833  [   40/   89]
per-ex loss: 0.561780  [   42/   89]
per-ex loss: 0.629454  [   44/   89]
per-ex loss: 0.412912  [   46/   89]
per-ex loss: 0.535759  [   48/   89]
per-ex loss: 0.525849  [   50/   89]
per-ex loss: 0.734011  [   52/   89]
per-ex loss: 0.716885  [   54/   89]
per-ex loss: 0.685609  [   56/   89]
per-ex loss: 0.838016  [   58/   89]
per-ex loss: 0.645897  [   60/   89]
per-ex loss: 0.469994  [   62/   89]
per-ex loss: 0.605184  [   64/   89]
per-ex loss: 0.713884  [   66/   89]
per-ex loss: 0.592488  [   68/   89]
per-ex loss: 0.743381  [   70/   89]
per-ex loss: 0.451992  [   72/   89]
per-ex loss: 0.535772  [   74/   89]
per-ex loss: 0.631064  [   76/   89]
per-ex loss: 0.581723  [   78/   89]
per-ex loss: 0.529889  [   80/   89]
per-ex loss: 0.519268  [   82/   89]
per-ex loss: 0.705955  [   84/   89]
per-ex loss: 0.497365  [   86/   89]
per-ex loss: 0.602188  [   88/   89]
per-ex loss: 0.713164  [   89/   89]
Train Error: Avg loss: 0.60742646
validation Error: 
 Avg loss: 0.71677375 
 F1: 0.452163 
 Precision: 0.787839 
 Recall: 0.317069
 IoU: 0.292126

test Error: 
 Avg loss: 0.69643709 
 F1: 0.473072 
 Precision: 0.799268 
 Recall: 0.335960
 IoU: 0.309819

We have finished training iteration 139
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_137_.pth
per-ex loss: 0.519000  [    2/   89]
per-ex loss: 0.665675  [    4/   89]
per-ex loss: 0.473516  [    6/   89]
per-ex loss: 0.515882  [    8/   89]
per-ex loss: 0.488995  [   10/   89]
per-ex loss: 0.525268  [   12/   89]
per-ex loss: 0.811867  [   14/   89]
per-ex loss: 0.570242  [   16/   89]
per-ex loss: 0.564975  [   18/   89]
per-ex loss: 0.597825  [   20/   89]
per-ex loss: 0.707124  [   22/   89]
per-ex loss: 0.787956  [   24/   89]
per-ex loss: 0.626278  [   26/   89]
per-ex loss: 0.576057  [   28/   89]
per-ex loss: 0.504726  [   30/   89]
per-ex loss: 0.521330  [   32/   89]
per-ex loss: 0.722545  [   34/   89]
per-ex loss: 0.654144  [   36/   89]
per-ex loss: 0.508581  [   38/   89]
per-ex loss: 0.567512  [   40/   89]
per-ex loss: 0.582650  [   42/   89]
per-ex loss: 0.741100  [   44/   89]
per-ex loss: 0.586299  [   46/   89]
per-ex loss: 0.642179  [   48/   89]
per-ex loss: 0.521511  [   50/   89]
per-ex loss: 0.665664  [   52/   89]
per-ex loss: 0.568022  [   54/   89]
per-ex loss: 0.540440  [   56/   89]
per-ex loss: 0.671652  [   58/   89]
per-ex loss: 0.527756  [   60/   89]
per-ex loss: 0.442393  [   62/   89]
per-ex loss: 0.511492  [   64/   89]
per-ex loss: 0.692376  [   66/   89]
per-ex loss: 0.586222  [   68/   89]
per-ex loss: 0.626200  [   70/   89]
per-ex loss: 0.849710  [   72/   89]
per-ex loss: 0.568966  [   74/   89]
per-ex loss: 0.557215  [   76/   89]
per-ex loss: 0.449150  [   78/   89]
per-ex loss: 0.796735  [   80/   89]
per-ex loss: 0.572080  [   82/   89]
per-ex loss: 0.772272  [   84/   89]
per-ex loss: 0.601132  [   86/   89]
per-ex loss: 0.715429  [   88/   89]
per-ex loss: 0.900780  [   89/   89]
Train Error: Avg loss: 0.61330943
validation Error: 
 Avg loss: 0.70096015 
 F1: 0.479931 
 Precision: 0.748265 
 Recall: 0.353252
 IoU: 0.315730

test Error: 
 Avg loss: 0.68847019 
 F1: 0.495546 
 Precision: 0.750204 
 Recall: 0.369962
 IoU: 0.329386

We have finished training iteration 140
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_138_.pth
per-ex loss: 0.383431  [    2/   89]
per-ex loss: 0.533146  [    4/   89]
per-ex loss: 0.571484  [    6/   89]
per-ex loss: 0.784320  [    8/   89]
per-ex loss: 0.664958  [   10/   89]
per-ex loss: 0.650826  [   12/   89]
per-ex loss: 0.440484  [   14/   89]
per-ex loss: 0.531381  [   16/   89]
per-ex loss: 0.510644  [   18/   89]
per-ex loss: 0.634903  [   20/   89]
per-ex loss: 0.422532  [   22/   89]
per-ex loss: 0.764473  [   24/   89]
per-ex loss: 0.644539  [   26/   89]
per-ex loss: 0.550164  [   28/   89]
per-ex loss: 0.520830  [   30/   89]
per-ex loss: 0.541008  [   32/   89]
per-ex loss: 0.706877  [   34/   89]
per-ex loss: 0.670478  [   36/   89]
per-ex loss: 0.654319  [   38/   89]
per-ex loss: 0.601882  [   40/   89]
per-ex loss: 0.612437  [   42/   89]
per-ex loss: 0.848035  [   44/   89]
per-ex loss: 0.718728  [   46/   89]
per-ex loss: 0.641543  [   48/   89]
per-ex loss: 0.512749  [   50/   89]
per-ex loss: 0.679146  [   52/   89]
per-ex loss: 0.552290  [   54/   89]
per-ex loss: 0.754572  [   56/   89]
per-ex loss: 0.751161  [   58/   89]
per-ex loss: 0.589481  [   60/   89]
per-ex loss: 0.634705  [   62/   89]
per-ex loss: 0.544226  [   64/   89]
per-ex loss: 0.463181  [   66/   89]
per-ex loss: 0.561209  [   68/   89]
per-ex loss: 0.718953  [   70/   89]
per-ex loss: 0.458612  [   72/   89]
per-ex loss: 0.585838  [   74/   89]
per-ex loss: 0.581783  [   76/   89]
per-ex loss: 0.634994  [   78/   89]
per-ex loss: 0.786398  [   80/   89]
per-ex loss: 0.574175  [   82/   89]
per-ex loss: 0.762429  [   84/   89]
per-ex loss: 0.637896  [   86/   89]
per-ex loss: 0.708902  [   88/   89]
per-ex loss: 0.540551  [   89/   89]
Train Error: Avg loss: 0.61414826
validation Error: 
 Avg loss: 0.70623739 
 F1: 0.494318 
 Precision: 0.679510 
 Recall: 0.388450
 IoU: 0.328302

test Error: 
 Avg loss: 0.68412901 
 F1: 0.517557 
 Precision: 0.708971 
 Recall: 0.407528
 IoU: 0.349124

We have finished training iteration 141
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_139_.pth
per-ex loss: 0.571677  [    2/   89]
per-ex loss: 0.486320  [    4/   89]
per-ex loss: 0.496202  [    6/   89]
per-ex loss: 0.442907  [    8/   89]
per-ex loss: 0.614936  [   10/   89]
per-ex loss: 0.582880  [   12/   89]
per-ex loss: 0.601322  [   14/   89]
per-ex loss: 0.697131  [   16/   89]
per-ex loss: 0.453888  [   18/   89]
per-ex loss: 0.626274  [   20/   89]
per-ex loss: 0.746450  [   22/   89]
per-ex loss: 0.732571  [   24/   89]
per-ex loss: 0.457269  [   26/   89]
per-ex loss: 0.689932  [   28/   89]
per-ex loss: 0.628634  [   30/   89]
per-ex loss: 0.735103  [   32/   89]
per-ex loss: 0.779018  [   34/   89]
per-ex loss: 0.778251  [   36/   89]
per-ex loss: 0.597465  [   38/   89]
per-ex loss: 0.723775  [   40/   89]
per-ex loss: 0.556636  [   42/   89]
per-ex loss: 0.587363  [   44/   89]
per-ex loss: 0.782242  [   46/   89]
per-ex loss: 0.640410  [   48/   89]
per-ex loss: 0.822054  [   50/   89]
per-ex loss: 0.616335  [   52/   89]
per-ex loss: 0.597460  [   54/   89]
per-ex loss: 0.547706  [   56/   89]
per-ex loss: 0.669169  [   58/   89]
per-ex loss: 0.509057  [   60/   89]
per-ex loss: 0.601575  [   62/   89]
per-ex loss: 0.664546  [   64/   89]
per-ex loss: 0.646293  [   66/   89]
per-ex loss: 0.623829  [   68/   89]
per-ex loss: 0.610629  [   70/   89]
per-ex loss: 0.747543  [   72/   89]
per-ex loss: 0.661795  [   74/   89]
per-ex loss: 0.489570  [   76/   89]
per-ex loss: 0.456343  [   78/   89]
per-ex loss: 0.581550  [   80/   89]
per-ex loss: 0.585670  [   82/   89]
per-ex loss: 0.521636  [   84/   89]
per-ex loss: 0.638712  [   86/   89]
per-ex loss: 0.499507  [   88/   89]
per-ex loss: 0.579596  [   89/   89]
Train Error: Avg loss: 0.61509400
validation Error: 
 Avg loss: 0.69778013 
 F1: 0.458957 
 Precision: 0.765506 
 Recall: 0.327720
 IoU: 0.297822

test Error: 
 Avg loss: 0.69095758 
 F1: 0.469901 
 Precision: 0.784005 
 Recall: 0.335490
 IoU: 0.307105

We have finished training iteration 142
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_140_.pth
per-ex loss: 0.413538  [    2/   89]
per-ex loss: 0.636272  [    4/   89]
per-ex loss: 0.571450  [    6/   89]
per-ex loss: 0.618150  [    8/   89]
per-ex loss: 0.636651  [   10/   89]
per-ex loss: 0.552136  [   12/   89]
per-ex loss: 0.563925  [   14/   89]
per-ex loss: 0.595409  [   16/   89]
per-ex loss: 0.547585  [   18/   89]
per-ex loss: 0.536145  [   20/   89]
per-ex loss: 0.555269  [   22/   89]
per-ex loss: 0.734089  [   24/   89]
per-ex loss: 0.681252  [   26/   89]
per-ex loss: 0.641383  [   28/   89]
per-ex loss: 0.662017  [   30/   89]
per-ex loss: 0.562496  [   32/   89]
per-ex loss: 0.564020  [   34/   89]
per-ex loss: 0.527617  [   36/   89]
per-ex loss: 0.664506  [   38/   89]
per-ex loss: 0.675294  [   40/   89]
per-ex loss: 0.714141  [   42/   89]
per-ex loss: 0.644808  [   44/   89]
per-ex loss: 0.629864  [   46/   89]
per-ex loss: 0.606289  [   48/   89]
per-ex loss: 0.805402  [   50/   89]
per-ex loss: 0.478757  [   52/   89]
per-ex loss: 0.567426  [   54/   89]
per-ex loss: 0.525410  [   56/   89]
per-ex loss: 0.484012  [   58/   89]
per-ex loss: 0.829713  [   60/   89]
per-ex loss: 0.768344  [   62/   89]
per-ex loss: 0.576579  [   64/   89]
per-ex loss: 0.682791  [   66/   89]
per-ex loss: 0.633990  [   68/   89]
per-ex loss: 0.704444  [   70/   89]
per-ex loss: 0.682359  [   72/   89]
per-ex loss: 0.500402  [   74/   89]
per-ex loss: 0.729145  [   76/   89]
per-ex loss: 0.621799  [   78/   89]
per-ex loss: 0.466018  [   80/   89]
per-ex loss: 0.559757  [   82/   89]
per-ex loss: 0.489412  [   84/   89]
per-ex loss: 0.564295  [   86/   89]
per-ex loss: 0.591667  [   88/   89]
per-ex loss: 0.436267  [   89/   89]
Train Error: Avg loss: 0.60516204
validation Error: 
 Avg loss: 0.69005984 
 F1: 0.496663 
 Precision: 0.716857 
 Recall: 0.379954
 IoU: 0.330374

test Error: 
 Avg loss: 0.67501911 
 F1: 0.515392 
 Precision: 0.735151 
 Recall: 0.396782
 IoU: 0.347157

We have finished training iteration 143
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_141_.pth
Error in cropping the image to the non-zero values in the fourth channel. Returned the original image.
per-ex loss: 0.460260  [    2/   89]
per-ex loss: 0.730662  [    4/   89]
per-ex loss: 0.660496  [    6/   89]
per-ex loss: 0.471530  [    8/   89]
per-ex loss: 0.452418  [   10/   89]
per-ex loss: 0.634522  [   12/   89]
per-ex loss: 0.606347  [   14/   89]
per-ex loss: 0.661606  [   16/   89]
per-ex loss: 0.764425  [   18/   89]
per-ex loss: 0.664608  [   20/   89]
per-ex loss: 0.660169  [   22/   89]
per-ex loss: 0.542768  [   24/   89]
per-ex loss: 0.717127  [   26/   89]
per-ex loss: 0.623241  [   28/   89]
per-ex loss: 0.518698  [   30/   89]
per-ex loss: 0.701124  [   32/   89]
per-ex loss: 0.600571  [   34/   89]
per-ex loss: 0.644900  [   36/   89]
per-ex loss: 0.706387  [   38/   89]
per-ex loss: 0.581086  [   40/   89]
per-ex loss: 0.534739  [   42/   89]
per-ex loss: 0.486524  [   44/   89]
per-ex loss: 0.525963  [   46/   89]
per-ex loss: 0.528502  [   48/   89]
per-ex loss: 0.444724  [   50/   89]
per-ex loss: 0.560470  [   52/   89]
per-ex loss: 0.614159  [   54/   89]
per-ex loss: 0.749587  [   56/   89]
per-ex loss: 0.764411  [   58/   89]
per-ex loss: 0.551738  [   60/   89]
per-ex loss: 0.553099  [   62/   89]
per-ex loss: 0.643883  [   64/   89]
per-ex loss: 0.533068  [   66/   89]
per-ex loss: 0.700826  [   68/   89]
per-ex loss: 0.539898  [   70/   89]
per-ex loss: 0.673771  [   72/   89]
per-ex loss: 0.688346  [   74/   89]
per-ex loss: 0.564935  [   76/   89]
per-ex loss: 0.582933  [   78/   89]
per-ex loss: 0.650466  [   80/   89]
per-ex loss: 0.542192  [   82/   89]
per-ex loss: 0.665270  [   84/   89]
per-ex loss: 0.488737  [   86/   89]
per-ex loss: 0.549733  [   88/   89]
per-ex loss: 0.908201  [   89/   89]
Train Error: Avg loss: 0.60998047
validation Error: 
 Avg loss: 0.70117996 
 F1: 0.508101 
 Precision: 0.610817 
 Recall: 0.434958
 IoU: 0.340573

test Error: 
 Avg loss: 0.68598150 
 F1: 0.537803 
 Precision: 0.645392 
 Recall: 0.460960
 IoU: 0.367805

We have finished training iteration 144
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_142_.pth
Error in cropping the image to the non-zero values in the fourth channel. Returned the original image.
per-ex loss: 0.586264  [    2/   89]
per-ex loss: 0.565709  [    4/   89]
per-ex loss: 0.650940  [    6/   89]
per-ex loss: 0.543033  [    8/   89]
per-ex loss: 0.591453  [   10/   89]
per-ex loss: 0.512078  [   12/   89]
per-ex loss: 0.696463  [   14/   89]
per-ex loss: 0.720907  [   16/   89]
per-ex loss: 0.619934  [   18/   89]
per-ex loss: 0.676274  [   20/   89]
per-ex loss: 0.737803  [   22/   89]
per-ex loss: 0.550521  [   24/   89]
per-ex loss: 0.500647  [   26/   89]
per-ex loss: 0.402799  [   28/   89]
per-ex loss: 0.848870  [   30/   89]
per-ex loss: 0.635417  [   32/   89]
per-ex loss: 0.763084  [   34/   89]
per-ex loss: 0.473617  [   36/   89]
per-ex loss: 0.539952  [   38/   89]
per-ex loss: 0.554057  [   40/   89]
per-ex loss: 0.542508  [   42/   89]
per-ex loss: 0.588122  [   44/   89]
per-ex loss: 0.772540  [   46/   89]
per-ex loss: 0.581865  [   48/   89]
per-ex loss: 0.719573  [   50/   89]
per-ex loss: 0.626940  [   52/   89]
per-ex loss: 0.485543  [   54/   89]
per-ex loss: 0.491632  [   56/   89]
per-ex loss: 0.525760  [   58/   89]
per-ex loss: 0.681202  [   60/   89]
per-ex loss: 0.494148  [   62/   89]
per-ex loss: 0.500362  [   64/   89]
per-ex loss: 0.650088  [   66/   89]
per-ex loss: 0.664544  [   68/   89]
per-ex loss: 0.497486  [   70/   89]
per-ex loss: 0.468987  [   72/   89]
per-ex loss: 0.528998  [   74/   89]
per-ex loss: 0.795964  [   76/   89]
per-ex loss: 0.597887  [   78/   89]
per-ex loss: 0.674449  [   80/   89]
per-ex loss: 0.661280  [   82/   89]
per-ex loss: 0.625219  [   84/   89]
per-ex loss: 0.529256  [   86/   89]
per-ex loss: 0.548600  [   88/   89]
per-ex loss: 0.628000  [   89/   89]
Train Error: Avg loss: 0.60112842
validation Error: 
 Avg loss: 0.69966392 
 F1: 0.481104 
 Precision: 0.729863 
 Recall: 0.358811
 IoU: 0.316746

test Error: 
 Avg loss: 0.67938446 
 F1: 0.494985 
 Precision: 0.747454 
 Recall: 0.370007
 IoU: 0.328891

We have finished training iteration 145
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_143_.pth
Error in cropping the image to the non-zero values in the fourth channel. Returned the original image.
per-ex loss: 0.575210  [    2/   89]
per-ex loss: 0.454337  [    4/   89]
per-ex loss: 0.702248  [    6/   89]
per-ex loss: 0.757977  [    8/   89]
per-ex loss: 0.738525  [   10/   89]
per-ex loss: 0.634526  [   12/   89]
per-ex loss: 0.543662  [   14/   89]
per-ex loss: 0.650925  [   16/   89]
per-ex loss: 0.580526  [   18/   89]
per-ex loss: 0.531688  [   20/   89]
per-ex loss: 0.509248  [   22/   89]
per-ex loss: 0.589401  [   24/   89]
per-ex loss: 0.603179  [   26/   89]
per-ex loss: 0.504722  [   28/   89]
per-ex loss: 0.607294  [   30/   89]
per-ex loss: 0.482783  [   32/   89]
per-ex loss: 0.542904  [   34/   89]
per-ex loss: 0.665912  [   36/   89]
per-ex loss: 0.588844  [   38/   89]
per-ex loss: 0.682486  [   40/   89]
per-ex loss: 0.717040  [   42/   89]
per-ex loss: 0.585589  [   44/   89]
per-ex loss: 0.563620  [   46/   89]
per-ex loss: 0.650893  [   48/   89]
per-ex loss: 0.737162  [   50/   89]
per-ex loss: 0.462214  [   52/   89]
per-ex loss: 0.467261  [   54/   89]
per-ex loss: 0.416740  [   56/   89]
per-ex loss: 0.516256  [   58/   89]
per-ex loss: 0.620179  [   60/   89]
per-ex loss: 0.643195  [   62/   89]
per-ex loss: 0.702280  [   64/   89]
per-ex loss: 0.571599  [   66/   89]
per-ex loss: 0.764300  [   68/   89]
per-ex loss: 0.745010  [   70/   89]
per-ex loss: 0.549349  [   72/   89]
per-ex loss: 0.559457  [   74/   89]
per-ex loss: 0.637425  [   76/   89]
per-ex loss: 0.525500  [   78/   89]
per-ex loss: 0.550918  [   80/   89]
per-ex loss: 0.738418  [   82/   89]
per-ex loss: 0.679322  [   84/   89]
per-ex loss: 0.570322  [   86/   89]
per-ex loss: 0.681474  [   88/   89]
per-ex loss: 0.503275  [   89/   89]
Train Error: Avg loss: 0.60233762
validation Error: 
 Avg loss: 0.69301230 
 F1: 0.505028 
 Precision: 0.672955 
 Recall: 0.404172
 IoU: 0.337818

test Error: 
 Avg loss: 0.67533133 
 F1: 0.530662 
 Precision: 0.696633 
 Recall: 0.428559
 IoU: 0.361157

We have finished training iteration 146
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_144_.pth
per-ex loss: 0.449000  [    2/   89]
per-ex loss: 0.615873  [    4/   89]
per-ex loss: 0.603477  [    6/   89]
per-ex loss: 0.684190  [    8/   89]
per-ex loss: 0.637415  [   10/   89]
per-ex loss: 0.489783  [   12/   89]
per-ex loss: 0.582431  [   14/   89]
per-ex loss: 0.575700  [   16/   89]
per-ex loss: 0.807341  [   18/   89]
per-ex loss: 0.749935  [   20/   89]
per-ex loss: 0.463285  [   22/   89]
per-ex loss: 0.560510  [   24/   89]
per-ex loss: 0.457993  [   26/   89]
per-ex loss: 0.716823  [   28/   89]
per-ex loss: 0.507720  [   30/   89]
per-ex loss: 0.791303  [   32/   89]
per-ex loss: 0.574278  [   34/   89]
per-ex loss: 0.673515  [   36/   89]
per-ex loss: 0.530255  [   38/   89]
per-ex loss: 0.775458  [   40/   89]
per-ex loss: 0.561394  [   42/   89]
per-ex loss: 0.608126  [   44/   89]
per-ex loss: 0.668001  [   46/   89]
per-ex loss: 0.468455  [   48/   89]
per-ex loss: 0.448079  [   50/   89]
per-ex loss: 0.665516  [   52/   89]
per-ex loss: 0.796187  [   54/   89]
per-ex loss: 0.610045  [   56/   89]
per-ex loss: 0.570429  [   58/   89]
per-ex loss: 0.461044  [   60/   89]
per-ex loss: 0.528888  [   62/   89]
per-ex loss: 0.549589  [   64/   89]
per-ex loss: 0.498976  [   66/   89]
per-ex loss: 0.822702  [   68/   89]
per-ex loss: 0.431816  [   70/   89]
per-ex loss: 0.628054  [   72/   89]
per-ex loss: 0.588409  [   74/   89]
per-ex loss: 0.477368  [   76/   89]
per-ex loss: 0.542105  [   78/   89]
per-ex loss: 0.673846  [   80/   89]
per-ex loss: 0.666171  [   82/   89]
per-ex loss: 0.449079  [   84/   89]
per-ex loss: 0.567270  [   86/   89]
per-ex loss: 0.617910  [   88/   89]
per-ex loss: 0.705913  [   89/   89]
Train Error: Avg loss: 0.59670345
validation Error: 
 Avg loss: 0.68924475 
 F1: 0.511160 
 Precision: 0.634267 
 Recall: 0.428074
 IoU: 0.343328

test Error: 
 Avg loss: 0.67321580 
 F1: 0.532188 
 Precision: 0.637990 
 Recall: 0.456486
 IoU: 0.362572

We have finished training iteration 147
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_145_.pth
per-ex loss: 0.719145  [    2/   89]
per-ex loss: 0.706008  [    4/   89]
per-ex loss: 0.481945  [    6/   89]
per-ex loss: 0.682247  [    8/   89]
per-ex loss: 0.543231  [   10/   89]
per-ex loss: 0.612997  [   12/   89]
per-ex loss: 0.584923  [   14/   89]
per-ex loss: 0.698457  [   16/   89]
per-ex loss: 0.501862  [   18/   89]
per-ex loss: 0.665801  [   20/   89]
per-ex loss: 0.543437  [   22/   89]
per-ex loss: 0.581086  [   24/   89]
per-ex loss: 0.687233  [   26/   89]
per-ex loss: 0.534913  [   28/   89]
per-ex loss: 0.553405  [   30/   89]
per-ex loss: 0.644389  [   32/   89]
per-ex loss: 0.634380  [   34/   89]
per-ex loss: 0.621418  [   36/   89]
per-ex loss: 0.651653  [   38/   89]
per-ex loss: 0.683863  [   40/   89]
per-ex loss: 0.717825  [   42/   89]
per-ex loss: 0.770813  [   44/   89]
per-ex loss: 0.443329  [   46/   89]
per-ex loss: 0.649184  [   48/   89]
per-ex loss: 0.680225  [   50/   89]
per-ex loss: 0.751632  [   52/   89]
per-ex loss: 0.555475  [   54/   89]
per-ex loss: 0.833333  [   56/   89]
per-ex loss: 0.549676  [   58/   89]
per-ex loss: 0.413615  [   60/   89]
per-ex loss: 0.725245  [   62/   89]
per-ex loss: 0.491888  [   64/   89]
per-ex loss: 0.567089  [   66/   89]
per-ex loss: 0.402301  [   68/   89]
per-ex loss: 0.659810  [   70/   89]
per-ex loss: 0.597698  [   72/   89]
per-ex loss: 0.524582  [   74/   89]
per-ex loss: 0.515600  [   76/   89]
per-ex loss: 0.549805  [   78/   89]
per-ex loss: 0.581123  [   80/   89]
per-ex loss: 0.442948  [   82/   89]
per-ex loss: 0.607248  [   84/   89]
per-ex loss: 0.632359  [   86/   89]
per-ex loss: 0.676208  [   88/   89]
per-ex loss: 0.676296  [   89/   89]
Train Error: Avg loss: 0.60772667
validation Error: 
 Avg loss: 0.68600294 
 F1: 0.483621 
 Precision: 0.713163 
 Recall: 0.365863
 IoU: 0.318932

test Error: 
 Avg loss: 0.68413799 
 F1: 0.482487 
 Precision: 0.745859 
 Recall: 0.356576
 IoU: 0.317946

We have finished training iteration 148
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_146_.pth
per-ex loss: 0.470807  [    2/   89]
per-ex loss: 0.594919  [    4/   89]
per-ex loss: 0.700683  [    6/   89]
per-ex loss: 0.737707  [    8/   89]
per-ex loss: 0.620263  [   10/   89]
per-ex loss: 0.681710  [   12/   89]
per-ex loss: 0.534879  [   14/   89]
per-ex loss: 0.619013  [   16/   89]
per-ex loss: 0.512819  [   18/   89]
per-ex loss: 0.631650  [   20/   89]
per-ex loss: 0.584165  [   22/   89]
per-ex loss: 0.613044  [   24/   89]
per-ex loss: 0.520148  [   26/   89]
per-ex loss: 0.565944  [   28/   89]
per-ex loss: 0.426332  [   30/   89]
per-ex loss: 0.518782  [   32/   89]
per-ex loss: 0.752590  [   34/   89]
per-ex loss: 0.404737  [   36/   89]
per-ex loss: 0.647301  [   38/   89]
per-ex loss: 0.577831  [   40/   89]
per-ex loss: 0.809852  [   42/   89]
per-ex loss: 0.658174  [   44/   89]
per-ex loss: 0.594673  [   46/   89]
per-ex loss: 0.763650  [   48/   89]
per-ex loss: 0.659233  [   50/   89]
per-ex loss: 0.545664  [   52/   89]
per-ex loss: 0.563637  [   54/   89]
per-ex loss: 0.640742  [   56/   89]
per-ex loss: 0.467480  [   58/   89]
per-ex loss: 0.710256  [   60/   89]
per-ex loss: 0.881555  [   62/   89]
per-ex loss: 0.630546  [   64/   89]
per-ex loss: 0.508113  [   66/   89]
per-ex loss: 0.793105  [   68/   89]
per-ex loss: 0.573006  [   70/   89]
per-ex loss: 0.761126  [   72/   89]
per-ex loss: 0.469316  [   74/   89]
per-ex loss: 0.785948  [   76/   89]
per-ex loss: 0.588235  [   78/   89]
per-ex loss: 0.737424  [   80/   89]
per-ex loss: 0.592703  [   82/   89]
per-ex loss: 0.447543  [   84/   89]
per-ex loss: 0.518145  [   86/   89]
per-ex loss: 0.632718  [   88/   89]
per-ex loss: 0.410500  [   89/   89]
Train Error: Avg loss: 0.61019257
validation Error: 
 Avg loss: 0.66748964 
 F1: 0.504679 
 Precision: 0.685149 
 Recall: 0.399460
 IoU: 0.337505

test Error: 
 Avg loss: 0.65846677 
 F1: 0.529484 
 Precision: 0.698452 
 Recall: 0.426344
 IoU: 0.360067

We have finished training iteration 149
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_147_.pth
per-ex loss: 0.780047  [    2/   89]
per-ex loss: 0.465352  [    4/   89]
per-ex loss: 0.477425  [    6/   89]
per-ex loss: 0.736125  [    8/   89]
per-ex loss: 0.574111  [   10/   89]
per-ex loss: 0.473775  [   12/   89]
per-ex loss: 0.622898  [   14/   89]
per-ex loss: 0.680729  [   16/   89]
per-ex loss: 0.653959  [   18/   89]
per-ex loss: 0.588024  [   20/   89]
per-ex loss: 0.560555  [   22/   89]
per-ex loss: 0.696171  [   24/   89]
per-ex loss: 0.822841  [   26/   89]
per-ex loss: 0.689510  [   28/   89]
per-ex loss: 0.544386  [   30/   89]
per-ex loss: 0.466332  [   32/   89]
per-ex loss: 0.448629  [   34/   89]
per-ex loss: 0.502458  [   36/   89]
per-ex loss: 0.501887  [   38/   89]
per-ex loss: 0.740535  [   40/   89]
per-ex loss: 0.644258  [   42/   89]
per-ex loss: 0.610012  [   44/   89]
per-ex loss: 0.533033  [   46/   89]
per-ex loss: 0.560637  [   48/   89]
per-ex loss: 0.646544  [   50/   89]
per-ex loss: 0.737761  [   52/   89]
per-ex loss: 0.488944  [   54/   89]
per-ex loss: 0.507917  [   56/   89]
per-ex loss: 0.698819  [   58/   89]
per-ex loss: 0.705042  [   60/   89]
per-ex loss: 0.661797  [   62/   89]
per-ex loss: 0.625141  [   64/   89]
per-ex loss: 0.440315  [   66/   89]
per-ex loss: 0.592094  [   68/   89]
per-ex loss: 0.807492  [   70/   89]
per-ex loss: 0.744956  [   72/   89]
per-ex loss: 0.682957  [   74/   89]
per-ex loss: 0.543618  [   76/   89]
per-ex loss: 0.644905  [   78/   89]
per-ex loss: 0.689148  [   80/   89]
per-ex loss: 0.564347  [   82/   89]
per-ex loss: 0.493528  [   84/   89]
per-ex loss: 0.545001  [   86/   89]
per-ex loss: 0.514362  [   88/   89]
per-ex loss: 0.431846  [   89/   89]
Train Error: Avg loss: 0.60311601
validation Error: 
 Avg loss: 0.68313488 
 F1: 0.487524 
 Precision: 0.743826 
 Recall: 0.362587
 IoU: 0.322335

test Error: 
 Avg loss: 0.66447487 
 F1: 0.504688 
 Precision: 0.755525 
 Recall: 0.378894
 IoU: 0.337514

We have finished training iteration 150
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_148_.pth
per-ex loss: 0.693515  [    2/   89]
per-ex loss: 0.701823  [    4/   89]
per-ex loss: 0.674477  [    6/   89]
per-ex loss: 0.562038  [    8/   89]
per-ex loss: 0.534868  [   10/   89]
per-ex loss: 0.578764  [   12/   89]
per-ex loss: 0.587535  [   14/   89]
per-ex loss: 0.478814  [   16/   89]
per-ex loss: 0.588377  [   18/   89]
per-ex loss: 0.725937  [   20/   89]
per-ex loss: 0.575598  [   22/   89]
per-ex loss: 0.675442  [   24/   89]
per-ex loss: 0.697387  [   26/   89]
per-ex loss: 0.602079  [   28/   89]
per-ex loss: 0.378870  [   30/   89]
per-ex loss: 0.518750  [   32/   89]
per-ex loss: 0.611080  [   34/   89]
per-ex loss: 0.574340  [   36/   89]
per-ex loss: 0.689215  [   38/   89]
per-ex loss: 0.678028  [   40/   89]
per-ex loss: 0.641482  [   42/   89]
per-ex loss: 0.689182  [   44/   89]
per-ex loss: 0.485706  [   46/   89]
per-ex loss: 0.555441  [   48/   89]
per-ex loss: 0.574831  [   50/   89]
per-ex loss: 0.546172  [   52/   89]
per-ex loss: 0.492306  [   54/   89]
per-ex loss: 0.454822  [   56/   89]
per-ex loss: 0.665548  [   58/   89]
per-ex loss: 0.806811  [   60/   89]
per-ex loss: 0.522731  [   62/   89]
per-ex loss: 0.576862  [   64/   89]
per-ex loss: 0.552482  [   66/   89]
per-ex loss: 0.437988  [   68/   89]
per-ex loss: 0.723095  [   70/   89]
per-ex loss: 0.657171  [   72/   89]
per-ex loss: 0.612045  [   74/   89]
per-ex loss: 0.574263  [   76/   89]
per-ex loss: 0.472242  [   78/   89]
per-ex loss: 0.468662  [   80/   89]
per-ex loss: 0.509625  [   82/   89]
per-ex loss: 0.564775  [   84/   89]
per-ex loss: 0.572737  [   86/   89]
per-ex loss: 0.521863  [   88/   89]
per-ex loss: 0.989945  [   89/   89]
Train Error: Avg loss: 0.59546061
validation Error: 
 Avg loss: 0.68303396 
 F1: 0.456263 
 Precision: 0.765430 
 Recall: 0.324994
 IoU: 0.295557

test Error: 
 Avg loss: 0.68047618 
 F1: 0.469797 
 Precision: 0.785671 
 Recall: 0.335081
 IoU: 0.307016

We have finished training iteration 151
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_149_.pth
per-ex loss: 0.701012  [    2/   89]
per-ex loss: 0.665715  [    4/   89]
per-ex loss: 0.524570  [    6/   89]
per-ex loss: 0.544476  [    8/   89]
per-ex loss: 0.504644  [   10/   89]
per-ex loss: 0.553072  [   12/   89]
per-ex loss: 0.637727  [   14/   89]
per-ex loss: 0.574070  [   16/   89]
per-ex loss: 0.594720  [   18/   89]
per-ex loss: 0.686378  [   20/   89]
per-ex loss: 0.588317  [   22/   89]
per-ex loss: 0.520491  [   24/   89]
per-ex loss: 0.600617  [   26/   89]
per-ex loss: 0.887552  [   28/   89]
per-ex loss: 0.502264  [   30/   89]
per-ex loss: 0.427272  [   32/   89]
per-ex loss: 0.489278  [   34/   89]
per-ex loss: 0.558619  [   36/   89]
per-ex loss: 0.581557  [   38/   89]
per-ex loss: 0.648901  [   40/   89]
per-ex loss: 0.496173  [   42/   89]
per-ex loss: 0.543306  [   44/   89]
per-ex loss: 0.663846  [   46/   89]
per-ex loss: 0.620341  [   48/   89]
per-ex loss: 0.601115  [   50/   89]
per-ex loss: 0.714771  [   52/   89]
per-ex loss: 0.579501  [   54/   89]
per-ex loss: 0.590813  [   56/   89]
per-ex loss: 0.489349  [   58/   89]
per-ex loss: 0.731952  [   60/   89]
per-ex loss: 0.666046  [   62/   89]
per-ex loss: 0.506844  [   64/   89]
per-ex loss: 0.768387  [   66/   89]
per-ex loss: 0.540665  [   68/   89]
per-ex loss: 0.404658  [   70/   89]
per-ex loss: 0.626548  [   72/   89]
per-ex loss: 0.563790  [   74/   89]
per-ex loss: 0.455456  [   76/   89]
per-ex loss: 0.585052  [   78/   89]
per-ex loss: 0.534667  [   80/   89]
per-ex loss: 0.562790  [   82/   89]
per-ex loss: 0.408433  [   84/   89]
per-ex loss: 0.729794  [   86/   89]
per-ex loss: 0.754519  [   88/   89]
per-ex loss: 0.821605  [   89/   89]
Train Error: Avg loss: 0.59448165
validation Error: 
 Avg loss: 0.67489922 
 F1: 0.489867 
 Precision: 0.714361 
 Recall: 0.372733
 IoU: 0.324387

test Error: 
 Avg loss: 0.65896263 
 F1: 0.527117 
 Precision: 0.706278 
 Recall: 0.420459
 IoU: 0.357881

We have finished training iteration 152
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_150_.pth
per-ex loss: 0.449313  [    2/   89]
per-ex loss: 0.497991  [    4/   89]
per-ex loss: 0.627402  [    6/   89]
per-ex loss: 0.643979  [    8/   89]
per-ex loss: 0.623241  [   10/   89]
per-ex loss: 0.565229  [   12/   89]
per-ex loss: 0.538516  [   14/   89]
per-ex loss: 0.685323  [   16/   89]
per-ex loss: 0.560683  [   18/   89]
per-ex loss: 0.628645  [   20/   89]
per-ex loss: 0.613913  [   22/   89]
per-ex loss: 0.707824  [   24/   89]
per-ex loss: 0.652700  [   26/   89]
per-ex loss: 0.485459  [   28/   89]
per-ex loss: 0.475853  [   30/   89]
per-ex loss: 0.598901  [   32/   89]
per-ex loss: 0.428278  [   34/   89]
per-ex loss: 0.856704  [   36/   89]
per-ex loss: 0.644406  [   38/   89]
per-ex loss: 0.674826  [   40/   89]
per-ex loss: 0.437186  [   42/   89]
per-ex loss: 0.575896  [   44/   89]
per-ex loss: 0.559916  [   46/   89]
per-ex loss: 0.470819  [   48/   89]
per-ex loss: 0.424818  [   50/   89]
per-ex loss: 0.575951  [   52/   89]
per-ex loss: 0.606058  [   54/   89]
per-ex loss: 0.507468  [   56/   89]
per-ex loss: 0.572394  [   58/   89]
per-ex loss: 0.665877  [   60/   89]
per-ex loss: 0.667019  [   62/   89]
per-ex loss: 0.682892  [   64/   89]
per-ex loss: 0.692684  [   66/   89]
per-ex loss: 0.570570  [   68/   89]
per-ex loss: 0.584740  [   70/   89]
per-ex loss: 0.533294  [   72/   89]
per-ex loss: 0.671291  [   74/   89]
per-ex loss: 0.602740  [   76/   89]
per-ex loss: 0.399818  [   78/   89]
per-ex loss: 0.793235  [   80/   89]
per-ex loss: 0.619141  [   82/   89]
per-ex loss: 0.539457  [   84/   89]
per-ex loss: 0.717267  [   86/   89]
per-ex loss: 0.502327  [   88/   89]
per-ex loss: 0.383007  [   89/   89]
Train Error: Avg loss: 0.58477890
validation Error: 
 Avg loss: 0.66834163 
 F1: 0.484276 
 Precision: 0.752661 
 Recall: 0.356982
 IoU: 0.319501

test Error: 
 Avg loss: 0.65728634 
 F1: 0.507178 
 Precision: 0.766762 
 Recall: 0.378902
 IoU: 0.339744

We have finished training iteration 153
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_151_.pth
Error in cropping the image to the non-zero values in the fourth channel. Returned the original image.
per-ex loss: 0.511232  [    2/   89]
per-ex loss: 0.518187  [    4/   89]
per-ex loss: 0.482292  [    6/   89]
per-ex loss: 0.471954  [    8/   89]
per-ex loss: 0.569503  [   10/   89]
per-ex loss: 0.564464  [   12/   89]
per-ex loss: 0.759110  [   14/   89]
per-ex loss: 0.689338  [   16/   89]
per-ex loss: 0.578180  [   18/   89]
per-ex loss: 0.782872  [   20/   89]
per-ex loss: 0.537377  [   22/   89]
per-ex loss: 0.555792  [   24/   89]
per-ex loss: 0.486217  [   26/   89]
per-ex loss: 0.446838  [   28/   89]
per-ex loss: 0.616256  [   30/   89]
per-ex loss: 0.521230  [   32/   89]
per-ex loss: 0.419330  [   34/   89]
per-ex loss: 0.643815  [   36/   89]
per-ex loss: 0.482594  [   38/   89]
per-ex loss: 0.518060  [   40/   89]
per-ex loss: 0.660605  [   42/   89]
per-ex loss: 0.531084  [   44/   89]
per-ex loss: 0.607324  [   46/   89]
per-ex loss: 0.489311  [   48/   89]
per-ex loss: 0.522263  [   50/   89]
per-ex loss: 0.670305  [   52/   89]
per-ex loss: 0.594863  [   54/   89]
per-ex loss: 0.568334  [   56/   89]
per-ex loss: 0.673595  [   58/   89]
per-ex loss: 0.651996  [   60/   89]
per-ex loss: 0.708591  [   62/   89]
per-ex loss: 0.486083  [   64/   89]
per-ex loss: 0.908780  [   66/   89]
per-ex loss: 0.703560  [   68/   89]
per-ex loss: 0.506031  [   70/   89]
per-ex loss: 0.538801  [   72/   89]
per-ex loss: 0.515115  [   74/   89]
per-ex loss: 0.645156  [   76/   89]
per-ex loss: 0.550413  [   78/   89]
per-ex loss: 0.529714  [   80/   89]
per-ex loss: 0.414911  [   82/   89]
per-ex loss: 0.613396  [   84/   89]
per-ex loss: 0.639517  [   86/   89]
per-ex loss: 0.575721  [   88/   89]
per-ex loss: 0.890128  [   89/   89]
Train Error: Avg loss: 0.58556077
validation Error: 
 Avg loss: 0.67732247 
 F1: 0.489366 
 Precision: 0.718619 
 Recall: 0.371007
 IoU: 0.323947

test Error: 
 Avg loss: 0.67181325 
 F1: 0.496973 
 Precision: 0.705006 
 Recall: 0.383739
 IoU: 0.330648

We have finished training iteration 154
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_152_.pth
Error in cropping the image to the non-zero values in the fourth channel. Returned the original image.
per-ex loss: 0.655155  [    2/   89]
per-ex loss: 0.598968  [    4/   89]
per-ex loss: 0.527768  [    6/   89]
per-ex loss: 0.546489  [    8/   89]
per-ex loss: 0.723313  [   10/   89]
per-ex loss: 0.656083  [   12/   89]
per-ex loss: 0.828985  [   14/   89]
per-ex loss: 0.590129  [   16/   89]
per-ex loss: 0.445626  [   18/   89]
per-ex loss: 0.659011  [   20/   89]
per-ex loss: 0.686235  [   22/   89]
per-ex loss: 0.632457  [   24/   89]
per-ex loss: 0.604207  [   26/   89]
per-ex loss: 0.488642  [   28/   89]
per-ex loss: 0.601912  [   30/   89]
per-ex loss: 0.673346  [   32/   89]
per-ex loss: 0.785865  [   34/   89]
per-ex loss: 0.468138  [   36/   89]
per-ex loss: 0.537820  [   38/   89]
per-ex loss: 0.611536  [   40/   89]
per-ex loss: 0.445054  [   42/   89]
per-ex loss: 0.711936  [   44/   89]
per-ex loss: 0.437786  [   46/   89]
per-ex loss: 0.589850  [   48/   89]
per-ex loss: 0.591282  [   50/   89]
per-ex loss: 0.504317  [   52/   89]
per-ex loss: 0.490004  [   54/   89]
per-ex loss: 0.560805  [   56/   89]
per-ex loss: 0.513867  [   58/   89]
per-ex loss: 0.537151  [   60/   89]
per-ex loss: 0.574180  [   62/   89]
per-ex loss: 0.665057  [   64/   89]
per-ex loss: 0.564538  [   66/   89]
per-ex loss: 0.497831  [   68/   89]
per-ex loss: 0.532963  [   70/   89]
per-ex loss: 0.612229  [   72/   89]
per-ex loss: 0.568408  [   74/   89]
per-ex loss: 0.544773  [   76/   89]
per-ex loss: 0.454666  [   78/   89]
per-ex loss: 0.555513  [   80/   89]
per-ex loss: 0.525937  [   82/   89]
per-ex loss: 0.467746  [   84/   89]
per-ex loss: 0.502827  [   86/   89]
per-ex loss: 0.698289  [   88/   89]
per-ex loss: 0.665841  [   89/   89]
Train Error: Avg loss: 0.58076743
validation Error: 
 Avg loss: 0.67654164 
 F1: 0.503932 
 Precision: 0.693612 
 Recall: 0.395716
 IoU: 0.336837

test Error: 
 Avg loss: 0.65408216 
 F1: 0.524097 
 Precision: 0.708337 
 Recall: 0.415916
 IoU: 0.355102

We have finished training iteration 155
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_153_.pth
per-ex loss: 0.536934  [    2/   89]
per-ex loss: 0.673931  [    4/   89]
per-ex loss: 0.520988  [    6/   89]
per-ex loss: 0.450130  [    8/   89]
per-ex loss: 0.523827  [   10/   89]
per-ex loss: 0.575094  [   12/   89]
per-ex loss: 0.604260  [   14/   89]
per-ex loss: 0.569950  [   16/   89]
per-ex loss: 0.666618  [   18/   89]
per-ex loss: 0.550021  [   20/   89]
per-ex loss: 0.490777  [   22/   89]
per-ex loss: 0.524148  [   24/   89]
per-ex loss: 0.594464  [   26/   89]
per-ex loss: 0.623139  [   28/   89]
per-ex loss: 0.488505  [   30/   89]
per-ex loss: 0.712991  [   32/   89]
per-ex loss: 0.499959  [   34/   89]
per-ex loss: 0.606538  [   36/   89]
per-ex loss: 0.716171  [   38/   89]
per-ex loss: 0.613235  [   40/   89]
per-ex loss: 0.705213  [   42/   89]
per-ex loss: 0.667253  [   44/   89]
per-ex loss: 0.470712  [   46/   89]
per-ex loss: 0.476352  [   48/   89]
per-ex loss: 0.474217  [   50/   89]
per-ex loss: 0.632322  [   52/   89]
per-ex loss: 0.436423  [   54/   89]
per-ex loss: 0.554335  [   56/   89]
per-ex loss: 0.648635  [   58/   89]
per-ex loss: 0.491042  [   60/   89]
per-ex loss: 0.575035  [   62/   89]
per-ex loss: 0.631853  [   64/   89]
per-ex loss: 0.617950  [   66/   89]
per-ex loss: 0.642623  [   68/   89]
per-ex loss: 0.558542  [   70/   89]
per-ex loss: 0.632120  [   72/   89]
per-ex loss: 0.737504  [   74/   89]
per-ex loss: 0.638506  [   76/   89]
per-ex loss: 0.620047  [   78/   89]
per-ex loss: 0.666074  [   80/   89]
per-ex loss: 0.638327  [   82/   89]
per-ex loss: 0.556259  [   84/   89]
per-ex loss: 0.433767  [   86/   89]
per-ex loss: 0.504637  [   88/   89]
per-ex loss: 0.519433  [   89/   89]
Train Error: Avg loss: 0.57935245
validation Error: 
 Avg loss: 0.67577629 
 F1: 0.504845 
 Precision: 0.652410 
 Recall: 0.411720
 IoU: 0.337654

test Error: 
 Avg loss: 0.65515053 
 F1: 0.531822 
 Precision: 0.652300 
 Recall: 0.448910
 IoU: 0.362233

We have finished training iteration 156
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_154_.pth
per-ex loss: 0.803000  [    2/   89]
per-ex loss: 0.621333  [    4/   89]
per-ex loss: 0.449177  [    6/   89]
per-ex loss: 0.494901  [    8/   89]
per-ex loss: 0.440944  [   10/   89]
per-ex loss: 0.474196  [   12/   89]
per-ex loss: 0.583489  [   14/   89]
per-ex loss: 0.688727  [   16/   89]
per-ex loss: 0.500155  [   18/   89]
per-ex loss: 0.623358  [   20/   89]
per-ex loss: 0.642338  [   22/   89]
per-ex loss: 0.494155  [   24/   89]
per-ex loss: 0.504615  [   26/   89]
per-ex loss: 0.544264  [   28/   89]
per-ex loss: 0.494326  [   30/   89]
per-ex loss: 0.512239  [   32/   89]
per-ex loss: 0.527261  [   34/   89]
per-ex loss: 0.618612  [   36/   89]
per-ex loss: 0.518462  [   38/   89]
per-ex loss: 0.749871  [   40/   89]
per-ex loss: 0.514423  [   42/   89]
per-ex loss: 0.576853  [   44/   89]
per-ex loss: 0.749089  [   46/   89]
per-ex loss: 0.629982  [   48/   89]
per-ex loss: 0.487385  [   50/   89]
per-ex loss: 0.374377  [   52/   89]
per-ex loss: 0.534642  [   54/   89]
per-ex loss: 0.584960  [   56/   89]
per-ex loss: 0.688544  [   58/   89]
per-ex loss: 0.540196  [   60/   89]
per-ex loss: 0.572167  [   62/   89]
per-ex loss: 0.678928  [   64/   89]
per-ex loss: 0.750310  [   66/   89]
per-ex loss: 0.499011  [   68/   89]
per-ex loss: 0.681004  [   70/   89]
per-ex loss: 0.483857  [   72/   89]
per-ex loss: 0.635124  [   74/   89]
per-ex loss: 0.580485  [   76/   89]
per-ex loss: 0.420619  [   78/   89]
per-ex loss: 0.635530  [   80/   89]
per-ex loss: 0.760038  [   82/   89]
per-ex loss: 0.518441  [   84/   89]
per-ex loss: 0.469146  [   86/   89]
per-ex loss: 0.660838  [   88/   89]
per-ex loss: 0.536970  [   89/   89]
Train Error: Avg loss: 0.57440756
validation Error: 
 Avg loss: 0.66531824 
 F1: 0.507874 
 Precision: 0.705884 
 Recall: 0.396617
 IoU: 0.340369

test Error: 
 Avg loss: 0.64841374 
 F1: 0.530955 
 Precision: 0.708818 
 Recall: 0.424448
 IoU: 0.361428

We have finished training iteration 157
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_155_.pth
per-ex loss: 0.419698  [    2/   89]
per-ex loss: 0.515865  [    4/   89]
per-ex loss: 0.478794  [    6/   89]
per-ex loss: 0.612925  [    8/   89]
per-ex loss: 0.438800  [   10/   89]
per-ex loss: 0.682629  [   12/   89]
per-ex loss: 0.747237  [   14/   89]
per-ex loss: 0.536386  [   16/   89]
per-ex loss: 0.561058  [   18/   89]
per-ex loss: 0.589121  [   20/   89]
per-ex loss: 0.834303  [   22/   89]
per-ex loss: 0.578396  [   24/   89]
per-ex loss: 0.423256  [   26/   89]
per-ex loss: 0.661068  [   28/   89]
per-ex loss: 0.539947  [   30/   89]
per-ex loss: 0.493665  [   32/   89]
per-ex loss: 0.474227  [   34/   89]
per-ex loss: 0.845917  [   36/   89]
per-ex loss: 0.474976  [   38/   89]
per-ex loss: 0.497019  [   40/   89]
per-ex loss: 0.675461  [   42/   89]
per-ex loss: 0.755345  [   44/   89]
per-ex loss: 0.477911  [   46/   89]
per-ex loss: 0.720423  [   48/   89]
per-ex loss: 0.561452  [   50/   89]
per-ex loss: 0.562267  [   52/   89]
per-ex loss: 0.660872  [   54/   89]
per-ex loss: 0.561869  [   56/   89]
per-ex loss: 0.359044  [   58/   89]
per-ex loss: 0.523710  [   60/   89]
per-ex loss: 0.444678  [   62/   89]
per-ex loss: 0.532608  [   64/   89]
per-ex loss: 0.518188  [   66/   89]
per-ex loss: 0.659638  [   68/   89]
per-ex loss: 0.627570  [   70/   89]
per-ex loss: 0.440106  [   72/   89]
per-ex loss: 0.612288  [   74/   89]
per-ex loss: 0.508187  [   76/   89]
per-ex loss: 0.698523  [   78/   89]
per-ex loss: 0.625273  [   80/   89]
per-ex loss: 0.517883  [   82/   89]
per-ex loss: 0.518755  [   84/   89]
per-ex loss: 0.626511  [   86/   89]
per-ex loss: 0.573981  [   88/   89]
per-ex loss: 0.627860  [   89/   89]
Train Error: Avg loss: 0.57323757
validation Error: 
 Avg loss: 0.66883724 
 F1: 0.517842 
 Precision: 0.600800 
 Recall: 0.455014
 IoU: 0.349383

test Error: 
 Avg loss: 0.64747012 
 F1: 0.547335 
 Precision: 0.604627 
 Recall: 0.499960
 IoU: 0.376779

We have finished training iteration 158
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_156_.pth
per-ex loss: 0.571115  [    2/   89]
per-ex loss: 0.594456  [    4/   89]
per-ex loss: 0.613257  [    6/   89]
per-ex loss: 0.553981  [    8/   89]
per-ex loss: 0.577888  [   10/   89]
per-ex loss: 0.484796  [   12/   89]
per-ex loss: 0.414993  [   14/   89]
per-ex loss: 0.446336  [   16/   89]
per-ex loss: 0.659774  [   18/   89]
per-ex loss: 0.496239  [   20/   89]
per-ex loss: 0.529143  [   22/   89]
per-ex loss: 0.457645  [   24/   89]
per-ex loss: 0.696633  [   26/   89]
per-ex loss: 0.526774  [   28/   89]
per-ex loss: 0.577671  [   30/   89]
per-ex loss: 0.818326  [   32/   89]
per-ex loss: 0.460406  [   34/   89]
per-ex loss: 0.684211  [   36/   89]
per-ex loss: 0.585106  [   38/   89]
per-ex loss: 0.660744  [   40/   89]
per-ex loss: 0.635609  [   42/   89]
per-ex loss: 0.645725  [   44/   89]
per-ex loss: 0.543579  [   46/   89]
per-ex loss: 0.499215  [   48/   89]
per-ex loss: 0.585666  [   50/   89]
per-ex loss: 0.651386  [   52/   89]
per-ex loss: 0.678446  [   54/   89]
per-ex loss: 0.548834  [   56/   89]
per-ex loss: 0.569044  [   58/   89]
per-ex loss: 0.427668  [   60/   89]
per-ex loss: 0.635889  [   62/   89]
per-ex loss: 0.537316  [   64/   89]
per-ex loss: 0.708639  [   66/   89]
per-ex loss: 0.704544  [   68/   89]
per-ex loss: 0.498704  [   70/   89]
per-ex loss: 0.584395  [   72/   89]
per-ex loss: 0.803722  [   74/   89]
per-ex loss: 0.576495  [   76/   89]
per-ex loss: 0.556158  [   78/   89]
per-ex loss: 0.609602  [   80/   89]
per-ex loss: 0.492314  [   82/   89]
per-ex loss: 0.494169  [   84/   89]
per-ex loss: 0.482533  [   86/   89]
per-ex loss: 0.704557  [   88/   89]
per-ex loss: 0.633004  [   89/   89]
Train Error: Avg loss: 0.58259351
validation Error: 
 Avg loss: 0.67641690 
 F1: 0.515623 
 Precision: 0.616882 
 Recall: 0.442920
 IoU: 0.347367

test Error: 
 Avg loss: 0.65153510 
 F1: 0.536769 
 Precision: 0.632337 
 Recall: 0.466296
 IoU: 0.366838

We have finished training iteration 159
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_157_.pth
per-ex loss: 0.561170  [    2/   89]
per-ex loss: 0.661496  [    4/   89]
per-ex loss: 0.530842  [    6/   89]
per-ex loss: 0.469248  [    8/   89]
per-ex loss: 0.557123  [   10/   89]
per-ex loss: 0.595345  [   12/   89]
per-ex loss: 0.710856  [   14/   89]
per-ex loss: 0.571061  [   16/   89]
per-ex loss: 0.756293  [   18/   89]
per-ex loss: 0.664898  [   20/   89]
per-ex loss: 0.502191  [   22/   89]
per-ex loss: 0.477901  [   24/   89]
per-ex loss: 0.386380  [   26/   89]
per-ex loss: 0.508041  [   28/   89]
per-ex loss: 0.541033  [   30/   89]
per-ex loss: 0.474497  [   32/   89]
per-ex loss: 0.794696  [   34/   89]
per-ex loss: 0.410554  [   36/   89]
per-ex loss: 0.496305  [   38/   89]
per-ex loss: 0.526087  [   40/   89]
per-ex loss: 0.451961  [   42/   89]
per-ex loss: 0.481811  [   44/   89]
per-ex loss: 0.722675  [   46/   89]
per-ex loss: 0.496720  [   48/   89]
per-ex loss: 0.537743  [   50/   89]
per-ex loss: 0.751213  [   52/   89]
per-ex loss: 0.503467  [   54/   89]
per-ex loss: 0.426316  [   56/   89]
per-ex loss: 0.627588  [   58/   89]
per-ex loss: 0.525317  [   60/   89]
per-ex loss: 0.785619  [   62/   89]
per-ex loss: 0.537503  [   64/   89]
per-ex loss: 0.524304  [   66/   89]
per-ex loss: 0.665265  [   68/   89]
per-ex loss: 0.693168  [   70/   89]
per-ex loss: 0.561636  [   72/   89]
per-ex loss: 0.562825  [   74/   89]
per-ex loss: 0.463623  [   76/   89]
per-ex loss: 0.673305  [   78/   89]
per-ex loss: 0.702942  [   80/   89]
per-ex loss: 0.478500  [   82/   89]
per-ex loss: 0.641465  [   84/   89]
per-ex loss: 0.647518  [   86/   89]
per-ex loss: 0.589957  [   88/   89]
per-ex loss: 0.550632  [   89/   89]
Train Error: Avg loss: 0.57331311
validation Error: 
 Avg loss: 0.66229297 
 F1: 0.482698 
 Precision: 0.727306 
 Recall: 0.361214
 IoU: 0.318129

test Error: 
 Avg loss: 0.65387647 
 F1: 0.495146 
 Precision: 0.734316 
 Recall: 0.373496
 IoU: 0.329033

We have finished training iteration 160
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_158_.pth
per-ex loss: 0.527791  [    2/   89]
per-ex loss: 0.504935  [    4/   89]
per-ex loss: 0.696398  [    6/   89]
per-ex loss: 0.507711  [    8/   89]
per-ex loss: 0.468473  [   10/   89]
per-ex loss: 0.466686  [   12/   89]
per-ex loss: 0.541918  [   14/   89]
per-ex loss: 0.539168  [   16/   89]
per-ex loss: 0.603436  [   18/   89]
per-ex loss: 0.851262  [   20/   89]
per-ex loss: 0.390471  [   22/   89]
per-ex loss: 0.497858  [   24/   89]
per-ex loss: 0.567327  [   26/   89]
per-ex loss: 0.636080  [   28/   89]
per-ex loss: 0.623546  [   30/   89]
per-ex loss: 0.434791  [   32/   89]
per-ex loss: 0.697426  [   34/   89]
per-ex loss: 0.426104  [   36/   89]
per-ex loss: 0.621233  [   38/   89]
per-ex loss: 0.598220  [   40/   89]
per-ex loss: 0.600527  [   42/   89]
per-ex loss: 0.556760  [   44/   89]
per-ex loss: 0.617324  [   46/   89]
per-ex loss: 0.372851  [   48/   89]
per-ex loss: 0.759900  [   50/   89]
per-ex loss: 0.570022  [   52/   89]
per-ex loss: 0.542011  [   54/   89]
per-ex loss: 0.547056  [   56/   89]
per-ex loss: 0.470014  [   58/   89]
per-ex loss: 0.815114  [   60/   89]
per-ex loss: 0.657316  [   62/   89]
per-ex loss: 0.592964  [   64/   89]
per-ex loss: 0.691408  [   66/   89]
per-ex loss: 0.527105  [   68/   89]
per-ex loss: 0.584171  [   70/   89]
per-ex loss: 0.553392  [   72/   89]
per-ex loss: 0.544402  [   74/   89]
per-ex loss: 0.467546  [   76/   89]
per-ex loss: 0.412251  [   78/   89]
per-ex loss: 0.674812  [   80/   89]
per-ex loss: 0.493189  [   82/   89]
per-ex loss: 0.621610  [   84/   89]
per-ex loss: 0.531340  [   86/   89]
per-ex loss: 0.641267  [   88/   89]
per-ex loss: 0.690440  [   89/   89]
Train Error: Avg loss: 0.57190280
validation Error: 
 Avg loss: 0.67969688 
 F1: 0.445471 
 Precision: 0.782825 
 Recall: 0.311313
 IoU: 0.286563

test Error: 
 Avg loss: 0.67652852 
 F1: 0.437241 
 Precision: 0.796221 
 Recall: 0.301368
 IoU: 0.279788

We have finished training iteration 161
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_159_.pth
per-ex loss: 0.467114  [    2/   89]
per-ex loss: 0.670056  [    4/   89]
per-ex loss: 0.683321  [    6/   89]
per-ex loss: 0.657328  [    8/   89]
per-ex loss: 0.718005  [   10/   89]
per-ex loss: 0.537846  [   12/   89]
per-ex loss: 0.729215  [   14/   89]
per-ex loss: 0.546013  [   16/   89]
per-ex loss: 0.551489  [   18/   89]
per-ex loss: 0.519687  [   20/   89]
per-ex loss: 0.632442  [   22/   89]
per-ex loss: 0.761706  [   24/   89]
per-ex loss: 0.405773  [   26/   89]
per-ex loss: 0.603756  [   28/   89]
per-ex loss: 0.411037  [   30/   89]
per-ex loss: 0.621576  [   32/   89]
per-ex loss: 0.503424  [   34/   89]
per-ex loss: 0.456661  [   36/   89]
per-ex loss: 0.537305  [   38/   89]
per-ex loss: 0.468365  [   40/   89]
per-ex loss: 0.507569  [   42/   89]
per-ex loss: 0.628237  [   44/   89]
per-ex loss: 0.470584  [   46/   89]
per-ex loss: 0.422718  [   48/   89]
per-ex loss: 0.506387  [   50/   89]
per-ex loss: 0.712696  [   52/   89]
per-ex loss: 0.624527  [   54/   89]
per-ex loss: 0.710205  [   56/   89]
per-ex loss: 0.675675  [   58/   89]
per-ex loss: 0.392703  [   60/   89]
per-ex loss: 0.541625  [   62/   89]
per-ex loss: 0.591550  [   64/   89]
per-ex loss: 0.757458  [   66/   89]
per-ex loss: 0.427140  [   68/   89]
per-ex loss: 0.490342  [   70/   89]
per-ex loss: 0.551288  [   72/   89]
per-ex loss: 0.580813  [   74/   89]
per-ex loss: 0.677243  [   76/   89]
per-ex loss: 0.569739  [   78/   89]
per-ex loss: 0.464968  [   80/   89]
per-ex loss: 0.547790  [   82/   89]
per-ex loss: 0.729359  [   84/   89]
per-ex loss: 0.608640  [   86/   89]
per-ex loss: 0.533748  [   88/   89]
per-ex loss: 0.464802  [   89/   89]
Train Error: Avg loss: 0.57044282
validation Error: 
 Avg loss: 0.65765930 
 F1: 0.492385 
 Precision: 0.701924 
 Recall: 0.379189
 IoU: 0.326599

test Error: 
 Avg loss: 0.64835877 
 F1: 0.507704 
 Precision: 0.692165 
 Recall: 0.400872
 IoU: 0.340217

We have finished training iteration 162
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_160_.pth
per-ex loss: 0.486753  [    2/   89]
per-ex loss: 0.658251  [    4/   89]
per-ex loss: 0.359441  [    6/   89]
per-ex loss: 0.625913  [    8/   89]
per-ex loss: 0.430499  [   10/   89]
per-ex loss: 0.641831  [   12/   89]
per-ex loss: 0.719155  [   14/   89]
per-ex loss: 0.602211  [   16/   89]
per-ex loss: 0.579894  [   18/   89]
per-ex loss: 0.505215  [   20/   89]
per-ex loss: 0.791305  [   22/   89]
per-ex loss: 0.544998  [   24/   89]
per-ex loss: 0.473623  [   26/   89]
per-ex loss: 0.465383  [   28/   89]
per-ex loss: 0.641870  [   30/   89]
per-ex loss: 0.493991  [   32/   89]
per-ex loss: 0.650213  [   34/   89]
per-ex loss: 0.464723  [   36/   89]
per-ex loss: 0.726531  [   38/   89]
per-ex loss: 0.460690  [   40/   89]
per-ex loss: 0.456739  [   42/   89]
per-ex loss: 0.671386  [   44/   89]
per-ex loss: 0.483580  [   46/   89]
per-ex loss: 0.569631  [   48/   89]
per-ex loss: 0.577054  [   50/   89]
per-ex loss: 0.509613  [   52/   89]
per-ex loss: 0.479325  [   54/   89]
per-ex loss: 0.644546  [   56/   89]
per-ex loss: 0.766530  [   58/   89]
per-ex loss: 0.567060  [   60/   89]
per-ex loss: 0.605781  [   62/   89]
per-ex loss: 0.664798  [   64/   89]
per-ex loss: 0.559763  [   66/   89]
per-ex loss: 0.439905  [   68/   89]
per-ex loss: 0.457320  [   70/   89]
per-ex loss: 0.427967  [   72/   89]
per-ex loss: 0.723920  [   74/   89]
per-ex loss: 0.708432  [   76/   89]
per-ex loss: 0.574731  [   78/   89]
per-ex loss: 0.608465  [   80/   89]
per-ex loss: 0.591688  [   82/   89]
per-ex loss: 0.502310  [   84/   89]
per-ex loss: 0.462366  [   86/   89]
per-ex loss: 0.561171  [   88/   89]
per-ex loss: 0.622151  [   89/   89]
Train Error: Avg loss: 0.56797160
validation Error: 
 Avg loss: 0.66592110 
 F1: 0.469551 
 Precision: 0.738617 
 Recall: 0.344174
 IoU: 0.306806

test Error: 
 Avg loss: 0.65425356 
 F1: 0.482290 
 Precision: 0.770386 
 Recall: 0.351021
 IoU: 0.317775

We have finished training iteration 163
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_161_.pth
per-ex loss: 0.421985  [    2/   89]
per-ex loss: 0.498364  [    4/   89]
per-ex loss: 0.514575  [    6/   89]
per-ex loss: 0.426022  [    8/   89]
per-ex loss: 0.554265  [   10/   89]
per-ex loss: 0.778964  [   12/   89]
per-ex loss: 0.437668  [   14/   89]
per-ex loss: 0.463495  [   16/   89]
per-ex loss: 0.515356  [   18/   89]
per-ex loss: 0.474040  [   20/   89]
per-ex loss: 0.596563  [   22/   89]
per-ex loss: 0.475135  [   24/   89]
per-ex loss: 0.494526  [   26/   89]
per-ex loss: 0.496915  [   28/   89]
per-ex loss: 0.462697  [   30/   89]
per-ex loss: 0.614957  [   32/   89]
per-ex loss: 0.693850  [   34/   89]
per-ex loss: 0.494854  [   36/   89]
per-ex loss: 0.602315  [   38/   89]
per-ex loss: 0.621867  [   40/   89]
per-ex loss: 0.797984  [   42/   89]
per-ex loss: 0.511913  [   44/   89]
per-ex loss: 0.732962  [   46/   89]
per-ex loss: 0.598205  [   48/   89]
per-ex loss: 0.684415  [   50/   89]
per-ex loss: 0.503248  [   52/   89]
per-ex loss: 0.481778  [   54/   89]
per-ex loss: 0.495682  [   56/   89]
per-ex loss: 0.670345  [   58/   89]
per-ex loss: 0.604173  [   60/   89]
per-ex loss: 0.781089  [   62/   89]
per-ex loss: 0.471502  [   64/   89]
per-ex loss: 0.673928  [   66/   89]
per-ex loss: 0.567177  [   68/   89]
per-ex loss: 0.560276  [   70/   89]
per-ex loss: 0.505399  [   72/   89]
per-ex loss: 0.494710  [   74/   89]
per-ex loss: 0.658615  [   76/   89]
per-ex loss: 0.385834  [   78/   89]
per-ex loss: 0.511354  [   80/   89]
per-ex loss: 0.575771  [   82/   89]
per-ex loss: 0.802238  [   84/   89]
per-ex loss: 0.515201  [   86/   89]
per-ex loss: 0.433350  [   88/   89]
per-ex loss: 0.458403  [   89/   89]
Train Error: Avg loss: 0.55808812
validation Error: 
 Avg loss: 0.65285410 
 F1: 0.476817 
 Precision: 0.734984 
 Recall: 0.352870
 IoU: 0.313040

test Error: 
 Avg loss: 0.64671567 
 F1: 0.482676 
 Precision: 0.753221 
 Recall: 0.355121
 IoU: 0.318110

We have finished training iteration 164
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_162_.pth
Error in cropping the image to the non-zero values in the fourth channel. Returned the original image.
per-ex loss: 0.563621  [    2/   89]
per-ex loss: 0.543049  [    4/   89]
per-ex loss: 0.659353  [    6/   89]
per-ex loss: 0.825186  [    8/   89]
per-ex loss: 0.513650  [   10/   89]
per-ex loss: 0.741324  [   12/   89]
per-ex loss: 0.695469  [   14/   89]
per-ex loss: 0.516349  [   16/   89]
per-ex loss: 0.491190  [   18/   89]
per-ex loss: 0.651962  [   20/   89]
per-ex loss: 0.536539  [   22/   89]
per-ex loss: 0.708540  [   24/   89]
per-ex loss: 0.606373  [   26/   89]
per-ex loss: 0.455251  [   28/   89]
per-ex loss: 0.553912  [   30/   89]
per-ex loss: 0.470621  [   32/   89]
per-ex loss: 0.404935  [   34/   89]
per-ex loss: 0.666882  [   36/   89]
per-ex loss: 0.470435  [   38/   89]
per-ex loss: 0.509000  [   40/   89]
per-ex loss: 0.693915  [   42/   89]
per-ex loss: 0.518533  [   44/   89]
per-ex loss: 0.433869  [   46/   89]
per-ex loss: 0.572789  [   48/   89]
per-ex loss: 0.522396  [   50/   89]
per-ex loss: 0.509202  [   52/   89]
per-ex loss: 0.674261  [   54/   89]
per-ex loss: 0.495752  [   56/   89]
per-ex loss: 0.419431  [   58/   89]
per-ex loss: 0.446783  [   60/   89]
per-ex loss: 0.558744  [   62/   89]
per-ex loss: 0.490948  [   64/   89]
per-ex loss: 0.565092  [   66/   89]
per-ex loss: 0.590973  [   68/   89]
per-ex loss: 0.399397  [   70/   89]
per-ex loss: 0.564625  [   72/   89]
per-ex loss: 0.716370  [   74/   89]
per-ex loss: 0.587654  [   76/   89]
per-ex loss: 0.483395  [   78/   89]
per-ex loss: 0.526765  [   80/   89]
per-ex loss: 0.723205  [   82/   89]
per-ex loss: 0.576645  [   84/   89]
per-ex loss: 0.441647  [   86/   89]
per-ex loss: 0.527966  [   88/   89]
per-ex loss: 0.549336  [   89/   89]
Train Error: Avg loss: 0.55940734
validation Error: 
 Avg loss: 0.65551699 
 F1: 0.514237 
 Precision: 0.665795 
 Recall: 0.418885
 IoU: 0.346110

test Error: 
 Avg loss: 0.63314451 
 F1: 0.532355 
 Precision: 0.681576 
 Recall: 0.436738
 IoU: 0.362728

We have finished training iteration 165
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_163_.pth
per-ex loss: 0.749659  [    2/   89]
per-ex loss: 0.455758  [    4/   89]
per-ex loss: 0.468775  [    6/   89]
per-ex loss: 0.581119  [    8/   89]
per-ex loss: 0.452703  [   10/   89]
per-ex loss: 0.665685  [   12/   89]
per-ex loss: 0.750025  [   14/   89]
per-ex loss: 0.473804  [   16/   89]
per-ex loss: 0.649953  [   18/   89]
per-ex loss: 0.567420  [   20/   89]
per-ex loss: 0.631291  [   22/   89]
per-ex loss: 0.431905  [   24/   89]
per-ex loss: 0.682838  [   26/   89]
per-ex loss: 0.717744  [   28/   89]
per-ex loss: 0.404929  [   30/   89]
per-ex loss: 0.581581  [   32/   89]
per-ex loss: 0.560909  [   34/   89]
per-ex loss: 0.491556  [   36/   89]
per-ex loss: 0.502571  [   38/   89]
per-ex loss: 0.502646  [   40/   89]
per-ex loss: 0.571297  [   42/   89]
per-ex loss: 0.490356  [   44/   89]
per-ex loss: 0.551456  [   46/   89]
per-ex loss: 0.643491  [   48/   89]
per-ex loss: 0.718284  [   50/   89]
per-ex loss: 0.501131  [   52/   89]
per-ex loss: 0.441783  [   54/   89]
per-ex loss: 0.599160  [   56/   89]
per-ex loss: 0.701449  [   58/   89]
per-ex loss: 0.640355  [   60/   89]
per-ex loss: 0.438353  [   62/   89]
per-ex loss: 0.373276  [   64/   89]
per-ex loss: 0.461773  [   66/   89]
per-ex loss: 0.640386  [   68/   89]
per-ex loss: 0.361752  [   70/   89]
per-ex loss: 0.561779  [   72/   89]
per-ex loss: 0.797389  [   74/   89]
per-ex loss: 0.505382  [   76/   89]
per-ex loss: 0.747795  [   78/   89]
per-ex loss: 0.598900  [   80/   89]
per-ex loss: 0.434620  [   82/   89]
per-ex loss: 0.438192  [   84/   89]
per-ex loss: 0.726530  [   86/   89]
per-ex loss: 0.526596  [   88/   89]
per-ex loss: 0.628990  [   89/   89]
Train Error: Avg loss: 0.56496326
validation Error: 
 Avg loss: 0.64206353 
 F1: 0.516895 
 Precision: 0.666816 
 Recall: 0.422013
 IoU: 0.348522

test Error: 
 Avg loss: 0.62318269 
 F1: 0.540914 
 Precision: 0.669627 
 Recall: 0.453705
 IoU: 0.370721

We have finished training iteration 166
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_164_.pth
per-ex loss: 0.683311  [    2/   89]
per-ex loss: 0.383418  [    4/   89]
per-ex loss: 0.487447  [    6/   89]
per-ex loss: 0.485602  [    8/   89]
per-ex loss: 0.649202  [   10/   89]
per-ex loss: 0.505259  [   12/   89]
per-ex loss: 0.667554  [   14/   89]
per-ex loss: 0.464688  [   16/   89]
per-ex loss: 0.763637  [   18/   89]
per-ex loss: 0.524806  [   20/   89]
per-ex loss: 0.640661  [   22/   89]
per-ex loss: 0.551577  [   24/   89]
per-ex loss: 0.476174  [   26/   89]
per-ex loss: 0.403815  [   28/   89]
per-ex loss: 0.625650  [   30/   89]
per-ex loss: 0.371377  [   32/   89]
per-ex loss: 0.518032  [   34/   89]
per-ex loss: 0.586605  [   36/   89]
per-ex loss: 0.632957  [   38/   89]
per-ex loss: 0.549215  [   40/   89]
per-ex loss: 0.377225  [   42/   89]
per-ex loss: 0.578460  [   44/   89]
per-ex loss: 0.662210  [   46/   89]
per-ex loss: 0.515327  [   48/   89]
per-ex loss: 0.565576  [   50/   89]
per-ex loss: 0.518583  [   52/   89]
per-ex loss: 0.472585  [   54/   89]
per-ex loss: 0.504850  [   56/   89]
per-ex loss: 0.626966  [   58/   89]
per-ex loss: 0.643449  [   60/   89]
per-ex loss: 0.414928  [   62/   89]
per-ex loss: 0.579906  [   64/   89]
per-ex loss: 0.408917  [   66/   89]
per-ex loss: 0.676827  [   68/   89]
per-ex loss: 0.772665  [   70/   89]
per-ex loss: 0.477736  [   72/   89]
per-ex loss: 0.500991  [   74/   89]
per-ex loss: 0.752612  [   76/   89]
per-ex loss: 0.606684  [   78/   89]
per-ex loss: 0.634481  [   80/   89]
per-ex loss: 0.507573  [   82/   89]
per-ex loss: 0.568847  [   84/   89]
per-ex loss: 0.532779  [   86/   89]
per-ex loss: 0.515573  [   88/   89]
per-ex loss: 0.440033  [   89/   89]
Train Error: Avg loss: 0.55170600
validation Error: 
 Avg loss: 0.64635192 
 F1: 0.500470 
 Precision: 0.698297 
 Recall: 0.389987
 IoU: 0.333751

test Error: 
 Avg loss: 0.62753916 
 F1: 0.525223 
 Precision: 0.709474 
 Recall: 0.416943
 IoU: 0.356138

We have finished training iteration 167
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_165_.pth
per-ex loss: 0.495497  [    2/   89]
per-ex loss: 0.611419  [    4/   89]
per-ex loss: 0.453908  [    6/   89]
per-ex loss: 0.527290  [    8/   89]
per-ex loss: 0.539216  [   10/   89]
per-ex loss: 0.521091  [   12/   89]
per-ex loss: 0.764143  [   14/   89]
per-ex loss: 0.570810  [   16/   89]
per-ex loss: 0.487101  [   18/   89]
per-ex loss: 0.520152  [   20/   89]
per-ex loss: 0.490523  [   22/   89]
per-ex loss: 0.583671  [   24/   89]
per-ex loss: 0.635706  [   26/   89]
per-ex loss: 0.439210  [   28/   89]
per-ex loss: 0.491320  [   30/   89]
per-ex loss: 0.649448  [   32/   89]
per-ex loss: 0.642849  [   34/   89]
per-ex loss: 0.525834  [   36/   89]
per-ex loss: 0.762538  [   38/   89]
per-ex loss: 0.602061  [   40/   89]
per-ex loss: 0.532284  [   42/   89]
per-ex loss: 0.475449  [   44/   89]
per-ex loss: 0.485172  [   46/   89]
per-ex loss: 0.596243  [   48/   89]
per-ex loss: 0.510251  [   50/   89]
per-ex loss: 0.811030  [   52/   89]
per-ex loss: 0.631896  [   54/   89]
per-ex loss: 0.397308  [   56/   89]
per-ex loss: 0.420887  [   58/   89]
per-ex loss: 0.497942  [   60/   89]
per-ex loss: 0.648958  [   62/   89]
per-ex loss: 0.623401  [   64/   89]
per-ex loss: 0.444530  [   66/   89]
per-ex loss: 0.614339  [   68/   89]
per-ex loss: 0.488831  [   70/   89]
per-ex loss: 0.528838  [   72/   89]
per-ex loss: 0.541719  [   74/   89]
per-ex loss: 0.540058  [   76/   89]
per-ex loss: 0.523955  [   78/   89]
per-ex loss: 0.445122  [   80/   89]
per-ex loss: 0.595225  [   82/   89]
per-ex loss: 0.536662  [   84/   89]
per-ex loss: 0.526750  [   86/   89]
per-ex loss: 0.722434  [   88/   89]
per-ex loss: 0.584063  [   89/   89]
Train Error: Avg loss: 0.55638070
validation Error: 
 Avg loss: 0.65258611 
 F1: 0.494376 
 Precision: 0.720011 
 Recall: 0.376416
 IoU: 0.328353

test Error: 
 Avg loss: 0.62757078 
 F1: 0.517443 
 Precision: 0.736310 
 Recall: 0.398877
 IoU: 0.349020

We have finished training iteration 168
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_166_.pth
per-ex loss: 0.650382  [    2/   89]
per-ex loss: 0.637376  [    4/   89]
per-ex loss: 0.618759  [    6/   89]
per-ex loss: 0.452819  [    8/   89]
per-ex loss: 0.584129  [   10/   89]
per-ex loss: 0.639380  [   12/   89]
per-ex loss: 0.520156  [   14/   89]
per-ex loss: 0.593095  [   16/   89]
per-ex loss: 0.454515  [   18/   89]
per-ex loss: 0.557619  [   20/   89]
per-ex loss: 0.514299  [   22/   89]
per-ex loss: 0.668656  [   24/   89]
per-ex loss: 0.455078  [   26/   89]
per-ex loss: 0.570189  [   28/   89]
per-ex loss: 0.492851  [   30/   89]
per-ex loss: 0.549613  [   32/   89]
per-ex loss: 0.477729  [   34/   89]
per-ex loss: 0.477866  [   36/   89]
per-ex loss: 0.696662  [   38/   89]
per-ex loss: 0.664746  [   40/   89]
per-ex loss: 0.446466  [   42/   89]
per-ex loss: 0.447222  [   44/   89]
per-ex loss: 0.752231  [   46/   89]
per-ex loss: 0.474703  [   48/   89]
per-ex loss: 0.731728  [   50/   89]
per-ex loss: 0.466877  [   52/   89]
per-ex loss: 0.590064  [   54/   89]
per-ex loss: 0.365688  [   56/   89]
per-ex loss: 0.582668  [   58/   89]
per-ex loss: 0.452843  [   60/   89]
per-ex loss: 0.518711  [   62/   89]
per-ex loss: 0.551093  [   64/   89]
per-ex loss: 0.487341  [   66/   89]
per-ex loss: 0.528729  [   68/   89]
per-ex loss: 0.560003  [   70/   89]
per-ex loss: 0.555074  [   72/   89]
per-ex loss: 0.633913  [   74/   89]
per-ex loss: 0.539768  [   76/   89]
per-ex loss: 0.476795  [   78/   89]
per-ex loss: 0.539903  [   80/   89]
per-ex loss: 0.596225  [   82/   89]
per-ex loss: 0.725612  [   84/   89]
per-ex loss: 0.458438  [   86/   89]
per-ex loss: 0.457761  [   88/   89]
per-ex loss: 0.740159  [   89/   89]
Train Error: Avg loss: 0.55457632
validation Error: 
 Avg loss: 0.65029004 
 F1: 0.516337 
 Precision: 0.592896 
 Recall: 0.457288
 IoU: 0.348015

test Error: 
 Avg loss: 0.62789573 
 F1: 0.545535 
 Precision: 0.627047 
 Recall: 0.482777
 IoU: 0.375076

We have finished training iteration 169
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_167_.pth
per-ex loss: 0.532343  [    2/   89]
per-ex loss: 0.493147  [    4/   89]
per-ex loss: 0.552099  [    6/   89]
per-ex loss: 0.730144  [    8/   89]
per-ex loss: 0.523821  [   10/   89]
per-ex loss: 0.532463  [   12/   89]
per-ex loss: 0.645512  [   14/   89]
per-ex loss: 0.429751  [   16/   89]
per-ex loss: 0.608046  [   18/   89]
per-ex loss: 0.550286  [   20/   89]
per-ex loss: 0.394483  [   22/   89]
per-ex loss: 0.457851  [   24/   89]
per-ex loss: 0.421845  [   26/   89]
per-ex loss: 0.560439  [   28/   89]
per-ex loss: 0.495908  [   30/   89]
per-ex loss: 0.602969  [   32/   89]
per-ex loss: 0.521183  [   34/   89]
per-ex loss: 0.407361  [   36/   89]
per-ex loss: 0.729826  [   38/   89]
per-ex loss: 0.718880  [   40/   89]
per-ex loss: 0.421409  [   42/   89]
per-ex loss: 0.591726  [   44/   89]
per-ex loss: 0.501809  [   46/   89]
per-ex loss: 0.603195  [   48/   89]
per-ex loss: 0.424603  [   50/   89]
per-ex loss: 0.427316  [   52/   89]
per-ex loss: 0.773688  [   54/   89]
per-ex loss: 0.692007  [   56/   89]
per-ex loss: 0.495357  [   58/   89]
per-ex loss: 0.415434  [   60/   89]
per-ex loss: 0.532730  [   62/   89]
per-ex loss: 0.638644  [   64/   89]
per-ex loss: 0.521628  [   66/   89]
per-ex loss: 0.727919  [   68/   89]
per-ex loss: 0.672363  [   70/   89]
per-ex loss: 0.534638  [   72/   89]
per-ex loss: 0.663571  [   74/   89]
per-ex loss: 0.724198  [   76/   89]
per-ex loss: 0.516164  [   78/   89]
per-ex loss: 0.455518  [   80/   89]
per-ex loss: 0.634482  [   82/   89]
per-ex loss: 0.374713  [   84/   89]
per-ex loss: 0.519250  [   86/   89]
per-ex loss: 0.555192  [   88/   89]
per-ex loss: 0.684179  [   89/   89]
Train Error: Avg loss: 0.55577975
validation Error: 
 Avg loss: 0.64292752 
 F1: 0.497657 
 Precision: 0.718840 
 Recall: 0.380560
 IoU: 0.331254

test Error: 
 Avg loss: 0.62316370 
 F1: 0.527314 
 Precision: 0.707410 
 Recall: 0.420309
 IoU: 0.358063

We have finished training iteration 170
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_168_.pth
per-ex loss: 0.404769  [    2/   89]
per-ex loss: 0.700907  [    4/   89]
per-ex loss: 0.690785  [    6/   89]
per-ex loss: 0.467975  [    8/   89]
per-ex loss: 0.485315  [   10/   89]
per-ex loss: 0.581502  [   12/   89]
per-ex loss: 0.554999  [   14/   89]
per-ex loss: 0.663931  [   16/   89]
per-ex loss: 0.482424  [   18/   89]
per-ex loss: 0.563486  [   20/   89]
per-ex loss: 0.464045  [   22/   89]
per-ex loss: 0.459171  [   24/   89]
per-ex loss: 0.540443  [   26/   89]
per-ex loss: 0.495229  [   28/   89]
per-ex loss: 0.595105  [   30/   89]
per-ex loss: 0.464845  [   32/   89]
per-ex loss: 0.399718  [   34/   89]
per-ex loss: 0.565830  [   36/   89]
per-ex loss: 0.602764  [   38/   89]
per-ex loss: 0.414963  [   40/   89]
per-ex loss: 0.602725  [   42/   89]
per-ex loss: 0.622406  [   44/   89]
per-ex loss: 0.495108  [   46/   89]
per-ex loss: 0.576432  [   48/   89]
per-ex loss: 0.717642  [   50/   89]
per-ex loss: 0.406200  [   52/   89]
per-ex loss: 0.550615  [   54/   89]
per-ex loss: 0.461944  [   56/   89]
per-ex loss: 0.608266  [   58/   89]
per-ex loss: 0.583143  [   60/   89]
per-ex loss: 0.679264  [   62/   89]
per-ex loss: 0.650760  [   64/   89]
per-ex loss: 0.552781  [   66/   89]
per-ex loss: 0.444046  [   68/   89]
per-ex loss: 0.418326  [   70/   89]
per-ex loss: 0.738449  [   72/   89]
per-ex loss: 0.663745  [   74/   89]
per-ex loss: 0.681824  [   76/   89]
per-ex loss: 0.573048  [   78/   89]
per-ex loss: 0.419260  [   80/   89]
per-ex loss: 0.635961  [   82/   89]
per-ex loss: 0.499684  [   84/   89]
per-ex loss: 0.508664  [   86/   89]
per-ex loss: 0.675142  [   88/   89]
per-ex loss: 0.448624  [   89/   89]
Train Error: Avg loss: 0.55138365
validation Error: 
 Avg loss: 0.64436854 
 F1: 0.499638 
 Precision: 0.708161 
 Recall: 0.385983
 IoU: 0.333012

test Error: 
 Avg loss: 0.62519900 
 F1: 0.522019 
 Precision: 0.698535 
 Recall: 0.416717
 IoU: 0.353197

We have finished training iteration 171
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_169_.pth
per-ex loss: 0.572057  [    2/   89]
per-ex loss: 0.457351  [    4/   89]
per-ex loss: 0.467161  [    6/   89]
per-ex loss: 0.511429  [    8/   89]
per-ex loss: 0.473704  [   10/   89]
per-ex loss: 0.419371  [   12/   89]
per-ex loss: 0.531636  [   14/   89]
per-ex loss: 0.435155  [   16/   89]
per-ex loss: 0.677231  [   18/   89]
per-ex loss: 0.472444  [   20/   89]
per-ex loss: 0.495776  [   22/   89]
per-ex loss: 0.849374  [   24/   89]
per-ex loss: 0.543895  [   26/   89]
per-ex loss: 0.535633  [   28/   89]
per-ex loss: 0.565926  [   30/   89]
per-ex loss: 0.458412  [   32/   89]
per-ex loss: 0.701697  [   34/   89]
per-ex loss: 0.573914  [   36/   89]
per-ex loss: 0.754850  [   38/   89]
per-ex loss: 0.691292  [   40/   89]
per-ex loss: 0.546918  [   42/   89]
per-ex loss: 0.499044  [   44/   89]
per-ex loss: 0.658597  [   46/   89]
per-ex loss: 0.549616  [   48/   89]
per-ex loss: 0.587814  [   50/   89]
per-ex loss: 0.461710  [   52/   89]
per-ex loss: 0.504088  [   54/   89]
per-ex loss: 0.475465  [   56/   89]
per-ex loss: 0.462194  [   58/   89]
per-ex loss: 0.427808  [   60/   89]
per-ex loss: 0.803265  [   62/   89]
per-ex loss: 0.542405  [   64/   89]
per-ex loss: 0.664822  [   66/   89]
per-ex loss: 0.435742  [   68/   89]
per-ex loss: 0.649143  [   70/   89]
per-ex loss: 0.658782  [   72/   89]
per-ex loss: 0.569086  [   74/   89]
per-ex loss: 0.677357  [   76/   89]
per-ex loss: 0.417372  [   78/   89]
per-ex loss: 0.418873  [   80/   89]
per-ex loss: 0.573657  [   82/   89]
per-ex loss: 0.624338  [   84/   89]
per-ex loss: 0.552145  [   86/   89]
per-ex loss: 0.451166  [   88/   89]
per-ex loss: 0.805605  [   89/   89]
Train Error: Avg loss: 0.56011826
validation Error: 
 Avg loss: 0.63185157 
 F1: 0.522461 
 Precision: 0.626982 
 Recall: 0.447810
 IoU: 0.353602

test Error: 
 Avg loss: 0.61879592 
 F1: 0.547697 
 Precision: 0.649318 
 Recall: 0.473579
 IoU: 0.377123

We have finished training iteration 172
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_170_.pth
per-ex loss: 0.472666  [    2/   89]
per-ex loss: 0.527828  [    4/   89]
per-ex loss: 0.565398  [    6/   89]
per-ex loss: 0.573063  [    8/   89]
per-ex loss: 0.583323  [   10/   89]
per-ex loss: 0.583905  [   12/   89]
per-ex loss: 0.830985  [   14/   89]
per-ex loss: 0.494397  [   16/   89]
per-ex loss: 0.503915  [   18/   89]
per-ex loss: 0.477157  [   20/   89]
per-ex loss: 0.456721  [   22/   89]
per-ex loss: 0.438786  [   24/   89]
per-ex loss: 0.537167  [   26/   89]
per-ex loss: 0.609171  [   28/   89]
per-ex loss: 0.557338  [   30/   89]
per-ex loss: 0.504450  [   32/   89]
per-ex loss: 0.557768  [   34/   89]
per-ex loss: 0.512097  [   36/   89]
per-ex loss: 0.646605  [   38/   89]
per-ex loss: 0.382191  [   40/   89]
per-ex loss: 0.602246  [   42/   89]
per-ex loss: 0.466013  [   44/   89]
per-ex loss: 0.550585  [   46/   89]
per-ex loss: 0.532727  [   48/   89]
per-ex loss: 0.588945  [   50/   89]
per-ex loss: 0.667849  [   52/   89]
per-ex loss: 0.441102  [   54/   89]
per-ex loss: 0.461186  [   56/   89]
per-ex loss: 0.766514  [   58/   89]
per-ex loss: 0.553047  [   60/   89]
per-ex loss: 0.459375  [   62/   89]
per-ex loss: 0.566989  [   64/   89]
per-ex loss: 0.739860  [   66/   89]
per-ex loss: 0.568326  [   68/   89]
per-ex loss: 0.541074  [   70/   89]
per-ex loss: 0.422211  [   72/   89]
per-ex loss: 0.487107  [   74/   89]
per-ex loss: 0.617893  [   76/   89]
per-ex loss: 0.659193  [   78/   89]
per-ex loss: 0.662775  [   80/   89]
per-ex loss: 0.684834  [   82/   89]
per-ex loss: 0.434640  [   84/   89]
per-ex loss: 0.428260  [   86/   89]
per-ex loss: 0.536025  [   88/   89]
per-ex loss: 0.625263  [   89/   89]
Train Error: Avg loss: 0.55286601
validation Error: 
 Avg loss: 0.64054074 
 F1: 0.521093 
 Precision: 0.623659 
 Recall: 0.447499
 IoU: 0.352351

test Error: 
 Avg loss: 0.61550240 
 F1: 0.546663 
 Precision: 0.632114 
 Recall: 0.481564
 IoU: 0.376143

We have finished training iteration 173
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_171_.pth
per-ex loss: 0.605167  [    2/   89]
per-ex loss: 0.562907  [    4/   89]
per-ex loss: 0.628369  [    6/   89]
per-ex loss: 0.749508  [    8/   89]
per-ex loss: 0.491168  [   10/   89]
per-ex loss: 0.504692  [   12/   89]
per-ex loss: 0.539020  [   14/   89]
per-ex loss: 0.687518  [   16/   89]
per-ex loss: 0.558074  [   18/   89]
per-ex loss: 0.436075  [   20/   89]
per-ex loss: 0.392756  [   22/   89]
per-ex loss: 0.663854  [   24/   89]
per-ex loss: 0.425075  [   26/   89]
per-ex loss: 0.510550  [   28/   89]
per-ex loss: 0.407686  [   30/   89]
per-ex loss: 0.682831  [   32/   89]
per-ex loss: 0.543733  [   34/   89]
per-ex loss: 0.548506  [   36/   89]
per-ex loss: 0.474851  [   38/   89]
per-ex loss: 0.552116  [   40/   89]
per-ex loss: 0.579549  [   42/   89]
per-ex loss: 0.442322  [   44/   89]
per-ex loss: 0.434393  [   46/   89]
per-ex loss: 0.700829  [   48/   89]
per-ex loss: 0.665632  [   50/   89]
per-ex loss: 0.501809  [   52/   89]
per-ex loss: 0.577676  [   54/   89]
per-ex loss: 0.461939  [   56/   89]
per-ex loss: 0.461069  [   58/   89]
per-ex loss: 0.530328  [   60/   89]
per-ex loss: 0.609606  [   62/   89]
per-ex loss: 0.546011  [   64/   89]
per-ex loss: 0.506358  [   66/   89]
per-ex loss: 0.454068  [   68/   89]
per-ex loss: 0.356676  [   70/   89]
per-ex loss: 0.504094  [   72/   89]
per-ex loss: 0.532144  [   74/   89]
per-ex loss: 0.568400  [   76/   89]
per-ex loss: 0.455683  [   78/   89]
per-ex loss: 0.613383  [   80/   89]
per-ex loss: 0.552440  [   82/   89]
per-ex loss: 0.509942  [   84/   89]
per-ex loss: 0.504929  [   86/   89]
per-ex loss: 0.519484  [   88/   89]
per-ex loss: 0.678928  [   89/   89]
Train Error: Avg loss: 0.53849221
validation Error: 
 Avg loss: 0.64523231 
 F1: 0.507416 
 Precision: 0.689097 
 Recall: 0.401548
 IoU: 0.339959

test Error: 
 Avg loss: 0.62376872 
 F1: 0.521647 
 Precision: 0.686634 
 Recall: 0.420587
 IoU: 0.352857

We have finished training iteration 174
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_172_.pth
per-ex loss: 0.484872  [    2/   89]
per-ex loss: 0.448634  [    4/   89]
per-ex loss: 0.576814  [    6/   89]
per-ex loss: 0.504654  [    8/   89]
per-ex loss: 0.620272  [   10/   89]
per-ex loss: 0.622539  [   12/   89]
per-ex loss: 0.680146  [   14/   89]
per-ex loss: 0.387094  [   16/   89]
per-ex loss: 0.608333  [   18/   89]
per-ex loss: 0.582429  [   20/   89]
per-ex loss: 0.530441  [   22/   89]
per-ex loss: 0.448613  [   24/   89]
per-ex loss: 0.504746  [   26/   89]
per-ex loss: 0.646505  [   28/   89]
per-ex loss: 0.628906  [   30/   89]
per-ex loss: 0.723977  [   32/   89]
per-ex loss: 0.646539  [   34/   89]
per-ex loss: 0.716550  [   36/   89]
per-ex loss: 0.496056  [   38/   89]
per-ex loss: 0.719249  [   40/   89]
per-ex loss: 0.536476  [   42/   89]
per-ex loss: 0.446887  [   44/   89]
per-ex loss: 0.536618  [   46/   89]
per-ex loss: 0.480809  [   48/   89]
per-ex loss: 0.422471  [   50/   89]
per-ex loss: 0.461540  [   52/   89]
per-ex loss: 0.583246  [   54/   89]
per-ex loss: 0.661375  [   56/   89]
per-ex loss: 0.503355  [   58/   89]
per-ex loss: 0.530891  [   60/   89]
per-ex loss: 0.491879  [   62/   89]
per-ex loss: 0.510884  [   64/   89]
per-ex loss: 0.456950  [   66/   89]
per-ex loss: 0.437620  [   68/   89]
per-ex loss: 0.743821  [   70/   89]
per-ex loss: 0.586130  [   72/   89]
per-ex loss: 0.445495  [   74/   89]
per-ex loss: 0.451969  [   76/   89]
per-ex loss: 0.489547  [   78/   89]
per-ex loss: 0.481366  [   80/   89]
per-ex loss: 0.479215  [   82/   89]
per-ex loss: 0.355002  [   84/   89]
per-ex loss: 0.688133  [   86/   89]
per-ex loss: 0.502232  [   88/   89]
per-ex loss: 0.659765  [   89/   89]
Train Error: Avg loss: 0.54491203
validation Error: 
 Avg loss: 0.62195418 
 F1: 0.518490 
 Precision: 0.654372 
 Recall: 0.429337
 IoU: 0.349974

test Error: 
 Avg loss: 0.60714800 
 F1: 0.543344 
 Precision: 0.652488 
 Recall: 0.465482
 IoU: 0.373008

We have finished training iteration 175
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_173_.pth
per-ex loss: 0.406765  [    2/   89]
per-ex loss: 0.503110  [    4/   89]
per-ex loss: 0.639311  [    6/   89]
per-ex loss: 0.500158  [    8/   89]
per-ex loss: 0.472521  [   10/   89]
per-ex loss: 0.760997  [   12/   89]
per-ex loss: 0.560275  [   14/   89]
per-ex loss: 0.546941  [   16/   89]
per-ex loss: 0.542314  [   18/   89]
per-ex loss: 0.476499  [   20/   89]
per-ex loss: 0.373313  [   22/   89]
per-ex loss: 0.464741  [   24/   89]
per-ex loss: 0.579026  [   26/   89]
per-ex loss: 0.586360  [   28/   89]
per-ex loss: 0.478099  [   30/   89]
per-ex loss: 0.612773  [   32/   89]
per-ex loss: 0.502033  [   34/   89]
per-ex loss: 0.589301  [   36/   89]
per-ex loss: 0.425918  [   38/   89]
per-ex loss: 0.435110  [   40/   89]
per-ex loss: 0.663615  [   42/   89]
per-ex loss: 0.597028  [   44/   89]
per-ex loss: 0.467314  [   46/   89]
per-ex loss: 0.572494  [   48/   89]
per-ex loss: 0.572464  [   50/   89]
per-ex loss: 0.697736  [   52/   89]
per-ex loss: 0.458183  [   54/   89]
per-ex loss: 0.563354  [   56/   89]
per-ex loss: 0.665155  [   58/   89]
per-ex loss: 0.467381  [   60/   89]
per-ex loss: 0.506380  [   62/   89]
per-ex loss: 0.504970  [   64/   89]
per-ex loss: 0.494761  [   66/   89]
per-ex loss: 0.555135  [   68/   89]
per-ex loss: 0.510161  [   70/   89]
per-ex loss: 0.706130  [   72/   89]
per-ex loss: 0.751131  [   74/   89]
per-ex loss: 0.546863  [   76/   89]
per-ex loss: 0.523113  [   78/   89]
per-ex loss: 0.387132  [   80/   89]
per-ex loss: 0.546275  [   82/   89]
per-ex loss: 0.397292  [   84/   89]
per-ex loss: 0.595526  [   86/   89]
per-ex loss: 0.618894  [   88/   89]
per-ex loss: 0.483444  [   89/   89]
Train Error: Avg loss: 0.54016661
validation Error: 
 Avg loss: 0.61917318 
 F1: 0.506140 
 Precision: 0.688654 
 Recall: 0.400101
 IoU: 0.338813

test Error: 
 Avg loss: 0.61023641 
 F1: 0.536041 
 Precision: 0.702352 
 Recall: 0.433413
 IoU: 0.366159

We have finished training iteration 176
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_174_.pth
per-ex loss: 0.485423  [    2/   89]
per-ex loss: 0.403008  [    4/   89]
per-ex loss: 0.443030  [    6/   89]
per-ex loss: 0.722419  [    8/   89]
per-ex loss: 0.480440  [   10/   89]
per-ex loss: 0.442651  [   12/   89]
per-ex loss: 0.458365  [   14/   89]
per-ex loss: 0.548074  [   16/   89]
per-ex loss: 0.429336  [   18/   89]
per-ex loss: 0.619076  [   20/   89]
per-ex loss: 0.605387  [   22/   89]
per-ex loss: 0.688686  [   24/   89]
per-ex loss: 0.624166  [   26/   89]
per-ex loss: 0.441644  [   28/   89]
per-ex loss: 0.625731  [   30/   89]
per-ex loss: 0.583713  [   32/   89]
per-ex loss: 0.526986  [   34/   89]
per-ex loss: 0.534144  [   36/   89]
per-ex loss: 0.448382  [   38/   89]
per-ex loss: 0.776302  [   40/   89]
per-ex loss: 0.639073  [   42/   89]
per-ex loss: 0.452253  [   44/   89]
per-ex loss: 0.605567  [   46/   89]
per-ex loss: 0.452767  [   48/   89]
per-ex loss: 0.441160  [   50/   89]
per-ex loss: 0.574911  [   52/   89]
per-ex loss: 0.509349  [   54/   89]
per-ex loss: 0.437759  [   56/   89]
per-ex loss: 0.524580  [   58/   89]
per-ex loss: 0.742168  [   60/   89]
per-ex loss: 0.636830  [   62/   89]
per-ex loss: 0.441962  [   64/   89]
per-ex loss: 0.832629  [   66/   89]
per-ex loss: 0.573125  [   68/   89]
per-ex loss: 0.529435  [   70/   89]
per-ex loss: 0.450674  [   72/   89]
per-ex loss: 0.420595  [   74/   89]
per-ex loss: 0.625434  [   76/   89]
per-ex loss: 0.499021  [   78/   89]
per-ex loss: 0.426737  [   80/   89]
per-ex loss: 0.540572  [   82/   89]
per-ex loss: 0.613964  [   84/   89]
per-ex loss: 0.556095  [   86/   89]
per-ex loss: 0.488170  [   88/   89]
per-ex loss: 0.331253  [   89/   89]
Train Error: Avg loss: 0.53851216
validation Error: 
 Avg loss: 0.61667670 
 F1: 0.508302 
 Precision: 0.675265 
 Recall: 0.407536
 IoU: 0.340754

test Error: 
 Avg loss: 0.60542084 
 F1: 0.532152 
 Precision: 0.699431 
 Recall: 0.429444
 IoU: 0.362539

We have finished training iteration 177
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_175_.pth
per-ex loss: 0.622651  [    2/   89]
per-ex loss: 0.535677  [    4/   89]
per-ex loss: 0.447947  [    6/   89]
per-ex loss: 0.521733  [    8/   89]
per-ex loss: 0.412291  [   10/   89]
per-ex loss: 0.402471  [   12/   89]
per-ex loss: 0.559916  [   14/   89]
per-ex loss: 0.335517  [   16/   89]
per-ex loss: 0.749609  [   18/   89]
per-ex loss: 0.547619  [   20/   89]
per-ex loss: 0.542420  [   22/   89]
per-ex loss: 0.429473  [   24/   89]
per-ex loss: 0.622655  [   26/   89]
per-ex loss: 0.473695  [   28/   89]
per-ex loss: 0.504362  [   30/   89]
per-ex loss: 0.659926  [   32/   89]
per-ex loss: 0.549893  [   34/   89]
per-ex loss: 0.426552  [   36/   89]
per-ex loss: 0.465008  [   38/   89]
per-ex loss: 0.641449  [   40/   89]
per-ex loss: 0.682243  [   42/   89]
per-ex loss: 0.419066  [   44/   89]
per-ex loss: 0.717012  [   46/   89]
per-ex loss: 0.489846  [   48/   89]
per-ex loss: 0.701502  [   50/   89]
per-ex loss: 0.546551  [   52/   89]
per-ex loss: 0.556751  [   54/   89]
per-ex loss: 0.453205  [   56/   89]
per-ex loss: 0.401477  [   58/   89]
per-ex loss: 0.678871  [   60/   89]
per-ex loss: 0.442639  [   62/   89]
per-ex loss: 0.638281  [   64/   89]
per-ex loss: 0.547818  [   66/   89]
per-ex loss: 0.628714  [   68/   89]
per-ex loss: 0.718276  [   70/   89]
per-ex loss: 0.400769  [   72/   89]
per-ex loss: 0.431997  [   74/   89]
per-ex loss: 0.519804  [   76/   89]
per-ex loss: 0.407190  [   78/   89]
per-ex loss: 0.467886  [   80/   89]
per-ex loss: 0.472900  [   82/   89]
per-ex loss: 0.552382  [   84/   89]
per-ex loss: 0.621205  [   86/   89]
per-ex loss: 0.566704  [   88/   89]
per-ex loss: 0.481285  [   89/   89]
Train Error: Avg loss: 0.53322751
validation Error: 
 Avg loss: 0.61414565 
 F1: 0.515470 
 Precision: 0.662086 
 Recall: 0.422016
 IoU: 0.347227

test Error: 
 Avg loss: 0.60432266 
 F1: 0.543367 
 Precision: 0.665504 
 Recall: 0.459108
 IoU: 0.373029

We have finished training iteration 178
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_176_.pth
per-ex loss: 0.433075  [    2/   89]
per-ex loss: 0.592485  [    4/   89]
per-ex loss: 0.542153  [    6/   89]
per-ex loss: 0.489726  [    8/   89]
per-ex loss: 0.522194  [   10/   89]
per-ex loss: 0.435958  [   12/   89]
per-ex loss: 0.452249  [   14/   89]
per-ex loss: 0.728639  [   16/   89]
per-ex loss: 0.742474  [   18/   89]
per-ex loss: 0.469664  [   20/   89]
per-ex loss: 0.566187  [   22/   89]
per-ex loss: 0.496814  [   24/   89]
per-ex loss: 0.723170  [   26/   89]
per-ex loss: 0.555845  [   28/   89]
per-ex loss: 0.434990  [   30/   89]
per-ex loss: 0.464702  [   32/   89]
per-ex loss: 0.467230  [   34/   89]
per-ex loss: 0.466864  [   36/   89]
per-ex loss: 0.422779  [   38/   89]
per-ex loss: 0.441960  [   40/   89]
per-ex loss: 0.588536  [   42/   89]
per-ex loss: 0.526649  [   44/   89]
per-ex loss: 0.633136  [   46/   89]
per-ex loss: 0.444555  [   48/   89]
per-ex loss: 0.421992  [   50/   89]
per-ex loss: 0.426310  [   52/   89]
per-ex loss: 0.539352  [   54/   89]
per-ex loss: 0.601702  [   56/   89]
per-ex loss: 0.679492  [   58/   89]
per-ex loss: 0.412528  [   60/   89]
per-ex loss: 0.755182  [   62/   89]
per-ex loss: 0.733236  [   64/   89]
per-ex loss: 0.810373  [   66/   89]
per-ex loss: 0.514580  [   68/   89]
per-ex loss: 0.456188  [   70/   89]
per-ex loss: 0.383529  [   72/   89]
per-ex loss: 0.604888  [   74/   89]
per-ex loss: 0.552006  [   76/   89]
per-ex loss: 0.498410  [   78/   89]
per-ex loss: 0.335788  [   80/   89]
per-ex loss: 0.492908  [   82/   89]
per-ex loss: 0.478755  [   84/   89]
per-ex loss: 0.493702  [   86/   89]
per-ex loss: 0.670439  [   88/   89]
per-ex loss: 0.492425  [   89/   89]
Train Error: Avg loss: 0.53324041
validation Error: 
 Avg loss: 0.63048621 
 F1: 0.522461 
 Precision: 0.622199 
 Recall: 0.450282
 IoU: 0.353602

test Error: 
 Avg loss: 0.59961918 
 F1: 0.554503 
 Precision: 0.638086 
 Recall: 0.490281
 IoU: 0.383607

We have finished training iteration 179
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_177_.pth
per-ex loss: 0.545167  [    2/   89]
per-ex loss: 0.526779  [    4/   89]
per-ex loss: 0.657615  [    6/   89]
per-ex loss: 0.494050  [    8/   89]
per-ex loss: 0.438842  [   10/   89]
per-ex loss: 0.642912  [   12/   89]
per-ex loss: 0.386141  [   14/   89]
per-ex loss: 0.540572  [   16/   89]
per-ex loss: 0.477839  [   18/   89]
per-ex loss: 0.564955  [   20/   89]
per-ex loss: 0.588069  [   22/   89]
per-ex loss: 0.441645  [   24/   89]
per-ex loss: 0.462628  [   26/   89]
per-ex loss: 0.578518  [   28/   89]
per-ex loss: 0.442873  [   30/   89]
per-ex loss: 0.591367  [   32/   89]
per-ex loss: 0.605148  [   34/   89]
per-ex loss: 0.596629  [   36/   89]
per-ex loss: 0.479561  [   38/   89]
per-ex loss: 0.821772  [   40/   89]
per-ex loss: 0.419498  [   42/   89]
per-ex loss: 0.656102  [   44/   89]
per-ex loss: 0.349395  [   46/   89]
per-ex loss: 0.439990  [   48/   89]
per-ex loss: 0.646292  [   50/   89]
per-ex loss: 0.409356  [   52/   89]
per-ex loss: 0.477527  [   54/   89]
per-ex loss: 0.576413  [   56/   89]
per-ex loss: 0.585228  [   58/   89]
per-ex loss: 0.392750  [   60/   89]
per-ex loss: 0.439150  [   62/   89]
per-ex loss: 0.655385  [   64/   89]
per-ex loss: 0.645113  [   66/   89]
per-ex loss: 0.451765  [   68/   89]
per-ex loss: 0.522880  [   70/   89]
per-ex loss: 0.553138  [   72/   89]
per-ex loss: 0.417374  [   74/   89]
per-ex loss: 0.642034  [   76/   89]
per-ex loss: 0.576118  [   78/   89]
per-ex loss: 0.459820  [   80/   89]
per-ex loss: 0.495007  [   82/   89]
per-ex loss: 0.590474  [   84/   89]
per-ex loss: 0.530181  [   86/   89]
per-ex loss: 0.708053  [   88/   89]
per-ex loss: 0.631336  [   89/   89]
Train Error: Avg loss: 0.53674356
validation Error: 
 Avg loss: 0.61488800 
 F1: 0.522253 
 Precision: 0.638994 
 Recall: 0.441578
 IoU: 0.353411

test Error: 
 Avg loss: 0.59835445 
 F1: 0.552078 
 Precision: 0.633618 
 Recall: 0.489132
 IoU: 0.381290

We have finished training iteration 180
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_178_.pth
per-ex loss: 0.493822  [    2/   89]
per-ex loss: 0.442400  [    4/   89]
per-ex loss: 0.472447  [    6/   89]
per-ex loss: 0.670852  [    8/   89]
per-ex loss: 0.433891  [   10/   89]
per-ex loss: 0.535639  [   12/   89]
per-ex loss: 0.453416  [   14/   89]
per-ex loss: 0.593240  [   16/   89]
per-ex loss: 0.484713  [   18/   89]
per-ex loss: 0.455884  [   20/   89]
per-ex loss: 0.658091  [   22/   89]
per-ex loss: 0.390726  [   24/   89]
per-ex loss: 0.448363  [   26/   89]
per-ex loss: 0.461944  [   28/   89]
per-ex loss: 0.623687  [   30/   89]
per-ex loss: 0.689363  [   32/   89]
per-ex loss: 0.405832  [   34/   89]
per-ex loss: 0.645309  [   36/   89]
per-ex loss: 0.478243  [   38/   89]
per-ex loss: 0.481400  [   40/   89]
per-ex loss: 0.477239  [   42/   89]
per-ex loss: 0.450073  [   44/   89]
per-ex loss: 0.631934  [   46/   89]
per-ex loss: 0.673663  [   48/   89]
per-ex loss: 0.430320  [   50/   89]
per-ex loss: 0.464859  [   52/   89]
per-ex loss: 0.416323  [   54/   89]
per-ex loss: 0.388074  [   56/   89]
per-ex loss: 0.459393  [   58/   89]
per-ex loss: 0.526064  [   60/   89]
per-ex loss: 0.574870  [   62/   89]
per-ex loss: 0.476708  [   64/   89]
per-ex loss: 0.382481  [   66/   89]
per-ex loss: 0.549344  [   68/   89]
per-ex loss: 0.736459  [   70/   89]
per-ex loss: 0.587752  [   72/   89]
per-ex loss: 0.424604  [   74/   89]
per-ex loss: 0.499901  [   76/   89]
per-ex loss: 0.688762  [   78/   89]
per-ex loss: 0.582481  [   80/   89]
per-ex loss: 0.557136  [   82/   89]
per-ex loss: 0.597094  [   84/   89]
per-ex loss: 0.495494  [   86/   89]
per-ex loss: 0.474403  [   88/   89]
per-ex loss: 0.559876  [   89/   89]
Train Error: Avg loss: 0.52054596
validation Error: 
 Avg loss: 0.62907615 
 F1: 0.527489 
 Precision: 0.579772 
 Recall: 0.483855
 IoU: 0.358224

test Error: 
 Avg loss: 0.61400733 
 F1: 0.546108 
 Precision: 0.572570 
 Recall: 0.521984
 IoU: 0.375618

We have finished training iteration 181
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_179_.pth
per-ex loss: 0.603111  [    2/   89]
per-ex loss: 0.510520  [    4/   89]
per-ex loss: 0.491046  [    6/   89]
per-ex loss: 0.443615  [    8/   89]
per-ex loss: 0.514028  [   10/   89]
per-ex loss: 0.439147  [   12/   89]
per-ex loss: 0.520734  [   14/   89]
per-ex loss: 0.673325  [   16/   89]
per-ex loss: 0.420118  [   18/   89]
per-ex loss: 0.458234  [   20/   89]
per-ex loss: 0.398679  [   22/   89]
per-ex loss: 0.670467  [   24/   89]
per-ex loss: 0.444263  [   26/   89]
per-ex loss: 0.437849  [   28/   89]
per-ex loss: 0.463125  [   30/   89]
per-ex loss: 0.511727  [   32/   89]
per-ex loss: 0.493655  [   34/   89]
per-ex loss: 0.450603  [   36/   89]
per-ex loss: 0.669505  [   38/   89]
per-ex loss: 0.700020  [   40/   89]
per-ex loss: 0.476786  [   42/   89]
per-ex loss: 0.587484  [   44/   89]
per-ex loss: 0.551249  [   46/   89]
per-ex loss: 0.427882  [   48/   89]
per-ex loss: 0.677877  [   50/   89]
per-ex loss: 0.329913  [   52/   89]
per-ex loss: 0.423726  [   54/   89]
per-ex loss: 0.703238  [   56/   89]
per-ex loss: 0.367427  [   58/   89]
per-ex loss: 0.590909  [   60/   89]
per-ex loss: 0.489256  [   62/   89]
per-ex loss: 0.621097  [   64/   89]
per-ex loss: 0.680361  [   66/   89]
per-ex loss: 0.695921  [   68/   89]
per-ex loss: 0.678506  [   70/   89]
per-ex loss: 0.535751  [   72/   89]
per-ex loss: 0.562869  [   74/   89]
per-ex loss: 0.506043  [   76/   89]
per-ex loss: 0.565601  [   78/   89]
per-ex loss: 0.420765  [   80/   89]
per-ex loss: 0.500643  [   82/   89]
per-ex loss: 0.625188  [   84/   89]
per-ex loss: 0.531257  [   86/   89]
per-ex loss: 0.507927  [   88/   89]
per-ex loss: 0.554516  [   89/   89]
Train Error: Avg loss: 0.53168807
validation Error: 
 Avg loss: 0.63283591 
 F1: 0.512185 
 Precision: 0.668869 
 Recall: 0.414976
 IoU: 0.344253

test Error: 
 Avg loss: 0.60513535 
 F1: 0.529555 
 Precision: 0.661250 
 Recall: 0.441605
 IoU: 0.360132

We have finished training iteration 182
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_180_.pth
per-ex loss: 0.471416  [    2/   89]
per-ex loss: 0.628969  [    4/   89]
per-ex loss: 0.402292  [    6/   89]
per-ex loss: 0.657874  [    8/   89]
per-ex loss: 0.699754  [   10/   89]
per-ex loss: 0.537032  [   12/   89]
per-ex loss: 0.514755  [   14/   89]
per-ex loss: 0.442190  [   16/   89]
per-ex loss: 0.490591  [   18/   89]
per-ex loss: 0.515072  [   20/   89]
per-ex loss: 0.514586  [   22/   89]
per-ex loss: 0.547897  [   24/   89]
per-ex loss: 0.519175  [   26/   89]
per-ex loss: 0.459063  [   28/   89]
per-ex loss: 0.681533  [   30/   89]
per-ex loss: 0.549376  [   32/   89]
per-ex loss: 0.394509  [   34/   89]
per-ex loss: 0.567153  [   36/   89]
per-ex loss: 0.444696  [   38/   89]
per-ex loss: 0.492410  [   40/   89]
per-ex loss: 0.541394  [   42/   89]
per-ex loss: 0.528481  [   44/   89]
per-ex loss: 0.503724  [   46/   89]
per-ex loss: 0.556216  [   48/   89]
per-ex loss: 0.570445  [   50/   89]
per-ex loss: 0.514566  [   52/   89]
per-ex loss: 0.457355  [   54/   89]
per-ex loss: 0.399584  [   56/   89]
per-ex loss: 0.473620  [   58/   89]
per-ex loss: 0.438692  [   60/   89]
per-ex loss: 0.676657  [   62/   89]
per-ex loss: 0.556843  [   64/   89]
per-ex loss: 0.470278  [   66/   89]
per-ex loss: 0.431039  [   68/   89]
per-ex loss: 0.520007  [   70/   89]
per-ex loss: 0.385314  [   72/   89]
per-ex loss: 0.425405  [   74/   89]
per-ex loss: 0.528231  [   76/   89]
per-ex loss: 0.506925  [   78/   89]
per-ex loss: 0.619880  [   80/   89]
per-ex loss: 0.579669  [   82/   89]
per-ex loss: 0.428200  [   84/   89]
per-ex loss: 0.584086  [   86/   89]
per-ex loss: 0.520022  [   88/   89]
per-ex loss: 0.509713  [   89/   89]
Train Error: Avg loss: 0.51681530
validation Error: 
 Avg loss: 0.60839621 
 F1: 0.516502 
 Precision: 0.621821 
 Recall: 0.441692
 IoU: 0.348165

test Error: 
 Avg loss: 0.59550641 
 F1: 0.551191 
 Precision: 0.604701 
 Recall: 0.506382
 IoU: 0.380444

We have finished training iteration 183
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_181_.pth
per-ex loss: 0.522893  [    2/   89]
per-ex loss: 0.504557  [    4/   89]
per-ex loss: 0.407789  [    6/   89]
per-ex loss: 0.412845  [    8/   89]
per-ex loss: 0.492149  [   10/   89]
per-ex loss: 0.419736  [   12/   89]
per-ex loss: 0.661225  [   14/   89]
per-ex loss: 0.506360  [   16/   89]
per-ex loss: 0.418028  [   18/   89]
per-ex loss: 0.556018  [   20/   89]
per-ex loss: 0.630150  [   22/   89]
per-ex loss: 0.596825  [   24/   89]
per-ex loss: 0.509976  [   26/   89]
per-ex loss: 0.378076  [   28/   89]
per-ex loss: 0.573196  [   30/   89]
per-ex loss: 0.579425  [   32/   89]
per-ex loss: 0.624069  [   34/   89]
per-ex loss: 0.621297  [   36/   89]
per-ex loss: 0.516877  [   38/   89]
per-ex loss: 0.647289  [   40/   89]
per-ex loss: 0.560350  [   42/   89]
per-ex loss: 0.343542  [   44/   89]
per-ex loss: 0.541203  [   46/   89]
per-ex loss: 0.496710  [   48/   89]
per-ex loss: 0.480891  [   50/   89]
per-ex loss: 0.455792  [   52/   89]
per-ex loss: 0.413997  [   54/   89]
per-ex loss: 0.493691  [   56/   89]
per-ex loss: 0.468452  [   58/   89]
per-ex loss: 0.443989  [   60/   89]
per-ex loss: 0.618203  [   62/   89]
per-ex loss: 0.535109  [   64/   89]
per-ex loss: 0.666132  [   66/   89]
per-ex loss: 0.643496  [   68/   89]
per-ex loss: 0.572006  [   70/   89]
per-ex loss: 0.492101  [   72/   89]
per-ex loss: 0.461228  [   74/   89]
per-ex loss: 0.402678  [   76/   89]
per-ex loss: 0.502292  [   78/   89]
per-ex loss: 0.566107  [   80/   89]
per-ex loss: 0.561200  [   82/   89]
per-ex loss: 0.532725  [   84/   89]
per-ex loss: 0.621967  [   86/   89]
per-ex loss: 0.598372  [   88/   89]
per-ex loss: 0.383193  [   89/   89]
Train Error: Avg loss: 0.52076018
validation Error: 
 Avg loss: 0.61173067 
 F1: 0.522764 
 Precision: 0.646535 
 Recall: 0.438767
 IoU: 0.353880

test Error: 
 Avg loss: 0.59276434 
 F1: 0.548458 
 Precision: 0.653327 
 Recall: 0.472599
 IoU: 0.377845

We have finished training iteration 184
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_182_.pth
per-ex loss: 0.374909  [    2/   89]
per-ex loss: 0.661823  [    4/   89]
per-ex loss: 0.553000  [    6/   89]
per-ex loss: 0.404312  [    8/   89]
per-ex loss: 0.488762  [   10/   89]
per-ex loss: 0.486203  [   12/   89]
per-ex loss: 0.558477  [   14/   89]
per-ex loss: 0.544577  [   16/   89]
per-ex loss: 0.693743  [   18/   89]
per-ex loss: 0.415895  [   20/   89]
per-ex loss: 0.422006  [   22/   89]
per-ex loss: 0.459548  [   24/   89]
per-ex loss: 0.419047  [   26/   89]
per-ex loss: 0.655360  [   28/   89]
per-ex loss: 0.419155  [   30/   89]
per-ex loss: 0.440164  [   32/   89]
per-ex loss: 0.582083  [   34/   89]
per-ex loss: 0.522045  [   36/   89]
per-ex loss: 0.439512  [   38/   89]
per-ex loss: 0.486014  [   40/   89]
per-ex loss: 0.536058  [   42/   89]
per-ex loss: 0.413022  [   44/   89]
per-ex loss: 0.562829  [   46/   89]
per-ex loss: 0.604326  [   48/   89]
per-ex loss: 0.496622  [   50/   89]
per-ex loss: 0.710844  [   52/   89]
per-ex loss: 0.657748  [   54/   89]
per-ex loss: 0.725899  [   56/   89]
per-ex loss: 0.420693  [   58/   89]
per-ex loss: 0.541226  [   60/   89]
per-ex loss: 0.439869  [   62/   89]
per-ex loss: 0.521630  [   64/   89]
per-ex loss: 0.445426  [   66/   89]
per-ex loss: 0.370791  [   68/   89]
per-ex loss: 0.744139  [   70/   89]
per-ex loss: 0.430752  [   72/   89]
per-ex loss: 0.528209  [   74/   89]
per-ex loss: 0.544866  [   76/   89]
per-ex loss: 0.515623  [   78/   89]
per-ex loss: 0.728628  [   80/   89]
per-ex loss: 0.569567  [   82/   89]
per-ex loss: 0.362850  [   84/   89]
per-ex loss: 0.440198  [   86/   89]
per-ex loss: 0.436944  [   88/   89]
per-ex loss: 0.750304  [   89/   89]
Train Error: Avg loss: 0.52279325
validation Error: 
 Avg loss: 0.61229700 
 F1: 0.520023 
 Precision: 0.628467 
 Recall: 0.443496
 IoU: 0.351372

test Error: 
 Avg loss: 0.61322504 
 F1: 0.521785 
 Precision: 0.600766 
 Recall: 0.461158
 IoU: 0.352983

We have finished training iteration 185
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_183_.pth
per-ex loss: 0.422668  [    2/   89]
per-ex loss: 0.536519  [    4/   89]
per-ex loss: 0.495740  [    6/   89]
per-ex loss: 0.441209  [    8/   89]
per-ex loss: 0.466712  [   10/   89]
per-ex loss: 0.444132  [   12/   89]
per-ex loss: 0.633846  [   14/   89]
per-ex loss: 0.442792  [   16/   89]
per-ex loss: 0.433250  [   18/   89]
per-ex loss: 0.550797  [   20/   89]
per-ex loss: 0.452153  [   22/   89]
per-ex loss: 0.325224  [   24/   89]
per-ex loss: 0.561213  [   26/   89]
per-ex loss: 0.564226  [   28/   89]
per-ex loss: 0.620202  [   30/   89]
per-ex loss: 0.733193  [   32/   89]
per-ex loss: 0.609360  [   34/   89]
per-ex loss: 0.665347  [   36/   89]
per-ex loss: 0.409951  [   38/   89]
per-ex loss: 0.503795  [   40/   89]
per-ex loss: 0.410816  [   42/   89]
per-ex loss: 0.664734  [   44/   89]
per-ex loss: 0.477691  [   46/   89]
per-ex loss: 0.699955  [   48/   89]
per-ex loss: 0.608537  [   50/   89]
per-ex loss: 0.543984  [   52/   89]
per-ex loss: 0.427863  [   54/   89]
per-ex loss: 0.539472  [   56/   89]
per-ex loss: 0.376177  [   58/   89]
per-ex loss: 0.574153  [   60/   89]
per-ex loss: 0.541431  [   62/   89]
per-ex loss: 0.453623  [   64/   89]
per-ex loss: 0.560568  [   66/   89]
per-ex loss: 0.525959  [   68/   89]
per-ex loss: 0.421484  [   70/   89]
per-ex loss: 0.461055  [   72/   89]
per-ex loss: 0.515242  [   74/   89]
per-ex loss: 0.482153  [   76/   89]
per-ex loss: 0.750298  [   78/   89]
per-ex loss: 0.353467  [   80/   89]
per-ex loss: 0.445325  [   82/   89]
per-ex loss: 0.548822  [   84/   89]
per-ex loss: 0.391376  [   86/   89]
per-ex loss: 0.512397  [   88/   89]
per-ex loss: 0.619112  [   89/   89]
Train Error: Avg loss: 0.51595607
validation Error: 
 Avg loss: 0.60634768 
 F1: 0.528691 
 Precision: 0.610080 
 Recall: 0.466462
 IoU: 0.359334

test Error: 
 Avg loss: 0.60020538 
 F1: 0.540809 
 Precision: 0.593548 
 Recall: 0.496678
 IoU: 0.370623

We have finished training iteration 186
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_184_.pth
per-ex loss: 0.701234  [    2/   89]
per-ex loss: 0.554623  [    4/   89]
per-ex loss: 0.455412  [    6/   89]
per-ex loss: 0.548956  [    8/   89]
per-ex loss: 0.502724  [   10/   89]
per-ex loss: 0.545172  [   12/   89]
per-ex loss: 0.399221  [   14/   89]
per-ex loss: 0.628444  [   16/   89]
per-ex loss: 0.440024  [   18/   89]
per-ex loss: 0.374974  [   20/   89]
per-ex loss: 0.679008  [   22/   89]
per-ex loss: 0.421608  [   24/   89]
per-ex loss: 0.445952  [   26/   89]
per-ex loss: 0.417817  [   28/   89]
per-ex loss: 0.439054  [   30/   89]
per-ex loss: 0.383658  [   32/   89]
per-ex loss: 0.590617  [   34/   89]
per-ex loss: 0.433466  [   36/   89]
per-ex loss: 0.431464  [   38/   89]
per-ex loss: 0.365771  [   40/   89]
per-ex loss: 0.410938  [   42/   89]
per-ex loss: 0.622955  [   44/   89]
per-ex loss: 0.445256  [   46/   89]
per-ex loss: 0.573164  [   48/   89]
per-ex loss: 0.431150  [   50/   89]
per-ex loss: 0.633317  [   52/   89]
per-ex loss: 0.476068  [   54/   89]
per-ex loss: 0.544911  [   56/   89]
per-ex loss: 0.665426  [   58/   89]
per-ex loss: 0.446935  [   60/   89]
per-ex loss: 0.615699  [   62/   89]
per-ex loss: 0.544089  [   64/   89]
per-ex loss: 0.476544  [   66/   89]
per-ex loss: 0.704330  [   68/   89]
per-ex loss: 0.548425  [   70/   89]
per-ex loss: 0.578562  [   72/   89]
per-ex loss: 0.591912  [   74/   89]
per-ex loss: 0.585808  [   76/   89]
per-ex loss: 0.448997  [   78/   89]
per-ex loss: 0.405414  [   80/   89]
per-ex loss: 0.410053  [   82/   89]
per-ex loss: 0.433289  [   84/   89]
per-ex loss: 0.536323  [   86/   89]
per-ex loss: 0.511977  [   88/   89]
per-ex loss: 0.722359  [   89/   89]
Train Error: Avg loss: 0.51384670
validation Error: 
 Avg loss: 0.61360978 
 F1: 0.519162 
 Precision: 0.651754 
 Recall: 0.431398
 IoU: 0.350586

test Error: 
 Avg loss: 0.58759737 
 F1: 0.545175 
 Precision: 0.659081 
 Recall: 0.464840
 IoU: 0.374736

We have finished training iteration 187
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_185_.pth
Error in cropping the image to the non-zero values in the fourth channel. Returned the original image.
per-ex loss: 0.606512  [    2/   89]
per-ex loss: 0.500365  [    4/   89]
per-ex loss: 0.545768  [    6/   89]
per-ex loss: 0.419714  [    8/   89]
per-ex loss: 0.421011  [   10/   89]
per-ex loss: 0.481402  [   12/   89]
per-ex loss: 0.632141  [   14/   89]
per-ex loss: 0.706552  [   16/   89]
per-ex loss: 0.434079  [   18/   89]
per-ex loss: 0.469006  [   20/   89]
per-ex loss: 0.597056  [   22/   89]
per-ex loss: 0.538939  [   24/   89]
per-ex loss: 0.393768  [   26/   89]
per-ex loss: 0.421607  [   28/   89]
per-ex loss: 0.548316  [   30/   89]
per-ex loss: 0.575686  [   32/   89]
per-ex loss: 0.483973  [   34/   89]
per-ex loss: 0.433557  [   36/   89]
per-ex loss: 0.510714  [   38/   89]
per-ex loss: 0.714954  [   40/   89]
per-ex loss: 0.607422  [   42/   89]
per-ex loss: 0.659717  [   44/   89]
per-ex loss: 0.540895  [   46/   89]
per-ex loss: 0.600689  [   48/   89]
per-ex loss: 0.389473  [   50/   89]
per-ex loss: 0.475104  [   52/   89]
per-ex loss: 0.418226  [   54/   89]
per-ex loss: 0.708423  [   56/   89]
per-ex loss: 0.386823  [   58/   89]
per-ex loss: 0.406928  [   60/   89]
per-ex loss: 0.412892  [   62/   89]
per-ex loss: 0.704565  [   64/   89]
per-ex loss: 0.543739  [   66/   89]
per-ex loss: 0.679854  [   68/   89]
per-ex loss: 0.415654  [   70/   89]
per-ex loss: 0.444723  [   72/   89]
per-ex loss: 0.384291  [   74/   89]
per-ex loss: 0.537586  [   76/   89]
per-ex loss: 0.461108  [   78/   89]
per-ex loss: 0.548132  [   80/   89]
per-ex loss: 0.569862  [   82/   89]
per-ex loss: 0.475054  [   84/   89]
per-ex loss: 0.375809  [   86/   89]
per-ex loss: 0.427920  [   88/   89]
per-ex loss: 0.431968  [   89/   89]
Train Error: Avg loss: 0.51204392
validation Error: 
 Avg loss: 0.60867404 
 F1: 0.517080 
 Precision: 0.669613 
 Recall: 0.421146
 IoU: 0.348690

test Error: 
 Avg loss: 0.58894571 
 F1: 0.535449 
 Precision: 0.690136 
 Recall: 0.437408
 IoU: 0.365606

We have finished training iteration 188
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_186_.pth
per-ex loss: 0.586037  [    2/   89]
per-ex loss: 0.563874  [    4/   89]
per-ex loss: 0.463041  [    6/   89]
per-ex loss: 0.377737  [    8/   89]
per-ex loss: 0.503268  [   10/   89]
per-ex loss: 0.541144  [   12/   89]
per-ex loss: 0.652353  [   14/   89]
per-ex loss: 0.493164  [   16/   89]
per-ex loss: 0.543449  [   18/   89]
per-ex loss: 0.464582  [   20/   89]
per-ex loss: 0.418668  [   22/   89]
per-ex loss: 0.389622  [   24/   89]
per-ex loss: 0.443127  [   26/   89]
per-ex loss: 0.539755  [   28/   89]
per-ex loss: 0.522087  [   30/   89]
per-ex loss: 0.596026  [   32/   89]
per-ex loss: 0.587369  [   34/   89]
per-ex loss: 0.531089  [   36/   89]
per-ex loss: 0.584054  [   38/   89]
per-ex loss: 0.508665  [   40/   89]
per-ex loss: 0.433686  [   42/   89]
per-ex loss: 0.390492  [   44/   89]
per-ex loss: 0.510074  [   46/   89]
per-ex loss: 0.670241  [   48/   89]
per-ex loss: 0.593938  [   50/   89]
per-ex loss: 0.489332  [   52/   89]
per-ex loss: 0.581037  [   54/   89]
per-ex loss: 0.583482  [   56/   89]
per-ex loss: 0.437205  [   58/   89]
per-ex loss: 0.736739  [   60/   89]
per-ex loss: 0.599987  [   62/   89]
per-ex loss: 0.512613  [   64/   89]
per-ex loss: 0.533886  [   66/   89]
per-ex loss: 0.473693  [   68/   89]
per-ex loss: 0.435257  [   70/   89]
per-ex loss: 0.568877  [   72/   89]
per-ex loss: 0.486945  [   74/   89]
per-ex loss: 0.517394  [   76/   89]
per-ex loss: 0.392616  [   78/   89]
per-ex loss: 0.475355  [   80/   89]
per-ex loss: 0.452689  [   82/   89]
per-ex loss: 0.744536  [   84/   89]
per-ex loss: 0.711992  [   86/   89]
per-ex loss: 0.597713  [   88/   89]
per-ex loss: 0.270743  [   89/   89]
Train Error: Avg loss: 0.52243627
validation Error: 
 Avg loss: 0.61051057 
 F1: 0.526406 
 Precision: 0.623931 
 Recall: 0.455248
 IoU: 0.357226

test Error: 
 Avg loss: 0.59235071 
 F1: 0.550165 
 Precision: 0.601378 
 Recall: 0.506990
 IoU: 0.379468

We have finished training iteration 189
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_187_.pth
per-ex loss: 0.701203  [    2/   89]
per-ex loss: 0.445975  [    4/   89]
per-ex loss: 0.615328  [    6/   89]
per-ex loss: 0.389927  [    8/   89]
per-ex loss: 0.519592  [   10/   89]
per-ex loss: 0.465525  [   12/   89]
per-ex loss: 0.378528  [   14/   89]
per-ex loss: 0.420277  [   16/   89]
per-ex loss: 0.481049  [   18/   89]
per-ex loss: 0.519284  [   20/   89]
per-ex loss: 0.458826  [   22/   89]
per-ex loss: 0.421421  [   24/   89]
per-ex loss: 0.509811  [   26/   89]
per-ex loss: 0.350808  [   28/   89]
per-ex loss: 0.387787  [   30/   89]
per-ex loss: 0.485145  [   32/   89]
per-ex loss: 0.403037  [   34/   89]
per-ex loss: 0.617416  [   36/   89]
per-ex loss: 0.629617  [   38/   89]
per-ex loss: 0.512030  [   40/   89]
per-ex loss: 0.666959  [   42/   89]
per-ex loss: 0.591324  [   44/   89]
per-ex loss: 0.531539  [   46/   89]
per-ex loss: 0.409116  [   48/   89]
per-ex loss: 0.615491  [   50/   89]
per-ex loss: 0.408100  [   52/   89]
per-ex loss: 0.492952  [   54/   89]
per-ex loss: 0.450707  [   56/   89]
per-ex loss: 0.439824  [   58/   89]
per-ex loss: 0.553927  [   60/   89]
per-ex loss: 0.548055  [   62/   89]
per-ex loss: 0.580559  [   64/   89]
per-ex loss: 0.543102  [   66/   89]
per-ex loss: 0.404936  [   68/   89]
per-ex loss: 0.808106  [   70/   89]
per-ex loss: 0.446540  [   72/   89]
per-ex loss: 0.411197  [   74/   89]
per-ex loss: 0.769014  [   76/   89]
per-ex loss: 0.681501  [   78/   89]
per-ex loss: 0.703539  [   80/   89]
per-ex loss: 0.513968  [   82/   89]
per-ex loss: 0.479992  [   84/   89]
per-ex loss: 0.512414  [   86/   89]
per-ex loss: 0.484374  [   88/   89]
per-ex loss: 0.474237  [   89/   89]
Train Error: Avg loss: 0.51631243
validation Error: 
 Avg loss: 0.61927030 
 F1: 0.521135 
 Precision: 0.627671 
 Recall: 0.445516
 IoU: 0.352388

test Error: 
 Avg loss: 0.58743158 
 F1: 0.546964 
 Precision: 0.634479 
 Recall: 0.480665
 IoU: 0.376429

We have finished training iteration 190
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_188_.pth
per-ex loss: 0.710276  [    2/   89]
per-ex loss: 0.637817  [    4/   89]
per-ex loss: 0.408703  [    6/   89]
per-ex loss: 0.526010  [    8/   89]
per-ex loss: 0.472944  [   10/   89]
per-ex loss: 0.657098  [   12/   89]
per-ex loss: 0.511194  [   14/   89]
per-ex loss: 0.436882  [   16/   89]
per-ex loss: 0.572549  [   18/   89]
per-ex loss: 0.485349  [   20/   89]
per-ex loss: 0.526815  [   22/   89]
per-ex loss: 0.497286  [   24/   89]
per-ex loss: 0.624335  [   26/   89]
per-ex loss: 0.458501  [   28/   89]
per-ex loss: 0.536456  [   30/   89]
per-ex loss: 0.452450  [   32/   89]
per-ex loss: 0.498907  [   34/   89]
per-ex loss: 0.385550  [   36/   89]
per-ex loss: 0.318176  [   38/   89]
per-ex loss: 0.465448  [   40/   89]
per-ex loss: 0.357746  [   42/   89]
per-ex loss: 0.401493  [   44/   89]
per-ex loss: 0.539555  [   46/   89]
per-ex loss: 0.589065  [   48/   89]
per-ex loss: 0.481740  [   50/   89]
per-ex loss: 0.481110  [   52/   89]
per-ex loss: 0.545188  [   54/   89]
per-ex loss: 0.625041  [   56/   89]
per-ex loss: 0.403251  [   58/   89]
per-ex loss: 0.389741  [   60/   89]
per-ex loss: 0.564463  [   62/   89]
per-ex loss: 0.478054  [   64/   89]
per-ex loss: 0.400272  [   66/   89]
per-ex loss: 0.447066  [   68/   89]
per-ex loss: 0.654546  [   70/   89]
per-ex loss: 0.693851  [   72/   89]
per-ex loss: 0.651966  [   74/   89]
per-ex loss: 0.522504  [   76/   89]
per-ex loss: 0.706274  [   78/   89]
per-ex loss: 0.430504  [   80/   89]
per-ex loss: 0.494517  [   82/   89]
per-ex loss: 0.580506  [   84/   89]
per-ex loss: 0.499652  [   86/   89]
per-ex loss: 0.664664  [   88/   89]
per-ex loss: 0.638316  [   89/   89]
Train Error: Avg loss: 0.52052951
validation Error: 
 Avg loss: 0.60727933 
 F1: 0.524480 
 Precision: 0.614403 
 Recall: 0.457518
 IoU: 0.355454

test Error: 
 Avg loss: 0.58351032 
 F1: 0.552925 
 Precision: 0.620733 
 Recall: 0.498473
 IoU: 0.382099

We have finished training iteration 191
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_189_.pth
per-ex loss: 0.421579  [    2/   89]
per-ex loss: 0.674254  [    4/   89]
per-ex loss: 0.424221  [    6/   89]
per-ex loss: 0.670431  [    8/   89]
per-ex loss: 0.567992  [   10/   89]
per-ex loss: 0.443016  [   12/   89]
per-ex loss: 0.461387  [   14/   89]
per-ex loss: 0.471218  [   16/   89]
per-ex loss: 0.674293  [   18/   89]
per-ex loss: 0.553450  [   20/   89]
per-ex loss: 0.325892  [   22/   89]
per-ex loss: 0.544878  [   24/   89]
per-ex loss: 0.476277  [   26/   89]
per-ex loss: 0.365648  [   28/   89]
per-ex loss: 0.621500  [   30/   89]
per-ex loss: 0.580882  [   32/   89]
per-ex loss: 0.430088  [   34/   89]
per-ex loss: 0.498529  [   36/   89]
per-ex loss: 0.450999  [   38/   89]
per-ex loss: 0.427697  [   40/   89]
per-ex loss: 0.582334  [   42/   89]
per-ex loss: 0.524692  [   44/   89]
per-ex loss: 0.461005  [   46/   89]
per-ex loss: 0.422399  [   48/   89]
per-ex loss: 0.622533  [   50/   89]
per-ex loss: 0.434150  [   52/   89]
per-ex loss: 0.592307  [   54/   89]
per-ex loss: 0.431826  [   56/   89]
per-ex loss: 0.726773  [   58/   89]
per-ex loss: 0.367592  [   60/   89]
per-ex loss: 0.461900  [   62/   89]
per-ex loss: 0.520689  [   64/   89]
per-ex loss: 0.493692  [   66/   89]
per-ex loss: 0.665776  [   68/   89]
per-ex loss: 0.554232  [   70/   89]
per-ex loss: 0.470036  [   72/   89]
per-ex loss: 0.613901  [   74/   89]
per-ex loss: 0.579415  [   76/   89]
per-ex loss: 0.437745  [   78/   89]
per-ex loss: 0.423588  [   80/   89]
per-ex loss: 0.360546  [   82/   89]
per-ex loss: 0.415175  [   84/   89]
per-ex loss: 0.481312  [   86/   89]
per-ex loss: 0.611633  [   88/   89]
per-ex loss: 0.434912  [   89/   89]
Train Error: Avg loss: 0.50609767
validation Error: 
 Avg loss: 0.60073093 
 F1: 0.514840 
 Precision: 0.675782 
 Recall: 0.415812
 IoU: 0.346656

test Error: 
 Avg loss: 0.58703435 
 F1: 0.527143 
 Precision: 0.676841 
 Recall: 0.431670
 IoU: 0.357905

We have finished training iteration 192
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_190_.pth
per-ex loss: 0.498164  [    2/   89]
per-ex loss: 0.474697  [    4/   89]
per-ex loss: 0.553912  [    6/   89]
per-ex loss: 0.534941  [    8/   89]
per-ex loss: 0.614690  [   10/   89]
per-ex loss: 0.603351  [   12/   89]
per-ex loss: 0.561866  [   14/   89]
per-ex loss: 0.710418  [   16/   89]
per-ex loss: 0.434734  [   18/   89]
per-ex loss: 0.687840  [   20/   89]
per-ex loss: 0.387621  [   22/   89]
per-ex loss: 0.437990  [   24/   89]
per-ex loss: 0.553667  [   26/   89]
per-ex loss: 0.541957  [   28/   89]
per-ex loss: 0.425005  [   30/   89]
per-ex loss: 0.650589  [   32/   89]
per-ex loss: 0.483655  [   34/   89]
per-ex loss: 0.458884  [   36/   89]
per-ex loss: 0.375845  [   38/   89]
per-ex loss: 0.438599  [   40/   89]
per-ex loss: 0.617014  [   42/   89]
per-ex loss: 0.404913  [   44/   89]
per-ex loss: 0.367225  [   46/   89]
per-ex loss: 0.456938  [   48/   89]
per-ex loss: 0.516000  [   50/   89]
per-ex loss: 0.782852  [   52/   89]
per-ex loss: 0.644459  [   54/   89]
per-ex loss: 0.435761  [   56/   89]
per-ex loss: 0.406779  [   58/   89]
per-ex loss: 0.632025  [   60/   89]
per-ex loss: 0.570686  [   62/   89]
per-ex loss: 0.444548  [   64/   89]
per-ex loss: 0.620002  [   66/   89]
per-ex loss: 0.447006  [   68/   89]
per-ex loss: 0.450326  [   70/   89]
per-ex loss: 0.480419  [   72/   89]
per-ex loss: 0.386756  [   74/   89]
per-ex loss: 0.436550  [   76/   89]
per-ex loss: 0.612870  [   78/   89]
per-ex loss: 0.608088  [   80/   89]
per-ex loss: 0.668462  [   82/   89]
per-ex loss: 0.466453  [   84/   89]
per-ex loss: 0.718964  [   86/   89]
per-ex loss: 0.572274  [   88/   89]
per-ex loss: 0.467281  [   89/   89]
Train Error: Avg loss: 0.52540168
validation Error: 
 Avg loss: 0.60012202 
 F1: 0.517409 
 Precision: 0.664841 
 Recall: 0.423496
 IoU: 0.348989

test Error: 
 Avg loss: 0.57992067 
 F1: 0.544292 
 Precision: 0.663042 
 Recall: 0.461616
 IoU: 0.373902

We have finished training iteration 193
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_191_.pth
Error in cropping the image to the non-zero values in the fourth channel. Returned the original image.
per-ex loss: 0.591409  [    2/   89]
per-ex loss: 0.645857  [    4/   89]
per-ex loss: 0.524179  [    6/   89]
per-ex loss: 0.469822  [    8/   89]
per-ex loss: 0.444570  [   10/   89]
per-ex loss: 0.492103  [   12/   89]
per-ex loss: 0.841242  [   14/   89]
per-ex loss: 0.484707  [   16/   89]
per-ex loss: 0.676010  [   18/   89]
per-ex loss: 0.393803  [   20/   89]
per-ex loss: 0.532370  [   22/   89]
per-ex loss: 0.455057  [   24/   89]
per-ex loss: 0.522168  [   26/   89]
per-ex loss: 0.410672  [   28/   89]
per-ex loss: 0.530155  [   30/   89]
per-ex loss: 0.530812  [   32/   89]
per-ex loss: 0.487858  [   34/   89]
per-ex loss: 0.404915  [   36/   89]
per-ex loss: 0.518411  [   38/   89]
per-ex loss: 0.545018  [   40/   89]
per-ex loss: 0.341272  [   42/   89]
per-ex loss: 0.528100  [   44/   89]
per-ex loss: 0.475405  [   46/   89]
per-ex loss: 0.610769  [   48/   89]
per-ex loss: 0.572682  [   50/   89]
per-ex loss: 0.428307  [   52/   89]
per-ex loss: 0.452866  [   54/   89]
per-ex loss: 0.527102  [   56/   89]
per-ex loss: 0.530588  [   58/   89]
per-ex loss: 0.383258  [   60/   89]
per-ex loss: 0.458120  [   62/   89]
per-ex loss: 0.447464  [   64/   89]
per-ex loss: 0.423678  [   66/   89]
per-ex loss: 0.631877  [   68/   89]
per-ex loss: 0.414279  [   70/   89]
per-ex loss: 0.437093  [   72/   89]
per-ex loss: 0.387083  [   74/   89]
per-ex loss: 0.564714  [   76/   89]
per-ex loss: 0.511868  [   78/   89]
per-ex loss: 0.460746  [   80/   89]
per-ex loss: 0.765739  [   82/   89]
per-ex loss: 0.473478  [   84/   89]
per-ex loss: 0.460812  [   86/   89]
per-ex loss: 0.507087  [   88/   89]
per-ex loss: 0.631634  [   89/   89]
Train Error: Avg loss: 0.50949243
validation Error: 
 Avg loss: 0.60473657 
 F1: 0.517562 
 Precision: 0.631866 
 Recall: 0.438278
 IoU: 0.349129

test Error: 
 Avg loss: 0.58784448 
 F1: 0.528844 
 Precision: 0.645720 
 Recall: 0.447793
 IoU: 0.359475

We have finished training iteration 194
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_192_.pth
per-ex loss: 0.491703  [    2/   89]
per-ex loss: 0.436646  [    4/   89]
per-ex loss: 0.531783  [    6/   89]
per-ex loss: 0.699198  [    8/   89]
per-ex loss: 0.441584  [   10/   89]
per-ex loss: 0.704771  [   12/   89]
per-ex loss: 0.554462  [   14/   89]
per-ex loss: 0.539715  [   16/   89]
per-ex loss: 0.411805  [   18/   89]
per-ex loss: 0.485725  [   20/   89]
per-ex loss: 0.517107  [   22/   89]
per-ex loss: 0.504081  [   24/   89]
per-ex loss: 0.438529  [   26/   89]
per-ex loss: 0.720144  [   28/   89]
per-ex loss: 0.387339  [   30/   89]
per-ex loss: 0.545824  [   32/   89]
per-ex loss: 0.440901  [   34/   89]
per-ex loss: 0.417370  [   36/   89]
per-ex loss: 0.521720  [   38/   89]
per-ex loss: 0.798415  [   40/   89]
per-ex loss: 0.410617  [   42/   89]
per-ex loss: 0.414512  [   44/   89]
per-ex loss: 0.377676  [   46/   89]
per-ex loss: 0.545835  [   48/   89]
per-ex loss: 0.375759  [   50/   89]
per-ex loss: 0.437504  [   52/   89]
per-ex loss: 0.390660  [   54/   89]
per-ex loss: 0.370450  [   56/   89]
per-ex loss: 0.404392  [   58/   89]
per-ex loss: 0.304823  [   60/   89]
per-ex loss: 0.569955  [   62/   89]
per-ex loss: 0.525518  [   64/   89]
per-ex loss: 0.452711  [   66/   89]
per-ex loss: 0.543971  [   68/   89]
per-ex loss: 0.619800  [   70/   89]
per-ex loss: 0.505393  [   72/   89]
per-ex loss: 0.557172  [   74/   89]
per-ex loss: 0.505854  [   76/   89]
per-ex loss: 0.627943  [   78/   89]
per-ex loss: 0.537543  [   80/   89]
per-ex loss: 0.638118  [   82/   89]
per-ex loss: 0.489509  [   84/   89]
per-ex loss: 0.385260  [   86/   89]
per-ex loss: 0.615582  [   88/   89]
per-ex loss: 0.535474  [   89/   89]
Train Error: Avg loss: 0.50513004
validation Error: 
 Avg loss: 0.59702267 
 F1: 0.525135 
 Precision: 0.625439 
 Recall: 0.452557
 IoU: 0.356057

test Error: 
 Avg loss: 0.58491136 
 F1: 0.545066 
 Precision: 0.607858 
 Recall: 0.494032
 IoU: 0.374633

We have finished training iteration 195
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_193_.pth
per-ex loss: 0.522200  [    2/   89]
per-ex loss: 0.509068  [    4/   89]
per-ex loss: 0.510160  [    6/   89]
per-ex loss: 0.394671  [    8/   89]
per-ex loss: 0.485322  [   10/   89]
per-ex loss: 0.454858  [   12/   89]
per-ex loss: 0.607721  [   14/   89]
per-ex loss: 0.632151  [   16/   89]
per-ex loss: 0.486996  [   18/   89]
per-ex loss: 0.552091  [   20/   89]
per-ex loss: 0.486703  [   22/   89]
per-ex loss: 0.618764  [   24/   89]
per-ex loss: 0.688244  [   26/   89]
per-ex loss: 0.724669  [   28/   89]
per-ex loss: 0.458005  [   30/   89]
per-ex loss: 0.444242  [   32/   89]
per-ex loss: 0.461113  [   34/   89]
per-ex loss: 0.507017  [   36/   89]
per-ex loss: 0.598390  [   38/   89]
per-ex loss: 0.467570  [   40/   89]
per-ex loss: 0.456471  [   42/   89]
per-ex loss: 0.463907  [   44/   89]
per-ex loss: 0.608793  [   46/   89]
per-ex loss: 0.746546  [   48/   89]
per-ex loss: 0.376403  [   50/   89]
per-ex loss: 0.371485  [   52/   89]
per-ex loss: 0.383705  [   54/   89]
per-ex loss: 0.520628  [   56/   89]
per-ex loss: 0.662828  [   58/   89]
per-ex loss: 0.463380  [   60/   89]
per-ex loss: 0.383729  [   62/   89]
per-ex loss: 0.622980  [   64/   89]
per-ex loss: 0.384977  [   66/   89]
per-ex loss: 0.563206  [   68/   89]
per-ex loss: 0.540236  [   70/   89]
per-ex loss: 0.459625  [   72/   89]
per-ex loss: 0.500446  [   74/   89]
per-ex loss: 0.455803  [   76/   89]
per-ex loss: 0.535368  [   78/   89]
per-ex loss: 0.415354  [   80/   89]
per-ex loss: 0.431752  [   82/   89]
per-ex loss: 0.408429  [   84/   89]
per-ex loss: 0.419952  [   86/   89]
per-ex loss: 0.304496  [   88/   89]
per-ex loss: 0.408631  [   89/   89]
Train Error: Avg loss: 0.49997968
validation Error: 
 Avg loss: 0.59523748 
 F1: 0.520216 
 Precision: 0.629781 
 Recall: 0.443125
 IoU: 0.351549

test Error: 
 Avg loss: 0.57261652 
 F1: 0.548407 
 Precision: 0.618316 
 Recall: 0.492701
 IoU: 0.377797

We have finished training iteration 196
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_194_.pth
per-ex loss: 0.416336  [    2/   89]
per-ex loss: 0.460813  [    4/   89]
per-ex loss: 0.430940  [    6/   89]
per-ex loss: 0.532102  [    8/   89]
per-ex loss: 0.392784  [   10/   89]
per-ex loss: 0.326693  [   12/   89]
per-ex loss: 0.449444  [   14/   89]
per-ex loss: 0.356756  [   16/   89]
per-ex loss: 0.403914  [   18/   89]
per-ex loss: 0.603951  [   20/   89]
per-ex loss: 0.472872  [   22/   89]
per-ex loss: 0.597232  [   24/   89]
per-ex loss: 0.544927  [   26/   89]
per-ex loss: 0.296430  [   28/   89]
per-ex loss: 0.452109  [   30/   89]
per-ex loss: 0.585678  [   32/   89]
per-ex loss: 0.694905  [   34/   89]
per-ex loss: 0.755264  [   36/   89]
per-ex loss: 0.399991  [   38/   89]
per-ex loss: 0.511347  [   40/   89]
per-ex loss: 0.438117  [   42/   89]
per-ex loss: 0.522081  [   44/   89]
per-ex loss: 0.422417  [   46/   89]
per-ex loss: 0.645342  [   48/   89]
per-ex loss: 0.452666  [   50/   89]
per-ex loss: 0.445807  [   52/   89]
per-ex loss: 0.636548  [   54/   89]
per-ex loss: 0.553223  [   56/   89]
per-ex loss: 0.555367  [   58/   89]
per-ex loss: 0.429628  [   60/   89]
per-ex loss: 0.544959  [   62/   89]
per-ex loss: 0.524346  [   64/   89]
per-ex loss: 0.443326  [   66/   89]
per-ex loss: 0.620091  [   68/   89]
per-ex loss: 0.730732  [   70/   89]
per-ex loss: 0.496018  [   72/   89]
per-ex loss: 0.541491  [   74/   89]
per-ex loss: 0.396812  [   76/   89]
per-ex loss: 0.578990  [   78/   89]
per-ex loss: 0.480308  [   80/   89]
per-ex loss: 0.502254  [   82/   89]
per-ex loss: 0.457088  [   84/   89]
per-ex loss: 0.525533  [   86/   89]
per-ex loss: 0.516047  [   88/   89]
per-ex loss: 0.618533  [   89/   89]
Train Error: Avg loss: 0.50582692
validation Error: 
 Avg loss: 0.60810983 
 F1: 0.523082 
 Precision: 0.597778 
 Recall: 0.464979
 IoU: 0.354171

test Error: 
 Avg loss: 0.58826052 
 F1: 0.540592 
 Precision: 0.591130 
 Recall: 0.498015
 IoU: 0.370419

We have finished training iteration 197
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_195_.pth
per-ex loss: 0.514397  [    2/   89]
per-ex loss: 0.396971  [    4/   89]
per-ex loss: 0.559700  [    6/   89]
per-ex loss: 0.511572  [    8/   89]
per-ex loss: 0.336555  [   10/   89]
per-ex loss: 0.457696  [   12/   89]
per-ex loss: 0.391218  [   14/   89]
per-ex loss: 0.494193  [   16/   89]
per-ex loss: 0.521838  [   18/   89]
per-ex loss: 0.668094  [   20/   89]
per-ex loss: 0.508397  [   22/   89]
per-ex loss: 0.593236  [   24/   89]
per-ex loss: 0.619460  [   26/   89]
per-ex loss: 0.598566  [   28/   89]
per-ex loss: 0.714267  [   30/   89]
per-ex loss: 0.471620  [   32/   89]
per-ex loss: 0.519521  [   34/   89]
per-ex loss: 0.472526  [   36/   89]
per-ex loss: 0.498054  [   38/   89]
per-ex loss: 0.429259  [   40/   89]
per-ex loss: 0.456953  [   42/   89]
per-ex loss: 0.463739  [   44/   89]
per-ex loss: 0.455302  [   46/   89]
per-ex loss: 0.523219  [   48/   89]
per-ex loss: 0.415940  [   50/   89]
per-ex loss: 0.440077  [   52/   89]
per-ex loss: 0.627128  [   54/   89]
per-ex loss: 0.463215  [   56/   89]
per-ex loss: 0.491514  [   58/   89]
per-ex loss: 0.420917  [   60/   89]
per-ex loss: 0.533106  [   62/   89]
per-ex loss: 0.576079  [   64/   89]
per-ex loss: 0.564200  [   66/   89]
per-ex loss: 0.559904  [   68/   89]
per-ex loss: 0.425972  [   70/   89]
per-ex loss: 0.340819  [   72/   89]
per-ex loss: 0.479370  [   74/   89]
per-ex loss: 0.601295  [   76/   89]
per-ex loss: 0.463835  [   78/   89]
per-ex loss: 0.422087  [   80/   89]
per-ex loss: 0.422071  [   82/   89]
per-ex loss: 0.425886  [   84/   89]
per-ex loss: 0.408423  [   86/   89]
per-ex loss: 0.581924  [   88/   89]
per-ex loss: 0.776946  [   89/   89]
Train Error: Avg loss: 0.50260146
validation Error: 
 Avg loss: 0.58911929 
 F1: 0.505813 
 Precision: 0.719802 
 Recall: 0.389900
 IoU: 0.338521

test Error: 
 Avg loss: 0.58315605 
 F1: 0.522835 
 Precision: 0.702920 
 Recall: 0.416206
 IoU: 0.353945

We have finished training iteration 198
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_196_.pth
per-ex loss: 0.496642  [    2/   89]
per-ex loss: 0.425434  [    4/   89]
per-ex loss: 0.522844  [    6/   89]
per-ex loss: 0.400131  [    8/   89]
per-ex loss: 0.426872  [   10/   89]
per-ex loss: 0.511416  [   12/   89]
per-ex loss: 0.387883  [   14/   89]
per-ex loss: 0.462354  [   16/   89]
per-ex loss: 0.471566  [   18/   89]
per-ex loss: 0.468717  [   20/   89]
per-ex loss: 0.576707  [   22/   89]
per-ex loss: 0.419432  [   24/   89]
per-ex loss: 0.429520  [   26/   89]
per-ex loss: 0.667193  [   28/   89]
per-ex loss: 0.511571  [   30/   89]
per-ex loss: 0.582180  [   32/   89]
per-ex loss: 0.407868  [   34/   89]
per-ex loss: 0.469929  [   36/   89]
per-ex loss: 0.627643  [   38/   89]
per-ex loss: 0.381835  [   40/   89]
per-ex loss: 0.667684  [   42/   89]
per-ex loss: 0.451155  [   44/   89]
per-ex loss: 0.567759  [   46/   89]
per-ex loss: 0.668957  [   48/   89]
per-ex loss: 0.452340  [   50/   89]
per-ex loss: 0.564960  [   52/   89]
per-ex loss: 0.346901  [   54/   89]
per-ex loss: 0.461282  [   56/   89]
per-ex loss: 0.469366  [   58/   89]
per-ex loss: 0.543930  [   60/   89]
per-ex loss: 0.508459  [   62/   89]
per-ex loss: 0.451538  [   64/   89]
per-ex loss: 0.651373  [   66/   89]
per-ex loss: 0.513421  [   68/   89]
per-ex loss: 0.604933  [   70/   89]
per-ex loss: 0.392577  [   72/   89]
per-ex loss: 0.553871  [   74/   89]
per-ex loss: 0.478271  [   76/   89]
per-ex loss: 0.466095  [   78/   89]
per-ex loss: 0.535629  [   80/   89]
per-ex loss: 0.725401  [   82/   89]
per-ex loss: 0.451200  [   84/   89]
per-ex loss: 0.519049  [   86/   89]
per-ex loss: 0.583648  [   88/   89]
per-ex loss: 0.585547  [   89/   89]
Train Error: Avg loss: 0.50806848
validation Error: 
 Avg loss: 0.59806001 
 F1: 0.519600 
 Precision: 0.653807 
 Recall: 0.431106
 IoU: 0.350986

test Error: 
 Avg loss: 0.56774576 
 F1: 0.546492 
 Precision: 0.654350 
 Recall: 0.469159
 IoU: 0.375981

We have finished training iteration 199
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_197_.pth
per-ex loss: 0.517006  [    2/   89]
per-ex loss: 0.495175  [    4/   89]
per-ex loss: 0.400067  [    6/   89]
per-ex loss: 0.430912  [    8/   89]
per-ex loss: 0.527370  [   10/   89]
per-ex loss: 0.453434  [   12/   89]
per-ex loss: 0.408775  [   14/   89]
per-ex loss: 0.612390  [   16/   89]
per-ex loss: 0.345433  [   18/   89]
per-ex loss: 0.554443  [   20/   89]
per-ex loss: 0.597050  [   22/   89]
per-ex loss: 0.533526  [   24/   89]
per-ex loss: 0.630497  [   26/   89]
per-ex loss: 0.408452  [   28/   89]
per-ex loss: 0.618552  [   30/   89]
per-ex loss: 0.625097  [   32/   89]
per-ex loss: 0.753258  [   34/   89]
per-ex loss: 0.356699  [   36/   89]
per-ex loss: 0.416963  [   38/   89]
per-ex loss: 0.483690  [   40/   89]
per-ex loss: 0.424861  [   42/   89]
per-ex loss: 0.388012  [   44/   89]
per-ex loss: 0.587394  [   46/   89]
per-ex loss: 0.422506  [   48/   89]
per-ex loss: 0.618429  [   50/   89]
per-ex loss: 0.463218  [   52/   89]
per-ex loss: 0.363865  [   54/   89]
per-ex loss: 0.375213  [   56/   89]
per-ex loss: 0.480622  [   58/   89]
per-ex loss: 0.705922  [   60/   89]
per-ex loss: 0.377597  [   62/   89]
per-ex loss: 0.398893  [   64/   89]
per-ex loss: 0.463034  [   66/   89]
per-ex loss: 0.510695  [   68/   89]
per-ex loss: 0.435484  [   70/   89]
per-ex loss: 0.541167  [   72/   89]
per-ex loss: 0.517118  [   74/   89]
per-ex loss: 0.458267  [   76/   89]
per-ex loss: 0.612372  [   78/   89]
per-ex loss: 0.445453  [   80/   89]
per-ex loss: 0.644119  [   82/   89]
per-ex loss: 0.418176  [   84/   89]
per-ex loss: 0.410870  [   86/   89]
per-ex loss: 0.418866  [   88/   89]
per-ex loss: 0.639415  [   89/   89]
Train Error: Avg loss: 0.49534134
validation Error: 
 Avg loss: 0.60209674 
 F1: 0.524242 
 Precision: 0.578149 
 Recall: 0.479530
 IoU: 0.355236

test Error: 
 Avg loss: 0.57385276 
 F1: 0.546101 
 Precision: 0.574070 
 Recall: 0.520732
 IoU: 0.375612

We have finished training iteration 200
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_198_.pth
per-ex loss: 0.447457  [    2/   89]
per-ex loss: 0.547096  [    4/   89]
per-ex loss: 0.400672  [    6/   89]
per-ex loss: 0.349314  [    8/   89]
per-ex loss: 0.350013  [   10/   89]
per-ex loss: 0.424365  [   12/   89]
per-ex loss: 0.395179  [   14/   89]
per-ex loss: 0.443516  [   16/   89]
per-ex loss: 0.690928  [   18/   89]
per-ex loss: 0.521163  [   20/   89]
per-ex loss: 0.611101  [   22/   89]
per-ex loss: 0.396998  [   24/   89]
per-ex loss: 0.432782  [   26/   89]
per-ex loss: 0.433170  [   28/   89]
per-ex loss: 0.451496  [   30/   89]
per-ex loss: 0.465965  [   32/   89]
per-ex loss: 0.592166  [   34/   89]
per-ex loss: 0.428139  [   36/   89]
per-ex loss: 0.465758  [   38/   89]
per-ex loss: 0.433110  [   40/   89]
per-ex loss: 0.429732  [   42/   89]
per-ex loss: 0.373646  [   44/   89]
per-ex loss: 0.647770  [   46/   89]
per-ex loss: 0.645416  [   48/   89]
per-ex loss: 0.398981  [   50/   89]
per-ex loss: 0.474931  [   52/   89]
per-ex loss: 0.611672  [   54/   89]
per-ex loss: 0.504476  [   56/   89]
per-ex loss: 0.698921  [   58/   89]
per-ex loss: 0.634247  [   60/   89]
per-ex loss: 0.459597  [   62/   89]
per-ex loss: 0.430584  [   64/   89]
per-ex loss: 0.440617  [   66/   89]
per-ex loss: 0.388329  [   68/   89]
per-ex loss: 0.691936  [   70/   89]
per-ex loss: 0.363617  [   72/   89]
per-ex loss: 0.458147  [   74/   89]
per-ex loss: 0.510736  [   76/   89]
per-ex loss: 0.612974  [   78/   89]
per-ex loss: 0.516792  [   80/   89]
per-ex loss: 0.638976  [   82/   89]
per-ex loss: 0.451868  [   84/   89]
per-ex loss: 0.575275  [   86/   89]
per-ex loss: 0.538772  [   88/   89]
per-ex loss: 0.466525  [   89/   89]
Train Error: Avg loss: 0.49433166
validation Error: 
 Avg loss: 0.60369510 
 F1: 0.485614 
 Precision: 0.733477 
 Recall: 0.362960
 IoU: 0.320668

test Error: 
 Avg loss: 0.58700431 
 F1: 0.513233 
 Precision: 0.723858 
 Recall: 0.397554
 IoU: 0.345201

We have finished training iteration 201
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_199_.pth
per-ex loss: 0.449584  [    2/   89]
per-ex loss: 0.424545  [    4/   89]
per-ex loss: 0.388843  [    6/   89]
per-ex loss: 0.401605  [    8/   89]
per-ex loss: 0.493472  [   10/   89]
per-ex loss: 0.639327  [   12/   89]
per-ex loss: 0.469790  [   14/   89]
per-ex loss: 0.399674  [   16/   89]
per-ex loss: 0.398484  [   18/   89]
per-ex loss: 0.512366  [   20/   89]
per-ex loss: 0.447028  [   22/   89]
per-ex loss: 0.529778  [   24/   89]
per-ex loss: 0.433870  [   26/   89]
per-ex loss: 0.550995  [   28/   89]
per-ex loss: 0.637675  [   30/   89]
per-ex loss: 0.579849  [   32/   89]
per-ex loss: 0.673602  [   34/   89]
per-ex loss: 0.393381  [   36/   89]
per-ex loss: 0.781390  [   38/   89]
per-ex loss: 0.510289  [   40/   89]
per-ex loss: 0.484311  [   42/   89]
per-ex loss: 0.624328  [   44/   89]
per-ex loss: 0.505793  [   46/   89]
per-ex loss: 0.522025  [   48/   89]
per-ex loss: 0.464468  [   50/   89]
per-ex loss: 0.621178  [   52/   89]
per-ex loss: 0.610663  [   54/   89]
per-ex loss: 0.471485  [   56/   89]
per-ex loss: 0.412479  [   58/   89]
per-ex loss: 0.488951  [   60/   89]
per-ex loss: 0.434396  [   62/   89]
per-ex loss: 0.487228  [   64/   89]
per-ex loss: 0.381928  [   66/   89]
per-ex loss: 0.396662  [   68/   89]
per-ex loss: 0.308138  [   70/   89]
per-ex loss: 0.429592  [   72/   89]
per-ex loss: 0.493785  [   74/   89]
per-ex loss: 0.423826  [   76/   89]
per-ex loss: 0.363159  [   78/   89]
per-ex loss: 0.608437  [   80/   89]
per-ex loss: 0.628952  [   82/   89]
per-ex loss: 0.486632  [   84/   89]
per-ex loss: 0.429593  [   86/   89]
per-ex loss: 0.575359  [   88/   89]
per-ex loss: 0.516846  [   89/   89]
Train Error: Avg loss: 0.49523911
validation Error: 
 Avg loss: 0.59872475 
 F1: 0.522306 
 Precision: 0.606939 
 Recall: 0.458387
 IoU: 0.353460

test Error: 
 Avg loss: 0.57968419 
 F1: 0.539749 
 Precision: 0.602091 
 Recall: 0.489105
 IoU: 0.369627

We have finished training iteration 202
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_200_.pth
per-ex loss: 0.641329  [    2/   89]
per-ex loss: 0.351159  [    4/   89]
per-ex loss: 0.469575  [    6/   89]
per-ex loss: 0.422690  [    8/   89]
per-ex loss: 0.587827  [   10/   89]
per-ex loss: 0.547996  [   12/   89]
per-ex loss: 0.618717  [   14/   89]
per-ex loss: 0.433659  [   16/   89]
per-ex loss: 0.575947  [   18/   89]
per-ex loss: 0.427101  [   20/   89]
per-ex loss: 0.540356  [   22/   89]
per-ex loss: 0.438150  [   24/   89]
per-ex loss: 0.391714  [   26/   89]
per-ex loss: 0.492260  [   28/   89]
per-ex loss: 0.500789  [   30/   89]
per-ex loss: 0.643908  [   32/   89]
per-ex loss: 0.610244  [   34/   89]
per-ex loss: 0.587939  [   36/   89]
per-ex loss: 0.467370  [   38/   89]
per-ex loss: 0.468373  [   40/   89]
per-ex loss: 0.479182  [   42/   89]
per-ex loss: 0.568188  [   44/   89]
per-ex loss: 0.501345  [   46/   89]
per-ex loss: 0.504007  [   48/   89]
per-ex loss: 0.411765  [   50/   89]
per-ex loss: 0.405581  [   52/   89]
per-ex loss: 0.488040  [   54/   89]
per-ex loss: 0.354819  [   56/   89]
per-ex loss: 0.363690  [   58/   89]
per-ex loss: 0.427739  [   60/   89]
per-ex loss: 0.508321  [   62/   89]
per-ex loss: 0.473129  [   64/   89]
per-ex loss: 0.499315  [   66/   89]
per-ex loss: 0.536496  [   68/   89]
per-ex loss: 0.388650  [   70/   89]
per-ex loss: 0.314887  [   72/   89]
per-ex loss: 0.499610  [   74/   89]
per-ex loss: 0.626418  [   76/   89]
per-ex loss: 0.473788  [   78/   89]
per-ex loss: 0.436656  [   80/   89]
per-ex loss: 0.362695  [   82/   89]
per-ex loss: 0.543159  [   84/   89]
per-ex loss: 0.504956  [   86/   89]
per-ex loss: 0.370445  [   88/   89]
per-ex loss: 0.383527  [   89/   89]
Train Error: Avg loss: 0.48096686
validation Error: 
 Avg loss: 0.59946570 
 F1: 0.522227 
 Precision: 0.580624 
 Recall: 0.474502
 IoU: 0.353387

test Error: 
 Avg loss: 0.57650555 
 F1: 0.543722 
 Precision: 0.599625 
 Recall: 0.497355
 IoU: 0.373365

We have finished training iteration 203
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_201_.pth
per-ex loss: 0.486650  [    2/   89]
per-ex loss: 0.547537  [    4/   89]
per-ex loss: 0.553824  [    6/   89]
per-ex loss: 0.790333  [    8/   89]
per-ex loss: 0.598983  [   10/   89]
per-ex loss: 0.606995  [   12/   89]
per-ex loss: 0.555687  [   14/   89]
per-ex loss: 0.586561  [   16/   89]
per-ex loss: 0.521648  [   18/   89]
per-ex loss: 0.533835  [   20/   89]
per-ex loss: 0.465465  [   22/   89]
per-ex loss: 0.551394  [   24/   89]
per-ex loss: 0.628200  [   26/   89]
per-ex loss: 0.576813  [   28/   89]
per-ex loss: 0.462222  [   30/   89]
per-ex loss: 0.394268  [   32/   89]
per-ex loss: 0.387163  [   34/   89]
per-ex loss: 0.457793  [   36/   89]
per-ex loss: 0.636899  [   38/   89]
per-ex loss: 0.387873  [   40/   89]
per-ex loss: 0.486577  [   42/   89]
per-ex loss: 0.413039  [   44/   89]
per-ex loss: 0.592489  [   46/   89]
per-ex loss: 0.560205  [   48/   89]
per-ex loss: 0.461265  [   50/   89]
per-ex loss: 0.484569  [   52/   89]
per-ex loss: 0.379300  [   54/   89]
per-ex loss: 0.640962  [   56/   89]
per-ex loss: 0.597558  [   58/   89]
per-ex loss: 0.395161  [   60/   89]
per-ex loss: 0.383332  [   62/   89]
per-ex loss: 0.412926  [   64/   89]
per-ex loss: 0.542367  [   66/   89]
per-ex loss: 0.551700  [   68/   89]
per-ex loss: 0.484150  [   70/   89]
per-ex loss: 0.413045  [   72/   89]
per-ex loss: 0.371026  [   74/   89]
per-ex loss: 0.377491  [   76/   89]
per-ex loss: 0.503836  [   78/   89]
per-ex loss: 0.468537  [   80/   89]
per-ex loss: 0.482513  [   82/   89]
per-ex loss: 0.458799  [   84/   89]
per-ex loss: 0.401998  [   86/   89]
per-ex loss: 0.726414  [   88/   89]
per-ex loss: 0.424002  [   89/   89]
Train Error: Avg loss: 0.50540894
validation Error: 
 Avg loss: 0.59224499 
 F1: 0.522255 
 Precision: 0.553465 
 Recall: 0.494377
 IoU: 0.353413

test Error: 
 Avg loss: 0.58441987 
 F1: 0.533824 
 Precision: 0.546902 
 Recall: 0.521356
 IoU: 0.364092

We have finished training iteration 204
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_202_.pth
per-ex loss: 0.414899  [    2/   89]
per-ex loss: 0.569187  [    4/   89]
per-ex loss: 0.296470  [    6/   89]
per-ex loss: 0.497134  [    8/   89]
per-ex loss: 0.609314  [   10/   89]
per-ex loss: 0.483085  [   12/   89]
per-ex loss: 0.457782  [   14/   89]
per-ex loss: 0.397415  [   16/   89]
per-ex loss: 0.486004  [   18/   89]
per-ex loss: 0.773110  [   20/   89]
per-ex loss: 0.527982  [   22/   89]
per-ex loss: 0.403124  [   24/   89]
per-ex loss: 0.571561  [   26/   89]
per-ex loss: 0.478893  [   28/   89]
per-ex loss: 0.529894  [   30/   89]
per-ex loss: 0.528218  [   32/   89]
per-ex loss: 0.510561  [   34/   89]
per-ex loss: 0.668566  [   36/   89]
per-ex loss: 0.373902  [   38/   89]
per-ex loss: 0.620816  [   40/   89]
per-ex loss: 0.370947  [   42/   89]
per-ex loss: 0.445431  [   44/   89]
per-ex loss: 0.442249  [   46/   89]
per-ex loss: 0.557814  [   48/   89]
per-ex loss: 0.496495  [   50/   89]
per-ex loss: 0.677228  [   52/   89]
per-ex loss: 0.662537  [   54/   89]
per-ex loss: 0.549197  [   56/   89]
per-ex loss: 0.429028  [   58/   89]
per-ex loss: 0.513032  [   60/   89]
per-ex loss: 0.633811  [   62/   89]
per-ex loss: 0.408372  [   64/   89]
per-ex loss: 0.464208  [   66/   89]
per-ex loss: 0.391203  [   68/   89]
per-ex loss: 0.375932  [   70/   89]
per-ex loss: 0.425763  [   72/   89]
per-ex loss: 0.383968  [   74/   89]
per-ex loss: 0.426134  [   76/   89]
per-ex loss: 0.547151  [   78/   89]
per-ex loss: 0.464548  [   80/   89]
per-ex loss: 0.378848  [   82/   89]
per-ex loss: 0.400878  [   84/   89]
per-ex loss: 0.401297  [   86/   89]
per-ex loss: 0.579691  [   88/   89]
per-ex loss: 0.622213  [   89/   89]
Train Error: Avg loss: 0.49435318
validation Error: 
 Avg loss: 0.58954491 
 F1: 0.524576 
 Precision: 0.657716 
 Recall: 0.436264
 IoU: 0.355543

test Error: 
 Avg loss: 0.56778403 
 F1: 0.539647 
 Precision: 0.647945 
 Recall: 0.462366
 IoU: 0.369532

We have finished training iteration 205
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_203_.pth
per-ex loss: 0.546856  [    2/   89]
per-ex loss: 0.337383  [    4/   89]
per-ex loss: 0.364571  [    6/   89]
per-ex loss: 0.409263  [    8/   89]
per-ex loss: 0.532450  [   10/   89]
per-ex loss: 0.512538  [   12/   89]
per-ex loss: 0.567765  [   14/   89]
per-ex loss: 0.386625  [   16/   89]
per-ex loss: 0.393532  [   18/   89]
per-ex loss: 0.420197  [   20/   89]
per-ex loss: 0.483168  [   22/   89]
per-ex loss: 0.536116  [   24/   89]
per-ex loss: 0.486479  [   26/   89]
per-ex loss: 0.628699  [   28/   89]
per-ex loss: 0.563247  [   30/   89]
per-ex loss: 0.421363  [   32/   89]
per-ex loss: 0.383138  [   34/   89]
per-ex loss: 0.385531  [   36/   89]
per-ex loss: 0.600081  [   38/   89]
per-ex loss: 0.490999  [   40/   89]
per-ex loss: 0.544942  [   42/   89]
per-ex loss: 0.421490  [   44/   89]
per-ex loss: 0.515062  [   46/   89]
per-ex loss: 0.426891  [   48/   89]
per-ex loss: 0.536170  [   50/   89]
per-ex loss: 0.370674  [   52/   89]
per-ex loss: 0.665751  [   54/   89]
per-ex loss: 0.430107  [   56/   89]
per-ex loss: 0.561564  [   58/   89]
per-ex loss: 0.423426  [   60/   89]
per-ex loss: 0.451565  [   62/   89]
per-ex loss: 0.490440  [   64/   89]
per-ex loss: 0.403232  [   66/   89]
per-ex loss: 0.627992  [   68/   89]
per-ex loss: 0.517348  [   70/   89]
per-ex loss: 0.422317  [   72/   89]
per-ex loss: 0.343328  [   74/   89]
per-ex loss: 0.496138  [   76/   89]
per-ex loss: 0.687729  [   78/   89]
per-ex loss: 0.400765  [   80/   89]
per-ex loss: 0.649428  [   82/   89]
per-ex loss: 0.418544  [   84/   89]
per-ex loss: 0.438958  [   86/   89]
per-ex loss: 0.706232  [   88/   89]
per-ex loss: 0.552725  [   89/   89]
Train Error: Avg loss: 0.48784033
validation Error: 
 Avg loss: 0.57845034 
 F1: 0.509172 
 Precision: 0.663193 
 Recall: 0.413207
 IoU: 0.341536

test Error: 
 Avg loss: 0.56772832 
 F1: 0.535720 
 Precision: 0.680561 
 Recall: 0.441711
 IoU: 0.365859

We have finished training iteration 206
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_204_.pth
per-ex loss: 0.614107  [    2/   89]
per-ex loss: 0.637900  [    4/   89]
per-ex loss: 0.414105  [    6/   89]
per-ex loss: 0.437719  [    8/   89]
per-ex loss: 0.413414  [   10/   89]
per-ex loss: 0.459456  [   12/   89]
per-ex loss: 0.415242  [   14/   89]
per-ex loss: 0.405260  [   16/   89]
per-ex loss: 0.614903  [   18/   89]
per-ex loss: 0.472564  [   20/   89]
per-ex loss: 0.492895  [   22/   89]
per-ex loss: 0.454888  [   24/   89]
per-ex loss: 0.405302  [   26/   89]
per-ex loss: 0.529295  [   28/   89]
per-ex loss: 0.463547  [   30/   89]
per-ex loss: 0.666950  [   32/   89]
per-ex loss: 0.417273  [   34/   89]
per-ex loss: 0.738673  [   36/   89]
per-ex loss: 0.426664  [   38/   89]
per-ex loss: 0.695524  [   40/   89]
per-ex loss: 0.451599  [   42/   89]
per-ex loss: 0.474790  [   44/   89]
per-ex loss: 0.432332  [   46/   89]
per-ex loss: 0.400702  [   48/   89]
per-ex loss: 0.384151  [   50/   89]
per-ex loss: 0.564284  [   52/   89]
per-ex loss: 0.520928  [   54/   89]
per-ex loss: 0.668544  [   56/   89]
per-ex loss: 0.582364  [   58/   89]
per-ex loss: 0.409657  [   60/   89]
per-ex loss: 0.385107  [   62/   89]
per-ex loss: 0.427777  [   64/   89]
per-ex loss: 0.481701  [   66/   89]
per-ex loss: 0.544523  [   68/   89]
per-ex loss: 0.528930  [   70/   89]
per-ex loss: 0.475247  [   72/   89]
per-ex loss: 0.428042  [   74/   89]
per-ex loss: 0.479954  [   76/   89]
per-ex loss: 0.497018  [   78/   89]
per-ex loss: 0.377907  [   80/   89]
per-ex loss: 0.504088  [   82/   89]
per-ex loss: 0.485694  [   84/   89]
per-ex loss: 0.294329  [   86/   89]
per-ex loss: 0.503396  [   88/   89]
per-ex loss: 0.584737  [   89/   89]
Train Error: Avg loss: 0.49029959
validation Error: 
 Avg loss: 0.59172875 
 F1: 0.519477 
 Precision: 0.638518 
 Recall: 0.437848
 IoU: 0.350874

test Error: 
 Avg loss: 0.57126718 
 F1: 0.536153 
 Precision: 0.634672 
 Recall: 0.464110
 IoU: 0.366263

We have finished training iteration 207
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_205_.pth
per-ex loss: 0.432368  [    2/   89]
per-ex loss: 0.621175  [    4/   89]
per-ex loss: 0.370845  [    6/   89]
per-ex loss: 0.543526  [    8/   89]
per-ex loss: 0.382952  [   10/   89]
per-ex loss: 0.456055  [   12/   89]
per-ex loss: 0.446147  [   14/   89]
per-ex loss: 0.670956  [   16/   89]
per-ex loss: 0.585558  [   18/   89]
per-ex loss: 0.364743  [   20/   89]
per-ex loss: 0.538018  [   22/   89]
per-ex loss: 0.372192  [   24/   89]
per-ex loss: 0.505606  [   26/   89]
per-ex loss: 0.425382  [   28/   89]
per-ex loss: 0.422975  [   30/   89]
per-ex loss: 0.429252  [   32/   89]
per-ex loss: 0.456574  [   34/   89]
per-ex loss: 0.536822  [   36/   89]
per-ex loss: 0.403045  [   38/   89]
per-ex loss: 0.411041  [   40/   89]
per-ex loss: 0.377374  [   42/   89]
per-ex loss: 0.589724  [   44/   89]
per-ex loss: 0.432171  [   46/   89]
per-ex loss: 0.468622  [   48/   89]
per-ex loss: 0.565786  [   50/   89]
per-ex loss: 0.410428  [   52/   89]
per-ex loss: 0.541806  [   54/   89]
per-ex loss: 0.504110  [   56/   89]
per-ex loss: 0.416445  [   58/   89]
per-ex loss: 0.389683  [   60/   89]
per-ex loss: 0.470078  [   62/   89]
per-ex loss: 0.585160  [   64/   89]
per-ex loss: 0.676567  [   66/   89]
per-ex loss: 0.370522  [   68/   89]
per-ex loss: 0.650662  [   70/   89]
per-ex loss: 0.441597  [   72/   89]
per-ex loss: 0.527645  [   74/   89]
per-ex loss: 0.649648  [   76/   89]
per-ex loss: 0.383674  [   78/   89]
per-ex loss: 0.512452  [   80/   89]
per-ex loss: 0.355923  [   82/   89]
per-ex loss: 0.480233  [   84/   89]
per-ex loss: 0.432039  [   86/   89]
per-ex loss: 0.429931  [   88/   89]
per-ex loss: 0.560252  [   89/   89]
Train Error: Avg loss: 0.47995033
validation Error: 
 Avg loss: 0.58549275 
 F1: 0.525043 
 Precision: 0.560816 
 Recall: 0.493560
 IoU: 0.355971

test Error: 
 Avg loss: 0.58512641 
 F1: 0.527091 
 Precision: 0.503666 
 Recall: 0.552802
 IoU: 0.357857

We have finished training iteration 208
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_206_.pth
per-ex loss: 0.403873  [    2/   89]
per-ex loss: 0.570533  [    4/   89]
per-ex loss: 0.382792  [    6/   89]
per-ex loss: 0.418782  [    8/   89]
per-ex loss: 0.537818  [   10/   89]
per-ex loss: 0.337693  [   12/   89]
per-ex loss: 0.499186  [   14/   89]
per-ex loss: 0.485378  [   16/   89]
per-ex loss: 0.430461  [   18/   89]
per-ex loss: 0.523528  [   20/   89]
per-ex loss: 0.748653  [   22/   89]
per-ex loss: 0.418373  [   24/   89]
per-ex loss: 0.533833  [   26/   89]
per-ex loss: 0.563490  [   28/   89]
per-ex loss: 0.617677  [   30/   89]
per-ex loss: 0.395798  [   32/   89]
per-ex loss: 0.576348  [   34/   89]
per-ex loss: 0.285802  [   36/   89]
per-ex loss: 0.489815  [   38/   89]
per-ex loss: 0.647408  [   40/   89]
per-ex loss: 0.367674  [   42/   89]
per-ex loss: 0.603922  [   44/   89]
per-ex loss: 0.419949  [   46/   89]
per-ex loss: 0.478437  [   48/   89]
per-ex loss: 0.354728  [   50/   89]
per-ex loss: 0.403000  [   52/   89]
per-ex loss: 0.371362  [   54/   89]
per-ex loss: 0.462814  [   56/   89]
per-ex loss: 0.443256  [   58/   89]
per-ex loss: 0.460437  [   60/   89]
per-ex loss: 0.411552  [   62/   89]
per-ex loss: 0.523593  [   64/   89]
per-ex loss: 0.586601  [   66/   89]
per-ex loss: 0.633651  [   68/   89]
per-ex loss: 0.501428  [   70/   89]
per-ex loss: 0.380823  [   72/   89]
per-ex loss: 0.495142  [   74/   89]
per-ex loss: 0.455759  [   76/   89]
per-ex loss: 0.643105  [   78/   89]
per-ex loss: 0.573096  [   80/   89]
per-ex loss: 0.581509  [   82/   89]
per-ex loss: 0.544567  [   84/   89]
per-ex loss: 0.504806  [   86/   89]
per-ex loss: 0.563963  [   88/   89]
per-ex loss: 0.431680  [   89/   89]
Train Error: Avg loss: 0.49031321
validation Error: 
 Avg loss: 0.58743118 
 F1: 0.529694 
 Precision: 0.612747 
 Recall: 0.466467
 IoU: 0.360261

test Error: 
 Avg loss: 0.55588255 
 F1: 0.555914 
 Precision: 0.615391 
 Recall: 0.506920
 IoU: 0.384959

We have finished training iteration 209
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_207_.pth
per-ex loss: 0.369238  [    2/   89]
per-ex loss: 0.413604  [    4/   89]
per-ex loss: 0.541737  [    6/   89]
per-ex loss: 0.559494  [    8/   89]
per-ex loss: 0.469271  [   10/   89]
per-ex loss: 0.404031  [   12/   89]
per-ex loss: 0.497110  [   14/   89]
per-ex loss: 0.441182  [   16/   89]
per-ex loss: 0.444363  [   18/   89]
per-ex loss: 0.625412  [   20/   89]
per-ex loss: 0.608121  [   22/   89]
per-ex loss: 0.541046  [   24/   89]
per-ex loss: 0.611543  [   26/   89]
per-ex loss: 0.386543  [   28/   89]
per-ex loss: 0.569450  [   30/   89]
per-ex loss: 0.450611  [   32/   89]
per-ex loss: 0.524077  [   34/   89]
per-ex loss: 0.491524  [   36/   89]
per-ex loss: 0.376635  [   38/   89]
per-ex loss: 0.565664  [   40/   89]
per-ex loss: 0.415072  [   42/   89]
per-ex loss: 0.444892  [   44/   89]
per-ex loss: 0.480133  [   46/   89]
per-ex loss: 0.427107  [   48/   89]
per-ex loss: 0.555438  [   50/   89]
per-ex loss: 0.432043  [   52/   89]
per-ex loss: 0.435346  [   54/   89]
per-ex loss: 0.457945  [   56/   89]
per-ex loss: 0.581243  [   58/   89]
per-ex loss: 0.353737  [   60/   89]
per-ex loss: 0.535723  [   62/   89]
per-ex loss: 0.405971  [   64/   89]
per-ex loss: 0.356498  [   66/   89]
per-ex loss: 0.539264  [   68/   89]
per-ex loss: 0.438808  [   70/   89]
per-ex loss: 0.479074  [   72/   89]
per-ex loss: 0.408185  [   74/   89]
per-ex loss: 0.663004  [   76/   89]
per-ex loss: 0.360591  [   78/   89]
per-ex loss: 0.460858  [   80/   89]
per-ex loss: 0.525183  [   82/   89]
per-ex loss: 0.491006  [   84/   89]
per-ex loss: 0.466806  [   86/   89]
per-ex loss: 0.513226  [   88/   89]
per-ex loss: 0.476217  [   89/   89]
Train Error: Avg loss: 0.47986726
validation Error: 
 Avg loss: 0.56784531 
 F1: 0.527259 
 Precision: 0.634883 
 Recall: 0.450835
 IoU: 0.358012

test Error: 
 Avg loss: 0.55885568 
 F1: 0.548450 
 Precision: 0.604701 
 Recall: 0.501774
 IoU: 0.377838

We have finished training iteration 210
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_208_.pth
per-ex loss: 0.514784  [    2/   89]
per-ex loss: 0.410222  [    4/   89]
per-ex loss: 0.617892  [    6/   89]
per-ex loss: 0.528568  [    8/   89]
per-ex loss: 0.786774  [   10/   89]
per-ex loss: 0.466727  [   12/   89]
per-ex loss: 0.615878  [   14/   89]
per-ex loss: 0.430998  [   16/   89]
per-ex loss: 0.491312  [   18/   89]
per-ex loss: 0.410584  [   20/   89]
per-ex loss: 0.390004  [   22/   89]
per-ex loss: 0.445518  [   24/   89]
per-ex loss: 0.768232  [   26/   89]
per-ex loss: 0.474221  [   28/   89]
per-ex loss: 0.396929  [   30/   89]
per-ex loss: 0.540507  [   32/   89]
per-ex loss: 0.423586  [   34/   89]
per-ex loss: 0.496328  [   36/   89]
per-ex loss: 0.360086  [   38/   89]
per-ex loss: 0.562368  [   40/   89]
per-ex loss: 0.581623  [   42/   89]
per-ex loss: 0.403084  [   44/   89]
per-ex loss: 0.386036  [   46/   89]
per-ex loss: 0.478115  [   48/   89]
per-ex loss: 0.754353  [   50/   89]
per-ex loss: 0.516806  [   52/   89]
per-ex loss: 0.701347  [   54/   89]
per-ex loss: 0.525671  [   56/   89]
per-ex loss: 0.472043  [   58/   89]
per-ex loss: 0.479995  [   60/   89]
per-ex loss: 0.409474  [   62/   89]
per-ex loss: 0.357719  [   64/   89]
per-ex loss: 0.403529  [   66/   89]
per-ex loss: 0.373262  [   68/   89]
per-ex loss: 0.513992  [   70/   89]
per-ex loss: 0.444305  [   72/   89]
per-ex loss: 0.438953  [   74/   89]
per-ex loss: 0.477032  [   76/   89]
per-ex loss: 0.535398  [   78/   89]
per-ex loss: 0.512236  [   80/   89]
per-ex loss: 0.440915  [   82/   89]
per-ex loss: 0.542218  [   84/   89]
per-ex loss: 0.303161  [   86/   89]
per-ex loss: 0.530183  [   88/   89]
per-ex loss: 0.665806  [   89/   89]
Train Error: Avg loss: 0.49730610
validation Error: 
 Avg loss: 0.58890627 
 F1: 0.504169 
 Precision: 0.662195 
 Recall: 0.407034
 IoU: 0.337050

test Error: 
 Avg loss: 0.56828085 
 F1: 0.523585 
 Precision: 0.682752 
 Recall: 0.424600
 IoU: 0.354632

We have finished training iteration 211
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_209_.pth
Error in cropping the image to the non-zero values in the fourth channel. Returned the original image.
per-ex loss: 0.449685  [    2/   89]
per-ex loss: 0.487951  [    4/   89]
per-ex loss: 0.381893  [    6/   89]
per-ex loss: 0.361529  [    8/   89]
per-ex loss: 0.597025  [   10/   89]
per-ex loss: 0.672621  [   12/   89]
per-ex loss: 0.368420  [   14/   89]
per-ex loss: 0.385206  [   16/   89]
per-ex loss: 0.445316  [   18/   89]
per-ex loss: 0.440014  [   20/   89]
per-ex loss: 0.380059  [   22/   89]
per-ex loss: 0.396177  [   24/   89]
per-ex loss: 0.456335  [   26/   89]
per-ex loss: 0.380687  [   28/   89]
per-ex loss: 0.493432  [   30/   89]
per-ex loss: 0.407965  [   32/   89]
per-ex loss: 0.425520  [   34/   89]
per-ex loss: 0.455581  [   36/   89]
per-ex loss: 0.381998  [   38/   89]
per-ex loss: 0.502636  [   40/   89]
per-ex loss: 0.474515  [   42/   89]
per-ex loss: 0.439222  [   44/   89]
per-ex loss: 0.571813  [   46/   89]
per-ex loss: 0.704874  [   48/   89]
per-ex loss: 0.338735  [   50/   89]
per-ex loss: 0.669362  [   52/   89]
per-ex loss: 0.497598  [   54/   89]
per-ex loss: 0.563034  [   56/   89]
per-ex loss: 0.359454  [   58/   89]
per-ex loss: 0.346597  [   60/   89]
per-ex loss: 0.481255  [   62/   89]
per-ex loss: 0.364667  [   64/   89]
per-ex loss: 0.583502  [   66/   89]
per-ex loss: 0.557767  [   68/   89]
per-ex loss: 0.706458  [   70/   89]
per-ex loss: 0.447487  [   72/   89]
per-ex loss: 0.630247  [   74/   89]
per-ex loss: 0.648461  [   76/   89]
per-ex loss: 0.376661  [   78/   89]
per-ex loss: 0.717215  [   80/   89]
per-ex loss: 0.449723  [   82/   89]
per-ex loss: 0.353582  [   84/   89]
per-ex loss: 0.521521  [   86/   89]
per-ex loss: 0.624447  [   88/   89]
per-ex loss: 0.527290  [   89/   89]
Train Error: Avg loss: 0.48501190
validation Error: 
 Avg loss: 0.57842603 
 F1: 0.518944 
 Precision: 0.687466 
 Recall: 0.416777
 IoU: 0.350388

test Error: 
 Avg loss: 0.55127261 
 F1: 0.550067 
 Precision: 0.685244 
 Recall: 0.459436
 IoU: 0.379375

We have finished training iteration 212
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_210_.pth
per-ex loss: 0.408269  [    2/   89]
per-ex loss: 0.430187  [    4/   89]
per-ex loss: 0.453329  [    6/   89]
per-ex loss: 0.636451  [    8/   89]
per-ex loss: 0.395574  [   10/   89]
per-ex loss: 0.394674  [   12/   89]
per-ex loss: 0.353763  [   14/   89]
per-ex loss: 0.395973  [   16/   89]
per-ex loss: 0.408964  [   18/   89]
per-ex loss: 0.626481  [   20/   89]
per-ex loss: 0.558740  [   22/   89]
per-ex loss: 0.613620  [   24/   89]
per-ex loss: 0.529673  [   26/   89]
per-ex loss: 0.515082  [   28/   89]
per-ex loss: 0.461515  [   30/   89]
per-ex loss: 0.442542  [   32/   89]
per-ex loss: 0.444555  [   34/   89]
per-ex loss: 0.467742  [   36/   89]
per-ex loss: 0.528911  [   38/   89]
per-ex loss: 0.600447  [   40/   89]
per-ex loss: 0.355046  [   42/   89]
per-ex loss: 0.382510  [   44/   89]
per-ex loss: 0.694159  [   46/   89]
per-ex loss: 0.602696  [   48/   89]
per-ex loss: 0.537801  [   50/   89]
per-ex loss: 0.597984  [   52/   89]
per-ex loss: 0.607728  [   54/   89]
per-ex loss: 0.437879  [   56/   89]
per-ex loss: 0.562831  [   58/   89]
per-ex loss: 0.445318  [   60/   89]
per-ex loss: 0.453513  [   62/   89]
per-ex loss: 0.423101  [   64/   89]
per-ex loss: 0.494076  [   66/   89]
per-ex loss: 0.598025  [   68/   89]
per-ex loss: 0.636994  [   70/   89]
per-ex loss: 0.471983  [   72/   89]
per-ex loss: 0.676517  [   74/   89]
per-ex loss: 0.433909  [   76/   89]
per-ex loss: 0.428811  [   78/   89]
per-ex loss: 0.383106  [   80/   89]
per-ex loss: 0.400445  [   82/   89]
per-ex loss: 0.344537  [   84/   89]
per-ex loss: 0.314744  [   86/   89]
per-ex loss: 0.435484  [   88/   89]
per-ex loss: 0.389919  [   89/   89]
Train Error: Avg loss: 0.48390247
validation Error: 
 Avg loss: 0.56419252 
 F1: 0.534899 
 Precision: 0.598314 
 Recall: 0.483638
 IoU: 0.365093

test Error: 
 Avg loss: 0.54930877 
 F1: 0.558162 
 Precision: 0.580995 
 Recall: 0.537056
 IoU: 0.387119

We have finished training iteration 213
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_211_.pth
per-ex loss: 0.350671  [    2/   89]
per-ex loss: 0.378270  [    4/   89]
per-ex loss: 0.362478  [    6/   89]
per-ex loss: 0.396010  [    8/   89]
per-ex loss: 0.677784  [   10/   89]
per-ex loss: 0.497687  [   12/   89]
per-ex loss: 0.640678  [   14/   89]
per-ex loss: 0.360157  [   16/   89]
per-ex loss: 0.634040  [   18/   89]
per-ex loss: 0.632165  [   20/   89]
per-ex loss: 0.352915  [   22/   89]
per-ex loss: 0.473913  [   24/   89]
per-ex loss: 0.586383  [   26/   89]
per-ex loss: 0.445141  [   28/   89]
per-ex loss: 0.564956  [   30/   89]
per-ex loss: 0.712215  [   32/   89]
per-ex loss: 0.609143  [   34/   89]
per-ex loss: 0.403745  [   36/   89]
per-ex loss: 0.377023  [   38/   89]
per-ex loss: 0.547406  [   40/   89]
per-ex loss: 0.444476  [   42/   89]
per-ex loss: 0.424906  [   44/   89]
per-ex loss: 0.377799  [   46/   89]
per-ex loss: 0.388066  [   48/   89]
per-ex loss: 0.455249  [   50/   89]
per-ex loss: 0.414685  [   52/   89]
per-ex loss: 0.564892  [   54/   89]
per-ex loss: 0.457385  [   56/   89]
per-ex loss: 0.395539  [   58/   89]
per-ex loss: 0.368976  [   60/   89]
per-ex loss: 0.569160  [   62/   89]
per-ex loss: 0.447570  [   64/   89]
per-ex loss: 0.461732  [   66/   89]
per-ex loss: 0.668567  [   68/   89]
per-ex loss: 0.418556  [   70/   89]
per-ex loss: 0.631294  [   72/   89]
per-ex loss: 0.447568  [   74/   89]
per-ex loss: 0.438749  [   76/   89]
per-ex loss: 0.334150  [   78/   89]
per-ex loss: 0.659982  [   80/   89]
per-ex loss: 0.619640  [   82/   89]
per-ex loss: 0.522254  [   84/   89]
per-ex loss: 0.385893  [   86/   89]
per-ex loss: 0.484373  [   88/   89]
per-ex loss: 0.418254  [   89/   89]
Train Error: Avg loss: 0.48449982
validation Error: 
 Avg loss: 0.57481741 
 F1: 0.513490 
 Precision: 0.666757 
 Recall: 0.417516
 IoU: 0.345433

test Error: 
 Avg loss: 0.54765592 
 F1: 0.550676 
 Precision: 0.665635 
 Recall: 0.469578
 IoU: 0.379954

We have finished training iteration 214
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_212_.pth
per-ex loss: 0.447943  [    2/   89]
per-ex loss: 0.579594  [    4/   89]
per-ex loss: 0.625260  [    6/   89]
per-ex loss: 0.348171  [    8/   89]
per-ex loss: 0.459870  [   10/   89]
per-ex loss: 0.534680  [   12/   89]
per-ex loss: 0.408606  [   14/   89]
per-ex loss: 0.397851  [   16/   89]
per-ex loss: 0.609678  [   18/   89]
per-ex loss: 0.563708  [   20/   89]
per-ex loss: 0.686709  [   22/   89]
per-ex loss: 0.583404  [   24/   89]
per-ex loss: 0.395453  [   26/   89]
per-ex loss: 0.457896  [   28/   89]
per-ex loss: 0.426134  [   30/   89]
per-ex loss: 0.418066  [   32/   89]
per-ex loss: 0.468298  [   34/   89]
per-ex loss: 0.411184  [   36/   89]
per-ex loss: 0.378534  [   38/   89]
per-ex loss: 0.533582  [   40/   89]
per-ex loss: 0.633052  [   42/   89]
per-ex loss: 0.386621  [   44/   89]
per-ex loss: 0.453748  [   46/   89]
per-ex loss: 0.550994  [   48/   89]
per-ex loss: 0.503207  [   50/   89]
per-ex loss: 0.599029  [   52/   89]
per-ex loss: 0.379888  [   54/   89]
per-ex loss: 0.405849  [   56/   89]
per-ex loss: 0.463010  [   58/   89]
per-ex loss: 0.606846  [   60/   89]
per-ex loss: 0.415498  [   62/   89]
per-ex loss: 0.450702  [   64/   89]
per-ex loss: 0.672594  [   66/   89]
per-ex loss: 0.377933  [   68/   89]
per-ex loss: 0.518235  [   70/   89]
per-ex loss: 0.513977  [   72/   89]
per-ex loss: 0.486491  [   74/   89]
per-ex loss: 0.392905  [   76/   89]
per-ex loss: 0.439186  [   78/   89]
per-ex loss: 0.401922  [   80/   89]
per-ex loss: 0.485497  [   82/   89]
per-ex loss: 0.452933  [   84/   89]
per-ex loss: 0.349263  [   86/   89]
per-ex loss: 0.439708  [   88/   89]
per-ex loss: 0.316311  [   89/   89]
Train Error: Avg loss: 0.47622271
validation Error: 
 Avg loss: 0.56259571 
 F1: 0.527667 
 Precision: 0.652585 
 Recall: 0.442888
 IoU: 0.358388

test Error: 
 Avg loss: 0.54828912 
 F1: 0.550274 
 Precision: 0.632088 
 Recall: 0.487212
 IoU: 0.379571

We have finished training iteration 215
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_213_.pth
per-ex loss: 0.403897  [    2/   89]
per-ex loss: 0.304246  [    4/   89]
per-ex loss: 0.444715  [    6/   89]
per-ex loss: 0.335473  [    8/   89]
per-ex loss: 0.629513  [   10/   89]
per-ex loss: 0.500714  [   12/   89]
per-ex loss: 0.365362  [   14/   89]
per-ex loss: 0.410260  [   16/   89]
per-ex loss: 0.388393  [   18/   89]
per-ex loss: 0.694518  [   20/   89]
per-ex loss: 0.382577  [   22/   89]
per-ex loss: 0.487215  [   24/   89]
per-ex loss: 0.555841  [   26/   89]
per-ex loss: 0.404387  [   28/   89]
per-ex loss: 0.487671  [   30/   89]
per-ex loss: 0.725063  [   32/   89]
per-ex loss: 0.609177  [   34/   89]
per-ex loss: 0.610944  [   36/   89]
per-ex loss: 0.394522  [   38/   89]
per-ex loss: 0.483674  [   40/   89]
per-ex loss: 0.551653  [   42/   89]
per-ex loss: 0.427455  [   44/   89]
per-ex loss: 0.578807  [   46/   89]
per-ex loss: 0.576737  [   48/   89]
per-ex loss: 0.355511  [   50/   89]
per-ex loss: 0.593648  [   52/   89]
per-ex loss: 0.622327  [   54/   89]
per-ex loss: 0.437324  [   56/   89]
per-ex loss: 0.404940  [   58/   89]
per-ex loss: 0.470527  [   60/   89]
per-ex loss: 0.457718  [   62/   89]
per-ex loss: 0.549794  [   64/   89]
per-ex loss: 0.413737  [   66/   89]
per-ex loss: 0.380235  [   68/   89]
per-ex loss: 0.446304  [   70/   89]
per-ex loss: 0.569226  [   72/   89]
per-ex loss: 0.405117  [   74/   89]
per-ex loss: 0.435777  [   76/   89]
per-ex loss: 0.442465  [   78/   89]
per-ex loss: 0.572286  [   80/   89]
per-ex loss: 0.431737  [   82/   89]
per-ex loss: 0.352019  [   84/   89]
per-ex loss: 0.519186  [   86/   89]
per-ex loss: 0.393721  [   88/   89]
per-ex loss: 0.571018  [   89/   89]
Train Error: Avg loss: 0.47949841
validation Error: 
 Avg loss: 0.56618696 
 F1: 0.531088 
 Precision: 0.634950 
 Recall: 0.456428
 IoU: 0.361552

test Error: 
 Avg loss: 0.54762638 
 F1: 0.553807 
 Precision: 0.622740 
 Recall: 0.498614
 IoU: 0.382941

We have finished training iteration 216
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_214_.pth
per-ex loss: 0.478531  [    2/   89]
per-ex loss: 0.594981  [    4/   89]
per-ex loss: 0.371676  [    6/   89]
per-ex loss: 0.417847  [    8/   89]
per-ex loss: 0.486013  [   10/   89]
per-ex loss: 0.453903  [   12/   89]
per-ex loss: 0.497462  [   14/   89]
per-ex loss: 0.694055  [   16/   89]
per-ex loss: 0.726313  [   18/   89]
per-ex loss: 0.657773  [   20/   89]
per-ex loss: 0.498239  [   22/   89]
per-ex loss: 0.435007  [   24/   89]
per-ex loss: 0.365328  [   26/   89]
per-ex loss: 0.450890  [   28/   89]
per-ex loss: 0.372531  [   30/   89]
per-ex loss: 0.398197  [   32/   89]
per-ex loss: 0.686069  [   34/   89]
per-ex loss: 0.454606  [   36/   89]
per-ex loss: 0.485067  [   38/   89]
per-ex loss: 0.471092  [   40/   89]
per-ex loss: 0.552121  [   42/   89]
per-ex loss: 0.456058  [   44/   89]
per-ex loss: 0.378684  [   46/   89]
per-ex loss: 0.415414  [   48/   89]
per-ex loss: 0.380216  [   50/   89]
per-ex loss: 0.386724  [   52/   89]
per-ex loss: 0.451911  [   54/   89]
per-ex loss: 0.475785  [   56/   89]
per-ex loss: 0.400462  [   58/   89]
per-ex loss: 0.434681  [   60/   89]
per-ex loss: 0.379343  [   62/   89]
per-ex loss: 0.543871  [   64/   89]
per-ex loss: 0.569486  [   66/   89]
per-ex loss: 0.469797  [   68/   89]
per-ex loss: 0.557126  [   70/   89]
per-ex loss: 0.499046  [   72/   89]
per-ex loss: 0.363635  [   74/   89]
per-ex loss: 0.441803  [   76/   89]
per-ex loss: 0.426746  [   78/   89]
per-ex loss: 0.468495  [   80/   89]
per-ex loss: 0.503849  [   82/   89]
per-ex loss: 0.439958  [   84/   89]
per-ex loss: 0.351069  [   86/   89]
per-ex loss: 0.465905  [   88/   89]
per-ex loss: 0.407424  [   89/   89]
Train Error: Avg loss: 0.47144861
validation Error: 
 Avg loss: 0.57517953 
 F1: 0.519640 
 Precision: 0.655877 
 Recall: 0.430267
 IoU: 0.351023

test Error: 
 Avg loss: 0.56341866 
 F1: 0.534014 
 Precision: 0.664428 
 Recall: 0.446396
 IoU: 0.364270

We have finished training iteration 217
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_215_.pth
per-ex loss: 0.487623  [    2/   89]
per-ex loss: 0.546759  [    4/   89]
per-ex loss: 0.441933  [    6/   89]
per-ex loss: 0.674887  [    8/   89]
per-ex loss: 0.352755  [   10/   89]
per-ex loss: 0.367141  [   12/   89]
per-ex loss: 0.402188  [   14/   89]
per-ex loss: 0.529631  [   16/   89]
per-ex loss: 0.437758  [   18/   89]
per-ex loss: 0.419747  [   20/   89]
per-ex loss: 0.387330  [   22/   89]
per-ex loss: 0.383526  [   24/   89]
per-ex loss: 0.483595  [   26/   89]
per-ex loss: 0.546835  [   28/   89]
per-ex loss: 0.581115  [   30/   89]
per-ex loss: 0.552122  [   32/   89]
per-ex loss: 0.548221  [   34/   89]
per-ex loss: 0.468008  [   36/   89]
per-ex loss: 0.400074  [   38/   89]
per-ex loss: 0.379891  [   40/   89]
per-ex loss: 0.360102  [   42/   89]
per-ex loss: 0.485017  [   44/   89]
per-ex loss: 0.510173  [   46/   89]
per-ex loss: 0.530012  [   48/   89]
per-ex loss: 0.585671  [   50/   89]
per-ex loss: 0.627359  [   52/   89]
per-ex loss: 0.447229  [   54/   89]
per-ex loss: 0.415290  [   56/   89]
per-ex loss: 0.434633  [   58/   89]
per-ex loss: 0.428316  [   60/   89]
per-ex loss: 0.408209  [   62/   89]
per-ex loss: 0.504585  [   64/   89]
per-ex loss: 0.370882  [   66/   89]
per-ex loss: 0.311268  [   68/   89]
per-ex loss: 0.616104  [   70/   89]
per-ex loss: 0.508379  [   72/   89]
per-ex loss: 0.617259  [   74/   89]
per-ex loss: 0.364652  [   76/   89]
per-ex loss: 0.376047  [   78/   89]
per-ex loss: 0.373687  [   80/   89]
per-ex loss: 0.414472  [   82/   89]
per-ex loss: 0.460530  [   84/   89]
per-ex loss: 0.414002  [   86/   89]
per-ex loss: 0.486416  [   88/   89]
per-ex loss: 0.669809  [   89/   89]
Train Error: Avg loss: 0.46913878
validation Error: 
 Avg loss: 0.56470635 
 F1: 0.532379 
 Precision: 0.614726 
 Recall: 0.469488
 IoU: 0.362750

test Error: 
 Avg loss: 0.55094512 
 F1: 0.548106 
 Precision: 0.595463 
 Recall: 0.507726
 IoU: 0.377511

We have finished training iteration 218
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_216_.pth
per-ex loss: 0.542153  [    2/   89]
per-ex loss: 0.522880  [    4/   89]
per-ex loss: 0.356211  [    6/   89]
per-ex loss: 0.379321  [    8/   89]
per-ex loss: 0.549780  [   10/   89]
per-ex loss: 0.521810  [   12/   89]
per-ex loss: 0.513436  [   14/   89]
per-ex loss: 0.466346  [   16/   89]
per-ex loss: 0.392206  [   18/   89]
per-ex loss: 0.554222  [   20/   89]
per-ex loss: 0.493740  [   22/   89]
per-ex loss: 0.508631  [   24/   89]
per-ex loss: 0.426502  [   26/   89]
per-ex loss: 0.435111  [   28/   89]
per-ex loss: 0.618264  [   30/   89]
per-ex loss: 0.704266  [   32/   89]
per-ex loss: 0.503977  [   34/   89]
per-ex loss: 0.350679  [   36/   89]
per-ex loss: 0.583740  [   38/   89]
per-ex loss: 0.461894  [   40/   89]
per-ex loss: 0.545941  [   42/   89]
per-ex loss: 0.385775  [   44/   89]
per-ex loss: 0.630544  [   46/   89]
per-ex loss: 0.692237  [   48/   89]
per-ex loss: 0.353293  [   50/   89]
per-ex loss: 0.396121  [   52/   89]
per-ex loss: 0.397391  [   54/   89]
per-ex loss: 0.441127  [   56/   89]
per-ex loss: 0.396690  [   58/   89]
per-ex loss: 0.401113  [   60/   89]
per-ex loss: 0.536966  [   62/   89]
per-ex loss: 0.625510  [   64/   89]
per-ex loss: 0.385562  [   66/   89]
per-ex loss: 0.597698  [   68/   89]
per-ex loss: 0.438866  [   70/   89]
per-ex loss: 0.486645  [   72/   89]
per-ex loss: 0.366563  [   74/   89]
per-ex loss: 0.503916  [   76/   89]
per-ex loss: 0.597951  [   78/   89]
per-ex loss: 0.448352  [   80/   89]
per-ex loss: 0.438116  [   82/   89]
per-ex loss: 0.406897  [   84/   89]
per-ex loss: 0.397385  [   86/   89]
per-ex loss: 0.414803  [   88/   89]
per-ex loss: 0.573269  [   89/   89]
Train Error: Avg loss: 0.48319784
validation Error: 
 Avg loss: 0.58480090 
 F1: 0.523618 
 Precision: 0.546102 
 Recall: 0.502912
 IoU: 0.354663

test Error: 
 Avg loss: 0.56000526 
 F1: 0.544524 
 Precision: 0.540523 
 Recall: 0.548584
 IoU: 0.374121

We have finished training iteration 219
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_217_.pth
per-ex loss: 0.486038  [    2/   89]
per-ex loss: 0.416471  [    4/   89]
per-ex loss: 0.405090  [    6/   89]
per-ex loss: 0.421696  [    8/   89]
per-ex loss: 0.671336  [   10/   89]
per-ex loss: 0.328352  [   12/   89]
per-ex loss: 0.519328  [   14/   89]
per-ex loss: 0.459792  [   16/   89]
per-ex loss: 0.654768  [   18/   89]
per-ex loss: 0.561320  [   20/   89]
per-ex loss: 0.415510  [   22/   89]
per-ex loss: 0.461054  [   24/   89]
per-ex loss: 0.424764  [   26/   89]
per-ex loss: 0.483822  [   28/   89]
per-ex loss: 0.351075  [   30/   89]
per-ex loss: 0.379415  [   32/   89]
per-ex loss: 0.610579  [   34/   89]
per-ex loss: 0.414969  [   36/   89]
per-ex loss: 0.654977  [   38/   89]
per-ex loss: 0.356152  [   40/   89]
per-ex loss: 0.507980  [   42/   89]
per-ex loss: 0.483746  [   44/   89]
per-ex loss: 0.566216  [   46/   89]
per-ex loss: 0.398773  [   48/   89]
per-ex loss: 0.556896  [   50/   89]
per-ex loss: 0.557215  [   52/   89]
per-ex loss: 0.462789  [   54/   89]
per-ex loss: 0.489488  [   56/   89]
per-ex loss: 0.328414  [   58/   89]
per-ex loss: 0.399630  [   60/   89]
per-ex loss: 0.415182  [   62/   89]
per-ex loss: 0.294396  [   64/   89]
per-ex loss: 0.361704  [   66/   89]
per-ex loss: 0.489020  [   68/   89]
per-ex loss: 0.585367  [   70/   89]
per-ex loss: 0.483501  [   72/   89]
per-ex loss: 0.433923  [   74/   89]
per-ex loss: 0.543602  [   76/   89]
per-ex loss: 0.441858  [   78/   89]
per-ex loss: 0.380823  [   80/   89]
per-ex loss: 0.582962  [   82/   89]
per-ex loss: 0.723929  [   84/   89]
per-ex loss: 0.543570  [   86/   89]
per-ex loss: 0.556403  [   88/   89]
per-ex loss: 0.583415  [   89/   89]
Train Error: Avg loss: 0.48105138
validation Error: 
 Avg loss: 0.57707914 
 F1: 0.526539 
 Precision: 0.570018 
 Recall: 0.489223
 IoU: 0.357349

test Error: 
 Avg loss: 0.55957718 
 F1: 0.540324 
 Precision: 0.542018 
 Recall: 0.538641
 IoU: 0.370167

We have finished training iteration 220
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_218_.pth
per-ex loss: 0.443170  [    2/   89]
per-ex loss: 0.354717  [    4/   89]
per-ex loss: 0.580226  [    6/   89]
per-ex loss: 0.483978  [    8/   89]
per-ex loss: 0.420641  [   10/   89]
per-ex loss: 0.375792  [   12/   89]
per-ex loss: 0.387746  [   14/   89]
per-ex loss: 0.267023  [   16/   89]
per-ex loss: 0.505623  [   18/   89]
per-ex loss: 0.381321  [   20/   89]
per-ex loss: 0.419419  [   22/   89]
per-ex loss: 0.690343  [   24/   89]
per-ex loss: 0.407225  [   26/   89]
per-ex loss: 0.476639  [   28/   89]
per-ex loss: 0.401203  [   30/   89]
per-ex loss: 0.509970  [   32/   89]
per-ex loss: 0.371365  [   34/   89]
per-ex loss: 0.493782  [   36/   89]
per-ex loss: 0.510474  [   38/   89]
per-ex loss: 0.452670  [   40/   89]
per-ex loss: 0.536874  [   42/   89]
per-ex loss: 0.595412  [   44/   89]
per-ex loss: 0.362957  [   46/   89]
per-ex loss: 0.652425  [   48/   89]
per-ex loss: 0.493800  [   50/   89]
per-ex loss: 0.349847  [   52/   89]
per-ex loss: 0.354960  [   54/   89]
per-ex loss: 0.334094  [   56/   89]
per-ex loss: 0.588516  [   58/   89]
per-ex loss: 0.473364  [   60/   89]
per-ex loss: 0.427738  [   62/   89]
per-ex loss: 0.507229  [   64/   89]
per-ex loss: 0.410035  [   66/   89]
per-ex loss: 0.564421  [   68/   89]
per-ex loss: 0.496742  [   70/   89]
per-ex loss: 0.384748  [   72/   89]
per-ex loss: 0.550544  [   74/   89]
per-ex loss: 0.436947  [   76/   89]
per-ex loss: 0.490239  [   78/   89]
per-ex loss: 0.600801  [   80/   89]
per-ex loss: 0.409154  [   82/   89]
per-ex loss: 0.694232  [   84/   89]
per-ex loss: 0.451251  [   86/   89]
per-ex loss: 0.632532  [   88/   89]
per-ex loss: 0.420824  [   89/   89]
Train Error: Avg loss: 0.47006696
validation Error: 
 Avg loss: 0.57252405 
 F1: 0.515279 
 Precision: 0.674312 
 Recall: 0.416945
 IoU: 0.347055

test Error: 
 Avg loss: 0.55026925 
 F1: 0.541327 
 Precision: 0.659960 
 Recall: 0.458846
 IoU: 0.371109

We have finished training iteration 221
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_219_.pth
Error in cropping the image to the non-zero values in the fourth channel. Returned the original image.
per-ex loss: 0.536789  [    2/   89]
per-ex loss: 0.354157  [    4/   89]
per-ex loss: 0.603166  [    6/   89]
per-ex loss: 0.427147  [    8/   89]
per-ex loss: 0.486449  [   10/   89]
per-ex loss: 0.457740  [   12/   89]
per-ex loss: 0.542465  [   14/   89]
per-ex loss: 0.545511  [   16/   89]
per-ex loss: 0.334231  [   18/   89]
per-ex loss: 0.543718  [   20/   89]
per-ex loss: 0.371283  [   22/   89]
per-ex loss: 0.411548  [   24/   89]
per-ex loss: 0.388672  [   26/   89]
per-ex loss: 0.419343  [   28/   89]
per-ex loss: 0.363196  [   30/   89]
per-ex loss: 0.373120  [   32/   89]
per-ex loss: 0.363065  [   34/   89]
per-ex loss: 0.474373  [   36/   89]
per-ex loss: 0.644541  [   38/   89]
per-ex loss: 0.369351  [   40/   89]
per-ex loss: 0.437551  [   42/   89]
per-ex loss: 0.666057  [   44/   89]
per-ex loss: 0.438732  [   46/   89]
per-ex loss: 0.384696  [   48/   89]
per-ex loss: 0.399713  [   50/   89]
per-ex loss: 0.396336  [   52/   89]
per-ex loss: 0.603090  [   54/   89]
per-ex loss: 0.485557  [   56/   89]
per-ex loss: 0.417828  [   58/   89]
per-ex loss: 0.355058  [   60/   89]
per-ex loss: 0.506080  [   62/   89]
per-ex loss: 0.501689  [   64/   89]
per-ex loss: 0.402516  [   66/   89]
per-ex loss: 0.418364  [   68/   89]
per-ex loss: 0.489507  [   70/   89]
per-ex loss: 0.482614  [   72/   89]
per-ex loss: 0.428603  [   74/   89]
per-ex loss: 0.469772  [   76/   89]
per-ex loss: 0.467788  [   78/   89]
per-ex loss: 0.389157  [   80/   89]
per-ex loss: 0.634483  [   82/   89]
per-ex loss: 0.466147  [   84/   89]
per-ex loss: 0.445585  [   86/   89]
per-ex loss: 0.509813  [   88/   89]
per-ex loss: 0.560670  [   89/   89]
Train Error: Avg loss: 0.46149485
validation Error: 
 Avg loss: 0.56660114 
 F1: 0.530146 
 Precision: 0.600143 
 Recall: 0.474772
 IoU: 0.360680

test Error: 
 Avg loss: 0.55504564 
 F1: 0.544875 
 Precision: 0.575626 
 Recall: 0.517243
 IoU: 0.374453

We have finished training iteration 222
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_220_.pth
per-ex loss: 0.501727  [    2/   89]
per-ex loss: 0.400225  [    4/   89]
per-ex loss: 0.498679  [    6/   89]
per-ex loss: 0.607492  [    8/   89]
per-ex loss: 0.381308  [   10/   89]
per-ex loss: 0.370485  [   12/   89]
per-ex loss: 0.356191  [   14/   89]
per-ex loss: 0.543920  [   16/   89]
per-ex loss: 0.356413  [   18/   89]
per-ex loss: 0.500545  [   20/   89]
per-ex loss: 0.538311  [   22/   89]
per-ex loss: 0.437808  [   24/   89]
per-ex loss: 0.408339  [   26/   89]
per-ex loss: 0.291772  [   28/   89]
per-ex loss: 0.494733  [   30/   89]
per-ex loss: 0.372967  [   32/   89]
per-ex loss: 0.478516  [   34/   89]
per-ex loss: 0.428802  [   36/   89]
per-ex loss: 0.584551  [   38/   89]
per-ex loss: 0.645085  [   40/   89]
per-ex loss: 0.446029  [   42/   89]
per-ex loss: 0.442713  [   44/   89]
per-ex loss: 0.407786  [   46/   89]
per-ex loss: 0.398082  [   48/   89]
per-ex loss: 0.388747  [   50/   89]
per-ex loss: 0.604578  [   52/   89]
per-ex loss: 0.474087  [   54/   89]
per-ex loss: 0.495285  [   56/   89]
per-ex loss: 0.472416  [   58/   89]
per-ex loss: 0.328041  [   60/   89]
per-ex loss: 0.451719  [   62/   89]
per-ex loss: 0.606731  [   64/   89]
per-ex loss: 0.502074  [   66/   89]
per-ex loss: 0.396654  [   68/   89]
per-ex loss: 0.466986  [   70/   89]
per-ex loss: 0.527885  [   72/   89]
per-ex loss: 0.392988  [   74/   89]
per-ex loss: 0.462440  [   76/   89]
per-ex loss: 0.428575  [   78/   89]
per-ex loss: 0.409813  [   80/   89]
per-ex loss: 0.489076  [   82/   89]
per-ex loss: 0.475604  [   84/   89]
per-ex loss: 0.439781  [   86/   89]
per-ex loss: 0.447810  [   88/   89]
per-ex loss: 0.418779  [   89/   89]
Train Error: Avg loss: 0.45716773
validation Error: 
 Avg loss: 0.56442474 
 F1: 0.516946 
 Precision: 0.675886 
 Recall: 0.418527
 IoU: 0.348569

test Error: 
 Avg loss: 0.54452731 
 F1: 0.542853 
 Precision: 0.652099 
 Recall: 0.464959
 IoU: 0.372545

We have finished training iteration 223
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_221_.pth
per-ex loss: 0.565917  [    2/   89]
per-ex loss: 0.384086  [    4/   89]
per-ex loss: 0.559748  [    6/   89]
per-ex loss: 0.357860  [    8/   89]
per-ex loss: 0.617308  [   10/   89]
per-ex loss: 0.535815  [   12/   89]
per-ex loss: 0.413993  [   14/   89]
per-ex loss: 0.427461  [   16/   89]
per-ex loss: 0.410564  [   18/   89]
per-ex loss: 0.365693  [   20/   89]
per-ex loss: 0.599474  [   22/   89]
per-ex loss: 0.370129  [   24/   89]
per-ex loss: 0.483791  [   26/   89]
per-ex loss: 0.518982  [   28/   89]
per-ex loss: 0.394754  [   30/   89]
per-ex loss: 0.461227  [   32/   89]
per-ex loss: 0.428890  [   34/   89]
per-ex loss: 0.648876  [   36/   89]
per-ex loss: 0.618013  [   38/   89]
per-ex loss: 0.419123  [   40/   89]
per-ex loss: 0.365680  [   42/   89]
per-ex loss: 0.351673  [   44/   89]
per-ex loss: 0.373112  [   46/   89]
per-ex loss: 0.496512  [   48/   89]
per-ex loss: 0.440941  [   50/   89]
per-ex loss: 0.595887  [   52/   89]
per-ex loss: 0.566654  [   54/   89]
per-ex loss: 0.364103  [   56/   89]
per-ex loss: 0.401672  [   58/   89]
per-ex loss: 0.484148  [   60/   89]
per-ex loss: 0.488844  [   62/   89]
per-ex loss: 0.377118  [   64/   89]
per-ex loss: 0.620712  [   66/   89]
per-ex loss: 0.455519  [   68/   89]
per-ex loss: 0.523612  [   70/   89]
per-ex loss: 0.573352  [   72/   89]
per-ex loss: 0.397229  [   74/   89]
per-ex loss: 0.479756  [   76/   89]
per-ex loss: 0.377564  [   78/   89]
per-ex loss: 0.387978  [   80/   89]
per-ex loss: 0.461251  [   82/   89]
per-ex loss: 0.523663  [   84/   89]
per-ex loss: 0.406402  [   86/   89]
per-ex loss: 0.293696  [   88/   89]
per-ex loss: 0.477992  [   89/   89]
Train Error: Avg loss: 0.46370604
validation Error: 
 Avg loss: 0.57959133 
 F1: 0.526239 
 Precision: 0.609652 
 Recall: 0.462904
 IoU: 0.357072

test Error: 
 Avg loss: 0.54262690 
 F1: 0.551988 
 Precision: 0.603262 
 Recall: 0.508748
 IoU: 0.381204

We have finished training iteration 224
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_222_.pth
per-ex loss: 0.374848  [    2/   89]
per-ex loss: 0.446175  [    4/   89]
per-ex loss: 0.466174  [    6/   89]
per-ex loss: 0.400413  [    8/   89]
per-ex loss: 0.421852  [   10/   89]
per-ex loss: 0.517693  [   12/   89]
per-ex loss: 0.384834  [   14/   89]
per-ex loss: 0.419432  [   16/   89]
per-ex loss: 0.404400  [   18/   89]
per-ex loss: 0.574766  [   20/   89]
per-ex loss: 0.628631  [   22/   89]
per-ex loss: 0.486072  [   24/   89]
per-ex loss: 0.517676  [   26/   89]
per-ex loss: 0.424413  [   28/   89]
per-ex loss: 0.385146  [   30/   89]
per-ex loss: 0.514324  [   32/   89]
per-ex loss: 0.391781  [   34/   89]
per-ex loss: 0.480868  [   36/   89]
per-ex loss: 0.500674  [   38/   89]
per-ex loss: 0.541521  [   40/   89]
per-ex loss: 0.373297  [   42/   89]
per-ex loss: 0.562585  [   44/   89]
per-ex loss: 0.388741  [   46/   89]
per-ex loss: 0.552703  [   48/   89]
per-ex loss: 0.387978  [   50/   89]
per-ex loss: 0.470125  [   52/   89]
per-ex loss: 0.457753  [   54/   89]
per-ex loss: 0.537958  [   56/   89]
per-ex loss: 0.553598  [   58/   89]
per-ex loss: 0.465584  [   60/   89]
per-ex loss: 0.435290  [   62/   89]
per-ex loss: 0.375740  [   64/   89]
per-ex loss: 0.395517  [   66/   89]
per-ex loss: 0.369593  [   68/   89]
per-ex loss: 0.467038  [   70/   89]
per-ex loss: 0.404359  [   72/   89]
per-ex loss: 0.489792  [   74/   89]
per-ex loss: 0.328088  [   76/   89]
per-ex loss: 0.414725  [   78/   89]
per-ex loss: 0.426587  [   80/   89]
per-ex loss: 0.422016  [   82/   89]
per-ex loss: 0.368663  [   84/   89]
per-ex loss: 0.625448  [   86/   89]
per-ex loss: 0.513160  [   88/   89]
per-ex loss: 0.699663  [   89/   89]
Train Error: Avg loss: 0.46150433
validation Error: 
 Avg loss: 0.56669773 
 F1: 0.525451 
 Precision: 0.630245 
 Recall: 0.450537
 IoU: 0.356347

test Error: 
 Avg loss: 0.55318206 
 F1: 0.536214 
 Precision: 0.616558 
 Recall: 0.474395
 IoU: 0.366320

We have finished training iteration 225
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_223_.pth
per-ex loss: 0.415735  [    2/   89]
per-ex loss: 0.504853  [    4/   89]
per-ex loss: 0.479877  [    6/   89]
per-ex loss: 0.368185  [    8/   89]
per-ex loss: 0.405434  [   10/   89]
per-ex loss: 0.397894  [   12/   89]
per-ex loss: 0.382534  [   14/   89]
per-ex loss: 0.736977  [   16/   89]
per-ex loss: 0.520276  [   18/   89]
per-ex loss: 0.477017  [   20/   89]
per-ex loss: 0.435833  [   22/   89]
per-ex loss: 0.481678  [   24/   89]
per-ex loss: 0.628984  [   26/   89]
per-ex loss: 0.469564  [   28/   89]
per-ex loss: 0.502440  [   30/   89]
per-ex loss: 0.477216  [   32/   89]
per-ex loss: 0.600056  [   34/   89]
per-ex loss: 0.579785  [   36/   89]
per-ex loss: 0.559645  [   38/   89]
per-ex loss: 0.444168  [   40/   89]
per-ex loss: 0.582776  [   42/   89]
per-ex loss: 0.464373  [   44/   89]
per-ex loss: 0.546049  [   46/   89]
per-ex loss: 0.342700  [   48/   89]
per-ex loss: 0.532273  [   50/   89]
per-ex loss: 0.378136  [   52/   89]
per-ex loss: 0.556883  [   54/   89]
per-ex loss: 0.348289  [   56/   89]
per-ex loss: 0.337727  [   58/   89]
per-ex loss: 0.373872  [   60/   89]
per-ex loss: 0.501441  [   62/   89]
per-ex loss: 0.373898  [   64/   89]
per-ex loss: 0.371714  [   66/   89]
per-ex loss: 0.735019  [   68/   89]
per-ex loss: 0.510953  [   70/   89]
per-ex loss: 0.491121  [   72/   89]
per-ex loss: 0.376494  [   74/   89]
per-ex loss: 0.371881  [   76/   89]
per-ex loss: 0.418972  [   78/   89]
per-ex loss: 0.367291  [   80/   89]
per-ex loss: 0.398744  [   82/   89]
per-ex loss: 0.340716  [   84/   89]
per-ex loss: 0.515549  [   86/   89]
per-ex loss: 0.470327  [   88/   89]
per-ex loss: 0.617810  [   89/   89]
Train Error: Avg loss: 0.47095911
validation Error: 
 Avg loss: 0.56635152 
 F1: 0.527322 
 Precision: 0.546568 
 Recall: 0.509385
 IoU: 0.358070

test Error: 
 Avg loss: 0.56248414 
 F1: 0.535319 
 Precision: 0.515436 
 Recall: 0.556798
 IoU: 0.365485

We have finished training iteration 226
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_224_.pth
per-ex loss: 0.483588  [    2/   89]
per-ex loss: 0.403172  [    4/   89]
per-ex loss: 0.462512  [    6/   89]
per-ex loss: 0.485392  [    8/   89]
per-ex loss: 0.403648  [   10/   89]
per-ex loss: 0.468338  [   12/   89]
per-ex loss: 0.508429  [   14/   89]
per-ex loss: 0.481944  [   16/   89]
per-ex loss: 0.373133  [   18/   89]
per-ex loss: 0.384595  [   20/   89]
per-ex loss: 0.339158  [   22/   89]
per-ex loss: 0.414524  [   24/   89]
per-ex loss: 0.422203  [   26/   89]
per-ex loss: 0.599855  [   28/   89]
per-ex loss: 0.357595  [   30/   89]
per-ex loss: 0.444666  [   32/   89]
per-ex loss: 0.413168  [   34/   89]
per-ex loss: 0.415934  [   36/   89]
per-ex loss: 0.375957  [   38/   89]
per-ex loss: 0.539963  [   40/   89]
per-ex loss: 0.353652  [   42/   89]
per-ex loss: 0.539096  [   44/   89]
per-ex loss: 0.464241  [   46/   89]
per-ex loss: 0.535279  [   48/   89]
per-ex loss: 0.356702  [   50/   89]
per-ex loss: 0.621999  [   52/   89]
per-ex loss: 0.393822  [   54/   89]
per-ex loss: 0.426465  [   56/   89]
per-ex loss: 0.588708  [   58/   89]
per-ex loss: 0.384906  [   60/   89]
per-ex loss: 0.738850  [   62/   89]
per-ex loss: 0.500935  [   64/   89]
per-ex loss: 0.395587  [   66/   89]
per-ex loss: 0.526037  [   68/   89]
per-ex loss: 0.371508  [   70/   89]
per-ex loss: 0.324097  [   72/   89]
per-ex loss: 0.396360  [   74/   89]
per-ex loss: 0.505107  [   76/   89]
per-ex loss: 0.493141  [   78/   89]
per-ex loss: 0.341215  [   80/   89]
per-ex loss: 0.667893  [   82/   89]
per-ex loss: 0.343117  [   84/   89]
per-ex loss: 0.594824  [   86/   89]
per-ex loss: 0.482384  [   88/   89]
per-ex loss: 0.407584  [   89/   89]
Train Error: Avg loss: 0.45625070
validation Error: 
 Avg loss: 0.56263028 
 F1: 0.529953 
 Precision: 0.615327 
 Recall: 0.465383
 IoU: 0.360501

test Error: 
 Avg loss: 0.54616561 
 F1: 0.542057 
 Precision: 0.588957 
 Recall: 0.502076
 IoU: 0.371796

We have finished training iteration 227
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_225_.pth
per-ex loss: 0.441344  [    2/   89]
per-ex loss: 0.499035  [    4/   89]
per-ex loss: 0.450744  [    6/   89]
per-ex loss: 0.436489  [    8/   89]
per-ex loss: 0.390763  [   10/   89]
per-ex loss: 0.442611  [   12/   89]
per-ex loss: 0.451592  [   14/   89]
per-ex loss: 0.376460  [   16/   89]
per-ex loss: 0.436440  [   18/   89]
per-ex loss: 0.580259  [   20/   89]
per-ex loss: 0.462379  [   22/   89]
per-ex loss: 0.699177  [   24/   89]
per-ex loss: 0.363363  [   26/   89]
per-ex loss: 0.382399  [   28/   89]
per-ex loss: 0.528992  [   30/   89]
per-ex loss: 0.513090  [   32/   89]
per-ex loss: 0.356372  [   34/   89]
per-ex loss: 0.446766  [   36/   89]
per-ex loss: 0.404479  [   38/   89]
per-ex loss: 0.506852  [   40/   89]
per-ex loss: 0.533408  [   42/   89]
per-ex loss: 0.380844  [   44/   89]
per-ex loss: 0.395607  [   46/   89]
per-ex loss: 0.349313  [   48/   89]
per-ex loss: 0.407245  [   50/   89]
per-ex loss: 0.612636  [   52/   89]
per-ex loss: 0.450696  [   54/   89]
per-ex loss: 0.347997  [   56/   89]
per-ex loss: 0.331071  [   58/   89]
per-ex loss: 0.471932  [   60/   89]
per-ex loss: 0.420173  [   62/   89]
per-ex loss: 0.490087  [   64/   89]
per-ex loss: 0.345460  [   66/   89]
per-ex loss: 0.560506  [   68/   89]
per-ex loss: 0.454163  [   70/   89]
per-ex loss: 0.394467  [   72/   89]
per-ex loss: 0.404909  [   74/   89]
per-ex loss: 0.667991  [   76/   89]
per-ex loss: 0.453922  [   78/   89]
per-ex loss: 0.450957  [   80/   89]
per-ex loss: 0.429156  [   82/   89]
per-ex loss: 0.460831  [   84/   89]
per-ex loss: 0.423445  [   86/   89]
per-ex loss: 0.434331  [   88/   89]
per-ex loss: 0.516415  [   89/   89]
Train Error: Avg loss: 0.45238150
validation Error: 
 Avg loss: 0.55514257 
 F1: 0.536991 
 Precision: 0.610966 
 Recall: 0.478994
 IoU: 0.367045

test Error: 
 Avg loss: 0.53994210 
 F1: 0.555038 
 Precision: 0.590002 
 Recall: 0.523987
 IoU: 0.384120

We have finished training iteration 228
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_226_.pth
per-ex loss: 0.431895  [    2/   89]
per-ex loss: 0.331004  [    4/   89]
per-ex loss: 0.429029  [    6/   89]
per-ex loss: 0.339767  [    8/   89]
per-ex loss: 0.576196  [   10/   89]
per-ex loss: 0.402708  [   12/   89]
per-ex loss: 0.533521  [   14/   89]
per-ex loss: 0.481588  [   16/   89]
per-ex loss: 0.438563  [   18/   89]
per-ex loss: 0.370829  [   20/   89]
per-ex loss: 0.502240  [   22/   89]
per-ex loss: 0.481702  [   24/   89]
per-ex loss: 0.510697  [   26/   89]
per-ex loss: 0.298594  [   28/   89]
per-ex loss: 0.434771  [   30/   89]
per-ex loss: 0.488666  [   32/   89]
per-ex loss: 0.490270  [   34/   89]
per-ex loss: 0.546909  [   36/   89]
per-ex loss: 0.374189  [   38/   89]
per-ex loss: 0.403110  [   40/   89]
per-ex loss: 0.459494  [   42/   89]
per-ex loss: 0.493556  [   44/   89]
per-ex loss: 0.353814  [   46/   89]
per-ex loss: 0.526417  [   48/   89]
per-ex loss: 0.385970  [   50/   89]
per-ex loss: 0.373139  [   52/   89]
per-ex loss: 0.470725  [   54/   89]
per-ex loss: 0.518948  [   56/   89]
per-ex loss: 0.416275  [   58/   89]
per-ex loss: 0.423317  [   60/   89]
per-ex loss: 0.619493  [   62/   89]
per-ex loss: 0.366744  [   64/   89]
per-ex loss: 0.526247  [   66/   89]
per-ex loss: 0.550735  [   68/   89]
per-ex loss: 0.658819  [   70/   89]
per-ex loss: 0.482861  [   72/   89]
per-ex loss: 0.408565  [   74/   89]
per-ex loss: 0.435342  [   76/   89]
per-ex loss: 0.550619  [   78/   89]
per-ex loss: 0.516468  [   80/   89]
per-ex loss: 0.421137  [   82/   89]
per-ex loss: 0.337641  [   84/   89]
per-ex loss: 0.328391  [   86/   89]
per-ex loss: 0.343340  [   88/   89]
per-ex loss: 0.654114  [   89/   89]
Train Error: Avg loss: 0.45529829
validation Error: 
 Avg loss: 0.56763229 
 F1: 0.512883 
 Precision: 0.674320 
 Recall: 0.413813
 IoU: 0.344884

test Error: 
 Avg loss: 0.53710330 
 F1: 0.550386 
 Precision: 0.665810 
 Recall: 0.469069
 IoU: 0.379678

We have finished training iteration 229
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_227_.pth
per-ex loss: 0.489456  [    2/   89]
per-ex loss: 0.532430  [    4/   89]
per-ex loss: 0.715728  [    6/   89]
per-ex loss: 0.482876  [    8/   89]
per-ex loss: 0.342664  [   10/   89]
per-ex loss: 0.592335  [   12/   89]
per-ex loss: 0.334176  [   14/   89]
per-ex loss: 0.529772  [   16/   89]
per-ex loss: 0.388463  [   18/   89]
per-ex loss: 0.570753  [   20/   89]
per-ex loss: 0.459769  [   22/   89]
per-ex loss: 0.395130  [   24/   89]
per-ex loss: 0.369661  [   26/   89]
per-ex loss: 0.383087  [   28/   89]
per-ex loss: 0.520834  [   30/   89]
per-ex loss: 0.529482  [   32/   89]
per-ex loss: 0.410118  [   34/   89]
per-ex loss: 0.391895  [   36/   89]
per-ex loss: 0.423562  [   38/   89]
per-ex loss: 0.427068  [   40/   89]
per-ex loss: 0.488477  [   42/   89]
per-ex loss: 0.507587  [   44/   89]
per-ex loss: 0.474351  [   46/   89]
per-ex loss: 0.701363  [   48/   89]
per-ex loss: 0.620953  [   50/   89]
per-ex loss: 0.412586  [   52/   89]
per-ex loss: 0.342047  [   54/   89]
per-ex loss: 0.526842  [   56/   89]
per-ex loss: 0.376109  [   58/   89]
per-ex loss: 0.378809  [   60/   89]
per-ex loss: 0.535725  [   62/   89]
per-ex loss: 0.465972  [   64/   89]
per-ex loss: 0.383567  [   66/   89]
per-ex loss: 0.399823  [   68/   89]
per-ex loss: 0.609529  [   70/   89]
per-ex loss: 0.381608  [   72/   89]
per-ex loss: 0.336344  [   74/   89]
per-ex loss: 0.310751  [   76/   89]
per-ex loss: 0.460447  [   78/   89]
per-ex loss: 0.362959  [   80/   89]
per-ex loss: 0.573493  [   82/   89]
per-ex loss: 0.384256  [   84/   89]
per-ex loss: 0.352618  [   86/   89]
per-ex loss: 0.431725  [   88/   89]
per-ex loss: 0.404197  [   89/   89]
Train Error: Avg loss: 0.45580882
validation Error: 
 Avg loss: 0.55521220 
 F1: 0.532437 
 Precision: 0.576021 
 Recall: 0.494985
 IoU: 0.362804

test Error: 
 Avg loss: 0.54476763 
 F1: 0.548006 
 Precision: 0.550176 
 Recall: 0.545852
 IoU: 0.377416

We have finished training iteration 230
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_228_.pth
per-ex loss: 0.331673  [    2/   89]
per-ex loss: 0.441109  [    4/   89]
per-ex loss: 0.515252  [    6/   89]
per-ex loss: 0.359649  [    8/   89]
per-ex loss: 0.352651  [   10/   89]
per-ex loss: 0.416876  [   12/   89]
per-ex loss: 0.470639  [   14/   89]
per-ex loss: 0.388939  [   16/   89]
per-ex loss: 0.543159  [   18/   89]
per-ex loss: 0.346687  [   20/   89]
per-ex loss: 0.534423  [   22/   89]
per-ex loss: 0.539074  [   24/   89]
per-ex loss: 0.611198  [   26/   89]
per-ex loss: 0.390091  [   28/   89]
per-ex loss: 0.455999  [   30/   89]
per-ex loss: 0.625227  [   32/   89]
per-ex loss: 0.463851  [   34/   89]
per-ex loss: 0.661848  [   36/   89]
per-ex loss: 0.369040  [   38/   89]
per-ex loss: 0.418906  [   40/   89]
per-ex loss: 0.515102  [   42/   89]
per-ex loss: 0.618211  [   44/   89]
per-ex loss: 0.426151  [   46/   89]
per-ex loss: 0.376695  [   48/   89]
per-ex loss: 0.354743  [   50/   89]
per-ex loss: 0.388626  [   52/   89]
per-ex loss: 0.403983  [   54/   89]
per-ex loss: 0.596462  [   56/   89]
per-ex loss: 0.363581  [   58/   89]
per-ex loss: 0.399343  [   60/   89]
per-ex loss: 0.534908  [   62/   89]
per-ex loss: 0.406027  [   64/   89]
per-ex loss: 0.345159  [   66/   89]
per-ex loss: 0.380746  [   68/   89]
per-ex loss: 0.377310  [   70/   89]
per-ex loss: 0.514997  [   72/   89]
per-ex loss: 0.375874  [   74/   89]
per-ex loss: 0.453213  [   76/   89]
per-ex loss: 0.481902  [   78/   89]
per-ex loss: 0.305540  [   80/   89]
per-ex loss: 0.670224  [   82/   89]
per-ex loss: 0.376952  [   84/   89]
per-ex loss: 0.506787  [   86/   89]
per-ex loss: 0.451848  [   88/   89]
per-ex loss: 0.353874  [   89/   89]
Train Error: Avg loss: 0.44921220
validation Error: 
 Avg loss: 0.56933483 
 F1: 0.522795 
 Precision: 0.637385 
 Recall: 0.443129
 IoU: 0.353908

test Error: 
 Avg loss: 0.53566560 
 F1: 0.551138 
 Precision: 0.651102 
 Recall: 0.477784
 IoU: 0.380394

We have finished training iteration 231
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_229_.pth
per-ex loss: 0.598456  [    2/   89]
per-ex loss: 0.383687  [    4/   89]
per-ex loss: 0.502680  [    6/   89]
per-ex loss: 0.404548  [    8/   89]
per-ex loss: 0.561175  [   10/   89]
per-ex loss: 0.341389  [   12/   89]
per-ex loss: 0.384689  [   14/   89]
per-ex loss: 0.365939  [   16/   89]
per-ex loss: 0.533639  [   18/   89]
per-ex loss: 0.574157  [   20/   89]
per-ex loss: 0.365929  [   22/   89]
per-ex loss: 0.472052  [   24/   89]
per-ex loss: 0.258136  [   26/   89]
per-ex loss: 0.345406  [   28/   89]
per-ex loss: 0.705184  [   30/   89]
per-ex loss: 0.379221  [   32/   89]
per-ex loss: 0.356075  [   34/   89]
per-ex loss: 0.438705  [   36/   89]
per-ex loss: 0.362973  [   38/   89]
per-ex loss: 0.686551  [   40/   89]
per-ex loss: 0.376006  [   42/   89]
per-ex loss: 0.398804  [   44/   89]
per-ex loss: 0.360119  [   46/   89]
per-ex loss: 0.408755  [   48/   89]
per-ex loss: 0.571039  [   50/   89]
per-ex loss: 0.416286  [   52/   89]
per-ex loss: 0.424126  [   54/   89]
per-ex loss: 0.480259  [   56/   89]
per-ex loss: 0.369454  [   58/   89]
per-ex loss: 0.593167  [   60/   89]
per-ex loss: 0.380674  [   62/   89]
per-ex loss: 0.391600  [   64/   89]
per-ex loss: 0.386843  [   66/   89]
per-ex loss: 0.394382  [   68/   89]
per-ex loss: 0.403176  [   70/   89]
per-ex loss: 0.627406  [   72/   89]
per-ex loss: 0.383052  [   74/   89]
per-ex loss: 0.378694  [   76/   89]
per-ex loss: 0.632910  [   78/   89]
per-ex loss: 0.481178  [   80/   89]
per-ex loss: 0.572635  [   82/   89]
per-ex loss: 0.538397  [   84/   89]
per-ex loss: 0.336391  [   86/   89]
per-ex loss: 0.476574  [   88/   89]
per-ex loss: 0.528143  [   89/   89]
Train Error: Avg loss: 0.45179246
validation Error: 
 Avg loss: 0.55823725 
 F1: 0.528468 
 Precision: 0.623070 
 Recall: 0.458806
 IoU: 0.359128

test Error: 
 Avg loss: 0.53921824 
 F1: 0.549534 
 Precision: 0.615902 
 Recall: 0.496077
 IoU: 0.378867

We have finished training iteration 232
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_230_.pth
per-ex loss: 0.368779  [    2/   89]
per-ex loss: 0.512015  [    4/   89]
per-ex loss: 0.390003  [    6/   89]
per-ex loss: 0.422218  [    8/   89]
per-ex loss: 0.462979  [   10/   89]
per-ex loss: 0.367566  [   12/   89]
per-ex loss: 0.336301  [   14/   89]
per-ex loss: 0.430747  [   16/   89]
per-ex loss: 0.483649  [   18/   89]
per-ex loss: 0.601685  [   20/   89]
per-ex loss: 0.472212  [   22/   89]
per-ex loss: 0.539888  [   24/   89]
per-ex loss: 0.392510  [   26/   89]
per-ex loss: 0.447115  [   28/   89]
per-ex loss: 0.462717  [   30/   89]
per-ex loss: 0.446963  [   32/   89]
per-ex loss: 0.435213  [   34/   89]
per-ex loss: 0.333971  [   36/   89]
per-ex loss: 0.430344  [   38/   89]
per-ex loss: 0.422912  [   40/   89]
per-ex loss: 0.364461  [   42/   89]
per-ex loss: 0.537059  [   44/   89]
per-ex loss: 0.366877  [   46/   89]
per-ex loss: 0.436951  [   48/   89]
per-ex loss: 0.404236  [   50/   89]
per-ex loss: 0.441149  [   52/   89]
per-ex loss: 0.465448  [   54/   89]
per-ex loss: 0.374507  [   56/   89]
per-ex loss: 0.443781  [   58/   89]
per-ex loss: 0.492741  [   60/   89]
per-ex loss: 0.529399  [   62/   89]
per-ex loss: 0.556731  [   64/   89]
per-ex loss: 0.527569  [   66/   89]
per-ex loss: 0.708877  [   68/   89]
per-ex loss: 0.346412  [   70/   89]
per-ex loss: 0.571443  [   72/   89]
per-ex loss: 0.643524  [   74/   89]
per-ex loss: 0.678219  [   76/   89]
per-ex loss: 0.398296  [   78/   89]
per-ex loss: 0.385601  [   80/   89]
per-ex loss: 0.537146  [   82/   89]
per-ex loss: 0.342157  [   84/   89]
per-ex loss: 0.416627  [   86/   89]
per-ex loss: 0.369624  [   88/   89]
per-ex loss: 0.513197  [   89/   89]
Train Error: Avg loss: 0.45804037
validation Error: 
 Avg loss: 0.56394773 
 F1: 0.515284 
 Precision: 0.638931 
 Recall: 0.431734
 IoU: 0.347059

test Error: 
 Avg loss: 0.53696253 
 F1: 0.545262 
 Precision: 0.631323 
 Recall: 0.479850
 IoU: 0.374818

We have finished training iteration 233
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_231_.pth
per-ex loss: 0.507434  [    2/   89]
per-ex loss: 0.354050  [    4/   89]
per-ex loss: 0.575507  [    6/   89]
per-ex loss: 0.399474  [    8/   89]
per-ex loss: 0.388281  [   10/   89]
per-ex loss: 0.460388  [   12/   89]
per-ex loss: 0.330343  [   14/   89]
per-ex loss: 0.402518  [   16/   89]
per-ex loss: 0.462167  [   18/   89]
per-ex loss: 0.517114  [   20/   89]
per-ex loss: 0.622214  [   22/   89]
per-ex loss: 0.555282  [   24/   89]
per-ex loss: 0.479633  [   26/   89]
per-ex loss: 0.433412  [   28/   89]
per-ex loss: 0.366195  [   30/   89]
per-ex loss: 0.507722  [   32/   89]
per-ex loss: 0.347833  [   34/   89]
per-ex loss: 0.399674  [   36/   89]
per-ex loss: 0.447484  [   38/   89]
per-ex loss: 0.421914  [   40/   89]
per-ex loss: 0.415548  [   42/   89]
per-ex loss: 0.523444  [   44/   89]
per-ex loss: 0.391174  [   46/   89]
per-ex loss: 0.403483  [   48/   89]
per-ex loss: 0.382316  [   50/   89]
per-ex loss: 0.615184  [   52/   89]
per-ex loss: 0.340534  [   54/   89]
per-ex loss: 0.553925  [   56/   89]
per-ex loss: 0.355805  [   58/   89]
per-ex loss: 0.437431  [   60/   89]
per-ex loss: 0.522407  [   62/   89]
per-ex loss: 0.473105  [   64/   89]
per-ex loss: 0.665689  [   66/   89]
per-ex loss: 0.449958  [   68/   89]
per-ex loss: 0.637148  [   70/   89]
per-ex loss: 0.426404  [   72/   89]
per-ex loss: 0.550857  [   74/   89]
per-ex loss: 0.429483  [   76/   89]
per-ex loss: 0.414648  [   78/   89]
per-ex loss: 0.351579  [   80/   89]
per-ex loss: 0.697051  [   82/   89]
per-ex loss: 0.353986  [   84/   89]
per-ex loss: 0.367009  [   86/   89]
per-ex loss: 0.407507  [   88/   89]
per-ex loss: 0.703368  [   89/   89]
Train Error: Avg loss: 0.46328179
validation Error: 
 Avg loss: 0.56372195 
 F1: 0.498793 
 Precision: 0.719918 
 Recall: 0.381587
 IoU: 0.332261

test Error: 
 Avg loss: 0.54719346 
 F1: 0.527846 
 Precision: 0.712591 
 Recall: 0.419172
 IoU: 0.358554

We have finished training iteration 234
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_232_.pth
per-ex loss: 0.359946  [    2/   89]
per-ex loss: 0.639000  [    4/   89]
per-ex loss: 0.559973  [    6/   89]
per-ex loss: 0.358404  [    8/   89]
per-ex loss: 0.379948  [   10/   89]
per-ex loss: 0.386409  [   12/   89]
per-ex loss: 0.426188  [   14/   89]
per-ex loss: 0.611112  [   16/   89]
per-ex loss: 0.475409  [   18/   89]
per-ex loss: 0.333169  [   20/   89]
per-ex loss: 0.408035  [   22/   89]
per-ex loss: 0.634749  [   24/   89]
per-ex loss: 0.479469  [   26/   89]
per-ex loss: 0.600370  [   28/   89]
per-ex loss: 0.489859  [   30/   89]
per-ex loss: 0.355929  [   32/   89]
per-ex loss: 0.356092  [   34/   89]
per-ex loss: 0.563439  [   36/   89]
per-ex loss: 0.529393  [   38/   89]
per-ex loss: 0.640453  [   40/   89]
per-ex loss: 0.563488  [   42/   89]
per-ex loss: 0.344348  [   44/   89]
per-ex loss: 0.390650  [   46/   89]
per-ex loss: 0.407893  [   48/   89]
per-ex loss: 0.705866  [   50/   89]
per-ex loss: 0.393515  [   52/   89]
per-ex loss: 0.509276  [   54/   89]
per-ex loss: 0.415872  [   56/   89]
per-ex loss: 0.370913  [   58/   89]
per-ex loss: 0.377651  [   60/   89]
per-ex loss: 0.413156  [   62/   89]
per-ex loss: 0.413957  [   64/   89]
per-ex loss: 0.418506  [   66/   89]
per-ex loss: 0.423831  [   68/   89]
per-ex loss: 0.358021  [   70/   89]
per-ex loss: 0.387161  [   72/   89]
per-ex loss: 0.366399  [   74/   89]
per-ex loss: 0.274871  [   76/   89]
per-ex loss: 0.341626  [   78/   89]
per-ex loss: 0.378867  [   80/   89]
per-ex loss: 0.497684  [   82/   89]
per-ex loss: 0.484348  [   84/   89]
per-ex loss: 0.408667  [   86/   89]
per-ex loss: 0.562026  [   88/   89]
per-ex loss: 0.621691  [   89/   89]
Train Error: Avg loss: 0.45372506
validation Error: 
 Avg loss: 0.54626166 
 F1: 0.534062 
 Precision: 0.604279 
 Recall: 0.478465
 IoU: 0.364314

test Error: 
 Avg loss: 0.52698329 
 F1: 0.562459 
 Precision: 0.589954 
 Recall: 0.537414
 IoU: 0.391265

We have finished training iteration 235
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_233_.pth
per-ex loss: 0.428878  [    2/   89]
per-ex loss: 0.429125  [    4/   89]
per-ex loss: 0.303927  [    6/   89]
per-ex loss: 0.485659  [    8/   89]
per-ex loss: 0.574729  [   10/   89]
per-ex loss: 0.429193  [   12/   89]
per-ex loss: 0.571203  [   14/   89]
per-ex loss: 0.356120  [   16/   89]
per-ex loss: 0.419730  [   18/   89]
per-ex loss: 0.495228  [   20/   89]
per-ex loss: 0.591170  [   22/   89]
per-ex loss: 0.455162  [   24/   89]
per-ex loss: 0.443707  [   26/   89]
per-ex loss: 0.390537  [   28/   89]
per-ex loss: 0.413142  [   30/   89]
per-ex loss: 0.435399  [   32/   89]
per-ex loss: 0.407616  [   34/   89]
per-ex loss: 0.485004  [   36/   89]
per-ex loss: 0.457305  [   38/   89]
per-ex loss: 0.485329  [   40/   89]
per-ex loss: 0.423909  [   42/   89]
per-ex loss: 0.428164  [   44/   89]
per-ex loss: 0.399517  [   46/   89]
per-ex loss: 0.353995  [   48/   89]
per-ex loss: 0.629196  [   50/   89]
per-ex loss: 0.367261  [   52/   89]
per-ex loss: 0.387871  [   54/   89]
per-ex loss: 0.494847  [   56/   89]
per-ex loss: 0.371785  [   58/   89]
per-ex loss: 0.463315  [   60/   89]
per-ex loss: 0.363946  [   62/   89]
per-ex loss: 0.396191  [   64/   89]
per-ex loss: 0.362521  [   66/   89]
per-ex loss: 0.379142  [   68/   89]
per-ex loss: 0.601525  [   70/   89]
per-ex loss: 0.493540  [   72/   89]
per-ex loss: 0.478836  [   74/   89]
per-ex loss: 0.561178  [   76/   89]
per-ex loss: 0.490117  [   78/   89]
per-ex loss: 0.412377  [   80/   89]
per-ex loss: 0.357533  [   82/   89]
per-ex loss: 0.508303  [   84/   89]
per-ex loss: 0.540260  [   86/   89]
per-ex loss: 0.394507  [   88/   89]
per-ex loss: 0.409472  [   89/   89]
Train Error: Avg loss: 0.44727719
validation Error: 
 Avg loss: 0.54221481 
 F1: 0.530850 
 Precision: 0.637123 
 Recall: 0.454961
 IoU: 0.361331

test Error: 
 Avg loss: 0.53073419 
 F1: 0.550608 
 Precision: 0.621206 
 Recall: 0.494418
 IoU: 0.379889

We have finished training iteration 236
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_234_.pth
per-ex loss: 0.441113  [    2/   89]
per-ex loss: 0.510312  [    4/   89]
per-ex loss: 0.401906  [    6/   89]
per-ex loss: 0.392717  [    8/   89]
per-ex loss: 0.403034  [   10/   89]
per-ex loss: 0.329140  [   12/   89]
per-ex loss: 0.442168  [   14/   89]
per-ex loss: 0.399686  [   16/   89]
per-ex loss: 0.365179  [   18/   89]
per-ex loss: 0.612973  [   20/   89]
per-ex loss: 0.398365  [   22/   89]
per-ex loss: 0.375804  [   24/   89]
per-ex loss: 0.582670  [   26/   89]
per-ex loss: 0.426420  [   28/   89]
per-ex loss: 0.397316  [   30/   89]
per-ex loss: 0.496471  [   32/   89]
per-ex loss: 0.459648  [   34/   89]
per-ex loss: 0.680622  [   36/   89]
per-ex loss: 0.340510  [   38/   89]
per-ex loss: 0.346210  [   40/   89]
per-ex loss: 0.343272  [   42/   89]
per-ex loss: 0.583379  [   44/   89]
per-ex loss: 0.358630  [   46/   89]
per-ex loss: 0.673256  [   48/   89]
per-ex loss: 0.403565  [   50/   89]
per-ex loss: 0.571604  [   52/   89]
per-ex loss: 0.450640  [   54/   89]
per-ex loss: 0.524925  [   56/   89]
per-ex loss: 0.368370  [   58/   89]
per-ex loss: 0.344874  [   60/   89]
per-ex loss: 0.427957  [   62/   89]
per-ex loss: 0.373036  [   64/   89]
per-ex loss: 0.309759  [   66/   89]
per-ex loss: 0.320858  [   68/   89]
per-ex loss: 0.544174  [   70/   89]
per-ex loss: 0.561794  [   72/   89]
per-ex loss: 0.565544  [   74/   89]
per-ex loss: 0.471597  [   76/   89]
per-ex loss: 0.574428  [   78/   89]
per-ex loss: 0.433102  [   80/   89]
per-ex loss: 0.399465  [   82/   89]
per-ex loss: 0.462141  [   84/   89]
per-ex loss: 0.546264  [   86/   89]
per-ex loss: 0.412498  [   88/   89]
per-ex loss: 0.599882  [   89/   89]
Train Error: Avg loss: 0.45393958
validation Error: 
 Avg loss: 0.54765351 
 F1: 0.528868 
 Precision: 0.611534 
 Recall: 0.465890
 IoU: 0.359497

test Error: 
 Avg loss: 0.52747587 
 F1: 0.559493 
 Precision: 0.609501 
 Recall: 0.517069
 IoU: 0.388400

We have finished training iteration 237
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_235_.pth
per-ex loss: 0.430821  [    2/   89]
per-ex loss: 0.463929  [    4/   89]
per-ex loss: 0.382790  [    6/   89]
per-ex loss: 0.429689  [    8/   89]
per-ex loss: 0.381829  [   10/   89]
per-ex loss: 0.629902  [   12/   89]
per-ex loss: 0.441003  [   14/   89]
per-ex loss: 0.383430  [   16/   89]
per-ex loss: 0.380266  [   18/   89]
per-ex loss: 0.430908  [   20/   89]
per-ex loss: 0.568387  [   22/   89]
per-ex loss: 0.568926  [   24/   89]
per-ex loss: 0.295394  [   26/   89]
per-ex loss: 0.359162  [   28/   89]
per-ex loss: 0.398076  [   30/   89]
per-ex loss: 0.370170  [   32/   89]
per-ex loss: 0.405811  [   34/   89]
per-ex loss: 0.727939  [   36/   89]
per-ex loss: 0.351882  [   38/   89]
per-ex loss: 0.518813  [   40/   89]
per-ex loss: 0.438360  [   42/   89]
per-ex loss: 0.385204  [   44/   89]
per-ex loss: 0.398236  [   46/   89]
per-ex loss: 0.441129  [   48/   89]
per-ex loss: 0.723312  [   50/   89]
per-ex loss: 0.508893  [   52/   89]
per-ex loss: 0.558774  [   54/   89]
per-ex loss: 0.410218  [   56/   89]
per-ex loss: 0.504875  [   58/   89]
per-ex loss: 0.413433  [   60/   89]
per-ex loss: 0.384932  [   62/   89]
per-ex loss: 0.384945  [   64/   89]
per-ex loss: 0.448483  [   66/   89]
per-ex loss: 0.497561  [   68/   89]
per-ex loss: 0.353988  [   70/   89]
per-ex loss: 0.372243  [   72/   89]
per-ex loss: 0.649810  [   74/   89]
per-ex loss: 0.362157  [   76/   89]
per-ex loss: 0.361008  [   78/   89]
per-ex loss: 0.443024  [   80/   89]
per-ex loss: 0.566509  [   82/   89]
per-ex loss: 0.418876  [   84/   89]
per-ex loss: 0.506828  [   86/   89]
per-ex loss: 0.354576  [   88/   89]
per-ex loss: 0.387206  [   89/   89]
Train Error: Avg loss: 0.44874902
validation Error: 
 Avg loss: 0.56023765 
 F1: 0.513748 
 Precision: 0.673527 
 Recall: 0.415242
 IoU: 0.345667

test Error: 
 Avg loss: 0.53663341 
 F1: 0.535487 
 Precision: 0.676180 
 Recall: 0.443258
 IoU: 0.365642

We have finished training iteration 238
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_236_.pth
per-ex loss: 0.403279  [    2/   89]
per-ex loss: 0.451379  [    4/   89]
per-ex loss: 0.346398  [    6/   89]
per-ex loss: 0.406183  [    8/   89]
per-ex loss: 0.518931  [   10/   89]
per-ex loss: 0.397557  [   12/   89]
per-ex loss: 0.389339  [   14/   89]
per-ex loss: 0.344368  [   16/   89]
per-ex loss: 0.358139  [   18/   89]
per-ex loss: 0.439639  [   20/   89]
per-ex loss: 0.309440  [   22/   89]
per-ex loss: 0.534613  [   24/   89]
per-ex loss: 0.410774  [   26/   89]
per-ex loss: 0.436884  [   28/   89]
per-ex loss: 0.595445  [   30/   89]
per-ex loss: 0.554295  [   32/   89]
per-ex loss: 0.316498  [   34/   89]
per-ex loss: 0.368601  [   36/   89]
per-ex loss: 0.433903  [   38/   89]
per-ex loss: 0.511797  [   40/   89]
per-ex loss: 0.457218  [   42/   89]
per-ex loss: 0.435388  [   44/   89]
per-ex loss: 0.548007  [   46/   89]
per-ex loss: 0.396349  [   48/   89]
per-ex loss: 0.419432  [   50/   89]
per-ex loss: 0.460196  [   52/   89]
per-ex loss: 0.548262  [   54/   89]
per-ex loss: 0.572127  [   56/   89]
per-ex loss: 0.494193  [   58/   89]
per-ex loss: 0.352383  [   60/   89]
per-ex loss: 0.360158  [   62/   89]
per-ex loss: 0.481706  [   64/   89]
per-ex loss: 0.432295  [   66/   89]
per-ex loss: 0.581618  [   68/   89]
per-ex loss: 0.358969  [   70/   89]
per-ex loss: 0.426700  [   72/   89]
per-ex loss: 0.271348  [   74/   89]
per-ex loss: 0.491915  [   76/   89]
per-ex loss: 0.532578  [   78/   89]
per-ex loss: 0.438817  [   80/   89]
per-ex loss: 0.400479  [   82/   89]
per-ex loss: 0.359637  [   84/   89]
per-ex loss: 0.422607  [   86/   89]
per-ex loss: 0.409428  [   88/   89]
per-ex loss: 0.459710  [   89/   89]
Train Error: Avg loss: 0.43642192
validation Error: 
 Avg loss: 0.55222148 
 F1: 0.529598 
 Precision: 0.597662 
 Recall: 0.475452
 IoU: 0.360172

test Error: 
 Avg loss: 0.53521341 
 F1: 0.544472 
 Precision: 0.554990 
 Recall: 0.534345
 IoU: 0.374072

We have finished training iteration 239
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_237_.pth
per-ex loss: 0.527656  [    2/   89]
per-ex loss: 0.406533  [    4/   89]
per-ex loss: 0.591205  [    6/   89]
per-ex loss: 0.381693  [    8/   89]
per-ex loss: 0.391646  [   10/   89]
per-ex loss: 0.405259  [   12/   89]
per-ex loss: 0.416796  [   14/   89]
per-ex loss: 0.351344  [   16/   89]
per-ex loss: 0.331645  [   18/   89]
per-ex loss: 0.459773  [   20/   89]
per-ex loss: 0.601080  [   22/   89]
per-ex loss: 0.441361  [   24/   89]
per-ex loss: 0.392021  [   26/   89]
per-ex loss: 0.514574  [   28/   89]
per-ex loss: 0.391650  [   30/   89]
per-ex loss: 0.376900  [   32/   89]
per-ex loss: 0.444749  [   34/   89]
per-ex loss: 0.335212  [   36/   89]
per-ex loss: 0.388820  [   38/   89]
per-ex loss: 0.484646  [   40/   89]
per-ex loss: 0.509831  [   42/   89]
per-ex loss: 0.481713  [   44/   89]
per-ex loss: 0.410753  [   46/   89]
per-ex loss: 0.417641  [   48/   89]
per-ex loss: 0.602796  [   50/   89]
per-ex loss: 0.576077  [   52/   89]
per-ex loss: 0.396788  [   54/   89]
per-ex loss: 0.455909  [   56/   89]
per-ex loss: 0.392806  [   58/   89]
per-ex loss: 0.726949  [   60/   89]
per-ex loss: 0.416827  [   62/   89]
per-ex loss: 0.380624  [   64/   89]
per-ex loss: 0.341213  [   66/   89]
per-ex loss: 0.570524  [   68/   89]
per-ex loss: 0.357881  [   70/   89]
per-ex loss: 0.411751  [   72/   89]
per-ex loss: 0.299333  [   74/   89]
per-ex loss: 0.440931  [   76/   89]
per-ex loss: 0.399229  [   78/   89]
per-ex loss: 0.446164  [   80/   89]
per-ex loss: 0.387440  [   82/   89]
per-ex loss: 0.354731  [   84/   89]
per-ex loss: 0.397287  [   86/   89]
per-ex loss: 0.547950  [   88/   89]
per-ex loss: 0.704490  [   89/   89]
Train Error: Avg loss: 0.44582668
validation Error: 
 Avg loss: 0.56022769 
 F1: 0.521981 
 Precision: 0.627876 
 Recall: 0.446651
 IoU: 0.353163

test Error: 
 Avg loss: 0.52582473 
 F1: 0.557027 
 Precision: 0.624751 
 Recall: 0.502550
 IoU: 0.386027

We have finished training iteration 240
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_238_.pth
per-ex loss: 0.356425  [    2/   89]
per-ex loss: 0.481342  [    4/   89]
per-ex loss: 0.392272  [    6/   89]
per-ex loss: 0.722430  [    8/   89]
per-ex loss: 0.371776  [   10/   89]
per-ex loss: 0.395277  [   12/   89]
per-ex loss: 0.323965  [   14/   89]
per-ex loss: 0.396570  [   16/   89]
per-ex loss: 0.478446  [   18/   89]
per-ex loss: 0.487761  [   20/   89]
per-ex loss: 0.380103  [   22/   89]
per-ex loss: 0.285146  [   24/   89]
per-ex loss: 0.493622  [   26/   89]
per-ex loss: 0.577202  [   28/   89]
per-ex loss: 0.666839  [   30/   89]
per-ex loss: 0.370105  [   32/   89]
per-ex loss: 0.341536  [   34/   89]
per-ex loss: 0.397563  [   36/   89]
per-ex loss: 0.383250  [   38/   89]
per-ex loss: 0.338544  [   40/   89]
per-ex loss: 0.561033  [   42/   89]
per-ex loss: 0.574059  [   44/   89]
per-ex loss: 0.353545  [   46/   89]
per-ex loss: 0.684941  [   48/   89]
per-ex loss: 0.425320  [   50/   89]
per-ex loss: 0.426052  [   52/   89]
per-ex loss: 0.411012  [   54/   89]
per-ex loss: 0.447167  [   56/   89]
per-ex loss: 0.504469  [   58/   89]
per-ex loss: 0.602818  [   60/   89]
per-ex loss: 0.343985  [   62/   89]
per-ex loss: 0.400166  [   64/   89]
per-ex loss: 0.507701  [   66/   89]
per-ex loss: 0.419810  [   68/   89]
per-ex loss: 0.526121  [   70/   89]
per-ex loss: 0.428769  [   72/   89]
per-ex loss: 0.322080  [   74/   89]
per-ex loss: 0.361339  [   76/   89]
per-ex loss: 0.505149  [   78/   89]
per-ex loss: 0.515625  [   80/   89]
per-ex loss: 0.398546  [   82/   89]
per-ex loss: 0.514020  [   84/   89]
per-ex loss: 0.593280  [   86/   89]
per-ex loss: 0.520034  [   88/   89]
per-ex loss: 0.378631  [   89/   89]
Train Error: Avg loss: 0.45257442
validation Error: 
 Avg loss: 0.54869755 
 F1: 0.527113 
 Precision: 0.608572 
 Recall: 0.464887
 IoU: 0.357878

test Error: 
 Avg loss: 0.52718016 
 F1: 0.550494 
 Precision: 0.592442 
 Recall: 0.514094
 IoU: 0.379781

We have finished training iteration 241
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_239_.pth
per-ex loss: 0.458698  [    2/   89]
per-ex loss: 0.360547  [    4/   89]
per-ex loss: 0.338537  [    6/   89]
per-ex loss: 0.566252  [    8/   89]
per-ex loss: 0.476836  [   10/   89]
per-ex loss: 0.444900  [   12/   89]
per-ex loss: 0.433843  [   14/   89]
per-ex loss: 0.408802  [   16/   89]
per-ex loss: 0.497095  [   18/   89]
per-ex loss: 0.588985  [   20/   89]
per-ex loss: 0.569716  [   22/   89]
per-ex loss: 0.344956  [   24/   89]
per-ex loss: 0.382110  [   26/   89]
per-ex loss: 0.495156  [   28/   89]
per-ex loss: 0.412758  [   30/   89]
per-ex loss: 0.568558  [   32/   89]
per-ex loss: 0.434133  [   34/   89]
per-ex loss: 0.359682  [   36/   89]
per-ex loss: 0.461680  [   38/   89]
per-ex loss: 0.412326  [   40/   89]
per-ex loss: 0.271541  [   42/   89]
per-ex loss: 0.530852  [   44/   89]
per-ex loss: 0.477798  [   46/   89]
per-ex loss: 0.575231  [   48/   89]
per-ex loss: 0.365438  [   50/   89]
per-ex loss: 0.412304  [   52/   89]
per-ex loss: 0.551957  [   54/   89]
per-ex loss: 0.598506  [   56/   89]
per-ex loss: 0.328335  [   58/   89]
per-ex loss: 0.453633  [   60/   89]
per-ex loss: 0.391633  [   62/   89]
per-ex loss: 0.414322  [   64/   89]
per-ex loss: 0.336554  [   66/   89]
per-ex loss: 0.447246  [   68/   89]
per-ex loss: 0.451391  [   70/   89]
per-ex loss: 0.425716  [   72/   89]
per-ex loss: 0.343787  [   74/   89]
per-ex loss: 0.635822  [   76/   89]
per-ex loss: 0.564481  [   78/   89]
per-ex loss: 0.344526  [   80/   89]
per-ex loss: 0.352869  [   82/   89]
per-ex loss: 0.350942  [   84/   89]
per-ex loss: 0.573443  [   86/   89]
per-ex loss: 0.375453  [   88/   89]
per-ex loss: 0.430210  [   89/   89]
Train Error: Avg loss: 0.44487914
validation Error: 
 Avg loss: 0.54100875 
 F1: 0.514505 
 Precision: 0.671803 
 Recall: 0.416892
 IoU: 0.346352

test Error: 
 Avg loss: 0.53311081 
 F1: 0.536348 
 Precision: 0.650280 
 Recall: 0.456386
 IoU: 0.366445

We have finished training iteration 242
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_240_.pth
per-ex loss: 0.474163  [    2/   89]
per-ex loss: 0.554890  [    4/   89]
per-ex loss: 0.335360  [    6/   89]
per-ex loss: 0.476415  [    8/   89]
per-ex loss: 0.432208  [   10/   89]
per-ex loss: 0.379918  [   12/   89]
per-ex loss: 0.443865  [   14/   89]
per-ex loss: 0.367854  [   16/   89]
per-ex loss: 0.307347  [   18/   89]
per-ex loss: 0.451931  [   20/   89]
per-ex loss: 0.543386  [   22/   89]
per-ex loss: 0.420163  [   24/   89]
per-ex loss: 0.323542  [   26/   89]
per-ex loss: 0.640572  [   28/   89]
per-ex loss: 0.478514  [   30/   89]
per-ex loss: 0.479277  [   32/   89]
per-ex loss: 0.418417  [   34/   89]
per-ex loss: 0.444738  [   36/   89]
per-ex loss: 0.462201  [   38/   89]
per-ex loss: 0.592232  [   40/   89]
per-ex loss: 0.595588  [   42/   89]
per-ex loss: 0.406416  [   44/   89]
per-ex loss: 0.459813  [   46/   89]
per-ex loss: 0.403660  [   48/   89]
per-ex loss: 0.392187  [   50/   89]
per-ex loss: 0.474568  [   52/   89]
per-ex loss: 0.440116  [   54/   89]
per-ex loss: 0.316215  [   56/   89]
per-ex loss: 0.465787  [   58/   89]
per-ex loss: 0.345939  [   60/   89]
per-ex loss: 0.403266  [   62/   89]
per-ex loss: 0.409212  [   64/   89]
per-ex loss: 0.373600  [   66/   89]
per-ex loss: 0.359883  [   68/   89]
per-ex loss: 0.351864  [   70/   89]
per-ex loss: 0.742938  [   72/   89]
per-ex loss: 0.406384  [   74/   89]
per-ex loss: 0.615778  [   76/   89]
per-ex loss: 0.445777  [   78/   89]
per-ex loss: 0.239627  [   80/   89]
per-ex loss: 0.433945  [   82/   89]
per-ex loss: 0.729245  [   84/   89]
per-ex loss: 0.484657  [   86/   89]
per-ex loss: 0.347321  [   88/   89]
per-ex loss: 0.376962  [   89/   89]
Train Error: Avg loss: 0.44550529
validation Error: 
 Avg loss: 0.55885982 
 F1: 0.527668 
 Precision: 0.616716 
 Recall: 0.461090
 IoU: 0.358389

test Error: 
 Avg loss: 0.52762638 
 F1: 0.551781 
 Precision: 0.598510 
 Recall: 0.511820
 IoU: 0.381007

We have finished training iteration 243
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_241_.pth
per-ex loss: 0.400184  [    2/   89]
per-ex loss: 0.429133  [    4/   89]
per-ex loss: 0.437401  [    6/   89]
per-ex loss: 0.375161  [    8/   89]
per-ex loss: 0.435008  [   10/   89]
per-ex loss: 0.352551  [   12/   89]
per-ex loss: 0.385236  [   14/   89]
per-ex loss: 0.426854  [   16/   89]
per-ex loss: 0.531716  [   18/   89]
per-ex loss: 0.571064  [   20/   89]
per-ex loss: 0.616166  [   22/   89]
per-ex loss: 0.644182  [   24/   89]
per-ex loss: 0.388335  [   26/   89]
per-ex loss: 0.440304  [   28/   89]
per-ex loss: 0.381554  [   30/   89]
per-ex loss: 0.362817  [   32/   89]
per-ex loss: 0.331432  [   34/   89]
per-ex loss: 0.438636  [   36/   89]
per-ex loss: 0.376464  [   38/   89]
per-ex loss: 0.396295  [   40/   89]
per-ex loss: 0.386910  [   42/   89]
per-ex loss: 0.407807  [   44/   89]
per-ex loss: 0.536169  [   46/   89]
per-ex loss: 0.594314  [   48/   89]
per-ex loss: 0.438857  [   50/   89]
per-ex loss: 0.387315  [   52/   89]
per-ex loss: 0.608175  [   54/   89]
per-ex loss: 0.407085  [   56/   89]
per-ex loss: 0.565232  [   58/   89]
per-ex loss: 0.454946  [   60/   89]
per-ex loss: 0.364245  [   62/   89]
per-ex loss: 0.658253  [   64/   89]
per-ex loss: 0.368170  [   66/   89]
per-ex loss: 0.368472  [   68/   89]
per-ex loss: 0.368838  [   70/   89]
per-ex loss: 0.673567  [   72/   89]
per-ex loss: 0.419940  [   74/   89]
per-ex loss: 0.508194  [   76/   89]
per-ex loss: 0.443501  [   78/   89]
per-ex loss: 0.634060  [   80/   89]
per-ex loss: 0.331670  [   82/   89]
per-ex loss: 0.406684  [   84/   89]
per-ex loss: 0.433590  [   86/   89]
per-ex loss: 0.374746  [   88/   89]
per-ex loss: 0.312005  [   89/   89]
Train Error: Avg loss: 0.44829417
validation Error: 
 Avg loss: 0.54671499 
 F1: 0.528420 
 Precision: 0.609203 
 Recall: 0.466553
 IoU: 0.359084

test Error: 
 Avg loss: 0.53159336 
 F1: 0.542514 
 Precision: 0.578429 
 Recall: 0.510799
 IoU: 0.372226

We have finished training iteration 244
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_242_.pth
per-ex loss: 0.384045  [    2/   89]
per-ex loss: 0.394531  [    4/   89]
per-ex loss: 0.381320  [    6/   89]
per-ex loss: 0.281280  [    8/   89]
per-ex loss: 0.592691  [   10/   89]
per-ex loss: 0.418818  [   12/   89]
per-ex loss: 0.352693  [   14/   89]
per-ex loss: 0.585337  [   16/   89]
per-ex loss: 0.555356  [   18/   89]
per-ex loss: 0.400416  [   20/   89]
per-ex loss: 0.344705  [   22/   89]
per-ex loss: 0.378088  [   24/   89]
per-ex loss: 0.433129  [   26/   89]
per-ex loss: 0.502922  [   28/   89]
per-ex loss: 0.468502  [   30/   89]
per-ex loss: 0.336811  [   32/   89]
per-ex loss: 0.456731  [   34/   89]
per-ex loss: 0.637703  [   36/   89]
per-ex loss: 0.357795  [   38/   89]
per-ex loss: 0.572951  [   40/   89]
per-ex loss: 0.393321  [   42/   89]
per-ex loss: 0.413897  [   44/   89]
per-ex loss: 0.564043  [   46/   89]
per-ex loss: 0.588559  [   48/   89]
per-ex loss: 0.476462  [   50/   89]
per-ex loss: 0.477049  [   52/   89]
per-ex loss: 0.393222  [   54/   89]
per-ex loss: 0.417173  [   56/   89]
per-ex loss: 0.628448  [   58/   89]
per-ex loss: 0.489943  [   60/   89]
per-ex loss: 0.442020  [   62/   89]
per-ex loss: 0.357256  [   64/   89]
per-ex loss: 0.403044  [   66/   89]
per-ex loss: 0.349099  [   68/   89]
per-ex loss: 0.522083  [   70/   89]
per-ex loss: 0.567321  [   72/   89]
per-ex loss: 0.336046  [   74/   89]
per-ex loss: 0.636614  [   76/   89]
per-ex loss: 0.386287  [   78/   89]
per-ex loss: 0.397508  [   80/   89]
per-ex loss: 0.469941  [   82/   89]
per-ex loss: 0.380225  [   84/   89]
per-ex loss: 0.405915  [   86/   89]
per-ex loss: 0.465570  [   88/   89]
per-ex loss: 0.353402  [   89/   89]
Train Error: Avg loss: 0.44778383
validation Error: 
 Avg loss: 0.54938768 
 F1: 0.529802 
 Precision: 0.607108 
 Recall: 0.469961
 IoU: 0.360361

test Error: 
 Avg loss: 0.53085374 
 F1: 0.547336 
 Precision: 0.585647 
 Recall: 0.513730
 IoU: 0.376781

We have finished training iteration 245
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_243_.pth
per-ex loss: 0.369143  [    2/   89]
per-ex loss: 0.376711  [    4/   89]
per-ex loss: 0.343635  [    6/   89]
per-ex loss: 0.339802  [    8/   89]
per-ex loss: 0.371264  [   10/   89]
per-ex loss: 0.499803  [   12/   89]
per-ex loss: 0.636693  [   14/   89]
per-ex loss: 0.570060  [   16/   89]
per-ex loss: 0.565653  [   18/   89]
per-ex loss: 0.642347  [   20/   89]
per-ex loss: 0.361241  [   22/   89]
per-ex loss: 0.511165  [   24/   89]
per-ex loss: 0.439016  [   26/   89]
per-ex loss: 0.362732  [   28/   89]
per-ex loss: 0.393974  [   30/   89]
per-ex loss: 0.454939  [   32/   89]
per-ex loss: 0.343015  [   34/   89]
per-ex loss: 0.534824  [   36/   89]
per-ex loss: 0.462932  [   38/   89]
per-ex loss: 0.559606  [   40/   89]
per-ex loss: 0.520206  [   42/   89]
per-ex loss: 0.348596  [   44/   89]
per-ex loss: 0.383549  [   46/   89]
per-ex loss: 0.427599  [   48/   89]
per-ex loss: 0.494355  [   50/   89]
per-ex loss: 0.354038  [   52/   89]
per-ex loss: 0.380137  [   54/   89]
per-ex loss: 0.426955  [   56/   89]
per-ex loss: 0.596450  [   58/   89]
per-ex loss: 0.340314  [   60/   89]
per-ex loss: 0.572962  [   62/   89]
per-ex loss: 0.436111  [   64/   89]
per-ex loss: 0.485531  [   66/   89]
per-ex loss: 0.306771  [   68/   89]
per-ex loss: 0.391888  [   70/   89]
per-ex loss: 0.352222  [   72/   89]
per-ex loss: 0.356835  [   74/   89]
per-ex loss: 0.391583  [   76/   89]
per-ex loss: 0.579723  [   78/   89]
per-ex loss: 0.386214  [   80/   89]
per-ex loss: 0.285428  [   82/   89]
per-ex loss: 0.444111  [   84/   89]
per-ex loss: 0.558824  [   86/   89]
per-ex loss: 0.334420  [   88/   89]
per-ex loss: 0.315906  [   89/   89]
Train Error: Avg loss: 0.43576187
validation Error: 
 Avg loss: 0.54511928 
 F1: 0.533229 
 Precision: 0.590610 
 Recall: 0.486011
 IoU: 0.363540

test Error: 
 Avg loss: 0.53204704 
 F1: 0.541125 
 Precision: 0.544926 
 Recall: 0.537377
 IoU: 0.370919

We have finished training iteration 246
Deleting model ./unet_zsc_train/saved_model_wrapper/models/UNet_244_.pth
Max training iterations reached: 200. Train_iter: 246, Initial_train_iter: 46
