/shared/home/matevz.vidovic/Diplomska/Prototip/Delo/model_wrapper.py:111: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.model = torch.load(self.prev_model_path, map_location=torch.device(device))
unet_original_main.py do_log: True
Log file name: log_08_11-22-08_01-2025.log.
            Add print_log_file_name=False to file_handler_setup() to disable this printout.
min_resource_percentage.py do_log: False
model_wrapper.py do_log: True
training_wrapper.py do_log: True
helper_img_and_fig_tools.py do_log: False
conv_resource_calc.py do_log: False
pruner.py do_log: False
helper_model_vizualization.py do_log: False
training_support.py do_log: True
helper_model_eval_graphs.py do_log: False
losses.py do_log: False
Args: Namespace(ptd='./Data/vein_and_sclera_data', sd='unet_b_train', mti=200, mtti=1000000000.0, pruning_phase=False, ifn='IPAD_eq', ips=1000000000.0, tras=-1, tp=False, yaml='z_pipeline_unet/unet_original_b.yaml', ntibp=None, ptp=None, map=None)
YAML: {'batch_size': 2, 'learning_rate': 1e-06, 'num_of_dataloader_workers': 7, 'train_epoch_size_limit': 400, 'num_epochs_per_training_iteration': 1, 'cleanup_k': 3, 'dataset_option': 'aug_bcosfire', 'optimizer_used': 'Adam', 'zero_out_non_sclera_on_predictions': False, 'loss_fn_name': 'MCDL', 'alphas': [], 'model': '64_2_6', 'input_width': 2048, 'input_height': 1024, 'input_channels': 4, 'output_channels': 2, 'num_train_iters_between_prunings': 10, 'max_auto_prunings': 70, 'proportion_to_prune': 0.01, 'prune_by_original_percent': True, 'num_filters_to_prune': -1, 'prune_n_kernels_at_once': 100, 'resource_name_to_prune_by': 'flops_num', 'importance_func': 'IPAD_eq'}
Validation phase: False
Namespace(ptd='./Data/vein_and_sclera_data', sd='unet_b_train', mti=200, mtti=1000000000.0, pruning_phase=False, ifn='IPAD_eq', ips=1000000000.0, tras=-1, tp=False, yaml='z_pipeline_unet/unet_original_b.yaml', ntibp=None, ptp=None, map=None)
Device: cuda
dataset_aug_bcosfire.py do_log: False
img_augments.py do_log: False
path to file: ./Data/vein_and_sclera_data
summary for train
valid images: 89
summary for val
valid images: 27
summary for test
valid images: 12
train dataset len: 89
val dataset len: 27
test dataset len: 12
train dataloader num of batches: 45
val dataloader num of batches: 14
test dataloader num of batches: 6
Loaded model path:  ./unet_b_train/saved_model_wrapper/models/UNet_334_.pth
per-ex loss: 0.547547  [    2/   89]
per-ex loss: 0.359311  [    4/   89]
per-ex loss: 0.389444  [    6/   89]
per-ex loss: 0.461920  [    8/   89]
per-ex loss: 0.395708  [   10/   89]
per-ex loss: 0.381254  [   12/   89]
per-ex loss: 0.516510  [   14/   89]
per-ex loss: 0.343383  [   16/   89]
per-ex loss: 0.461771  [   18/   89]
per-ex loss: 0.430492  [   20/   89]
per-ex loss: 0.627430  [   22/   89]
per-ex loss: 0.746411  [   24/   89]
per-ex loss: 0.401868  [   26/   89]
per-ex loss: 0.636080  [   28/   89]
per-ex loss: 0.456668  [   30/   89]
per-ex loss: 0.382021  [   32/   89]
per-ex loss: 0.461490  [   34/   89]
per-ex loss: 0.500138  [   36/   89]
per-ex loss: 0.512926  [   38/   89]
per-ex loss: 0.415666  [   40/   89]
per-ex loss: 0.422122  [   42/   89]
per-ex loss: 0.583039  [   44/   89]
per-ex loss: 0.467660  [   46/   89]
per-ex loss: 0.535631  [   48/   89]
per-ex loss: 0.370638  [   50/   89]
per-ex loss: 0.601452  [   52/   89]
per-ex loss: 0.598048  [   54/   89]
per-ex loss: 0.387409  [   56/   89]
per-ex loss: 0.454884  [   58/   89]
per-ex loss: 0.413061  [   60/   89]
per-ex loss: 0.481661  [   62/   89]
per-ex loss: 0.418399  [   64/   89]
per-ex loss: 0.402047  [   66/   89]
per-ex loss: 0.384140  [   68/   89]
per-ex loss: 0.452810  [   70/   89]
per-ex loss: 0.372597  [   72/   89]
per-ex loss: 0.409384  [   74/   89]
per-ex loss: 0.355808  [   76/   89]
per-ex loss: 0.639401  [   78/   89]
per-ex loss: 0.518754  [   80/   89]
per-ex loss: 0.565368  [   82/   89]
per-ex loss: 0.606195  [   84/   89]
per-ex loss: 0.625814  [   86/   89]
per-ex loss: 0.422385  [   88/   89]
per-ex loss: 0.543365  [   89/   89]
Train Error: Avg loss: 0.47689133
validation Error: 
 Avg loss: 0.51595652 
 F1: 0.506025 
 Precision: 0.616026 
 Recall: 0.429357
 IoU: 0.338710

test Error: 
 Avg loss: 0.48139640 
 F1: 0.554928 
 Precision: 0.680242 
 Recall: 0.468602
 IoU: 0.384014

We have finished training iteration 335
Couldn't delete ./unet_b_train/saved_model_wrapper/models/UNet_333_.pth. Probably doesn't exist.
per-ex loss: 0.370819  [    2/   89]
per-ex loss: 0.402852  [    4/   89]
per-ex loss: 0.436395  [    6/   89]
per-ex loss: 0.560665  [    8/   89]
per-ex loss: 0.592155  [   10/   89]
per-ex loss: 0.633134  [   12/   89]
per-ex loss: 0.350376  [   14/   89]
per-ex loss: 0.505467  [   16/   89]
per-ex loss: 0.409447  [   18/   89]
per-ex loss: 0.537678  [   20/   89]
per-ex loss: 0.454646  [   22/   89]
per-ex loss: 0.601184  [   24/   89]
per-ex loss: 0.474520  [   26/   89]
per-ex loss: 0.434621  [   28/   89]
per-ex loss: 0.629136  [   30/   89]
per-ex loss: 0.441492  [   32/   89]
per-ex loss: 0.486951  [   34/   89]
per-ex loss: 0.403332  [   36/   89]
per-ex loss: 0.503920  [   38/   89]
per-ex loss: 0.532666  [   40/   89]
per-ex loss: 0.426419  [   42/   89]
per-ex loss: 0.428852  [   44/   89]
per-ex loss: 0.428148  [   46/   89]
per-ex loss: 0.695285  [   48/   89]
per-ex loss: 0.461860  [   50/   89]
per-ex loss: 0.425575  [   52/   89]
per-ex loss: 0.534042  [   54/   89]
per-ex loss: 0.385807  [   56/   89]
per-ex loss: 0.425341  [   58/   89]
per-ex loss: 0.554284  [   60/   89]
per-ex loss: 0.420137  [   62/   89]
per-ex loss: 0.404333  [   64/   89]
per-ex loss: 0.494483  [   66/   89]
per-ex loss: 0.397322  [   68/   89]
per-ex loss: 0.567476  [   70/   89]
per-ex loss: 0.590324  [   72/   89]
per-ex loss: 0.559926  [   74/   89]
per-ex loss: 0.359319  [   76/   89]
per-ex loss: 0.377899  [   78/   89]
per-ex loss: 0.447322  [   80/   89]
per-ex loss: 0.442340  [   82/   89]
per-ex loss: 0.433565  [   84/   89]
per-ex loss: 0.393485  [   86/   89]
per-ex loss: 0.427965  [   88/   89]
per-ex loss: 0.592086  [   89/   89]
Train Error: Avg loss: 0.47633443
validation Error: 
 Avg loss: 0.51261152 
 F1: 0.506608 
 Precision: 0.592053 
 Recall: 0.442715
 IoU: 0.339233

test Error: 
 Avg loss: 0.47793075 
 F1: 0.558947 
 Precision: 0.671362 
 Recall: 0.478779
 IoU: 0.387874

We have finished training iteration 336
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_334_.pth
per-ex loss: 0.601738  [    2/   89]
per-ex loss: 0.388545  [    4/   89]
per-ex loss: 0.386780  [    6/   89]
per-ex loss: 0.503420  [    8/   89]
per-ex loss: 0.564992  [   10/   89]
per-ex loss: 0.435671  [   12/   89]
per-ex loss: 0.677746  [   14/   89]
per-ex loss: 0.459663  [   16/   89]
per-ex loss: 0.581657  [   18/   89]
per-ex loss: 0.514169  [   20/   89]
per-ex loss: 0.485910  [   22/   89]
per-ex loss: 0.394610  [   24/   89]
per-ex loss: 0.444801  [   26/   89]
per-ex loss: 0.447370  [   28/   89]
per-ex loss: 0.418884  [   30/   89]
per-ex loss: 0.394528  [   32/   89]
per-ex loss: 0.631579  [   34/   89]
per-ex loss: 0.512950  [   36/   89]
per-ex loss: 0.438597  [   38/   89]
per-ex loss: 0.439166  [   40/   89]
per-ex loss: 0.366478  [   42/   89]
per-ex loss: 0.415550  [   44/   89]
per-ex loss: 0.421569  [   46/   89]
per-ex loss: 0.443441  [   48/   89]
per-ex loss: 0.483787  [   50/   89]
per-ex loss: 0.412094  [   52/   89]
per-ex loss: 0.584363  [   54/   89]
per-ex loss: 0.371292  [   56/   89]
per-ex loss: 0.545175  [   58/   89]
per-ex loss: 0.583612  [   60/   89]
per-ex loss: 0.466005  [   62/   89]
per-ex loss: 0.380663  [   64/   89]
per-ex loss: 0.399305  [   66/   89]
per-ex loss: 0.539639  [   68/   89]
per-ex loss: 0.517896  [   70/   89]
per-ex loss: 0.389143  [   72/   89]
per-ex loss: 0.462019  [   74/   89]
per-ex loss: 0.449037  [   76/   89]
per-ex loss: 0.522608  [   78/   89]
per-ex loss: 0.491448  [   80/   89]
per-ex loss: 0.405569  [   82/   89]
per-ex loss: 0.354448  [   84/   89]
per-ex loss: 0.465787  [   86/   89]
per-ex loss: 0.466832  [   88/   89]
per-ex loss: 0.330161  [   89/   89]
Train Error: Avg loss: 0.46645993
validation Error: 
 Avg loss: 0.51779132 
 F1: 0.509934 
 Precision: 0.593065 
 Recall: 0.447242
 IoU: 0.342222

test Error: 
 Avg loss: 0.47440964 
 F1: 0.562801 
 Precision: 0.671292 
 Recall: 0.484499
 IoU: 0.391596

We have finished training iteration 337
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_335_.pth
Error in cropping the image to the non-zero values in the fourth channel. Returned the original image.
per-ex loss: 0.513875  [    2/   89]
per-ex loss: 0.402624  [    4/   89]
per-ex loss: 0.353929  [    6/   89]
per-ex loss: 0.510327  [    8/   89]
per-ex loss: 0.463657  [   10/   89]
per-ex loss: 0.587385  [   12/   89]
per-ex loss: 0.644690  [   14/   89]
per-ex loss: 0.560564  [   16/   89]
per-ex loss: 0.382281  [   18/   89]
per-ex loss: 0.650577  [   20/   89]
per-ex loss: 0.385419  [   22/   89]
per-ex loss: 0.372685  [   24/   89]
per-ex loss: 0.435649  [   26/   89]
per-ex loss: 0.461446  [   28/   89]
per-ex loss: 0.387853  [   30/   89]
per-ex loss: 0.488232  [   32/   89]
per-ex loss: 0.565578  [   34/   89]
per-ex loss: 0.585588  [   36/   89]
per-ex loss: 0.415344  [   38/   89]
per-ex loss: 0.355188  [   40/   89]
per-ex loss: 0.532036  [   42/   89]
per-ex loss: 0.454840  [   44/   89]
per-ex loss: 0.451156  [   46/   89]
per-ex loss: 0.506388  [   48/   89]
per-ex loss: 0.372617  [   50/   89]
per-ex loss: 0.473838  [   52/   89]
per-ex loss: 0.523131  [   54/   89]
per-ex loss: 0.475893  [   56/   89]
per-ex loss: 0.576794  [   58/   89]
per-ex loss: 0.570520  [   60/   89]
per-ex loss: 0.420318  [   62/   89]
per-ex loss: 0.369289  [   64/   89]
per-ex loss: 0.546862  [   66/   89]
per-ex loss: 0.481124  [   68/   89]
per-ex loss: 0.363079  [   70/   89]
per-ex loss: 0.572583  [   72/   89]
per-ex loss: 0.629045  [   74/   89]
per-ex loss: 0.520368  [   76/   89]
per-ex loss: 0.406008  [   78/   89]
per-ex loss: 0.628912  [   80/   89]
per-ex loss: 0.357441  [   82/   89]
per-ex loss: 0.459658  [   84/   89]
per-ex loss: 0.498400  [   86/   89]
per-ex loss: 0.476747  [   88/   89]
per-ex loss: 0.408168  [   89/   89]
Train Error: Avg loss: 0.47995792
validation Error: 
 Avg loss: 0.53857421 
 F1: 0.486478 
 Precision: 0.606947 
 Recall: 0.405911
 IoU: 0.321421

test Error: 
 Avg loss: 0.51433377 
 F1: 0.522295 
 Precision: 0.641182 
 Recall: 0.440599
 IoU: 0.353450

We have finished training iteration 338
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_323_.pth
per-ex loss: 0.534152  [    2/   89]
per-ex loss: 0.583513  [    4/   89]
per-ex loss: 0.481426  [    6/   89]
per-ex loss: 0.685063  [    8/   89]
per-ex loss: 0.352694  [   10/   89]
per-ex loss: 0.427424  [   12/   89]
per-ex loss: 0.466728  [   14/   89]
per-ex loss: 0.374257  [   16/   89]
per-ex loss: 0.374183  [   18/   89]
per-ex loss: 0.401426  [   20/   89]
per-ex loss: 0.400704  [   22/   89]
per-ex loss: 0.382996  [   24/   89]
per-ex loss: 0.446252  [   26/   89]
per-ex loss: 0.621464  [   28/   89]
per-ex loss: 0.500653  [   30/   89]
per-ex loss: 0.401374  [   32/   89]
per-ex loss: 0.521529  [   34/   89]
per-ex loss: 0.355677  [   36/   89]
per-ex loss: 0.486516  [   38/   89]
per-ex loss: 0.635587  [   40/   89]
per-ex loss: 0.494804  [   42/   89]
per-ex loss: 0.448736  [   44/   89]
per-ex loss: 0.464596  [   46/   89]
per-ex loss: 0.420255  [   48/   89]
per-ex loss: 0.561956  [   50/   89]
per-ex loss: 0.453238  [   52/   89]
per-ex loss: 0.648095  [   54/   89]
per-ex loss: 0.416076  [   56/   89]
per-ex loss: 0.471233  [   58/   89]
per-ex loss: 0.383859  [   60/   89]
per-ex loss: 0.575179  [   62/   89]
per-ex loss: 0.383300  [   64/   89]
per-ex loss: 0.535537  [   66/   89]
per-ex loss: 0.412961  [   68/   89]
per-ex loss: 0.421658  [   70/   89]
per-ex loss: 0.418960  [   72/   89]
per-ex loss: 0.532636  [   74/   89]
per-ex loss: 0.584285  [   76/   89]
per-ex loss: 0.550941  [   78/   89]
per-ex loss: 0.448044  [   80/   89]
per-ex loss: 0.409729  [   82/   89]
per-ex loss: 0.395493  [   84/   89]
per-ex loss: 0.490309  [   86/   89]
per-ex loss: 0.558955  [   88/   89]
per-ex loss: 0.385443  [   89/   89]
Train Error: Avg loss: 0.47333104
validation Error: 
 Avg loss: 0.52446029 
 F1: 0.492527 
 Precision: 0.630558 
 Recall: 0.404074
 IoU: 0.326724

test Error: 
 Avg loss: 0.50616583 
 F1: 0.530453 
 Precision: 0.669356 
 Recall: 0.439293
 IoU: 0.360964

We have finished training iteration 339
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_337_.pth
per-ex loss: 0.572431  [    2/   89]
per-ex loss: 0.538454  [    4/   89]
per-ex loss: 0.580483  [    6/   89]
per-ex loss: 0.568319  [    8/   89]
per-ex loss: 0.423364  [   10/   89]
per-ex loss: 0.496325  [   12/   89]
per-ex loss: 0.609034  [   14/   89]
per-ex loss: 0.513925  [   16/   89]
per-ex loss: 0.360060  [   18/   89]
per-ex loss: 0.548106  [   20/   89]
per-ex loss: 0.469104  [   22/   89]
per-ex loss: 0.467303  [   24/   89]
per-ex loss: 0.528129  [   26/   89]
per-ex loss: 0.378303  [   28/   89]
per-ex loss: 0.635261  [   30/   89]
per-ex loss: 0.369340  [   32/   89]
per-ex loss: 0.483590  [   34/   89]
per-ex loss: 0.484697  [   36/   89]
per-ex loss: 0.623195  [   38/   89]
per-ex loss: 0.450345  [   40/   89]
per-ex loss: 0.462546  [   42/   89]
per-ex loss: 0.400239  [   44/   89]
per-ex loss: 0.482669  [   46/   89]
per-ex loss: 0.366760  [   48/   89]
per-ex loss: 0.449620  [   50/   89]
per-ex loss: 0.429934  [   52/   89]
per-ex loss: 0.391424  [   54/   89]
per-ex loss: 0.673126  [   56/   89]
per-ex loss: 0.401112  [   58/   89]
per-ex loss: 0.419233  [   60/   89]
per-ex loss: 0.473358  [   62/   89]
per-ex loss: 0.481681  [   64/   89]
per-ex loss: 0.435963  [   66/   89]
per-ex loss: 0.484521  [   68/   89]
per-ex loss: 0.444223  [   70/   89]
per-ex loss: 0.487718  [   72/   89]
per-ex loss: 0.389693  [   74/   89]
per-ex loss: 0.373200  [   76/   89]
per-ex loss: 0.388532  [   78/   89]
per-ex loss: 0.457782  [   80/   89]
per-ex loss: 0.479119  [   82/   89]
per-ex loss: 0.477005  [   84/   89]
per-ex loss: 0.425570  [   86/   89]
per-ex loss: 0.365940  [   88/   89]
per-ex loss: 0.709158  [   89/   89]
Train Error: Avg loss: 0.47666435
validation Error: 
 Avg loss: 0.50145636 
 F1: 0.508221 
 Precision: 0.608536 
 Recall: 0.436299
 IoU: 0.340681

test Error: 
 Avg loss: 0.47793580 
 F1: 0.559131 
 Precision: 0.685117 
 Recall: 0.472283
 IoU: 0.388051

We have finished training iteration 340
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_338_.pth
per-ex loss: 0.363595  [    2/   89]
per-ex loss: 0.424096  [    4/   89]
per-ex loss: 0.629218  [    6/   89]
per-ex loss: 0.489023  [    8/   89]
per-ex loss: 0.458663  [   10/   89]
per-ex loss: 0.615654  [   12/   89]
per-ex loss: 0.499842  [   14/   89]
per-ex loss: 0.410279  [   16/   89]
per-ex loss: 0.642590  [   18/   89]
per-ex loss: 0.373968  [   20/   89]
per-ex loss: 0.394833  [   22/   89]
per-ex loss: 0.389865  [   24/   89]
per-ex loss: 0.423513  [   26/   89]
per-ex loss: 0.497685  [   28/   89]
per-ex loss: 0.424313  [   30/   89]
per-ex loss: 0.511232  [   32/   89]
per-ex loss: 0.428670  [   34/   89]
per-ex loss: 0.359549  [   36/   89]
per-ex loss: 0.518290  [   38/   89]
per-ex loss: 0.464799  [   40/   89]
per-ex loss: 0.474880  [   42/   89]
per-ex loss: 0.425201  [   44/   89]
per-ex loss: 0.374150  [   46/   89]
per-ex loss: 0.425710  [   48/   89]
per-ex loss: 0.358816  [   50/   89]
per-ex loss: 0.655100  [   52/   89]
per-ex loss: 0.448198  [   54/   89]
per-ex loss: 0.474413  [   56/   89]
per-ex loss: 0.633322  [   58/   89]
per-ex loss: 0.513028  [   60/   89]
per-ex loss: 0.374084  [   62/   89]
per-ex loss: 0.669039  [   64/   89]
per-ex loss: 0.446904  [   66/   89]
per-ex loss: 0.630017  [   68/   89]
per-ex loss: 0.439632  [   70/   89]
per-ex loss: 0.497658  [   72/   89]
per-ex loss: 0.416495  [   74/   89]
per-ex loss: 0.436791  [   76/   89]
per-ex loss: 0.365466  [   78/   89]
per-ex loss: 0.482042  [   80/   89]
per-ex loss: 0.436317  [   82/   89]
per-ex loss: 0.349207  [   84/   89]
per-ex loss: 0.562388  [   86/   89]
per-ex loss: 0.453912  [   88/   89]
per-ex loss: 0.510165  [   89/   89]
Train Error: Avg loss: 0.47050241
validation Error: 
 Avg loss: 0.52577778 
 F1: 0.505771 
 Precision: 0.609321 
 Recall: 0.432304
 IoU: 0.338483

test Error: 
 Avg loss: 0.48390739 
 F1: 0.552865 
 Precision: 0.675905 
 Recall: 0.467723
 IoU: 0.382041

We have finished training iteration 341
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_339_.pth
per-ex loss: 0.423710  [    2/   89]
per-ex loss: 0.436853  [    4/   89]
per-ex loss: 0.417749  [    6/   89]
per-ex loss: 0.423290  [    8/   89]
per-ex loss: 0.478637  [   10/   89]
per-ex loss: 0.472621  [   12/   89]
per-ex loss: 0.565933  [   14/   89]
per-ex loss: 0.466921  [   16/   89]
per-ex loss: 0.502414  [   18/   89]
per-ex loss: 0.395445  [   20/   89]
per-ex loss: 0.524912  [   22/   89]
per-ex loss: 0.457867  [   24/   89]
per-ex loss: 0.430871  [   26/   89]
per-ex loss: 0.389818  [   28/   89]
per-ex loss: 0.388127  [   30/   89]
per-ex loss: 0.484327  [   32/   89]
per-ex loss: 0.660903  [   34/   89]
per-ex loss: 0.694108  [   36/   89]
per-ex loss: 0.667702  [   38/   89]
per-ex loss: 0.398588  [   40/   89]
per-ex loss: 0.370379  [   42/   89]
per-ex loss: 0.335737  [   44/   89]
per-ex loss: 0.504277  [   46/   89]
per-ex loss: 0.437986  [   48/   89]
per-ex loss: 0.440289  [   50/   89]
per-ex loss: 0.384741  [   52/   89]
per-ex loss: 0.486329  [   54/   89]
per-ex loss: 0.560864  [   56/   89]
per-ex loss: 0.392392  [   58/   89]
per-ex loss: 0.525930  [   60/   89]
per-ex loss: 0.394905  [   62/   89]
per-ex loss: 0.473182  [   64/   89]
per-ex loss: 0.606677  [   66/   89]
per-ex loss: 0.550564  [   68/   89]
per-ex loss: 0.394715  [   70/   89]
per-ex loss: 0.474378  [   72/   89]
per-ex loss: 0.457670  [   74/   89]
per-ex loss: 0.539577  [   76/   89]
per-ex loss: 0.392183  [   78/   89]
per-ex loss: 0.557684  [   80/   89]
per-ex loss: 0.375531  [   82/   89]
per-ex loss: 0.479836  [   84/   89]
per-ex loss: 0.430147  [   86/   89]
per-ex loss: 0.405273  [   88/   89]
per-ex loss: 0.391746  [   89/   89]
Train Error: Avg loss: 0.46763974
validation Error: 
 Avg loss: 0.54454408 
 F1: 0.478893 
 Precision: 0.604665 
 Recall: 0.396433
 IoU: 0.314832

test Error: 
 Avg loss: 0.52524857 
 F1: 0.511793 
 Precision: 0.628844 
 Recall: 0.431479
 IoU: 0.343899

We have finished training iteration 342
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_336_.pth
per-ex loss: 0.536397  [    2/   89]
per-ex loss: 0.477279  [    4/   89]
per-ex loss: 0.591837  [    6/   89]
per-ex loss: 0.361542  [    8/   89]
per-ex loss: 0.374392  [   10/   89]
per-ex loss: 0.394794  [   12/   89]
per-ex loss: 0.485139  [   14/   89]
per-ex loss: 0.359909  [   16/   89]
per-ex loss: 0.487917  [   18/   89]
per-ex loss: 0.355896  [   20/   89]
per-ex loss: 0.457572  [   22/   89]
per-ex loss: 0.400058  [   24/   89]
per-ex loss: 0.544453  [   26/   89]
per-ex loss: 0.441656  [   28/   89]
per-ex loss: 0.404482  [   30/   89]
per-ex loss: 0.413983  [   32/   89]
per-ex loss: 0.433409  [   34/   89]
per-ex loss: 0.470556  [   36/   89]
per-ex loss: 0.640731  [   38/   89]
per-ex loss: 0.491808  [   40/   89]
per-ex loss: 0.484117  [   42/   89]
per-ex loss: 0.450881  [   44/   89]
per-ex loss: 0.495999  [   46/   89]
per-ex loss: 0.437968  [   48/   89]
per-ex loss: 0.678299  [   50/   89]
per-ex loss: 0.359008  [   52/   89]
per-ex loss: 0.449426  [   54/   89]
per-ex loss: 0.421191  [   56/   89]
per-ex loss: 0.573934  [   58/   89]
per-ex loss: 0.535465  [   60/   89]
per-ex loss: 0.509562  [   62/   89]
per-ex loss: 0.561612  [   64/   89]
per-ex loss: 0.511605  [   66/   89]
per-ex loss: 0.427809  [   68/   89]
per-ex loss: 0.404875  [   70/   89]
per-ex loss: 0.419611  [   72/   89]
per-ex loss: 0.500325  [   74/   89]
per-ex loss: 0.560685  [   76/   89]
per-ex loss: 0.359321  [   78/   89]
per-ex loss: 0.384230  [   80/   89]
per-ex loss: 0.469126  [   82/   89]
per-ex loss: 0.493388  [   84/   89]
per-ex loss: 0.430380  [   86/   89]
per-ex loss: 0.553818  [   88/   89]
per-ex loss: 0.601441  [   89/   89]
Train Error: Avg loss: 0.47106416
validation Error: 
 Avg loss: 0.54300172 
 F1: 0.480432 
 Precision: 0.635473 
 Recall: 0.386207
 IoU: 0.316164

test Error: 
 Avg loss: 0.52378444 
 F1: 0.511884 
 Precision: 0.662089 
 Recall: 0.417229
 IoU: 0.343981

We have finished training iteration 343
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_341_.pth
per-ex loss: 0.426920  [    2/   89]
per-ex loss: 0.444715  [    4/   89]
per-ex loss: 0.461326  [    6/   89]
per-ex loss: 0.618081  [    8/   89]
per-ex loss: 0.353679  [   10/   89]
per-ex loss: 0.394343  [   12/   89]
per-ex loss: 0.558878  [   14/   89]
per-ex loss: 0.424867  [   16/   89]
per-ex loss: 0.595528  [   18/   89]
per-ex loss: 0.459449  [   20/   89]
per-ex loss: 0.472231  [   22/   89]
per-ex loss: 0.761876  [   24/   89]
per-ex loss: 0.476255  [   26/   89]
per-ex loss: 0.410019  [   28/   89]
per-ex loss: 0.512058  [   30/   89]
per-ex loss: 0.678355  [   32/   89]
per-ex loss: 0.379641  [   34/   89]
per-ex loss: 0.438595  [   36/   89]
per-ex loss: 0.461334  [   38/   89]
per-ex loss: 0.419990  [   40/   89]
per-ex loss: 0.370983  [   42/   89]
per-ex loss: 0.423617  [   44/   89]
per-ex loss: 0.455204  [   46/   89]
per-ex loss: 0.490143  [   48/   89]
per-ex loss: 0.571030  [   50/   89]
per-ex loss: 0.411550  [   52/   89]
per-ex loss: 0.541889  [   54/   89]
per-ex loss: 0.532501  [   56/   89]
per-ex loss: 0.428185  [   58/   89]
per-ex loss: 0.442757  [   60/   89]
per-ex loss: 0.420045  [   62/   89]
per-ex loss: 0.602189  [   64/   89]
per-ex loss: 0.451937  [   66/   89]
per-ex loss: 0.513570  [   68/   89]
per-ex loss: 0.404500  [   70/   89]
per-ex loss: 0.563969  [   72/   89]
per-ex loss: 0.485048  [   74/   89]
per-ex loss: 0.514865  [   76/   89]
per-ex loss: 0.383210  [   78/   89]
per-ex loss: 0.368481  [   80/   89]
per-ex loss: 0.459262  [   82/   89]
per-ex loss: 0.462067  [   84/   89]
per-ex loss: 0.479134  [   86/   89]
per-ex loss: 0.419266  [   88/   89]
per-ex loss: 0.647829  [   89/   89]
Train Error: Avg loss: 0.47980829
validation Error: 
 Avg loss: 0.51048400 
 F1: 0.508111 
 Precision: 0.613439 
 Recall: 0.433652
 IoU: 0.340582

test Error: 
 Avg loss: 0.48169686 
 F1: 0.554496 
 Precision: 0.679140 
 Recall: 0.468509
 IoU: 0.383600

We have finished training iteration 344
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_342_.pth
per-ex loss: 0.499106  [    2/   89]
per-ex loss: 0.451705  [    4/   89]
per-ex loss: 0.406331  [    6/   89]
per-ex loss: 0.539540  [    8/   89]
per-ex loss: 0.406848  [   10/   89]
per-ex loss: 0.528994  [   12/   89]
per-ex loss: 0.493713  [   14/   89]
per-ex loss: 0.392365  [   16/   89]
per-ex loss: 0.615843  [   18/   89]
per-ex loss: 0.450875  [   20/   89]
per-ex loss: 0.631641  [   22/   89]
per-ex loss: 0.365113  [   24/   89]
per-ex loss: 0.426420  [   26/   89]
per-ex loss: 0.448218  [   28/   89]
per-ex loss: 0.542805  [   30/   89]
per-ex loss: 0.365919  [   32/   89]
per-ex loss: 0.404972  [   34/   89]
per-ex loss: 0.564581  [   36/   89]
per-ex loss: 0.417212  [   38/   89]
per-ex loss: 0.406561  [   40/   89]
per-ex loss: 0.428253  [   42/   89]
per-ex loss: 0.473582  [   44/   89]
per-ex loss: 0.397500  [   46/   89]
per-ex loss: 0.722894  [   48/   89]
per-ex loss: 0.362561  [   50/   89]
per-ex loss: 0.504281  [   52/   89]
per-ex loss: 0.403909  [   54/   89]
per-ex loss: 0.559461  [   56/   89]
per-ex loss: 0.479462  [   58/   89]
per-ex loss: 0.428149  [   60/   89]
per-ex loss: 0.427590  [   62/   89]
per-ex loss: 0.444644  [   64/   89]
per-ex loss: 0.572854  [   66/   89]
per-ex loss: 0.468140  [   68/   89]
per-ex loss: 0.554483  [   70/   89]
per-ex loss: 0.416393  [   72/   89]
per-ex loss: 0.442998  [   74/   89]
per-ex loss: 0.450113  [   76/   89]
per-ex loss: 0.673361  [   78/   89]
per-ex loss: 0.392539  [   80/   89]
per-ex loss: 0.613331  [   82/   89]
per-ex loss: 0.379200  [   84/   89]
per-ex loss: 0.426740  [   86/   89]
per-ex loss: 0.503418  [   88/   89]
per-ex loss: 0.454219  [   89/   89]
Train Error: Avg loss: 0.47419637
validation Error: 
 Avg loss: 0.52232536 
 F1: 0.505433 
 Precision: 0.616519 
 Recall: 0.428267
 IoU: 0.338180

test Error: 
 Avg loss: 0.48974515 
 F1: 0.546464 
 Precision: 0.668171 
 Recall: 0.462263
 IoU: 0.375955

We have finished training iteration 345
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_343_.pth
per-ex loss: 0.632658  [    2/   89]
per-ex loss: 0.499478  [    4/   89]
per-ex loss: 0.446990  [    6/   89]
per-ex loss: 0.446905  [    8/   89]
per-ex loss: 0.425841  [   10/   89]
per-ex loss: 0.434010  [   12/   89]
per-ex loss: 0.382837  [   14/   89]
per-ex loss: 0.458034  [   16/   89]
per-ex loss: 0.390447  [   18/   89]
per-ex loss: 0.608440  [   20/   89]
per-ex loss: 0.610848  [   22/   89]
per-ex loss: 0.374564  [   24/   89]
per-ex loss: 0.436182  [   26/   89]
per-ex loss: 0.342613  [   28/   89]
per-ex loss: 0.672908  [   30/   89]
per-ex loss: 0.406251  [   32/   89]
per-ex loss: 0.407115  [   34/   89]
per-ex loss: 0.379028  [   36/   89]
per-ex loss: 0.353104  [   38/   89]
per-ex loss: 0.636594  [   40/   89]
per-ex loss: 0.471038  [   42/   89]
per-ex loss: 0.658142  [   44/   89]
per-ex loss: 0.479759  [   46/   89]
per-ex loss: 0.528530  [   48/   89]
per-ex loss: 0.394820  [   50/   89]
per-ex loss: 0.402214  [   52/   89]
per-ex loss: 0.463729  [   54/   89]
per-ex loss: 0.665470  [   56/   89]
per-ex loss: 0.483400  [   58/   89]
per-ex loss: 0.468202  [   60/   89]
per-ex loss: 0.587431  [   62/   89]
per-ex loss: 0.390708  [   64/   89]
per-ex loss: 0.509391  [   66/   89]
per-ex loss: 0.377692  [   68/   89]
per-ex loss: 0.552069  [   70/   89]
per-ex loss: 0.471964  [   72/   89]
per-ex loss: 0.555949  [   74/   89]
per-ex loss: 0.376792  [   76/   89]
per-ex loss: 0.488642  [   78/   89]
per-ex loss: 0.457828  [   80/   89]
per-ex loss: 0.381719  [   82/   89]
per-ex loss: 0.417687  [   84/   89]
per-ex loss: 0.433961  [   86/   89]
per-ex loss: 0.387958  [   88/   89]
per-ex loss: 0.391251  [   89/   89]
Train Error: Avg loss: 0.46980430
validation Error: 
 Avg loss: 0.52646970 
 F1: 0.504109 
 Precision: 0.617922 
 Recall: 0.425701
 IoU: 0.336996

test Error: 
 Avg loss: 0.49249726 
 F1: 0.544745 
 Precision: 0.660944 
 Recall: 0.463295
 IoU: 0.374330

We have finished training iteration 346
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_344_.pth
per-ex loss: 0.410212  [    2/   89]
per-ex loss: 0.380036  [    4/   89]
per-ex loss: 0.493969  [    6/   89]
per-ex loss: 0.390486  [    8/   89]
per-ex loss: 0.439636  [   10/   89]
per-ex loss: 0.380443  [   12/   89]
per-ex loss: 0.654397  [   14/   89]
per-ex loss: 0.387412  [   16/   89]
per-ex loss: 0.505592  [   18/   89]
per-ex loss: 0.346594  [   20/   89]
per-ex loss: 0.483091  [   22/   89]
per-ex loss: 0.469906  [   24/   89]
per-ex loss: 0.490011  [   26/   89]
per-ex loss: 0.353182  [   28/   89]
per-ex loss: 0.368713  [   30/   89]
per-ex loss: 0.623799  [   32/   89]
per-ex loss: 0.471691  [   34/   89]
per-ex loss: 0.527596  [   36/   89]
per-ex loss: 0.520430  [   38/   89]
per-ex loss: 0.516789  [   40/   89]
per-ex loss: 0.563014  [   42/   89]
per-ex loss: 0.639661  [   44/   89]
per-ex loss: 0.386126  [   46/   89]
per-ex loss: 0.408543  [   48/   89]
per-ex loss: 0.541630  [   50/   89]
per-ex loss: 0.621698  [   52/   89]
per-ex loss: 0.582086  [   54/   89]
per-ex loss: 0.383904  [   56/   89]
per-ex loss: 0.373532  [   58/   89]
per-ex loss: 0.570537  [   60/   89]
per-ex loss: 0.659453  [   62/   89]
per-ex loss: 0.562959  [   64/   89]
per-ex loss: 0.740004  [   66/   89]
per-ex loss: 0.355449  [   68/   89]
per-ex loss: 0.624320  [   70/   89]
per-ex loss: 0.411784  [   72/   89]
per-ex loss: 0.398005  [   74/   89]
per-ex loss: 0.397579  [   76/   89]
per-ex loss: 0.496373  [   78/   89]
per-ex loss: 0.366739  [   80/   89]
per-ex loss: 0.408377  [   82/   89]
per-ex loss: 0.458314  [   84/   89]
per-ex loss: 0.529074  [   86/   89]
per-ex loss: 0.475359  [   88/   89]
per-ex loss: 0.339566  [   89/   89]
Train Error: Avg loss: 0.47795716
validation Error: 
 Avg loss: 0.53615523 
 F1: 0.496619 
 Precision: 0.638942 
 Recall: 0.406150
 IoU: 0.330335

test Error: 
 Avg loss: 0.50389015 
 F1: 0.532710 
 Precision: 0.670247 
 Recall: 0.442009
 IoU: 0.363057

We have finished training iteration 347
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_345_.pth
per-ex loss: 0.396949  [    2/   89]
per-ex loss: 0.403748  [    4/   89]
per-ex loss: 0.682077  [    6/   89]
per-ex loss: 0.676656  [    8/   89]
per-ex loss: 0.560276  [   10/   89]
per-ex loss: 0.397116  [   12/   89]
per-ex loss: 0.399488  [   14/   89]
per-ex loss: 0.409436  [   16/   89]
per-ex loss: 0.655429  [   18/   89]
per-ex loss: 0.386953  [   20/   89]
per-ex loss: 0.434745  [   22/   89]
per-ex loss: 0.400285  [   24/   89]
per-ex loss: 0.574590  [   26/   89]
per-ex loss: 0.460193  [   28/   89]
per-ex loss: 0.478281  [   30/   89]
per-ex loss: 0.394535  [   32/   89]
per-ex loss: 0.426951  [   34/   89]
per-ex loss: 0.491761  [   36/   89]
per-ex loss: 0.398473  [   38/   89]
per-ex loss: 0.447140  [   40/   89]
per-ex loss: 0.452229  [   42/   89]
per-ex loss: 0.502533  [   44/   89]
per-ex loss: 0.611451  [   46/   89]
per-ex loss: 0.474850  [   48/   89]
per-ex loss: 0.389754  [   50/   89]
per-ex loss: 0.452300  [   52/   89]
per-ex loss: 0.533670  [   54/   89]
per-ex loss: 0.405522  [   56/   89]
per-ex loss: 0.388971  [   58/   89]
per-ex loss: 0.398128  [   60/   89]
per-ex loss: 0.396166  [   62/   89]
per-ex loss: 0.519418  [   64/   89]
per-ex loss: 0.411783  [   66/   89]
per-ex loss: 0.460964  [   68/   89]
per-ex loss: 0.504461  [   70/   89]
per-ex loss: 0.370491  [   72/   89]
per-ex loss: 0.555173  [   74/   89]
per-ex loss: 0.551689  [   76/   89]
per-ex loss: 0.482747  [   78/   89]
per-ex loss: 0.414005  [   80/   89]
per-ex loss: 0.468227  [   82/   89]
per-ex loss: 0.382849  [   84/   89]
per-ex loss: 0.519998  [   86/   89]
per-ex loss: 0.474667  [   88/   89]
per-ex loss: 0.324593  [   89/   89]
Train Error: Avg loss: 0.46492713
validation Error: 
 Avg loss: 0.50477863 
 F1: 0.509700 
 Precision: 0.591139 
 Recall: 0.447984
 IoU: 0.342012

test Error: 
 Avg loss: 0.47437993 
 F1: 0.562674 
 Precision: 0.670400 
 Recall: 0.484776
 IoU: 0.391473

We have finished training iteration 348
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_346_.pth
per-ex loss: 0.444343  [    2/   89]
per-ex loss: 0.408664  [    4/   89]
per-ex loss: 0.380034  [    6/   89]
per-ex loss: 0.418035  [    8/   89]
per-ex loss: 0.357487  [   10/   89]
per-ex loss: 0.479201  [   12/   89]
per-ex loss: 0.467305  [   14/   89]
per-ex loss: 0.391813  [   16/   89]
per-ex loss: 0.364743  [   18/   89]
per-ex loss: 0.403982  [   20/   89]
per-ex loss: 0.407871  [   22/   89]
per-ex loss: 0.449770  [   24/   89]
per-ex loss: 0.425652  [   26/   89]
per-ex loss: 0.443355  [   28/   89]
per-ex loss: 0.403260  [   30/   89]
per-ex loss: 0.373596  [   32/   89]
per-ex loss: 0.648454  [   34/   89]
per-ex loss: 0.500548  [   36/   89]
per-ex loss: 0.580633  [   38/   89]
per-ex loss: 0.404690  [   40/   89]
per-ex loss: 0.577832  [   42/   89]
per-ex loss: 0.665907  [   44/   89]
per-ex loss: 0.426933  [   46/   89]
per-ex loss: 0.415126  [   48/   89]
per-ex loss: 0.430186  [   50/   89]
per-ex loss: 0.370111  [   52/   89]
per-ex loss: 0.398851  [   54/   89]
per-ex loss: 0.574018  [   56/   89]
per-ex loss: 0.441000  [   58/   89]
per-ex loss: 0.526636  [   60/   89]
per-ex loss: 0.615515  [   62/   89]
per-ex loss: 0.511603  [   64/   89]
per-ex loss: 0.574249  [   66/   89]
per-ex loss: 0.409669  [   68/   89]
per-ex loss: 0.450289  [   70/   89]
per-ex loss: 0.433156  [   72/   89]
per-ex loss: 0.449930  [   74/   89]
per-ex loss: 0.473857  [   76/   89]
per-ex loss: 0.535893  [   78/   89]
per-ex loss: 0.609535  [   80/   89]
per-ex loss: 0.652672  [   82/   89]
per-ex loss: 0.420118  [   84/   89]
per-ex loss: 0.635018  [   86/   89]
per-ex loss: 0.522404  [   88/   89]
per-ex loss: 0.481609  [   89/   89]
Train Error: Avg loss: 0.47456780
validation Error: 
 Avg loss: 0.52417402 
 F1: 0.487520 
 Precision: 0.654039 
 Recall: 0.388585
 IoU: 0.322331

test Error: 
 Avg loss: 0.51458151 
 F1: 0.520865 
 Precision: 0.680225 
 Recall: 0.422001
 IoU: 0.352142

We have finished training iteration 349
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_347_.pth
per-ex loss: 0.410772  [    2/   89]
per-ex loss: 0.603634  [    4/   89]
per-ex loss: 0.402170  [    6/   89]
per-ex loss: 0.368676  [    8/   89]
per-ex loss: 0.428622  [   10/   89]
per-ex loss: 0.588434  [   12/   89]
per-ex loss: 0.382980  [   14/   89]
per-ex loss: 0.472689  [   16/   89]
per-ex loss: 0.390003  [   18/   89]
per-ex loss: 0.493823  [   20/   89]
per-ex loss: 0.565717  [   22/   89]
per-ex loss: 0.579047  [   24/   89]
per-ex loss: 0.429272  [   26/   89]
per-ex loss: 0.558621  [   28/   89]
per-ex loss: 0.465314  [   30/   89]
per-ex loss: 0.425496  [   32/   89]
per-ex loss: 0.454870  [   34/   89]
per-ex loss: 0.451898  [   36/   89]
per-ex loss: 0.435562  [   38/   89]
per-ex loss: 0.472245  [   40/   89]
per-ex loss: 0.567764  [   42/   89]
per-ex loss: 0.416526  [   44/   89]
per-ex loss: 0.641524  [   46/   89]
per-ex loss: 0.370146  [   48/   89]
per-ex loss: 0.460190  [   50/   89]
per-ex loss: 0.498048  [   52/   89]
per-ex loss: 0.545031  [   54/   89]
per-ex loss: 0.411142  [   56/   89]
per-ex loss: 0.374259  [   58/   89]
per-ex loss: 0.385746  [   60/   89]
per-ex loss: 0.400086  [   62/   89]
per-ex loss: 0.358330  [   64/   89]
per-ex loss: 0.605860  [   66/   89]
per-ex loss: 0.591165  [   68/   89]
per-ex loss: 0.580275  [   70/   89]
per-ex loss: 0.594632  [   72/   89]
per-ex loss: 0.518767  [   74/   89]
per-ex loss: 0.470936  [   76/   89]
per-ex loss: 0.371663  [   78/   89]
per-ex loss: 0.383814  [   80/   89]
per-ex loss: 0.437683  [   82/   89]
per-ex loss: 0.435198  [   84/   89]
per-ex loss: 0.468566  [   86/   89]
per-ex loss: 0.572499  [   88/   89]
per-ex loss: 0.396555  [   89/   89]
Train Error: Avg loss: 0.47191664
validation Error: 
 Avg loss: 0.51989084 
 F1: 0.494924 
 Precision: 0.588213 
 Recall: 0.427176
 IoU: 0.328837

test Error: 
 Avg loss: 0.50742318 
 F1: 0.530312 
 Precision: 0.615294 
 Recall: 0.465955
 IoU: 0.360833

We have finished training iteration 350
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_309_.pth
per-ex loss: 0.490862  [    2/   89]
per-ex loss: 0.478347  [    4/   89]
per-ex loss: 0.520545  [    6/   89]
per-ex loss: 0.397697  [    8/   89]
per-ex loss: 0.468842  [   10/   89]
per-ex loss: 0.554834  [   12/   89]
per-ex loss: 0.412816  [   14/   89]
per-ex loss: 0.357931  [   16/   89]
per-ex loss: 0.385842  [   18/   89]
per-ex loss: 0.456617  [   20/   89]
per-ex loss: 0.570864  [   22/   89]
per-ex loss: 0.463677  [   24/   89]
per-ex loss: 0.471097  [   26/   89]
per-ex loss: 0.586539  [   28/   89]
per-ex loss: 0.432009  [   30/   89]
per-ex loss: 0.504958  [   32/   89]
per-ex loss: 0.439647  [   34/   89]
per-ex loss: 0.458089  [   36/   89]
per-ex loss: 0.349132  [   38/   89]
per-ex loss: 0.562626  [   40/   89]
per-ex loss: 0.406498  [   42/   89]
per-ex loss: 0.425701  [   44/   89]
per-ex loss: 0.607500  [   46/   89]
per-ex loss: 0.476806  [   48/   89]
per-ex loss: 0.611336  [   50/   89]
per-ex loss: 0.404183  [   52/   89]
per-ex loss: 0.441302  [   54/   89]
per-ex loss: 0.399185  [   56/   89]
per-ex loss: 0.400877  [   58/   89]
per-ex loss: 0.408209  [   60/   89]
per-ex loss: 0.429960  [   62/   89]
per-ex loss: 0.475317  [   64/   89]
per-ex loss: 0.594818  [   66/   89]
per-ex loss: 0.510598  [   68/   89]
per-ex loss: 0.495081  [   70/   89]
per-ex loss: 0.396391  [   72/   89]
per-ex loss: 0.473909  [   74/   89]
per-ex loss: 0.448950  [   76/   89]
per-ex loss: 0.491301  [   78/   89]
per-ex loss: 0.344828  [   80/   89]
per-ex loss: 0.511846  [   82/   89]
per-ex loss: 0.636847  [   84/   89]
per-ex loss: 0.466309  [   86/   89]
per-ex loss: 0.445440  [   88/   89]
per-ex loss: 0.488504  [   89/   89]
Train Error: Avg loss: 0.47010373
validation Error: 
 Avg loss: 0.51542354 
 F1: 0.506740 
 Precision: 0.590308 
 Recall: 0.443899
 IoU: 0.339352

test Error: 
 Avg loss: 0.48070268 
 F1: 0.555144 
 Precision: 0.660673 
 Recall: 0.478684
 IoU: 0.384221

We have finished training iteration 351
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_349_.pth
per-ex loss: 0.463653  [    2/   89]
per-ex loss: 0.367267  [    4/   89]
per-ex loss: 0.455371  [    6/   89]
per-ex loss: 0.485821  [    8/   89]
per-ex loss: 0.353147  [   10/   89]
per-ex loss: 0.477174  [   12/   89]
per-ex loss: 0.434126  [   14/   89]
per-ex loss: 0.618469  [   16/   89]
per-ex loss: 0.384018  [   18/   89]
per-ex loss: 0.433225  [   20/   89]
per-ex loss: 0.441136  [   22/   89]
per-ex loss: 0.403397  [   24/   89]
per-ex loss: 0.466982  [   26/   89]
per-ex loss: 0.506281  [   28/   89]
per-ex loss: 0.499258  [   30/   89]
per-ex loss: 0.598710  [   32/   89]
per-ex loss: 0.553860  [   34/   89]
per-ex loss: 0.516781  [   36/   89]
per-ex loss: 0.461619  [   38/   89]
per-ex loss: 0.385876  [   40/   89]
per-ex loss: 0.517211  [   42/   89]
per-ex loss: 0.410094  [   44/   89]
per-ex loss: 0.484352  [   46/   89]
per-ex loss: 0.590935  [   48/   89]
per-ex loss: 0.603379  [   50/   89]
per-ex loss: 0.398517  [   52/   89]
per-ex loss: 0.339740  [   54/   89]
per-ex loss: 0.413931  [   56/   89]
per-ex loss: 0.475636  [   58/   89]
per-ex loss: 0.444132  [   60/   89]
per-ex loss: 0.488792  [   62/   89]
per-ex loss: 0.424330  [   64/   89]
per-ex loss: 0.620384  [   66/   89]
per-ex loss: 0.469940  [   68/   89]
per-ex loss: 0.578179  [   70/   89]
per-ex loss: 0.446398  [   72/   89]
per-ex loss: 0.399836  [   74/   89]
per-ex loss: 0.362067  [   76/   89]
per-ex loss: 0.639236  [   78/   89]
per-ex loss: 0.398425  [   80/   89]
per-ex loss: 0.455784  [   82/   89]
per-ex loss: 0.426920  [   84/   89]
per-ex loss: 0.467347  [   86/   89]
per-ex loss: 0.503172  [   88/   89]
per-ex loss: 0.378447  [   89/   89]
Train Error: Avg loss: 0.46763008
validation Error: 
 Avg loss: 0.50300959 
 F1: 0.510746 
 Precision: 0.593361 
 Recall: 0.448325
 IoU: 0.342954

test Error: 
 Avg loss: 0.47444617 
 F1: 0.562048 
 Precision: 0.668722 
 Recall: 0.484725
 IoU: 0.390867

We have finished training iteration 352
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_350_.pth
per-ex loss: 0.408256  [    2/   89]
per-ex loss: 0.411337  [    4/   89]
per-ex loss: 0.596716  [    6/   89]
per-ex loss: 0.570579  [    8/   89]
per-ex loss: 0.433748  [   10/   89]
per-ex loss: 0.712120  [   12/   89]
per-ex loss: 0.490969  [   14/   89]
per-ex loss: 0.440864  [   16/   89]
per-ex loss: 0.636093  [   18/   89]
per-ex loss: 0.378699  [   20/   89]
per-ex loss: 0.388187  [   22/   89]
per-ex loss: 0.599777  [   24/   89]
per-ex loss: 0.600216  [   26/   89]
per-ex loss: 0.554303  [   28/   89]
per-ex loss: 0.444122  [   30/   89]
per-ex loss: 0.445051  [   32/   89]
per-ex loss: 0.539278  [   34/   89]
per-ex loss: 0.338631  [   36/   89]
per-ex loss: 0.433694  [   38/   89]
per-ex loss: 0.357572  [   40/   89]
per-ex loss: 0.413132  [   42/   89]
per-ex loss: 0.469367  [   44/   89]
per-ex loss: 0.552046  [   46/   89]
per-ex loss: 0.513364  [   48/   89]
per-ex loss: 0.508351  [   50/   89]
per-ex loss: 0.460376  [   52/   89]
per-ex loss: 0.366974  [   54/   89]
per-ex loss: 0.358213  [   56/   89]
per-ex loss: 0.409602  [   58/   89]
per-ex loss: 0.464570  [   60/   89]
per-ex loss: 0.525973  [   62/   89]
per-ex loss: 0.380350  [   64/   89]
per-ex loss: 0.591698  [   66/   89]
per-ex loss: 0.453389  [   68/   89]
per-ex loss: 0.374935  [   70/   89]
per-ex loss: 0.557794  [   72/   89]
per-ex loss: 0.399718  [   74/   89]
per-ex loss: 0.476775  [   76/   89]
per-ex loss: 0.414686  [   78/   89]
per-ex loss: 0.355532  [   80/   89]
per-ex loss: 0.462547  [   82/   89]
per-ex loss: 0.528095  [   84/   89]
per-ex loss: 0.531916  [   86/   89]
per-ex loss: 0.533123  [   88/   89]
per-ex loss: 0.559311  [   89/   89]
Train Error: Avg loss: 0.47648989
validation Error: 
 Avg loss: 0.51742328 
 F1: 0.511079 
 Precision: 0.613009 
 Recall: 0.438213
 IoU: 0.343254

test Error: 
 Avg loss: 0.47700521 
 F1: 0.559783 
 Precision: 0.682734 
 Recall: 0.474357
 IoU: 0.388679

We have finished training iteration 353
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_351_.pth
per-ex loss: 0.371511  [    2/   89]
per-ex loss: 0.465440  [    4/   89]
per-ex loss: 0.575043  [    6/   89]
per-ex loss: 0.414871  [    8/   89]
per-ex loss: 0.366786  [   10/   89]
per-ex loss: 0.449701  [   12/   89]
per-ex loss: 0.426052  [   14/   89]
per-ex loss: 0.429388  [   16/   89]
per-ex loss: 0.612455  [   18/   89]
per-ex loss: 0.410790  [   20/   89]
per-ex loss: 0.362675  [   22/   89]
per-ex loss: 0.361473  [   24/   89]
per-ex loss: 0.385502  [   26/   89]
per-ex loss: 0.638274  [   28/   89]
per-ex loss: 0.359451  [   30/   89]
per-ex loss: 0.602265  [   32/   89]
per-ex loss: 0.575179  [   34/   89]
per-ex loss: 0.372750  [   36/   89]
per-ex loss: 0.403432  [   38/   89]
per-ex loss: 0.528798  [   40/   89]
per-ex loss: 0.530225  [   42/   89]
per-ex loss: 0.510533  [   44/   89]
per-ex loss: 0.403147  [   46/   89]
per-ex loss: 0.381485  [   48/   89]
per-ex loss: 0.590570  [   50/   89]
per-ex loss: 0.530305  [   52/   89]
per-ex loss: 0.428036  [   54/   89]
per-ex loss: 0.536458  [   56/   89]
per-ex loss: 0.568591  [   58/   89]
per-ex loss: 0.522396  [   60/   89]
per-ex loss: 0.401066  [   62/   89]
per-ex loss: 0.410238  [   64/   89]
per-ex loss: 0.581957  [   66/   89]
per-ex loss: 0.539078  [   68/   89]
per-ex loss: 0.462909  [   70/   89]
per-ex loss: 0.466068  [   72/   89]
per-ex loss: 0.404757  [   74/   89]
per-ex loss: 0.453010  [   76/   89]
per-ex loss: 0.485115  [   78/   89]
per-ex loss: 0.439796  [   80/   89]
per-ex loss: 0.439023  [   82/   89]
per-ex loss: 0.472610  [   84/   89]
per-ex loss: 0.407773  [   86/   89]
per-ex loss: 0.576096  [   88/   89]
per-ex loss: 0.412946  [   89/   89]
Train Error: Avg loss: 0.46813384
validation Error: 
 Avg loss: 0.54078700 
 F1: 0.498544 
 Precision: 0.639891 
 Recall: 0.408344
 IoU: 0.332040

test Error: 
 Avg loss: 0.49981517 
 F1: 0.535755 
 Precision: 0.676443 
 Recall: 0.443512
 IoU: 0.365892

We have finished training iteration 354
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_348_.pth
per-ex loss: 0.537687  [    2/   89]
per-ex loss: 0.363374  [    4/   89]
per-ex loss: 0.506471  [    6/   89]
per-ex loss: 0.408777  [    8/   89]
per-ex loss: 0.467009  [   10/   89]
per-ex loss: 0.428262  [   12/   89]
per-ex loss: 0.465609  [   14/   89]
per-ex loss: 0.441198  [   16/   89]
per-ex loss: 0.414625  [   18/   89]
per-ex loss: 0.353364  [   20/   89]
per-ex loss: 0.422573  [   22/   89]
per-ex loss: 0.387698  [   24/   89]
per-ex loss: 0.413218  [   26/   89]
per-ex loss: 0.385763  [   28/   89]
per-ex loss: 0.426006  [   30/   89]
per-ex loss: 0.602762  [   32/   89]
per-ex loss: 0.378996  [   34/   89]
per-ex loss: 0.496421  [   36/   89]
per-ex loss: 0.443979  [   38/   89]
per-ex loss: 0.506089  [   40/   89]
per-ex loss: 0.548000  [   42/   89]
per-ex loss: 0.569864  [   44/   89]
per-ex loss: 0.373259  [   46/   89]
per-ex loss: 0.551402  [   48/   89]
per-ex loss: 0.412183  [   50/   89]
per-ex loss: 0.457573  [   52/   89]
per-ex loss: 0.390536  [   54/   89]
per-ex loss: 0.410133  [   56/   89]
per-ex loss: 0.446886  [   58/   89]
per-ex loss: 0.500846  [   60/   89]
per-ex loss: 0.614128  [   62/   89]
per-ex loss: 0.615190  [   64/   89]
per-ex loss: 0.470212  [   66/   89]
per-ex loss: 0.463904  [   68/   89]
per-ex loss: 0.440035  [   70/   89]
per-ex loss: 0.406561  [   72/   89]
per-ex loss: 0.494403  [   74/   89]
per-ex loss: 0.605822  [   76/   89]
per-ex loss: 0.376046  [   78/   89]
per-ex loss: 0.446444  [   80/   89]
per-ex loss: 0.574774  [   82/   89]
per-ex loss: 0.389436  [   84/   89]
per-ex loss: 0.458519  [   86/   89]
per-ex loss: 0.547291  [   88/   89]
per-ex loss: 0.637264  [   89/   89]
Train Error: Avg loss: 0.46779099
validation Error: 
 Avg loss: 0.54301052 
 F1: 0.483792 
 Precision: 0.633374 
 Recall: 0.391365
 IoU: 0.319081

test Error: 
 Avg loss: 0.51792073 
 F1: 0.518120 
 Precision: 0.653227 
 Recall: 0.429323
 IoU: 0.349637

We have finished training iteration 355
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_353_.pth
per-ex loss: 0.428376  [    2/   89]
per-ex loss: 0.442660  [    4/   89]
per-ex loss: 0.513258  [    6/   89]
per-ex loss: 0.470646  [    8/   89]
per-ex loss: 0.407844  [   10/   89]
per-ex loss: 0.635392  [   12/   89]
per-ex loss: 0.426600  [   14/   89]
per-ex loss: 0.409974  [   16/   89]
per-ex loss: 0.401005  [   18/   89]
per-ex loss: 0.411380  [   20/   89]
per-ex loss: 0.416862  [   22/   89]
per-ex loss: 0.411766  [   24/   89]
per-ex loss: 0.441631  [   26/   89]
per-ex loss: 0.399808  [   28/   89]
per-ex loss: 0.376729  [   30/   89]
per-ex loss: 0.457491  [   32/   89]
per-ex loss: 0.611084  [   34/   89]
per-ex loss: 0.335807  [   36/   89]
per-ex loss: 0.415154  [   38/   89]
per-ex loss: 0.423195  [   40/   89]
per-ex loss: 0.387152  [   42/   89]
per-ex loss: 0.386064  [   44/   89]
per-ex loss: 0.420774  [   46/   89]
per-ex loss: 0.667764  [   48/   89]
per-ex loss: 0.444828  [   50/   89]
per-ex loss: 0.413568  [   52/   89]
per-ex loss: 0.661258  [   54/   89]
per-ex loss: 0.389969  [   56/   89]
per-ex loss: 0.486810  [   58/   89]
per-ex loss: 0.489842  [   60/   89]
per-ex loss: 0.659763  [   62/   89]
per-ex loss: 0.492387  [   64/   89]
per-ex loss: 0.588910  [   66/   89]
per-ex loss: 0.597661  [   68/   89]
per-ex loss: 0.488390  [   70/   89]
per-ex loss: 0.370170  [   72/   89]
per-ex loss: 0.493291  [   74/   89]
per-ex loss: 0.428762  [   76/   89]
per-ex loss: 0.500176  [   78/   89]
per-ex loss: 0.523995  [   80/   89]
per-ex loss: 0.439932  [   82/   89]
per-ex loss: 0.433033  [   84/   89]
per-ex loss: 0.624425  [   86/   89]
per-ex loss: 0.548417  [   88/   89]
per-ex loss: 0.666626  [   89/   89]
Train Error: Avg loss: 0.47645844
validation Error: 
 Avg loss: 0.52477301 
 F1: 0.502179 
 Precision: 0.647811 
 Recall: 0.410007
 IoU: 0.335273

test Error: 
 Avg loss: 0.49623658 
 F1: 0.539404 
 Precision: 0.700507 
 Recall: 0.438546
 IoU: 0.369304

We have finished training iteration 356
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_354_.pth
per-ex loss: 0.346605  [    2/   89]
per-ex loss: 0.388469  [    4/   89]
per-ex loss: 0.449507  [    6/   89]
per-ex loss: 0.400969  [    8/   89]
per-ex loss: 0.606564  [   10/   89]
per-ex loss: 0.525332  [   12/   89]
per-ex loss: 0.385151  [   14/   89]
per-ex loss: 0.456521  [   16/   89]
per-ex loss: 0.414643  [   18/   89]
per-ex loss: 0.426257  [   20/   89]
per-ex loss: 0.352871  [   22/   89]
per-ex loss: 0.568554  [   24/   89]
per-ex loss: 0.461921  [   26/   89]
per-ex loss: 0.432226  [   28/   89]
per-ex loss: 0.498037  [   30/   89]
per-ex loss: 0.366547  [   32/   89]
per-ex loss: 0.529237  [   34/   89]
per-ex loss: 0.523485  [   36/   89]
per-ex loss: 0.441703  [   38/   89]
per-ex loss: 0.517260  [   40/   89]
per-ex loss: 0.671067  [   42/   89]
per-ex loss: 0.396805  [   44/   89]
per-ex loss: 0.431897  [   46/   89]
per-ex loss: 0.608138  [   48/   89]
per-ex loss: 0.438283  [   50/   89]
per-ex loss: 0.474985  [   52/   89]
per-ex loss: 0.412793  [   54/   89]
per-ex loss: 0.355641  [   56/   89]
per-ex loss: 0.481665  [   58/   89]
per-ex loss: 0.455105  [   60/   89]
per-ex loss: 0.657065  [   62/   89]
per-ex loss: 0.499000  [   64/   89]
per-ex loss: 0.502260  [   66/   89]
per-ex loss: 0.371201  [   68/   89]
per-ex loss: 0.410667  [   70/   89]
per-ex loss: 0.514021  [   72/   89]
per-ex loss: 0.521088  [   74/   89]
per-ex loss: 0.458757  [   76/   89]
per-ex loss: 0.410662  [   78/   89]
per-ex loss: 0.713584  [   80/   89]
per-ex loss: 0.532631  [   82/   89]
per-ex loss: 0.358725  [   84/   89]
per-ex loss: 0.533657  [   86/   89]
per-ex loss: 0.408956  [   88/   89]
per-ex loss: 0.403478  [   89/   89]
Train Error: Avg loss: 0.46919975
validation Error: 
 Avg loss: 0.53783583 
 F1: 0.485893 
 Precision: 0.631326 
 Recall: 0.394919
 IoU: 0.320910

test Error: 
 Avg loss: 0.51690761 
 F1: 0.519299 
 Precision: 0.652234 
 Recall: 0.431377
 IoU: 0.350711

We have finished training iteration 357
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_355_.pth
per-ex loss: 0.421532  [    2/   89]
per-ex loss: 0.555367  [    4/   89]
per-ex loss: 0.423975  [    6/   89]
per-ex loss: 0.604627  [    8/   89]
per-ex loss: 0.391575  [   10/   89]
per-ex loss: 0.578791  [   12/   89]
per-ex loss: 0.410784  [   14/   89]
per-ex loss: 0.401196  [   16/   89]
per-ex loss: 0.396974  [   18/   89]
per-ex loss: 0.519892  [   20/   89]
per-ex loss: 0.561167  [   22/   89]
per-ex loss: 0.559277  [   24/   89]
per-ex loss: 0.381839  [   26/   89]
per-ex loss: 0.555510  [   28/   89]
per-ex loss: 0.498373  [   30/   89]
per-ex loss: 0.529304  [   32/   89]
per-ex loss: 0.469533  [   34/   89]
per-ex loss: 0.570152  [   36/   89]
per-ex loss: 0.411365  [   38/   89]
per-ex loss: 0.390295  [   40/   89]
per-ex loss: 0.474893  [   42/   89]
per-ex loss: 0.568954  [   44/   89]
per-ex loss: 0.416039  [   46/   89]
per-ex loss: 0.366101  [   48/   89]
per-ex loss: 0.473804  [   50/   89]
per-ex loss: 0.414807  [   52/   89]
per-ex loss: 0.597525  [   54/   89]
per-ex loss: 0.394675  [   56/   89]
per-ex loss: 0.422710  [   58/   89]
per-ex loss: 0.501995  [   60/   89]
per-ex loss: 0.449903  [   62/   89]
per-ex loss: 0.431490  [   64/   89]
per-ex loss: 0.399447  [   66/   89]
per-ex loss: 0.609442  [   68/   89]
per-ex loss: 0.399561  [   70/   89]
per-ex loss: 0.450726  [   72/   89]
per-ex loss: 0.374028  [   74/   89]
per-ex loss: 0.651700  [   76/   89]
per-ex loss: 0.447575  [   78/   89]
per-ex loss: 0.410381  [   80/   89]
per-ex loss: 0.400942  [   82/   89]
per-ex loss: 0.348665  [   84/   89]
per-ex loss: 0.402850  [   86/   89]
per-ex loss: 0.673688  [   88/   89]
per-ex loss: 0.447215  [   89/   89]
Train Error: Avg loss: 0.47023656
validation Error: 
 Avg loss: 0.53464803 
 F1: 0.492093 
 Precision: 0.631807 
 Recall: 0.402980
 IoU: 0.326342

test Error: 
 Avg loss: 0.50971269 
 F1: 0.526390 
 Precision: 0.658867 
 Recall: 0.438268
 IoU: 0.357211

We have finished training iteration 358
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_356_.pth
per-ex loss: 0.433666  [    2/   89]
per-ex loss: 0.506970  [    4/   89]
per-ex loss: 0.541677  [    6/   89]
per-ex loss: 0.435581  [    8/   89]
per-ex loss: 0.600665  [   10/   89]
per-ex loss: 0.483654  [   12/   89]
per-ex loss: 0.407865  [   14/   89]
per-ex loss: 0.467387  [   16/   89]
per-ex loss: 0.432060  [   18/   89]
per-ex loss: 0.483420  [   20/   89]
per-ex loss: 0.377560  [   22/   89]
per-ex loss: 0.352571  [   24/   89]
per-ex loss: 0.384271  [   26/   89]
per-ex loss: 0.372406  [   28/   89]
per-ex loss: 0.492105  [   30/   89]
per-ex loss: 0.447326  [   32/   89]
per-ex loss: 0.541604  [   34/   89]
per-ex loss: 0.662196  [   36/   89]
per-ex loss: 0.605121  [   38/   89]
per-ex loss: 0.583395  [   40/   89]
per-ex loss: 0.398980  [   42/   89]
per-ex loss: 0.599979  [   44/   89]
per-ex loss: 0.555118  [   46/   89]
per-ex loss: 0.519923  [   48/   89]
per-ex loss: 0.360676  [   50/   89]
per-ex loss: 0.532004  [   52/   89]
per-ex loss: 0.513512  [   54/   89]
per-ex loss: 0.575675  [   56/   89]
per-ex loss: 0.451588  [   58/   89]
per-ex loss: 0.415973  [   60/   89]
per-ex loss: 0.501540  [   62/   89]
per-ex loss: 0.365333  [   64/   89]
per-ex loss: 0.367037  [   66/   89]
per-ex loss: 0.409556  [   68/   89]
per-ex loss: 0.506044  [   70/   89]
per-ex loss: 0.372100  [   72/   89]
per-ex loss: 0.433967  [   74/   89]
per-ex loss: 0.659917  [   76/   89]
per-ex loss: 0.477697  [   78/   89]
per-ex loss: 0.468229  [   80/   89]
per-ex loss: 0.420995  [   82/   89]
per-ex loss: 0.414124  [   84/   89]
per-ex loss: 0.356243  [   86/   89]
per-ex loss: 0.374352  [   88/   89]
per-ex loss: 0.408313  [   89/   89]
Train Error: Avg loss: 0.46823055
validation Error: 
 Avg loss: 0.50977044 
 F1: 0.505768 
 Precision: 0.601549 
 Recall: 0.436300
 IoU: 0.338481

test Error: 
 Avg loss: 0.48445264 
 F1: 0.551301 
 Precision: 0.671563 
 Recall: 0.467569
 IoU: 0.380549

We have finished training iteration 359
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_357_.pth
per-ex loss: 0.498105  [    2/   89]
per-ex loss: 0.379185  [    4/   89]
per-ex loss: 0.454551  [    6/   89]
per-ex loss: 0.413988  [    8/   89]
per-ex loss: 0.508042  [   10/   89]
per-ex loss: 0.487971  [   12/   89]
per-ex loss: 0.389585  [   14/   89]
per-ex loss: 0.399614  [   16/   89]
per-ex loss: 0.403583  [   18/   89]
per-ex loss: 0.521497  [   20/   89]
per-ex loss: 0.593119  [   22/   89]
per-ex loss: 0.604868  [   24/   89]
per-ex loss: 0.538546  [   26/   89]
per-ex loss: 0.412830  [   28/   89]
per-ex loss: 0.438017  [   30/   89]
per-ex loss: 0.396517  [   32/   89]
per-ex loss: 0.618029  [   34/   89]
per-ex loss: 0.466289  [   36/   89]
per-ex loss: 0.435561  [   38/   89]
per-ex loss: 0.616786  [   40/   89]
per-ex loss: 0.370337  [   42/   89]
per-ex loss: 0.590354  [   44/   89]
per-ex loss: 0.394158  [   46/   89]
per-ex loss: 0.434052  [   48/   89]
per-ex loss: 0.575698  [   50/   89]
per-ex loss: 0.452652  [   52/   89]
per-ex loss: 0.476180  [   54/   89]
per-ex loss: 0.440313  [   56/   89]
per-ex loss: 0.499362  [   58/   89]
per-ex loss: 0.409643  [   60/   89]
per-ex loss: 0.449638  [   62/   89]
per-ex loss: 0.461219  [   64/   89]
per-ex loss: 0.390082  [   66/   89]
per-ex loss: 0.379667  [   68/   89]
per-ex loss: 0.591164  [   70/   89]
per-ex loss: 0.436472  [   72/   89]
per-ex loss: 0.390985  [   74/   89]
per-ex loss: 0.392584  [   76/   89]
per-ex loss: 0.643581  [   78/   89]
per-ex loss: 0.467458  [   80/   89]
per-ex loss: 0.397063  [   82/   89]
per-ex loss: 0.430330  [   84/   89]
per-ex loss: 0.477847  [   86/   89]
per-ex loss: 0.428843  [   88/   89]
per-ex loss: 0.384391  [   89/   89]
Train Error: Avg loss: 0.46535022
validation Error: 
 Avg loss: 0.53765033 
 F1: 0.490669 
 Precision: 0.630537 
 Recall: 0.401588
 IoU: 0.325090

test Error: 
 Avg loss: 0.51137265 
 F1: 0.524031 
 Precision: 0.664830 
 Recall: 0.432446
 IoU: 0.355042

We have finished training iteration 360
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_358_.pth
per-ex loss: 0.506597  [    2/   89]
per-ex loss: 0.478504  [    4/   89]
per-ex loss: 0.496908  [    6/   89]
per-ex loss: 0.390923  [    8/   89]
per-ex loss: 0.488534  [   10/   89]
per-ex loss: 0.410984  [   12/   89]
per-ex loss: 0.372171  [   14/   89]
per-ex loss: 0.394567  [   16/   89]
per-ex loss: 0.380342  [   18/   89]
per-ex loss: 0.630013  [   20/   89]
per-ex loss: 0.618956  [   22/   89]
per-ex loss: 0.619006  [   24/   89]
per-ex loss: 0.411236  [   26/   89]
per-ex loss: 0.377466  [   28/   89]
per-ex loss: 0.667429  [   30/   89]
per-ex loss: 0.455852  [   32/   89]
per-ex loss: 0.477657  [   34/   89]
per-ex loss: 0.578876  [   36/   89]
per-ex loss: 0.421668  [   38/   89]
per-ex loss: 0.346493  [   40/   89]
per-ex loss: 0.654808  [   42/   89]
per-ex loss: 0.466019  [   44/   89]
per-ex loss: 0.420379  [   46/   89]
per-ex loss: 0.464236  [   48/   89]
per-ex loss: 0.388474  [   50/   89]
per-ex loss: 0.457425  [   52/   89]
per-ex loss: 0.436843  [   54/   89]
per-ex loss: 0.571098  [   56/   89]
per-ex loss: 0.464651  [   58/   89]
per-ex loss: 0.405551  [   60/   89]
per-ex loss: 0.410180  [   62/   89]
per-ex loss: 0.424901  [   64/   89]
per-ex loss: 0.534708  [   66/   89]
per-ex loss: 0.453202  [   68/   89]
per-ex loss: 0.548985  [   70/   89]
per-ex loss: 0.570137  [   72/   89]
per-ex loss: 0.417709  [   74/   89]
per-ex loss: 0.482930  [   76/   89]
per-ex loss: 0.459627  [   78/   89]
per-ex loss: 0.364575  [   80/   89]
per-ex loss: 0.410671  [   82/   89]
per-ex loss: 0.503571  [   84/   89]
per-ex loss: 0.497362  [   86/   89]
per-ex loss: 0.375341  [   88/   89]
per-ex loss: 0.550077  [   89/   89]
Train Error: Avg loss: 0.47239205
validation Error: 
 Avg loss: 0.51988228 
 F1: 0.509099 
 Precision: 0.624365 
 Recall: 0.429759
 IoU: 0.341471

test Error: 
 Avg loss: 0.48229131 
 F1: 0.553891 
 Precision: 0.692016 
 Recall: 0.461731
 IoU: 0.383022

We have finished training iteration 361
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_359_.pth
per-ex loss: 0.481197  [    2/   89]
per-ex loss: 0.587017  [    4/   89]
per-ex loss: 0.600930  [    6/   89]
per-ex loss: 0.739500  [    8/   89]
per-ex loss: 0.508796  [   10/   89]
per-ex loss: 0.342905  [   12/   89]
per-ex loss: 0.437988  [   14/   89]
per-ex loss: 0.408949  [   16/   89]
per-ex loss: 0.516728  [   18/   89]
per-ex loss: 0.567970  [   20/   89]
per-ex loss: 0.404626  [   22/   89]
per-ex loss: 0.417112  [   24/   89]
per-ex loss: 0.645216  [   26/   89]
per-ex loss: 0.395787  [   28/   89]
per-ex loss: 0.641781  [   30/   89]
per-ex loss: 0.463193  [   32/   89]
per-ex loss: 0.571464  [   34/   89]
per-ex loss: 0.540429  [   36/   89]
per-ex loss: 0.383031  [   38/   89]
per-ex loss: 0.420437  [   40/   89]
per-ex loss: 0.469994  [   42/   89]
per-ex loss: 0.392408  [   44/   89]
per-ex loss: 0.358092  [   46/   89]
per-ex loss: 0.404073  [   48/   89]
per-ex loss: 0.466575  [   50/   89]
per-ex loss: 0.516383  [   52/   89]
per-ex loss: 0.368485  [   54/   89]
per-ex loss: 0.369537  [   56/   89]
per-ex loss: 0.387645  [   58/   89]
per-ex loss: 0.495407  [   60/   89]
per-ex loss: 0.402505  [   62/   89]
per-ex loss: 0.435754  [   64/   89]
per-ex loss: 0.562258  [   66/   89]
per-ex loss: 0.680891  [   68/   89]
per-ex loss: 0.390178  [   70/   89]
per-ex loss: 0.410067  [   72/   89]
per-ex loss: 0.424343  [   74/   89]
per-ex loss: 0.528218  [   76/   89]
per-ex loss: 0.521323  [   78/   89]
per-ex loss: 0.553811  [   80/   89]
per-ex loss: 0.398619  [   82/   89]
per-ex loss: 0.375369  [   84/   89]
per-ex loss: 0.476896  [   86/   89]
per-ex loss: 0.532057  [   88/   89]
per-ex loss: 0.632373  [   89/   89]
Train Error: Avg loss: 0.48062930
validation Error: 
 Avg loss: 0.50453106 
 F1: 0.508351 
 Precision: 0.628100 
 Recall: 0.426951
 IoU: 0.340798

test Error: 
 Avg loss: 0.48144391 
 F1: 0.555269 
 Precision: 0.704223 
 Recall: 0.458327
 IoU: 0.384341

We have finished training iteration 362
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_360_.pth
per-ex loss: 0.466138  [    2/   89]
per-ex loss: 0.362747  [    4/   89]
per-ex loss: 0.407807  [    6/   89]
per-ex loss: 0.417626  [    8/   89]
per-ex loss: 0.485890  [   10/   89]
per-ex loss: 0.584386  [   12/   89]
per-ex loss: 0.418398  [   14/   89]
per-ex loss: 0.472731  [   16/   89]
per-ex loss: 0.419552  [   18/   89]
per-ex loss: 0.517545  [   20/   89]
per-ex loss: 0.539388  [   22/   89]
per-ex loss: 0.613185  [   24/   89]
per-ex loss: 0.460586  [   26/   89]
per-ex loss: 0.577324  [   28/   89]
per-ex loss: 0.467695  [   30/   89]
per-ex loss: 0.515110  [   32/   89]
per-ex loss: 0.461930  [   34/   89]
per-ex loss: 0.348451  [   36/   89]
per-ex loss: 0.463961  [   38/   89]
per-ex loss: 0.436363  [   40/   89]
per-ex loss: 0.404099  [   42/   89]
per-ex loss: 0.424880  [   44/   89]
per-ex loss: 0.434954  [   46/   89]
per-ex loss: 0.512108  [   48/   89]
per-ex loss: 0.517594  [   50/   89]
per-ex loss: 0.448200  [   52/   89]
per-ex loss: 0.503030  [   54/   89]
per-ex loss: 0.368883  [   56/   89]
per-ex loss: 0.408053  [   58/   89]
per-ex loss: 0.431536  [   60/   89]
per-ex loss: 0.346689  [   62/   89]
per-ex loss: 0.446980  [   64/   89]
per-ex loss: 0.465844  [   66/   89]
per-ex loss: 0.601216  [   68/   89]
per-ex loss: 0.426803  [   70/   89]
per-ex loss: 0.408796  [   72/   89]
per-ex loss: 0.410946  [   74/   89]
per-ex loss: 0.656436  [   76/   89]
per-ex loss: 0.416613  [   78/   89]
per-ex loss: 0.483374  [   80/   89]
per-ex loss: 0.373596  [   82/   89]
per-ex loss: 0.480883  [   84/   89]
per-ex loss: 0.475029  [   86/   89]
per-ex loss: 0.449381  [   88/   89]
per-ex loss: 0.582679  [   89/   89]
Train Error: Avg loss: 0.46478706
validation Error: 
 Avg loss: 0.54935143 
 F1: 0.484205 
 Precision: 0.641461 
 Recall: 0.388872
 IoU: 0.319440

test Error: 
 Avg loss: 0.51862531 
 F1: 0.516637 
 Precision: 0.675280 
 Recall: 0.418354
 IoU: 0.348288

We have finished training iteration 363
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_361_.pth
per-ex loss: 0.432370  [    2/   89]
per-ex loss: 0.517282  [    4/   89]
per-ex loss: 0.548136  [    6/   89]
per-ex loss: 0.476428  [    8/   89]
per-ex loss: 0.446114  [   10/   89]
per-ex loss: 0.466155  [   12/   89]
per-ex loss: 0.482472  [   14/   89]
per-ex loss: 0.584151  [   16/   89]
per-ex loss: 0.426739  [   18/   89]
per-ex loss: 0.466699  [   20/   89]
per-ex loss: 0.444839  [   22/   89]
per-ex loss: 0.612651  [   24/   89]
per-ex loss: 0.437189  [   26/   89]
per-ex loss: 0.372318  [   28/   89]
per-ex loss: 0.556368  [   30/   89]
per-ex loss: 0.462596  [   32/   89]
per-ex loss: 0.440261  [   34/   89]
per-ex loss: 0.357992  [   36/   89]
per-ex loss: 0.499808  [   38/   89]
per-ex loss: 0.655089  [   40/   89]
per-ex loss: 0.415106  [   42/   89]
per-ex loss: 0.581776  [   44/   89]
per-ex loss: 0.499342  [   46/   89]
per-ex loss: 0.470692  [   48/   89]
per-ex loss: 0.376603  [   50/   89]
per-ex loss: 0.391605  [   52/   89]
per-ex loss: 0.487834  [   54/   89]
per-ex loss: 0.533837  [   56/   89]
per-ex loss: 0.378044  [   58/   89]
per-ex loss: 0.350734  [   60/   89]
per-ex loss: 0.419147  [   62/   89]
per-ex loss: 0.441860  [   64/   89]
per-ex loss: 0.594297  [   66/   89]
per-ex loss: 0.420299  [   68/   89]
per-ex loss: 0.402097  [   70/   89]
per-ex loss: 0.480637  [   72/   89]
per-ex loss: 0.476930  [   74/   89]
per-ex loss: 0.492300  [   76/   89]
per-ex loss: 0.419333  [   78/   89]
per-ex loss: 0.483067  [   80/   89]
per-ex loss: 0.358143  [   82/   89]
per-ex loss: 0.458545  [   84/   89]
per-ex loss: 0.407547  [   86/   89]
per-ex loss: 0.527076  [   88/   89]
per-ex loss: 0.443798  [   89/   89]
Train Error: Avg loss: 0.46658465
validation Error: 
 Avg loss: 0.52361252 
 F1: 0.493533 
 Precision: 0.639697 
 Recall: 0.401739
 IoU: 0.327609

test Error: 
 Avg loss: 0.50848500 
 F1: 0.527624 
 Precision: 0.669356 
 Recall: 0.435426
 IoU: 0.358349

We have finished training iteration 364
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_362_.pth
per-ex loss: 0.524201  [    2/   89]
per-ex loss: 0.369445  [    4/   89]
per-ex loss: 0.470111  [    6/   89]
per-ex loss: 0.399604  [    8/   89]
per-ex loss: 0.570643  [   10/   89]
per-ex loss: 0.457205  [   12/   89]
per-ex loss: 0.459946  [   14/   89]
per-ex loss: 0.357265  [   16/   89]
per-ex loss: 0.354770  [   18/   89]
per-ex loss: 0.407491  [   20/   89]
per-ex loss: 0.586409  [   22/   89]
per-ex loss: 0.382302  [   24/   89]
per-ex loss: 0.424730  [   26/   89]
per-ex loss: 0.391660  [   28/   89]
per-ex loss: 0.547214  [   30/   89]
per-ex loss: 0.490045  [   32/   89]
per-ex loss: 0.524403  [   34/   89]
per-ex loss: 0.440787  [   36/   89]
per-ex loss: 0.621369  [   38/   89]
per-ex loss: 0.395419  [   40/   89]
per-ex loss: 0.626963  [   42/   89]
per-ex loss: 0.452906  [   44/   89]
per-ex loss: 0.474851  [   46/   89]
per-ex loss: 0.396228  [   48/   89]
per-ex loss: 0.355030  [   50/   89]
per-ex loss: 0.431558  [   52/   89]
per-ex loss: 0.523043  [   54/   89]
per-ex loss: 0.554058  [   56/   89]
per-ex loss: 0.383598  [   58/   89]
per-ex loss: 0.428903  [   60/   89]
per-ex loss: 0.423886  [   62/   89]
per-ex loss: 0.450095  [   64/   89]
per-ex loss: 0.417679  [   66/   89]
per-ex loss: 0.452154  [   68/   89]
per-ex loss: 0.546408  [   70/   89]
per-ex loss: 0.638364  [   72/   89]
per-ex loss: 0.413809  [   74/   89]
per-ex loss: 0.511913  [   76/   89]
per-ex loss: 0.552596  [   78/   89]
per-ex loss: 0.359878  [   80/   89]
per-ex loss: 0.444506  [   82/   89]
per-ex loss: 0.391786  [   84/   89]
per-ex loss: 0.560503  [   86/   89]
per-ex loss: 0.361214  [   88/   89]
per-ex loss: 0.438848  [   89/   89]
Train Error: Avg loss: 0.46146208
validation Error: 
 Avg loss: 0.53715089 
 F1: 0.480133 
 Precision: 0.634613 
 Recall: 0.386138
 IoU: 0.315905

test Error: 
 Avg loss: 0.52264141 
 F1: 0.512749 
 Precision: 0.653507 
 Recall: 0.421881
 IoU: 0.344763

We have finished training iteration 365
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_363_.pth
Error in cropping the image to the non-zero values in the fourth channel. Returned the original image.
per-ex loss: 0.469943  [    2/   89]
per-ex loss: 0.579330  [    4/   89]
per-ex loss: 0.434652  [    6/   89]
per-ex loss: 0.434298  [    8/   89]
per-ex loss: 0.526053  [   10/   89]
per-ex loss: 0.383394  [   12/   89]
per-ex loss: 0.515840  [   14/   89]
per-ex loss: 0.402245  [   16/   89]
per-ex loss: 0.554291  [   18/   89]
per-ex loss: 0.471229  [   20/   89]
per-ex loss: 0.577244  [   22/   89]
per-ex loss: 0.401219  [   24/   89]
per-ex loss: 0.442876  [   26/   89]
per-ex loss: 0.440057  [   28/   89]
per-ex loss: 0.476325  [   30/   89]
per-ex loss: 0.490847  [   32/   89]
per-ex loss: 0.378272  [   34/   89]
per-ex loss: 0.491431  [   36/   89]
per-ex loss: 0.407892  [   38/   89]
per-ex loss: 0.467180  [   40/   89]
per-ex loss: 0.639596  [   42/   89]
per-ex loss: 0.374152  [   44/   89]
per-ex loss: 0.514212  [   46/   89]
per-ex loss: 0.378300  [   48/   89]
per-ex loss: 0.422323  [   50/   89]
per-ex loss: 0.376008  [   52/   89]
per-ex loss: 0.425275  [   54/   89]
per-ex loss: 0.496123  [   56/   89]
per-ex loss: 0.658674  [   58/   89]
per-ex loss: 0.444944  [   60/   89]
per-ex loss: 0.580540  [   62/   89]
per-ex loss: 0.550394  [   64/   89]
per-ex loss: 0.413761  [   66/   89]
per-ex loss: 0.488926  [   68/   89]
per-ex loss: 0.712753  [   70/   89]
per-ex loss: 0.410734  [   72/   89]
per-ex loss: 0.627440  [   74/   89]
per-ex loss: 0.380208  [   76/   89]
per-ex loss: 0.375935  [   78/   89]
per-ex loss: 0.479852  [   80/   89]
per-ex loss: 0.422811  [   82/   89]
per-ex loss: 0.489655  [   84/   89]
per-ex loss: 0.398494  [   86/   89]
per-ex loss: 0.358204  [   88/   89]
per-ex loss: 0.418152  [   89/   89]
Train Error: Avg loss: 0.47071300
validation Error: 
 Avg loss: 0.53425713 
 F1: 0.488248 
 Precision: 0.621167 
 Recall: 0.402188
 IoU: 0.322969

test Error: 
 Avg loss: 0.51299875 
 F1: 0.522991 
 Precision: 0.653542 
 Recall: 0.435914
 IoU: 0.354088

We have finished training iteration 366
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_364_.pth
per-ex loss: 0.436837  [    2/   89]
per-ex loss: 0.448441  [    4/   89]
per-ex loss: 0.530045  [    6/   89]
per-ex loss: 0.453843  [    8/   89]
per-ex loss: 0.444197  [   10/   89]
per-ex loss: 0.366502  [   12/   89]
per-ex loss: 0.381120  [   14/   89]
per-ex loss: 0.452023  [   16/   89]
per-ex loss: 0.403871  [   18/   89]
per-ex loss: 0.638914  [   20/   89]
per-ex loss: 0.439149  [   22/   89]
per-ex loss: 0.565619  [   24/   89]
per-ex loss: 0.537935  [   26/   89]
per-ex loss: 0.421344  [   28/   89]
per-ex loss: 0.565760  [   30/   89]
per-ex loss: 0.394374  [   32/   89]
per-ex loss: 0.462384  [   34/   89]
per-ex loss: 0.383549  [   36/   89]
per-ex loss: 0.434341  [   38/   89]
per-ex loss: 0.581283  [   40/   89]
per-ex loss: 0.550577  [   42/   89]
per-ex loss: 0.392783  [   44/   89]
per-ex loss: 0.427167  [   46/   89]
per-ex loss: 0.402818  [   48/   89]
per-ex loss: 0.413003  [   50/   89]
per-ex loss: 0.597011  [   52/   89]
per-ex loss: 0.472074  [   54/   89]
per-ex loss: 0.570852  [   56/   89]
per-ex loss: 0.455425  [   58/   89]
per-ex loss: 0.358139  [   60/   89]
per-ex loss: 0.449720  [   62/   89]
per-ex loss: 0.486116  [   64/   89]
per-ex loss: 0.388370  [   66/   89]
per-ex loss: 0.604635  [   68/   89]
per-ex loss: 0.583386  [   70/   89]
per-ex loss: 0.487083  [   72/   89]
per-ex loss: 0.352607  [   74/   89]
per-ex loss: 0.374538  [   76/   89]
per-ex loss: 0.370528  [   78/   89]
per-ex loss: 0.411603  [   80/   89]
per-ex loss: 0.362467  [   82/   89]
per-ex loss: 0.506258  [   84/   89]
per-ex loss: 0.575451  [   86/   89]
per-ex loss: 0.425188  [   88/   89]
per-ex loss: 0.394924  [   89/   89]
Train Error: Avg loss: 0.46120568
validation Error: 
 Avg loss: 0.53555801 
 F1: 0.489567 
 Precision: 0.659607 
 Recall: 0.389228
 IoU: 0.324124

test Error: 
 Avg loss: 0.51242011 
 F1: 0.522602 
 Precision: 0.686490 
 Recall: 0.421884
 IoU: 0.353731

We have finished training iteration 367
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_365_.pth
per-ex loss: 0.598777  [    2/   89]
per-ex loss: 0.365993  [    4/   89]
per-ex loss: 0.463088  [    6/   89]
per-ex loss: 0.477281  [    8/   89]
per-ex loss: 0.549868  [   10/   89]
per-ex loss: 0.363611  [   12/   89]
per-ex loss: 0.386830  [   14/   89]
per-ex loss: 0.503769  [   16/   89]
per-ex loss: 0.446331  [   18/   89]
per-ex loss: 0.488558  [   20/   89]
per-ex loss: 0.447408  [   22/   89]
per-ex loss: 0.559569  [   24/   89]
per-ex loss: 0.492726  [   26/   89]
per-ex loss: 0.496056  [   28/   89]
per-ex loss: 0.507656  [   30/   89]
per-ex loss: 0.365073  [   32/   89]
per-ex loss: 0.603809  [   34/   89]
per-ex loss: 0.521672  [   36/   89]
per-ex loss: 0.519100  [   38/   89]
per-ex loss: 0.453327  [   40/   89]
per-ex loss: 0.417632  [   42/   89]
per-ex loss: 0.470889  [   44/   89]
per-ex loss: 0.358021  [   46/   89]
per-ex loss: 0.474407  [   48/   89]
per-ex loss: 0.489614  [   50/   89]
per-ex loss: 0.453805  [   52/   89]
per-ex loss: 0.469299  [   54/   89]
per-ex loss: 0.424773  [   56/   89]
per-ex loss: 0.351174  [   58/   89]
per-ex loss: 0.529045  [   60/   89]
per-ex loss: 0.384142  [   62/   89]
per-ex loss: 0.480897  [   64/   89]
per-ex loss: 0.422292  [   66/   89]
per-ex loss: 0.476270  [   68/   89]
per-ex loss: 0.412317  [   70/   89]
per-ex loss: 0.547685  [   72/   89]
per-ex loss: 0.637790  [   74/   89]
per-ex loss: 0.482700  [   76/   89]
per-ex loss: 0.417068  [   78/   89]
per-ex loss: 0.451223  [   80/   89]
per-ex loss: 0.376236  [   82/   89]
per-ex loss: 0.486883  [   84/   89]
per-ex loss: 0.433915  [   86/   89]
per-ex loss: 0.595224  [   88/   89]
per-ex loss: 0.361872  [   89/   89]
Train Error: Avg loss: 0.46701503
validation Error: 
 Avg loss: 0.54373088 
 F1: 0.486229 
 Precision: 0.637516 
 Recall: 0.392974
 IoU: 0.321204

test Error: 
 Avg loss: 0.51537619 
 F1: 0.519919 
 Precision: 0.671319 
 Recall: 0.424241
 IoU: 0.351277

We have finished training iteration 368
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_366_.pth
per-ex loss: 0.608513  [    2/   89]
per-ex loss: 0.404107  [    4/   89]
per-ex loss: 0.597281  [    6/   89]
per-ex loss: 0.443685  [    8/   89]
per-ex loss: 0.361956  [   10/   89]
per-ex loss: 0.382763  [   12/   89]
per-ex loss: 0.456643  [   14/   89]
per-ex loss: 0.580416  [   16/   89]
per-ex loss: 0.489760  [   18/   89]
per-ex loss: 0.561216  [   20/   89]
per-ex loss: 0.378902  [   22/   89]
per-ex loss: 0.540745  [   24/   89]
per-ex loss: 0.616306  [   26/   89]
per-ex loss: 0.474061  [   28/   89]
per-ex loss: 0.409405  [   30/   89]
per-ex loss: 0.419434  [   32/   89]
per-ex loss: 0.400794  [   34/   89]
per-ex loss: 0.540082  [   36/   89]
per-ex loss: 0.432680  [   38/   89]
per-ex loss: 0.515365  [   40/   89]
per-ex loss: 0.598086  [   42/   89]
per-ex loss: 0.520351  [   44/   89]
per-ex loss: 0.573375  [   46/   89]
per-ex loss: 0.400747  [   48/   89]
per-ex loss: 0.367786  [   50/   89]
per-ex loss: 0.431494  [   52/   89]
per-ex loss: 0.425106  [   54/   89]
per-ex loss: 0.610374  [   56/   89]
per-ex loss: 0.479085  [   58/   89]
per-ex loss: 0.385743  [   60/   89]
per-ex loss: 0.442516  [   62/   89]
per-ex loss: 0.416811  [   64/   89]
per-ex loss: 0.733815  [   66/   89]
per-ex loss: 0.380400  [   68/   89]
per-ex loss: 0.561041  [   70/   89]
per-ex loss: 0.441466  [   72/   89]
per-ex loss: 0.346704  [   74/   89]
per-ex loss: 0.499547  [   76/   89]
per-ex loss: 0.447737  [   78/   89]
per-ex loss: 0.481310  [   80/   89]
per-ex loss: 0.408157  [   82/   89]
per-ex loss: 0.481994  [   84/   89]
per-ex loss: 0.685183  [   86/   89]
per-ex loss: 0.573209  [   88/   89]
per-ex loss: 0.391996  [   89/   89]
Train Error: Avg loss: 0.48218107
validation Error: 
 Avg loss: 0.53616643 
 F1: 0.488865 
 Precision: 0.651128 
 Recall: 0.391341
 IoU: 0.323508

test Error: 
 Avg loss: 0.51417850 
 F1: 0.520873 
 Precision: 0.685161 
 Recall: 0.420134
 IoU: 0.352149

We have finished training iteration 369
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_367_.pth
per-ex loss: 0.494206  [    2/   89]
per-ex loss: 0.460656  [    4/   89]
per-ex loss: 0.362609  [    6/   89]
per-ex loss: 0.495516  [    8/   89]
per-ex loss: 0.680698  [   10/   89]
per-ex loss: 0.510922  [   12/   89]
per-ex loss: 0.433400  [   14/   89]
per-ex loss: 0.477429  [   16/   89]
per-ex loss: 0.437715  [   18/   89]
per-ex loss: 0.360445  [   20/   89]
per-ex loss: 0.476969  [   22/   89]
per-ex loss: 0.584734  [   24/   89]
per-ex loss: 0.383325  [   26/   89]
per-ex loss: 0.370907  [   28/   89]
per-ex loss: 0.401298  [   30/   89]
per-ex loss: 0.469217  [   32/   89]
per-ex loss: 0.390031  [   34/   89]
per-ex loss: 0.490232  [   36/   89]
per-ex loss: 0.417653  [   38/   89]
per-ex loss: 0.425186  [   40/   89]
per-ex loss: 0.609537  [   42/   89]
per-ex loss: 0.545034  [   44/   89]
per-ex loss: 0.488293  [   46/   89]
per-ex loss: 0.494043  [   48/   89]
per-ex loss: 0.414356  [   50/   89]
per-ex loss: 0.377743  [   52/   89]
per-ex loss: 0.412793  [   54/   89]
per-ex loss: 0.594536  [   56/   89]
per-ex loss: 0.433708  [   58/   89]
per-ex loss: 0.601778  [   60/   89]
per-ex loss: 0.471517  [   62/   89]
per-ex loss: 0.608756  [   64/   89]
per-ex loss: 0.498606  [   66/   89]
per-ex loss: 0.478539  [   68/   89]
per-ex loss: 0.534013  [   70/   89]
per-ex loss: 0.445740  [   72/   89]
per-ex loss: 0.392824  [   74/   89]
per-ex loss: 0.351967  [   76/   89]
per-ex loss: 0.502333  [   78/   89]
per-ex loss: 0.451961  [   80/   89]
per-ex loss: 0.430023  [   82/   89]
per-ex loss: 0.610935  [   84/   89]
per-ex loss: 0.464240  [   86/   89]
per-ex loss: 0.379531  [   88/   89]
per-ex loss: 0.377253  [   89/   89]
Train Error: Avg loss: 0.46873788
validation Error: 
 Avg loss: 0.50917056 
 F1: 0.511504 
 Precision: 0.618243 
 Recall: 0.436196
 IoU: 0.343638

test Error: 
 Avg loss: 0.47792767 
 F1: 0.558839 
 Precision: 0.687229 
 Recall: 0.470870
 IoU: 0.387770

We have finished training iteration 370
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_368_.pth
per-ex loss: 0.419918  [    2/   89]
per-ex loss: 0.506012  [    4/   89]
per-ex loss: 0.487839  [    6/   89]
per-ex loss: 0.368707  [    8/   89]
per-ex loss: 0.536352  [   10/   89]
per-ex loss: 0.567007  [   12/   89]
per-ex loss: 0.552077  [   14/   89]
per-ex loss: 0.422894  [   16/   89]
per-ex loss: 0.348267  [   18/   89]
per-ex loss: 0.373190  [   20/   89]
per-ex loss: 0.433770  [   22/   89]
per-ex loss: 0.426876  [   24/   89]
per-ex loss: 0.451545  [   26/   89]
per-ex loss: 0.473121  [   28/   89]
per-ex loss: 0.443552  [   30/   89]
per-ex loss: 0.481814  [   32/   89]
per-ex loss: 0.359331  [   34/   89]
per-ex loss: 0.375245  [   36/   89]
per-ex loss: 0.557609  [   38/   89]
per-ex loss: 0.581528  [   40/   89]
per-ex loss: 0.586081  [   42/   89]
per-ex loss: 0.561652  [   44/   89]
per-ex loss: 0.487569  [   46/   89]
per-ex loss: 0.394747  [   48/   89]
per-ex loss: 0.392499  [   50/   89]
per-ex loss: 0.378826  [   52/   89]
per-ex loss: 0.750244  [   54/   89]
per-ex loss: 0.414093  [   56/   89]
per-ex loss: 0.570678  [   58/   89]
per-ex loss: 0.408836  [   60/   89]
per-ex loss: 0.440492  [   62/   89]
per-ex loss: 0.468889  [   64/   89]
per-ex loss: 0.479177  [   66/   89]
per-ex loss: 0.586325  [   68/   89]
per-ex loss: 0.615464  [   70/   89]
per-ex loss: 0.416901  [   72/   89]
per-ex loss: 0.463507  [   74/   89]
per-ex loss: 0.517357  [   76/   89]
per-ex loss: 0.412532  [   78/   89]
per-ex loss: 0.436586  [   80/   89]
per-ex loss: 0.638254  [   82/   89]
per-ex loss: 0.464435  [   84/   89]
per-ex loss: 0.344512  [   86/   89]
per-ex loss: 0.553902  [   88/   89]
per-ex loss: 0.590708  [   89/   89]
Train Error: Avg loss: 0.47868712
validation Error: 
 Avg loss: 0.51527472 
 F1: 0.502300 
 Precision: 0.646946 
 Recall: 0.410515
 IoU: 0.335381

test Error: 
 Avg loss: 0.49757814 
 F1: 0.538044 
 Precision: 0.684190 
 Recall: 0.443343
 IoU: 0.368030

We have finished training iteration 371
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_369_.pth
per-ex loss: 0.475966  [    2/   89]
per-ex loss: 0.647864  [    4/   89]
per-ex loss: 0.518674  [    6/   89]
per-ex loss: 0.425469  [    8/   89]
per-ex loss: 0.375697  [   10/   89]
per-ex loss: 0.548993  [   12/   89]
per-ex loss: 0.632854  [   14/   89]
per-ex loss: 0.425145  [   16/   89]
per-ex loss: 0.382749  [   18/   89]
per-ex loss: 0.562627  [   20/   89]
per-ex loss: 0.412999  [   22/   89]
per-ex loss: 0.499898  [   24/   89]
per-ex loss: 0.451697  [   26/   89]
per-ex loss: 0.369898  [   28/   89]
per-ex loss: 0.456455  [   30/   89]
per-ex loss: 0.594845  [   32/   89]
per-ex loss: 0.411755  [   34/   89]
per-ex loss: 0.461404  [   36/   89]
per-ex loss: 0.393578  [   38/   89]
per-ex loss: 0.564585  [   40/   89]
per-ex loss: 0.558703  [   42/   89]
per-ex loss: 0.592610  [   44/   89]
per-ex loss: 0.458357  [   46/   89]
per-ex loss: 0.439109  [   48/   89]
per-ex loss: 0.391882  [   50/   89]
per-ex loss: 0.600645  [   52/   89]
per-ex loss: 0.507101  [   54/   89]
per-ex loss: 0.503779  [   56/   89]
per-ex loss: 0.420936  [   58/   89]
per-ex loss: 0.385797  [   60/   89]
per-ex loss: 0.461581  [   62/   89]
per-ex loss: 0.486484  [   64/   89]
per-ex loss: 0.440059  [   66/   89]
per-ex loss: 0.419800  [   68/   89]
per-ex loss: 0.387007  [   70/   89]
per-ex loss: 0.372484  [   72/   89]
per-ex loss: 0.426578  [   74/   89]
per-ex loss: 0.410649  [   76/   89]
per-ex loss: 0.404350  [   78/   89]
per-ex loss: 0.379377  [   80/   89]
per-ex loss: 0.614000  [   82/   89]
per-ex loss: 0.411901  [   84/   89]
per-ex loss: 0.525109  [   86/   89]
per-ex loss: 0.363121  [   88/   89]
per-ex loss: 0.381471  [   89/   89]
Train Error: Avg loss: 0.46568984
validation Error: 
 Avg loss: 0.52856109 
 F1: 0.488010 
 Precision: 0.623469 
 Recall: 0.400907
 IoU: 0.322760

test Error: 
 Avg loss: 0.51442417 
 F1: 0.522881 
 Precision: 0.640312 
 Recall: 0.441848
 IoU: 0.353987

We have finished training iteration 372
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_370_.pth
per-ex loss: 0.377100  [    2/   89]
per-ex loss: 0.495740  [    4/   89]
per-ex loss: 0.413177  [    6/   89]
per-ex loss: 0.463308  [    8/   89]
per-ex loss: 0.592525  [   10/   89]
per-ex loss: 0.440436  [   12/   89]
per-ex loss: 0.635447  [   14/   89]
per-ex loss: 0.455431  [   16/   89]
per-ex loss: 0.352897  [   18/   89]
per-ex loss: 0.459953  [   20/   89]
per-ex loss: 0.452459  [   22/   89]
per-ex loss: 0.517847  [   24/   89]
per-ex loss: 0.488439  [   26/   89]
per-ex loss: 0.402094  [   28/   89]
per-ex loss: 0.446584  [   30/   89]
per-ex loss: 0.461180  [   32/   89]
per-ex loss: 0.499068  [   34/   89]
per-ex loss: 0.473636  [   36/   89]
per-ex loss: 0.363061  [   38/   89]
per-ex loss: 0.495749  [   40/   89]
per-ex loss: 0.496953  [   42/   89]
per-ex loss: 0.486205  [   44/   89]
per-ex loss: 0.569725  [   46/   89]
per-ex loss: 0.469550  [   48/   89]
per-ex loss: 0.521022  [   50/   89]
per-ex loss: 0.386425  [   52/   89]
per-ex loss: 0.392487  [   54/   89]
per-ex loss: 0.417221  [   56/   89]
per-ex loss: 0.623303  [   58/   89]
per-ex loss: 0.373450  [   60/   89]
per-ex loss: 0.473202  [   62/   89]
per-ex loss: 0.389083  [   64/   89]
per-ex loss: 0.463641  [   66/   89]
per-ex loss: 0.612322  [   68/   89]
per-ex loss: 0.448760  [   70/   89]
per-ex loss: 0.403447  [   72/   89]
per-ex loss: 0.354765  [   74/   89]
per-ex loss: 0.658460  [   76/   89]
per-ex loss: 0.447788  [   78/   89]
per-ex loss: 0.482566  [   80/   89]
per-ex loss: 0.577941  [   82/   89]
per-ex loss: 0.417811  [   84/   89]
per-ex loss: 0.388567  [   86/   89]
per-ex loss: 0.582305  [   88/   89]
per-ex loss: 0.403428  [   89/   89]
Train Error: Avg loss: 0.46947906
validation Error: 
 Avg loss: 0.51504140 
 F1: 0.509102 
 Precision: 0.624247 
 Recall: 0.429820
 IoU: 0.341474

test Error: 
 Avg loss: 0.48624114 
 F1: 0.549872 
 Precision: 0.678366 
 Recall: 0.462304
 IoU: 0.379189

We have finished training iteration 373
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_371_.pth
per-ex loss: 0.399927  [    2/   89]
per-ex loss: 0.464861  [    4/   89]
per-ex loss: 0.435706  [    6/   89]
per-ex loss: 0.418274  [    8/   89]
per-ex loss: 0.411635  [   10/   89]
per-ex loss: 0.468425  [   12/   89]
per-ex loss: 0.505289  [   14/   89]
per-ex loss: 0.462690  [   16/   89]
per-ex loss: 0.415105  [   18/   89]
per-ex loss: 0.426398  [   20/   89]
per-ex loss: 0.429762  [   22/   89]
per-ex loss: 0.542451  [   24/   89]
per-ex loss: 0.392834  [   26/   89]
per-ex loss: 0.622785  [   28/   89]
per-ex loss: 0.648885  [   30/   89]
per-ex loss: 0.434389  [   32/   89]
per-ex loss: 0.384739  [   34/   89]
per-ex loss: 0.546849  [   36/   89]
per-ex loss: 0.402177  [   38/   89]
per-ex loss: 0.655628  [   40/   89]
per-ex loss: 0.381806  [   42/   89]
per-ex loss: 0.444675  [   44/   89]
per-ex loss: 0.463059  [   46/   89]
per-ex loss: 0.548204  [   48/   89]
per-ex loss: 0.411541  [   50/   89]
per-ex loss: 0.478347  [   52/   89]
per-ex loss: 0.482328  [   54/   89]
per-ex loss: 0.626711  [   56/   89]
per-ex loss: 0.356572  [   58/   89]
per-ex loss: 0.429070  [   60/   89]
per-ex loss: 0.474780  [   62/   89]
per-ex loss: 0.600458  [   64/   89]
per-ex loss: 0.368732  [   66/   89]
per-ex loss: 0.500371  [   68/   89]
per-ex loss: 0.420095  [   70/   89]
per-ex loss: 0.417349  [   72/   89]
per-ex loss: 0.401738  [   74/   89]
per-ex loss: 0.556813  [   76/   89]
per-ex loss: 0.364120  [   78/   89]
per-ex loss: 0.476170  [   80/   89]
per-ex loss: 0.659023  [   82/   89]
per-ex loss: 0.390742  [   84/   89]
per-ex loss: 0.607710  [   86/   89]
per-ex loss: 0.411472  [   88/   89]
per-ex loss: 0.539555  [   89/   89]
Train Error: Avg loss: 0.47289447
validation Error: 
 Avg loss: 0.51659944 
 F1: 0.499962 
 Precision: 0.637891 
 Recall: 0.411077
 IoU: 0.333300

test Error: 
 Avg loss: 0.49885256 
 F1: 0.537065 
 Precision: 0.672569 
 Recall: 0.447005
 IoU: 0.367115

We have finished training iteration 374
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_372_.pth
per-ex loss: 0.464603  [    2/   89]
per-ex loss: 0.447763  [    4/   89]
per-ex loss: 0.529063  [    6/   89]
per-ex loss: 0.375629  [    8/   89]
per-ex loss: 0.492515  [   10/   89]
per-ex loss: 0.487935  [   12/   89]
per-ex loss: 0.565048  [   14/   89]
per-ex loss: 0.400562  [   16/   89]
per-ex loss: 0.448361  [   18/   89]
per-ex loss: 0.334418  [   20/   89]
per-ex loss: 0.645427  [   22/   89]
per-ex loss: 0.469083  [   24/   89]
per-ex loss: 0.492136  [   26/   89]
per-ex loss: 0.517042  [   28/   89]
per-ex loss: 0.361328  [   30/   89]
per-ex loss: 0.532244  [   32/   89]
per-ex loss: 0.370880  [   34/   89]
per-ex loss: 0.570094  [   36/   89]
per-ex loss: 0.539415  [   38/   89]
per-ex loss: 0.607520  [   40/   89]
per-ex loss: 0.503970  [   42/   89]
per-ex loss: 0.579298  [   44/   89]
per-ex loss: 0.543909  [   46/   89]
per-ex loss: 0.398633  [   48/   89]
per-ex loss: 0.517039  [   50/   89]
per-ex loss: 0.543892  [   52/   89]
per-ex loss: 0.548228  [   54/   89]
per-ex loss: 0.594761  [   56/   89]
per-ex loss: 0.396856  [   58/   89]
per-ex loss: 0.464768  [   60/   89]
per-ex loss: 0.493314  [   62/   89]
per-ex loss: 0.376476  [   64/   89]
per-ex loss: 0.441281  [   66/   89]
per-ex loss: 0.574048  [   68/   89]
per-ex loss: 0.362249  [   70/   89]
per-ex loss: 0.474281  [   72/   89]
per-ex loss: 0.424832  [   74/   89]
per-ex loss: 0.375306  [   76/   89]
per-ex loss: 0.574272  [   78/   89]
per-ex loss: 0.370007  [   80/   89]
per-ex loss: 0.413283  [   82/   89]
per-ex loss: 0.481107  [   84/   89]
per-ex loss: 0.501668  [   86/   89]
per-ex loss: 0.378284  [   88/   89]
per-ex loss: 0.409837  [   89/   89]
Train Error: Avg loss: 0.47539263
validation Error: 
 Avg loss: 0.51534617 
 F1: 0.512517 
 Precision: 0.598390 
 Recall: 0.448197
 IoU: 0.344553

test Error: 
 Avg loss: 0.47333282 
 F1: 0.563163 
 Precision: 0.669522 
 Recall: 0.485964
 IoU: 0.391946

We have finished training iteration 375
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_373_.pth
per-ex loss: 0.528242  [    2/   89]
per-ex loss: 0.380185  [    4/   89]
per-ex loss: 0.413467  [    6/   89]
per-ex loss: 0.487644  [    8/   89]
per-ex loss: 0.411113  [   10/   89]
per-ex loss: 0.415842  [   12/   89]
per-ex loss: 0.478751  [   14/   89]
per-ex loss: 0.622306  [   16/   89]
per-ex loss: 0.433602  [   18/   89]
per-ex loss: 0.592035  [   20/   89]
per-ex loss: 0.414522  [   22/   89]
per-ex loss: 0.587532  [   24/   89]
per-ex loss: 0.430270  [   26/   89]
per-ex loss: 0.446279  [   28/   89]
per-ex loss: 0.564697  [   30/   89]
per-ex loss: 0.455794  [   32/   89]
per-ex loss: 0.609434  [   34/   89]
per-ex loss: 0.383317  [   36/   89]
per-ex loss: 0.471399  [   38/   89]
per-ex loss: 0.407588  [   40/   89]
per-ex loss: 0.503319  [   42/   89]
per-ex loss: 0.407433  [   44/   89]
per-ex loss: 0.558860  [   46/   89]
per-ex loss: 0.366577  [   48/   89]
per-ex loss: 0.381504  [   50/   89]
per-ex loss: 0.480041  [   52/   89]
per-ex loss: 0.373831  [   54/   89]
per-ex loss: 0.555267  [   56/   89]
per-ex loss: 0.426549  [   58/   89]
per-ex loss: 0.351114  [   60/   89]
per-ex loss: 0.446285  [   62/   89]
per-ex loss: 0.367050  [   64/   89]
per-ex loss: 0.503763  [   66/   89]
per-ex loss: 0.626505  [   68/   89]
per-ex loss: 0.406640  [   70/   89]
per-ex loss: 0.399058  [   72/   89]
per-ex loss: 0.405491  [   74/   89]
per-ex loss: 0.606922  [   76/   89]
per-ex loss: 0.615787  [   78/   89]
per-ex loss: 0.416395  [   80/   89]
per-ex loss: 0.423078  [   82/   89]
per-ex loss: 0.447977  [   84/   89]
per-ex loss: 0.627355  [   86/   89]
per-ex loss: 0.639216  [   88/   89]
per-ex loss: 0.568603  [   89/   89]
Train Error: Avg loss: 0.47641424
validation Error: 
 Avg loss: 0.54579301 
 F1: 0.473473 
 Precision: 0.662134 
 Recall: 0.368482
 IoU: 0.310163

test Error: 
 Avg loss: 0.53086525 
 F1: 0.503826 
 Precision: 0.675931 
 Recall: 0.401577
 IoU: 0.336743

We have finished training iteration 376
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_374_.pth
per-ex loss: 0.495148  [    2/   89]
per-ex loss: 0.429504  [    4/   89]
per-ex loss: 0.397050  [    6/   89]
per-ex loss: 0.477742  [    8/   89]
per-ex loss: 0.465321  [   10/   89]
per-ex loss: 0.388852  [   12/   89]
per-ex loss: 0.505059  [   14/   89]
per-ex loss: 0.564951  [   16/   89]
per-ex loss: 0.571650  [   18/   89]
per-ex loss: 0.587560  [   20/   89]
per-ex loss: 0.412759  [   22/   89]
per-ex loss: 0.612861  [   24/   89]
per-ex loss: 0.603017  [   26/   89]
per-ex loss: 0.543580  [   28/   89]
per-ex loss: 0.426803  [   30/   89]
per-ex loss: 0.462455  [   32/   89]
per-ex loss: 0.492356  [   34/   89]
per-ex loss: 0.391528  [   36/   89]
per-ex loss: 0.363746  [   38/   89]
per-ex loss: 0.605011  [   40/   89]
per-ex loss: 0.419067  [   42/   89]
per-ex loss: 0.527123  [   44/   89]
per-ex loss: 0.358593  [   46/   89]
per-ex loss: 0.440517  [   48/   89]
per-ex loss: 0.451521  [   50/   89]
per-ex loss: 0.428245  [   52/   89]
per-ex loss: 0.378229  [   54/   89]
per-ex loss: 0.392801  [   56/   89]
per-ex loss: 0.416040  [   58/   89]
per-ex loss: 0.445203  [   60/   89]
per-ex loss: 0.507352  [   62/   89]
per-ex loss: 0.376948  [   64/   89]
per-ex loss: 0.631740  [   66/   89]
per-ex loss: 0.344358  [   68/   89]
per-ex loss: 0.372541  [   70/   89]
per-ex loss: 0.486741  [   72/   89]
per-ex loss: 0.482270  [   74/   89]
per-ex loss: 0.444827  [   76/   89]
per-ex loss: 0.369574  [   78/   89]
per-ex loss: 0.634635  [   80/   89]
per-ex loss: 0.516727  [   82/   89]
per-ex loss: 0.388194  [   84/   89]
per-ex loss: 0.386848  [   86/   89]
per-ex loss: 0.486994  [   88/   89]
per-ex loss: 0.533177  [   89/   89]
Train Error: Avg loss: 0.46704924
validation Error: 
 Avg loss: 0.50444481 
 F1: 0.510290 
 Precision: 0.625473 
 Recall: 0.430932
 IoU: 0.342543

test Error: 
 Avg loss: 0.48340442 
 F1: 0.552746 
 Precision: 0.685799 
 Recall: 0.462932
 IoU: 0.381927

We have finished training iteration 377
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_375_.pth
per-ex loss: 0.393060  [    2/   89]
per-ex loss: 0.492116  [    4/   89]
per-ex loss: 0.380009  [    6/   89]
per-ex loss: 0.486170  [    8/   89]
per-ex loss: 0.420083  [   10/   89]
per-ex loss: 0.418717  [   12/   89]
per-ex loss: 0.565831  [   14/   89]
per-ex loss: 0.598589  [   16/   89]
per-ex loss: 0.543596  [   18/   89]
per-ex loss: 0.361718  [   20/   89]
per-ex loss: 0.399281  [   22/   89]
per-ex loss: 0.488726  [   24/   89]
per-ex loss: 0.460600  [   26/   89]
per-ex loss: 0.522044  [   28/   89]
per-ex loss: 0.402195  [   30/   89]
per-ex loss: 0.387089  [   32/   89]
per-ex loss: 0.445245  [   34/   89]
per-ex loss: 0.507900  [   36/   89]
per-ex loss: 0.506406  [   38/   89]
per-ex loss: 0.548036  [   40/   89]
per-ex loss: 0.509077  [   42/   89]
per-ex loss: 0.462652  [   44/   89]
per-ex loss: 0.567139  [   46/   89]
per-ex loss: 0.493848  [   48/   89]
per-ex loss: 0.471572  [   50/   89]
per-ex loss: 0.468732  [   52/   89]
per-ex loss: 0.462546  [   54/   89]
per-ex loss: 0.391232  [   56/   89]
per-ex loss: 0.452427  [   58/   89]
per-ex loss: 0.428097  [   60/   89]
per-ex loss: 0.343940  [   62/   89]
per-ex loss: 0.408980  [   64/   89]
per-ex loss: 0.441699  [   66/   89]
per-ex loss: 0.582963  [   68/   89]
per-ex loss: 0.427870  [   70/   89]
per-ex loss: 0.453199  [   72/   89]
per-ex loss: 0.622540  [   74/   89]
per-ex loss: 0.445430  [   76/   89]
per-ex loss: 0.403116  [   78/   89]
per-ex loss: 0.377743  [   80/   89]
per-ex loss: 0.604339  [   82/   89]
per-ex loss: 0.472174  [   84/   89]
per-ex loss: 0.395471  [   86/   89]
per-ex loss: 0.420821  [   88/   89]
per-ex loss: 0.572424  [   89/   89]
Train Error: Avg loss: 0.46683193
validation Error: 
 Avg loss: 0.51895998 
 F1: 0.497507 
 Precision: 0.629543 
 Recall: 0.411254
 IoU: 0.331121

test Error: 
 Avg loss: 0.50326190 
 F1: 0.533268 
 Precision: 0.661385 
 Recall: 0.446731
 IoU: 0.363576

We have finished training iteration 378
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_376_.pth
per-ex loss: 0.380130  [    2/   89]
per-ex loss: 0.571654  [    4/   89]
per-ex loss: 0.418560  [    6/   89]
per-ex loss: 0.368863  [    8/   89]
per-ex loss: 0.463915  [   10/   89]
per-ex loss: 0.356887  [   12/   89]
per-ex loss: 0.620987  [   14/   89]
per-ex loss: 0.376299  [   16/   89]
per-ex loss: 0.593128  [   18/   89]
per-ex loss: 0.544418  [   20/   89]
per-ex loss: 0.396672  [   22/   89]
per-ex loss: 0.445158  [   24/   89]
per-ex loss: 0.395737  [   26/   89]
per-ex loss: 0.403980  [   28/   89]
per-ex loss: 0.528596  [   30/   89]
per-ex loss: 0.458780  [   32/   89]
per-ex loss: 0.529116  [   34/   89]
per-ex loss: 0.436150  [   36/   89]
per-ex loss: 0.399039  [   38/   89]
per-ex loss: 0.500105  [   40/   89]
per-ex loss: 0.368968  [   42/   89]
per-ex loss: 0.448713  [   44/   89]
per-ex loss: 0.412201  [   46/   89]
per-ex loss: 0.624721  [   48/   89]
per-ex loss: 0.558117  [   50/   89]
per-ex loss: 0.560927  [   52/   89]
per-ex loss: 0.532122  [   54/   89]
per-ex loss: 0.395953  [   56/   89]
per-ex loss: 0.430320  [   58/   89]
per-ex loss: 0.433495  [   60/   89]
per-ex loss: 0.439221  [   62/   89]
per-ex loss: 0.383375  [   64/   89]
per-ex loss: 0.435453  [   66/   89]
per-ex loss: 0.447163  [   68/   89]
per-ex loss: 0.424521  [   70/   89]
per-ex loss: 0.520022  [   72/   89]
per-ex loss: 0.391129  [   74/   89]
per-ex loss: 0.473107  [   76/   89]
per-ex loss: 0.381421  [   78/   89]
per-ex loss: 0.542943  [   80/   89]
per-ex loss: 0.494409  [   82/   89]
per-ex loss: 0.579277  [   84/   89]
per-ex loss: 0.470301  [   86/   89]
per-ex loss: 0.585282  [   88/   89]
per-ex loss: 0.598042  [   89/   89]
Train Error: Avg loss: 0.46931952
validation Error: 
 Avg loss: 0.52205592 
 F1: 0.495226 
 Precision: 0.626965 
 Recall: 0.409237
 IoU: 0.329103

test Error: 
 Avg loss: 0.50635289 
 F1: 0.529942 
 Precision: 0.656926 
 Recall: 0.444098
 IoU: 0.360491

We have finished training iteration 379
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_377_.pth
Error in cropping the image to the non-zero values in the fourth channel. Returned the original image.
per-ex loss: 0.630850  [    2/   89]
per-ex loss: 0.390019  [    4/   89]
per-ex loss: 0.487309  [    6/   89]
per-ex loss: 0.393357  [    8/   89]
per-ex loss: 0.491211  [   10/   89]
per-ex loss: 0.391620  [   12/   89]
per-ex loss: 0.413930  [   14/   89]
per-ex loss: 0.618243  [   16/   89]
per-ex loss: 0.582985  [   18/   89]
per-ex loss: 0.460195  [   20/   89]
per-ex loss: 0.555088  [   22/   89]
per-ex loss: 0.364001  [   24/   89]
per-ex loss: 0.385799  [   26/   89]
per-ex loss: 0.390097  [   28/   89]
per-ex loss: 0.607901  [   30/   89]
per-ex loss: 0.523469  [   32/   89]
per-ex loss: 0.403312  [   34/   89]
per-ex loss: 0.408551  [   36/   89]
per-ex loss: 0.563677  [   38/   89]
per-ex loss: 0.405445  [   40/   89]
per-ex loss: 0.392406  [   42/   89]
per-ex loss: 0.455504  [   44/   89]
per-ex loss: 0.346530  [   46/   89]
per-ex loss: 0.597937  [   48/   89]
per-ex loss: 0.546660  [   50/   89]
per-ex loss: 0.487911  [   52/   89]
per-ex loss: 0.474640  [   54/   89]
per-ex loss: 0.602517  [   56/   89]
per-ex loss: 0.535962  [   58/   89]
per-ex loss: 0.467304  [   60/   89]
per-ex loss: 0.503981  [   62/   89]
per-ex loss: 0.447539  [   64/   89]
per-ex loss: 0.442515  [   66/   89]
per-ex loss: 0.488111  [   68/   89]
per-ex loss: 0.455660  [   70/   89]
per-ex loss: 0.492778  [   72/   89]
per-ex loss: 0.432129  [   74/   89]
per-ex loss: 0.384966  [   76/   89]
per-ex loss: 0.558030  [   78/   89]
per-ex loss: 0.400313  [   80/   89]
per-ex loss: 0.447496  [   82/   89]
per-ex loss: 0.397641  [   84/   89]
per-ex loss: 0.445863  [   86/   89]
per-ex loss: 0.512217  [   88/   89]
per-ex loss: 0.519232  [   89/   89]
Train Error: Avg loss: 0.47339784
validation Error: 
 Avg loss: 0.51421086 
 F1: 0.507480 
 Precision: 0.607255 
 Recall: 0.435866
 IoU: 0.340016

test Error: 
 Avg loss: 0.48415697 
 F1: 0.551553 
 Precision: 0.669456 
 Recall: 0.468961
 IoU: 0.380789

We have finished training iteration 380
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_378_.pth
Error in cropping the image to the non-zero values in the fourth channel. Returned the original image.
per-ex loss: 0.424876  [    2/   89]
per-ex loss: 0.522429  [    4/   89]
per-ex loss: 0.384926  [    6/   89]
per-ex loss: 0.562646  [    8/   89]
per-ex loss: 0.389289  [   10/   89]
per-ex loss: 0.439486  [   12/   89]
per-ex loss: 0.595814  [   14/   89]
per-ex loss: 0.582139  [   16/   89]
per-ex loss: 0.392885  [   18/   89]
per-ex loss: 0.536429  [   20/   89]
per-ex loss: 0.529067  [   22/   89]
per-ex loss: 0.431415  [   24/   89]
per-ex loss: 0.386150  [   26/   89]
per-ex loss: 0.411693  [   28/   89]
per-ex loss: 0.403168  [   30/   89]
per-ex loss: 0.458162  [   32/   89]
per-ex loss: 0.553206  [   34/   89]
per-ex loss: 0.470582  [   36/   89]
per-ex loss: 0.636031  [   38/   89]
per-ex loss: 0.600982  [   40/   89]
per-ex loss: 0.484434  [   42/   89]
per-ex loss: 0.499840  [   44/   89]
per-ex loss: 0.445897  [   46/   89]
per-ex loss: 0.371022  [   48/   89]
per-ex loss: 0.366082  [   50/   89]
per-ex loss: 0.494291  [   52/   89]
per-ex loss: 0.378615  [   54/   89]
per-ex loss: 0.667351  [   56/   89]
per-ex loss: 0.447874  [   58/   89]
per-ex loss: 0.399356  [   60/   89]
per-ex loss: 0.593434  [   62/   89]
per-ex loss: 0.578321  [   64/   89]
per-ex loss: 0.412461  [   66/   89]
per-ex loss: 0.389460  [   68/   89]
per-ex loss: 0.542113  [   70/   89]
per-ex loss: 0.390803  [   72/   89]
per-ex loss: 0.528665  [   74/   89]
per-ex loss: 0.425990  [   76/   89]
per-ex loss: 0.443431  [   78/   89]
per-ex loss: 0.415054  [   80/   89]
per-ex loss: 0.410401  [   82/   89]
per-ex loss: 0.504063  [   84/   89]
per-ex loss: 0.484587  [   86/   89]
per-ex loss: 0.494733  [   88/   89]
per-ex loss: 0.639269  [   89/   89]
Train Error: Avg loss: 0.47819828
validation Error: 
 Avg loss: 0.50535744 
 F1: 0.514071 
 Precision: 0.595981 
 Recall: 0.451956
 IoU: 0.345959

test Error: 
 Avg loss: 0.47215365 
 F1: 0.565329 
 Precision: 0.661529 
 Recall: 0.493556
 IoU: 0.394048

We have finished training iteration 381
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_379_.pth
per-ex loss: 0.378485  [    2/   89]
per-ex loss: 0.654255  [    4/   89]
per-ex loss: 0.390384  [    6/   89]
per-ex loss: 0.416242  [    8/   89]
per-ex loss: 0.382880  [   10/   89]
per-ex loss: 0.604485  [   12/   89]
per-ex loss: 0.376561  [   14/   89]
per-ex loss: 0.470843  [   16/   89]
per-ex loss: 0.382571  [   18/   89]
per-ex loss: 0.512066  [   20/   89]
per-ex loss: 0.500912  [   22/   89]
per-ex loss: 0.458950  [   24/   89]
per-ex loss: 0.438759  [   26/   89]
per-ex loss: 0.491756  [   28/   89]
per-ex loss: 0.438187  [   30/   89]
per-ex loss: 0.437097  [   32/   89]
per-ex loss: 0.430508  [   34/   89]
per-ex loss: 0.601506  [   36/   89]
per-ex loss: 0.482476  [   38/   89]
per-ex loss: 0.436294  [   40/   89]
per-ex loss: 0.381397  [   42/   89]
per-ex loss: 0.443629  [   44/   89]
per-ex loss: 0.362468  [   46/   89]
per-ex loss: 0.468704  [   48/   89]
per-ex loss: 0.471210  [   50/   89]
per-ex loss: 0.449639  [   52/   89]
per-ex loss: 0.456687  [   54/   89]
per-ex loss: 0.452011  [   56/   89]
per-ex loss: 0.415553  [   58/   89]
per-ex loss: 0.465490  [   60/   89]
per-ex loss: 0.522703  [   62/   89]
per-ex loss: 0.444078  [   64/   89]
per-ex loss: 0.415046  [   66/   89]
per-ex loss: 0.350586  [   68/   89]
per-ex loss: 0.586391  [   70/   89]
per-ex loss: 0.379036  [   72/   89]
per-ex loss: 0.425791  [   74/   89]
per-ex loss: 0.539939  [   76/   89]
per-ex loss: 0.508314  [   78/   89]
per-ex loss: 0.587778  [   80/   89]
per-ex loss: 0.400382  [   82/   89]
per-ex loss: 0.619083  [   84/   89]
per-ex loss: 0.634110  [   86/   89]
per-ex loss: 0.552112  [   88/   89]
per-ex loss: 0.523311  [   89/   89]
Train Error: Avg loss: 0.46979254
validation Error: 
 Avg loss: 0.54769131 
 F1: 0.471035 
 Precision: 0.657427 
 Recall: 0.366988
 IoU: 0.308075

test Error: 
 Avg loss: 0.53348440 
 F1: 0.501583 
 Precision: 0.670602 
 Recall: 0.400612
 IoU: 0.334742

We have finished training iteration 382
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_380_.pth
Error in cropping the image to the non-zero values in the fourth channel. Returned the original image.
per-ex loss: 0.607583  [    2/   89]
per-ex loss: 0.394958  [    4/   89]
per-ex loss: 0.441213  [    6/   89]
per-ex loss: 0.415227  [    8/   89]
per-ex loss: 0.504338  [   10/   89]
per-ex loss: 0.426344  [   12/   89]
per-ex loss: 0.477331  [   14/   89]
per-ex loss: 0.615613  [   16/   89]
per-ex loss: 0.470131  [   18/   89]
per-ex loss: 0.383907  [   20/   89]
per-ex loss: 0.458641  [   22/   89]
per-ex loss: 0.371319  [   24/   89]
per-ex loss: 0.358094  [   26/   89]
per-ex loss: 0.632180  [   28/   89]
per-ex loss: 0.432366  [   30/   89]
per-ex loss: 0.558120  [   32/   89]
per-ex loss: 0.633961  [   34/   89]
per-ex loss: 0.451957  [   36/   89]
per-ex loss: 0.547253  [   38/   89]
per-ex loss: 0.416618  [   40/   89]
per-ex loss: 0.372307  [   42/   89]
per-ex loss: 0.368532  [   44/   89]
per-ex loss: 0.384978  [   46/   89]
per-ex loss: 0.424548  [   48/   89]
per-ex loss: 0.590123  [   50/   89]
per-ex loss: 0.390627  [   52/   89]
per-ex loss: 0.449479  [   54/   89]
per-ex loss: 0.598768  [   56/   89]
per-ex loss: 0.372223  [   58/   89]
per-ex loss: 0.424528  [   60/   89]
per-ex loss: 0.457297  [   62/   89]
per-ex loss: 0.484793  [   64/   89]
per-ex loss: 0.377838  [   66/   89]
per-ex loss: 0.684516  [   68/   89]
per-ex loss: 0.415870  [   70/   89]
per-ex loss: 0.384386  [   72/   89]
per-ex loss: 0.471967  [   74/   89]
per-ex loss: 0.554184  [   76/   89]
per-ex loss: 0.448469  [   78/   89]
per-ex loss: 0.567796  [   80/   89]
per-ex loss: 0.473812  [   82/   89]
per-ex loss: 0.507305  [   84/   89]
per-ex loss: 0.528954  [   86/   89]
per-ex loss: 0.623658  [   88/   89]
per-ex loss: 0.409400  [   89/   89]
Train Error: Avg loss: 0.47474474
validation Error: 
 Avg loss: 0.51844794 
 F1: 0.493204 
 Precision: 0.631467 
 Recall: 0.404612
 IoU: 0.327319

test Error: 
 Avg loss: 0.50978071 
 F1: 0.526341 
 Precision: 0.661167 
 Recall: 0.437189
 IoU: 0.357166

We have finished training iteration 383
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_381_.pth
per-ex loss: 0.492205  [    2/   89]
per-ex loss: 0.396554  [    4/   89]
per-ex loss: 0.414742  [    6/   89]
per-ex loss: 0.604927  [    8/   89]
per-ex loss: 0.443535  [   10/   89]
per-ex loss: 0.652825  [   12/   89]
per-ex loss: 0.504845  [   14/   89]
per-ex loss: 0.491162  [   16/   89]
per-ex loss: 0.372919  [   18/   89]
per-ex loss: 0.462964  [   20/   89]
per-ex loss: 0.423649  [   22/   89]
per-ex loss: 0.469214  [   24/   89]
per-ex loss: 0.515580  [   26/   89]
per-ex loss: 0.394848  [   28/   89]
per-ex loss: 0.367559  [   30/   89]
per-ex loss: 0.602563  [   32/   89]
per-ex loss: 0.367844  [   34/   89]
per-ex loss: 0.458772  [   36/   89]
per-ex loss: 0.418409  [   38/   89]
per-ex loss: 0.653464  [   40/   89]
per-ex loss: 0.464808  [   42/   89]
per-ex loss: 0.429641  [   44/   89]
per-ex loss: 0.439417  [   46/   89]
per-ex loss: 0.613656  [   48/   89]
per-ex loss: 0.386265  [   50/   89]
per-ex loss: 0.488075  [   52/   89]
per-ex loss: 0.459617  [   54/   89]
per-ex loss: 0.456617  [   56/   89]
per-ex loss: 0.411703  [   58/   89]
per-ex loss: 0.448435  [   60/   89]
per-ex loss: 0.412361  [   62/   89]
per-ex loss: 0.422490  [   64/   89]
per-ex loss: 0.388700  [   66/   89]
per-ex loss: 0.432119  [   68/   89]
per-ex loss: 0.373974  [   70/   89]
per-ex loss: 0.478885  [   72/   89]
per-ex loss: 0.430698  [   74/   89]
per-ex loss: 0.422475  [   76/   89]
per-ex loss: 0.405295  [   78/   89]
per-ex loss: 0.395114  [   80/   89]
per-ex loss: 0.382984  [   82/   89]
per-ex loss: 0.689871  [   84/   89]
per-ex loss: 0.654471  [   86/   89]
per-ex loss: 0.528507  [   88/   89]
per-ex loss: 0.612603  [   89/   89]
Train Error: Avg loss: 0.46971907
validation Error: 
 Avg loss: 0.54261699 
 F1: 0.477382 
 Precision: 0.648220 
 Recall: 0.377810
 IoU: 0.313527

test Error: 
 Avg loss: 0.52361892 
 F1: 0.511328 
 Precision: 0.663296 
 Recall: 0.416015
 IoU: 0.343479

We have finished training iteration 384
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_382_.pth
per-ex loss: 0.561135  [    2/   89]
per-ex loss: 0.552411  [    4/   89]
per-ex loss: 0.598799  [    6/   89]
per-ex loss: 0.501979  [    8/   89]
per-ex loss: 0.518821  [   10/   89]
per-ex loss: 0.403924  [   12/   89]
per-ex loss: 0.518861  [   14/   89]
per-ex loss: 0.600845  [   16/   89]
per-ex loss: 0.599795  [   18/   89]
per-ex loss: 0.441146  [   20/   89]
per-ex loss: 0.425191  [   22/   89]
per-ex loss: 0.380691  [   24/   89]
per-ex loss: 0.408893  [   26/   89]
per-ex loss: 0.464058  [   28/   89]
per-ex loss: 0.473015  [   30/   89]
per-ex loss: 0.389806  [   32/   89]
per-ex loss: 0.401915  [   34/   89]
per-ex loss: 0.561705  [   36/   89]
per-ex loss: 0.464438  [   38/   89]
per-ex loss: 0.362250  [   40/   89]
per-ex loss: 0.472574  [   42/   89]
per-ex loss: 0.371711  [   44/   89]
per-ex loss: 0.591534  [   46/   89]
per-ex loss: 0.428274  [   48/   89]
per-ex loss: 0.581194  [   50/   89]
per-ex loss: 0.499937  [   52/   89]
per-ex loss: 0.381377  [   54/   89]
per-ex loss: 0.392953  [   56/   89]
per-ex loss: 0.474830  [   58/   89]
per-ex loss: 0.410568  [   60/   89]
per-ex loss: 0.378355  [   62/   89]
per-ex loss: 0.383211  [   64/   89]
per-ex loss: 0.539469  [   66/   89]
per-ex loss: 0.401806  [   68/   89]
per-ex loss: 0.428016  [   70/   89]
per-ex loss: 0.463228  [   72/   89]
per-ex loss: 0.386817  [   74/   89]
per-ex loss: 0.627681  [   76/   89]
per-ex loss: 0.369315  [   78/   89]
per-ex loss: 0.484065  [   80/   89]
per-ex loss: 0.517007  [   82/   89]
per-ex loss: 0.374423  [   84/   89]
per-ex loss: 0.422207  [   86/   89]
per-ex loss: 0.384054  [   88/   89]
per-ex loss: 0.646278  [   89/   89]
Train Error: Avg loss: 0.46756793
validation Error: 
 Avg loss: 0.51841162 
 F1: 0.512995 
 Precision: 0.621608 
 Recall: 0.436693
 IoU: 0.344986

test Error: 
 Avg loss: 0.47771306 
 F1: 0.558983 
 Precision: 0.689887 
 Recall: 0.469833
 IoU: 0.387908

We have finished training iteration 385
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_383_.pth
per-ex loss: 0.419458  [    2/   89]
per-ex loss: 0.500273  [    4/   89]
per-ex loss: 0.467288  [    6/   89]
per-ex loss: 0.361668  [    8/   89]
per-ex loss: 0.412598  [   10/   89]
per-ex loss: 0.567498  [   12/   89]
per-ex loss: 0.477323  [   14/   89]
per-ex loss: 0.656401  [   16/   89]
per-ex loss: 0.456735  [   18/   89]
per-ex loss: 0.441139  [   20/   89]
per-ex loss: 0.553327  [   22/   89]
per-ex loss: 0.517113  [   24/   89]
per-ex loss: 0.425748  [   26/   89]
per-ex loss: 0.557256  [   28/   89]
per-ex loss: 0.378176  [   30/   89]
per-ex loss: 0.421702  [   32/   89]
per-ex loss: 0.393793  [   34/   89]
per-ex loss: 0.426698  [   36/   89]
per-ex loss: 0.416342  [   38/   89]
per-ex loss: 0.623086  [   40/   89]
per-ex loss: 0.500072  [   42/   89]
per-ex loss: 0.427154  [   44/   89]
per-ex loss: 0.469102  [   46/   89]
per-ex loss: 0.624246  [   48/   89]
per-ex loss: 0.418427  [   50/   89]
per-ex loss: 0.423030  [   52/   89]
per-ex loss: 0.495445  [   54/   89]
per-ex loss: 0.587884  [   56/   89]
per-ex loss: 0.480314  [   58/   89]
per-ex loss: 0.456352  [   60/   89]
per-ex loss: 0.392095  [   62/   89]
per-ex loss: 0.415859  [   64/   89]
per-ex loss: 0.368848  [   66/   89]
per-ex loss: 0.371271  [   68/   89]
per-ex loss: 0.463278  [   70/   89]
per-ex loss: 0.407029  [   72/   89]
per-ex loss: 0.449479  [   74/   89]
per-ex loss: 0.388649  [   76/   89]
per-ex loss: 0.435343  [   78/   89]
per-ex loss: 0.400708  [   80/   89]
per-ex loss: 0.414640  [   82/   89]
per-ex loss: 0.565767  [   84/   89]
per-ex loss: 0.375209  [   86/   89]
per-ex loss: 0.499178  [   88/   89]
per-ex loss: 0.416146  [   89/   89]
Train Error: Avg loss: 0.46042550
validation Error: 
 Avg loss: 0.53791969 
 F1: 0.496535 
 Precision: 0.602238 
 Recall: 0.422397
 IoU: 0.330260

test Error: 
 Avg loss: 0.50507112 
 F1: 0.531504 
 Precision: 0.641667 
 Recall: 0.453625
 IoU: 0.361938

We have finished training iteration 386
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_384_.pth
per-ex loss: 0.566958  [    2/   89]
per-ex loss: 0.360631  [    4/   89]
per-ex loss: 0.387509  [    6/   89]
per-ex loss: 0.542266  [    8/   89]
per-ex loss: 0.406298  [   10/   89]
per-ex loss: 0.426776  [   12/   89]
per-ex loss: 0.629628  [   14/   89]
per-ex loss: 0.492459  [   16/   89]
per-ex loss: 0.385551  [   18/   89]
per-ex loss: 0.624530  [   20/   89]
per-ex loss: 0.482207  [   22/   89]
per-ex loss: 0.657496  [   24/   89]
per-ex loss: 0.427318  [   26/   89]
per-ex loss: 0.473013  [   28/   89]
per-ex loss: 0.635216  [   30/   89]
per-ex loss: 0.364929  [   32/   89]
per-ex loss: 0.403790  [   34/   89]
per-ex loss: 0.426790  [   36/   89]
per-ex loss: 0.554708  [   38/   89]
per-ex loss: 0.521233  [   40/   89]
per-ex loss: 0.388511  [   42/   89]
per-ex loss: 0.368297  [   44/   89]
per-ex loss: 0.497850  [   46/   89]
per-ex loss: 0.458393  [   48/   89]
per-ex loss: 0.412836  [   50/   89]
per-ex loss: 0.378439  [   52/   89]
per-ex loss: 0.363818  [   54/   89]
per-ex loss: 0.535107  [   56/   89]
per-ex loss: 0.416439  [   58/   89]
per-ex loss: 0.466630  [   60/   89]
per-ex loss: 0.373124  [   62/   89]
per-ex loss: 0.613404  [   64/   89]
per-ex loss: 0.479442  [   66/   89]
per-ex loss: 0.400140  [   68/   89]
per-ex loss: 0.416926  [   70/   89]
per-ex loss: 0.529556  [   72/   89]
per-ex loss: 0.468181  [   74/   89]
per-ex loss: 0.466053  [   76/   89]
per-ex loss: 0.382509  [   78/   89]
per-ex loss: 0.412476  [   80/   89]
per-ex loss: 0.519238  [   82/   89]
per-ex loss: 0.468845  [   84/   89]
per-ex loss: 0.609455  [   86/   89]
per-ex loss: 0.579227  [   88/   89]
per-ex loss: 0.415393  [   89/   89]
Train Error: Avg loss: 0.47087989
validation Error: 
 Avg loss: 0.55710541 
 F1: 0.473848 
 Precision: 0.655143 
 Recall: 0.371144
 IoU: 0.310486

test Error: 
 Avg loss: 0.53056391 
 F1: 0.504709 
 Precision: 0.664992 
 Recall: 0.406686
 IoU: 0.337533

We have finished training iteration 387
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_385_.pth
per-ex loss: 0.453339  [    2/   89]
per-ex loss: 0.483344  [    4/   89]
per-ex loss: 0.558410  [    6/   89]
per-ex loss: 0.445227  [    8/   89]
per-ex loss: 0.462185  [   10/   89]
per-ex loss: 0.424048  [   12/   89]
per-ex loss: 0.575927  [   14/   89]
per-ex loss: 0.443680  [   16/   89]
per-ex loss: 0.570331  [   18/   89]
per-ex loss: 0.775670  [   20/   89]
per-ex loss: 0.389478  [   22/   89]
per-ex loss: 0.383308  [   24/   89]
per-ex loss: 0.489731  [   26/   89]
per-ex loss: 0.451346  [   28/   89]
per-ex loss: 0.511938  [   30/   89]
per-ex loss: 0.413541  [   32/   89]
per-ex loss: 0.472618  [   34/   89]
per-ex loss: 0.391141  [   36/   89]
per-ex loss: 0.352745  [   38/   89]
per-ex loss: 0.569570  [   40/   89]
per-ex loss: 0.413729  [   42/   89]
per-ex loss: 0.533156  [   44/   89]
per-ex loss: 0.389431  [   46/   89]
per-ex loss: 0.381655  [   48/   89]
per-ex loss: 0.498493  [   50/   89]
per-ex loss: 0.357459  [   52/   89]
per-ex loss: 0.387569  [   54/   89]
per-ex loss: 0.433173  [   56/   89]
per-ex loss: 0.475190  [   58/   89]
per-ex loss: 0.658064  [   60/   89]
per-ex loss: 0.400873  [   62/   89]
per-ex loss: 0.455628  [   64/   89]
per-ex loss: 0.364144  [   66/   89]
per-ex loss: 0.354220  [   68/   89]
per-ex loss: 0.492781  [   70/   89]
per-ex loss: 0.443391  [   72/   89]
per-ex loss: 0.595688  [   74/   89]
per-ex loss: 0.665468  [   76/   89]
per-ex loss: 0.411140  [   78/   89]
per-ex loss: 0.395111  [   80/   89]
per-ex loss: 0.411220  [   82/   89]
per-ex loss: 0.483175  [   84/   89]
per-ex loss: 0.519810  [   86/   89]
per-ex loss: 0.533095  [   88/   89]
per-ex loss: 0.629420  [   89/   89]
Train Error: Avg loss: 0.47334807
validation Error: 
 Avg loss: 0.50620200 
 F1: 0.512038 
 Precision: 0.626600 
 Recall: 0.432893
 IoU: 0.344121

test Error: 
 Avg loss: 0.48024259 
 F1: 0.556542 
 Precision: 0.692353 
 Recall: 0.465274
 IoU: 0.385561

We have finished training iteration 388
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_386_.pth
per-ex loss: 0.480804  [    2/   89]
per-ex loss: 0.390935  [    4/   89]
per-ex loss: 0.625017  [    6/   89]
per-ex loss: 0.488222  [    8/   89]
per-ex loss: 0.452154  [   10/   89]
per-ex loss: 0.586398  [   12/   89]
per-ex loss: 0.553276  [   14/   89]
per-ex loss: 0.463839  [   16/   89]
per-ex loss: 0.415030  [   18/   89]
per-ex loss: 0.535438  [   20/   89]
per-ex loss: 0.584660  [   22/   89]
per-ex loss: 0.452535  [   24/   89]
per-ex loss: 0.448381  [   26/   89]
per-ex loss: 0.428106  [   28/   89]
per-ex loss: 0.389740  [   30/   89]
per-ex loss: 0.391822  [   32/   89]
per-ex loss: 0.370729  [   34/   89]
per-ex loss: 0.385317  [   36/   89]
per-ex loss: 0.603899  [   38/   89]
per-ex loss: 0.587702  [   40/   89]
per-ex loss: 0.491754  [   42/   89]
per-ex loss: 0.576372  [   44/   89]
per-ex loss: 0.430500  [   46/   89]
per-ex loss: 0.519580  [   48/   89]
per-ex loss: 0.440577  [   50/   89]
per-ex loss: 0.677535  [   52/   89]
per-ex loss: 0.521164  [   54/   89]
per-ex loss: 0.514239  [   56/   89]
per-ex loss: 0.364884  [   58/   89]
per-ex loss: 0.391123  [   60/   89]
per-ex loss: 0.391861  [   62/   89]
per-ex loss: 0.425305  [   64/   89]
per-ex loss: 0.506296  [   66/   89]
per-ex loss: 0.560187  [   68/   89]
per-ex loss: 0.406337  [   70/   89]
per-ex loss: 0.389487  [   72/   89]
per-ex loss: 0.402564  [   74/   89]
per-ex loss: 0.420121  [   76/   89]
per-ex loss: 0.417427  [   78/   89]
per-ex loss: 0.392663  [   80/   89]
per-ex loss: 0.383050  [   82/   89]
per-ex loss: 0.502080  [   84/   89]
per-ex loss: 0.377651  [   86/   89]
per-ex loss: 0.442696  [   88/   89]
per-ex loss: 0.420382  [   89/   89]
Train Error: Avg loss: 0.46666309
validation Error: 
 Avg loss: 0.53556027 
 F1: 0.501422 
 Precision: 0.621720 
 Recall: 0.420130
 IoU: 0.334598

test Error: 
 Avg loss: 0.49789739 
 F1: 0.537716 
 Precision: 0.670925 
 Recall: 0.448640
 IoU: 0.367723

We have finished training iteration 389
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_387_.pth
per-ex loss: 0.558897  [    2/   89]
per-ex loss: 0.484883  [    4/   89]
per-ex loss: 0.468727  [    6/   89]
per-ex loss: 0.408366  [    8/   89]
per-ex loss: 0.425083  [   10/   89]
per-ex loss: 0.405645  [   12/   89]
per-ex loss: 0.646385  [   14/   89]
per-ex loss: 0.511514  [   16/   89]
per-ex loss: 0.761185  [   18/   89]
per-ex loss: 0.516023  [   20/   89]
per-ex loss: 0.364203  [   22/   89]
per-ex loss: 0.470492  [   24/   89]
per-ex loss: 0.436986  [   26/   89]
per-ex loss: 0.542896  [   28/   89]
per-ex loss: 0.393792  [   30/   89]
per-ex loss: 0.555566  [   32/   89]
per-ex loss: 0.411711  [   34/   89]
per-ex loss: 0.517093  [   36/   89]
per-ex loss: 0.410490  [   38/   89]
per-ex loss: 0.471857  [   40/   89]
per-ex loss: 0.387767  [   42/   89]
per-ex loss: 0.517707  [   44/   89]
per-ex loss: 0.389567  [   46/   89]
per-ex loss: 0.417374  [   48/   89]
per-ex loss: 0.379078  [   50/   89]
per-ex loss: 0.430870  [   52/   89]
per-ex loss: 0.355702  [   54/   89]
per-ex loss: 0.484979  [   56/   89]
per-ex loss: 0.374209  [   58/   89]
per-ex loss: 0.353503  [   60/   89]
per-ex loss: 0.487185  [   62/   89]
per-ex loss: 0.571197  [   64/   89]
per-ex loss: 0.408658  [   66/   89]
per-ex loss: 0.414695  [   68/   89]
per-ex loss: 0.444159  [   70/   89]
per-ex loss: 0.502992  [   72/   89]
per-ex loss: 0.447233  [   74/   89]
per-ex loss: 0.410539  [   76/   89]
per-ex loss: 0.380788  [   78/   89]
per-ex loss: 0.544670  [   80/   89]
per-ex loss: 0.443318  [   82/   89]
per-ex loss: 0.462058  [   84/   89]
per-ex loss: 0.390227  [   86/   89]
per-ex loss: 0.696641  [   88/   89]
per-ex loss: 0.326834  [   89/   89]
Train Error: Avg loss: 0.46186093
validation Error: 
 Avg loss: 0.51492994 
 F1: 0.511610 
 Precision: 0.599093 
 Recall: 0.446421
 IoU: 0.343734

test Error: 
 Avg loss: 0.47672520 
 F1: 0.560338 
 Precision: 0.668888 
 Recall: 0.482101
 IoU: 0.389215

We have finished training iteration 390
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_388_.pth
per-ex loss: 0.477553  [    2/   89]
per-ex loss: 0.368050  [    4/   89]
per-ex loss: 0.463919  [    6/   89]
per-ex loss: 0.378185  [    8/   89]
per-ex loss: 0.484952  [   10/   89]
per-ex loss: 0.460302  [   12/   89]
per-ex loss: 0.448672  [   14/   89]
per-ex loss: 0.495281  [   16/   89]
per-ex loss: 0.635682  [   18/   89]
per-ex loss: 0.361893  [   20/   89]
per-ex loss: 0.582848  [   22/   89]
per-ex loss: 0.483337  [   24/   89]
per-ex loss: 0.390295  [   26/   89]
per-ex loss: 0.474656  [   28/   89]
per-ex loss: 0.448460  [   30/   89]
per-ex loss: 0.405195  [   32/   89]
per-ex loss: 0.551834  [   34/   89]
per-ex loss: 0.364650  [   36/   89]
per-ex loss: 0.408004  [   38/   89]
per-ex loss: 0.505101  [   40/   89]
per-ex loss: 0.472807  [   42/   89]
per-ex loss: 0.556018  [   44/   89]
per-ex loss: 0.435397  [   46/   89]
per-ex loss: 0.641717  [   48/   89]
per-ex loss: 0.391813  [   50/   89]
per-ex loss: 0.589251  [   52/   89]
per-ex loss: 0.445339  [   54/   89]
per-ex loss: 0.396965  [   56/   89]
per-ex loss: 0.433975  [   58/   89]
per-ex loss: 0.396418  [   60/   89]
per-ex loss: 0.383443  [   62/   89]
per-ex loss: 0.530495  [   64/   89]
per-ex loss: 0.384792  [   66/   89]
per-ex loss: 0.507761  [   68/   89]
per-ex loss: 0.426064  [   70/   89]
per-ex loss: 0.429279  [   72/   89]
per-ex loss: 0.490675  [   74/   89]
per-ex loss: 0.351167  [   76/   89]
per-ex loss: 0.585722  [   78/   89]
per-ex loss: 0.444412  [   80/   89]
per-ex loss: 0.471244  [   82/   89]
per-ex loss: 0.508906  [   84/   89]
per-ex loss: 0.748511  [   86/   89]
per-ex loss: 0.531605  [   88/   89]
per-ex loss: 0.328046  [   89/   89]
Train Error: Avg loss: 0.46823758
validation Error: 
 Avg loss: 0.55651447 
 F1: 0.472232 
 Precision: 0.674926 
 Recall: 0.363166
 IoU: 0.309099

test Error: 
 Avg loss: 0.53092915 
 F1: 0.503937 
 Precision: 0.692165 
 Recall: 0.396195
 IoU: 0.336842

We have finished training iteration 391
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_389_.pth
per-ex loss: 0.577927  [    2/   89]
per-ex loss: 0.556605  [    4/   89]
per-ex loss: 0.468670  [    6/   89]
per-ex loss: 0.479499  [    8/   89]
per-ex loss: 0.565133  [   10/   89]
per-ex loss: 0.403813  [   12/   89]
per-ex loss: 0.519255  [   14/   89]
per-ex loss: 0.404703  [   16/   89]
per-ex loss: 0.574111  [   18/   89]
per-ex loss: 0.435968  [   20/   89]
per-ex loss: 0.434366  [   22/   89]
per-ex loss: 0.456714  [   24/   89]
per-ex loss: 0.654176  [   26/   89]
per-ex loss: 0.426397  [   28/   89]
per-ex loss: 0.431598  [   30/   89]
per-ex loss: 0.348062  [   32/   89]
per-ex loss: 0.484074  [   34/   89]
per-ex loss: 0.509626  [   36/   89]
per-ex loss: 0.613474  [   38/   89]
per-ex loss: 0.600793  [   40/   89]
per-ex loss: 0.363787  [   42/   89]
per-ex loss: 0.580628  [   44/   89]
per-ex loss: 0.374204  [   46/   89]
per-ex loss: 0.484321  [   48/   89]
per-ex loss: 0.404002  [   50/   89]
per-ex loss: 0.422061  [   52/   89]
per-ex loss: 0.388425  [   54/   89]
per-ex loss: 0.565450  [   56/   89]
per-ex loss: 0.494709  [   58/   89]
per-ex loss: 0.380148  [   60/   89]
per-ex loss: 0.421028  [   62/   89]
per-ex loss: 0.474108  [   64/   89]
per-ex loss: 0.351064  [   66/   89]
per-ex loss: 0.446712  [   68/   89]
per-ex loss: 0.493883  [   70/   89]
per-ex loss: 0.465460  [   72/   89]
per-ex loss: 0.398347  [   74/   89]
per-ex loss: 0.444892  [   76/   89]
per-ex loss: 0.430423  [   78/   89]
per-ex loss: 0.374533  [   80/   89]
per-ex loss: 0.358676  [   82/   89]
per-ex loss: 0.364911  [   84/   89]
per-ex loss: 0.446346  [   86/   89]
per-ex loss: 0.626930  [   88/   89]
per-ex loss: 0.688615  [   89/   89]
Train Error: Avg loss: 0.47085836
validation Error: 
 Avg loss: 0.51831443 
 F1: 0.507108 
 Precision: 0.635132 
 Recall: 0.422038
 IoU: 0.339682

test Error: 
 Avg loss: 0.49043876 
 F1: 0.545521 
 Precision: 0.681825 
 Recall: 0.454635
 IoU: 0.375063

We have finished training iteration 392
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_390_.pth
per-ex loss: 0.579970  [    2/   89]
per-ex loss: 0.450416  [    4/   89]
per-ex loss: 0.466784  [    6/   89]
per-ex loss: 0.548748  [    8/   89]
per-ex loss: 0.383609  [   10/   89]
per-ex loss: 0.395790  [   12/   89]
per-ex loss: 0.376563  [   14/   89]
per-ex loss: 0.442991  [   16/   89]
per-ex loss: 0.634018  [   18/   89]
per-ex loss: 0.409178  [   20/   89]
per-ex loss: 0.442239  [   22/   89]
per-ex loss: 0.499670  [   24/   89]
per-ex loss: 0.331357  [   26/   89]
per-ex loss: 0.428838  [   28/   89]
per-ex loss: 0.655696  [   30/   89]
per-ex loss: 0.383319  [   32/   89]
per-ex loss: 0.394594  [   34/   89]
per-ex loss: 0.390943  [   36/   89]
per-ex loss: 0.551437  [   38/   89]
per-ex loss: 0.414388  [   40/   89]
per-ex loss: 0.595213  [   42/   89]
per-ex loss: 0.421168  [   44/   89]
per-ex loss: 0.412762  [   46/   89]
per-ex loss: 0.423319  [   48/   89]
per-ex loss: 0.407536  [   50/   89]
per-ex loss: 0.490018  [   52/   89]
per-ex loss: 0.638156  [   54/   89]
per-ex loss: 0.380025  [   56/   89]
per-ex loss: 0.641637  [   58/   89]
per-ex loss: 0.581312  [   60/   89]
per-ex loss: 0.384703  [   62/   89]
per-ex loss: 0.566162  [   64/   89]
per-ex loss: 0.413693  [   66/   89]
per-ex loss: 0.593827  [   68/   89]
per-ex loss: 0.451381  [   70/   89]
per-ex loss: 0.450188  [   72/   89]
per-ex loss: 0.463206  [   74/   89]
per-ex loss: 0.409203  [   76/   89]
per-ex loss: 0.595764  [   78/   89]
per-ex loss: 0.504217  [   80/   89]
per-ex loss: 0.485214  [   82/   89]
per-ex loss: 0.388163  [   84/   89]
per-ex loss: 0.508352  [   86/   89]
per-ex loss: 0.376699  [   88/   89]
per-ex loss: 0.689452  [   89/   89]
Train Error: Avg loss: 0.47670926
validation Error: 
 Avg loss: 0.50892419 
 F1: 0.511306 
 Precision: 0.620832 
 Recall: 0.434629
 IoU: 0.343459

test Error: 
 Avg loss: 0.48030063 
 F1: 0.556285 
 Precision: 0.681737 
 Recall: 0.469828
 IoU: 0.385315

We have finished training iteration 393
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_391_.pth
per-ex loss: 0.553228  [    2/   89]
per-ex loss: 0.398498  [    4/   89]
per-ex loss: 0.552135  [    6/   89]
per-ex loss: 0.400298  [    8/   89]
per-ex loss: 0.474672  [   10/   89]
per-ex loss: 0.538873  [   12/   89]
per-ex loss: 0.572267  [   14/   89]
per-ex loss: 0.523825  [   16/   89]
per-ex loss: 0.594975  [   18/   89]
per-ex loss: 0.406302  [   20/   89]
per-ex loss: 0.430682  [   22/   89]
per-ex loss: 0.385599  [   24/   89]
per-ex loss: 0.465737  [   26/   89]
per-ex loss: 0.460664  [   28/   89]
per-ex loss: 0.512863  [   30/   89]
per-ex loss: 0.372529  [   32/   89]
per-ex loss: 0.381774  [   34/   89]
per-ex loss: 0.382645  [   36/   89]
per-ex loss: 0.484753  [   38/   89]
per-ex loss: 0.509921  [   40/   89]
per-ex loss: 0.552503  [   42/   89]
per-ex loss: 0.654639  [   44/   89]
per-ex loss: 0.575307  [   46/   89]
per-ex loss: 0.408737  [   48/   89]
per-ex loss: 0.440991  [   50/   89]
per-ex loss: 0.543678  [   52/   89]
per-ex loss: 0.502065  [   54/   89]
per-ex loss: 0.501598  [   56/   89]
per-ex loss: 0.427134  [   58/   89]
per-ex loss: 0.395894  [   60/   89]
per-ex loss: 0.626294  [   62/   89]
per-ex loss: 0.438007  [   64/   89]
per-ex loss: 0.514804  [   66/   89]
per-ex loss: 0.450959  [   68/   89]
per-ex loss: 0.398480  [   70/   89]
per-ex loss: 0.645845  [   72/   89]
per-ex loss: 0.382454  [   74/   89]
per-ex loss: 0.379974  [   76/   89]
per-ex loss: 0.401160  [   78/   89]
per-ex loss: 0.369417  [   80/   89]
per-ex loss: 0.519125  [   82/   89]
per-ex loss: 0.532903  [   84/   89]
per-ex loss: 0.478146  [   86/   89]
per-ex loss: 0.354415  [   88/   89]
per-ex loss: 0.349535  [   89/   89]
Train Error: Avg loss: 0.47214009
validation Error: 
 Avg loss: 0.52120319 
 F1: 0.500100 
 Precision: 0.626218 
 Recall: 0.416266
 IoU: 0.333422

test Error: 
 Avg loss: 0.50201421 
 F1: 0.533889 
 Precision: 0.659566 
 Recall: 0.448440
 IoU: 0.364153

We have finished training iteration 394
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_392_.pth
per-ex loss: 0.433415  [    2/   89]
per-ex loss: 0.409216  [    4/   89]
per-ex loss: 0.473762  [    6/   89]
per-ex loss: 0.449009  [    8/   89]
per-ex loss: 0.365784  [   10/   89]
per-ex loss: 0.380842  [   12/   89]
per-ex loss: 0.466845  [   14/   89]
per-ex loss: 0.351935  [   16/   89]
per-ex loss: 0.497965  [   18/   89]
per-ex loss: 0.476836  [   20/   89]
per-ex loss: 0.472367  [   22/   89]
per-ex loss: 0.572014  [   24/   89]
per-ex loss: 0.371673  [   26/   89]
per-ex loss: 0.404146  [   28/   89]
per-ex loss: 0.469680  [   30/   89]
per-ex loss: 0.482776  [   32/   89]
per-ex loss: 0.410090  [   34/   89]
per-ex loss: 0.413478  [   36/   89]
per-ex loss: 0.412218  [   38/   89]
per-ex loss: 0.430022  [   40/   89]
per-ex loss: 0.398381  [   42/   89]
per-ex loss: 0.655463  [   44/   89]
per-ex loss: 0.574319  [   46/   89]
per-ex loss: 0.361428  [   48/   89]
per-ex loss: 0.663225  [   50/   89]
per-ex loss: 0.598168  [   52/   89]
per-ex loss: 0.460895  [   54/   89]
per-ex loss: 0.468053  [   56/   89]
per-ex loss: 0.409861  [   58/   89]
per-ex loss: 0.417719  [   60/   89]
per-ex loss: 0.360829  [   62/   89]
per-ex loss: 0.460234  [   64/   89]
per-ex loss: 0.465331  [   66/   89]
per-ex loss: 0.478714  [   68/   89]
per-ex loss: 0.595466  [   70/   89]
per-ex loss: 0.524339  [   72/   89]
per-ex loss: 0.438511  [   74/   89]
per-ex loss: 0.444674  [   76/   89]
per-ex loss: 0.584872  [   78/   89]
per-ex loss: 0.463626  [   80/   89]
per-ex loss: 0.390213  [   82/   89]
per-ex loss: 0.533143  [   84/   89]
per-ex loss: 0.575899  [   86/   89]
per-ex loss: 0.346882  [   88/   89]
per-ex loss: 0.434720  [   89/   89]
Train Error: Avg loss: 0.46331195
validation Error: 
 Avg loss: 0.50606225 
 F1: 0.509963 
 Precision: 0.605477 
 Recall: 0.440477
 IoU: 0.342248

test Error: 
 Avg loss: 0.48108198 
 F1: 0.555197 
 Precision: 0.670680 
 Recall: 0.473641
 IoU: 0.384271

We have finished training iteration 395
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_393_.pth
Error in cropping the image to the non-zero values in the fourth channel. Returned the original image.
per-ex loss: 0.548760  [    2/   89]
per-ex loss: 0.416357  [    4/   89]
per-ex loss: 0.369844  [    6/   89]
per-ex loss: 0.429869  [    8/   89]
per-ex loss: 0.563879  [   10/   89]
per-ex loss: 0.497349  [   12/   89]
per-ex loss: 0.540097  [   14/   89]
per-ex loss: 0.399484  [   16/   89]
per-ex loss: 0.466120  [   18/   89]
per-ex loss: 0.531795  [   20/   89]
per-ex loss: 0.462396  [   22/   89]
per-ex loss: 0.526120  [   24/   89]
per-ex loss: 0.419120  [   26/   89]
per-ex loss: 0.515620  [   28/   89]
per-ex loss: 0.409664  [   30/   89]
per-ex loss: 0.415586  [   32/   89]
per-ex loss: 0.509583  [   34/   89]
per-ex loss: 0.475237  [   36/   89]
per-ex loss: 0.474012  [   38/   89]
per-ex loss: 0.482595  [   40/   89]
per-ex loss: 0.394296  [   42/   89]
per-ex loss: 0.416250  [   44/   89]
per-ex loss: 0.437010  [   46/   89]
per-ex loss: 0.374117  [   48/   89]
per-ex loss: 0.511532  [   50/   89]
per-ex loss: 0.436007  [   52/   89]
per-ex loss: 0.594953  [   54/   89]
per-ex loss: 0.525854  [   56/   89]
per-ex loss: 0.472415  [   58/   89]
per-ex loss: 0.449896  [   60/   89]
per-ex loss: 0.474237  [   62/   89]
per-ex loss: 0.373173  [   64/   89]
per-ex loss: 0.446079  [   66/   89]
per-ex loss: 0.354577  [   68/   89]
per-ex loss: 0.496075  [   70/   89]
per-ex loss: 0.411618  [   72/   89]
per-ex loss: 0.375423  [   74/   89]
per-ex loss: 0.365009  [   76/   89]
per-ex loss: 0.375169  [   78/   89]
per-ex loss: 0.604942  [   80/   89]
per-ex loss: 0.459197  [   82/   89]
per-ex loss: 0.571690  [   84/   89]
per-ex loss: 0.350038  [   86/   89]
per-ex loss: 0.497744  [   88/   89]
per-ex loss: 0.430899  [   89/   89]
Train Error: Avg loss: 0.45892643
validation Error: 
 Avg loss: 0.50862462 
 F1: 0.511465 
 Precision: 0.609701 
 Recall: 0.440493
 IoU: 0.343603

test Error: 
 Avg loss: 0.48037557 
 F1: 0.556216 
 Precision: 0.673745 
 Recall: 0.473600
 IoU: 0.385249

We have finished training iteration 396
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_394_.pth
per-ex loss: 0.389895  [    2/   89]
per-ex loss: 0.483822  [    4/   89]
per-ex loss: 0.467615  [    6/   89]
per-ex loss: 0.554233  [    8/   89]
per-ex loss: 0.464045  [   10/   89]
per-ex loss: 0.512256  [   12/   89]
per-ex loss: 0.410060  [   14/   89]
per-ex loss: 0.467935  [   16/   89]
per-ex loss: 0.453789  [   18/   89]
per-ex loss: 0.532147  [   20/   89]
per-ex loss: 0.631560  [   22/   89]
per-ex loss: 0.390387  [   24/   89]
per-ex loss: 0.412720  [   26/   89]
per-ex loss: 0.492926  [   28/   89]
per-ex loss: 0.355224  [   30/   89]
per-ex loss: 0.364950  [   32/   89]
per-ex loss: 0.426849  [   34/   89]
per-ex loss: 0.374010  [   36/   89]
per-ex loss: 0.485221  [   38/   89]
per-ex loss: 0.421293  [   40/   89]
per-ex loss: 0.541692  [   42/   89]
per-ex loss: 0.430890  [   44/   89]
per-ex loss: 0.430337  [   46/   89]
per-ex loss: 0.765665  [   48/   89]
per-ex loss: 0.579883  [   50/   89]
per-ex loss: 0.360266  [   52/   89]
per-ex loss: 0.492779  [   54/   89]
per-ex loss: 0.564415  [   56/   89]
per-ex loss: 0.619688  [   58/   89]
per-ex loss: 0.547138  [   60/   89]
per-ex loss: 0.400322  [   62/   89]
per-ex loss: 0.368379  [   64/   89]
per-ex loss: 0.547210  [   66/   89]
per-ex loss: 0.436824  [   68/   89]
per-ex loss: 0.370891  [   70/   89]
per-ex loss: 0.575010  [   72/   89]
per-ex loss: 0.412473  [   74/   89]
per-ex loss: 0.482420  [   76/   89]
per-ex loss: 0.484815  [   78/   89]
per-ex loss: 0.383753  [   80/   89]
per-ex loss: 0.455669  [   82/   89]
per-ex loss: 0.387498  [   84/   89]
per-ex loss: 0.386947  [   86/   89]
per-ex loss: 0.452972  [   88/   89]
per-ex loss: 0.672830  [   89/   89]
Train Error: Avg loss: 0.47203782
validation Error: 
 Avg loss: 0.52632338 
 F1: 0.505841 
 Precision: 0.624897 
 Recall: 0.424891
 IoU: 0.338546

test Error: 
 Avg loss: 0.49164386 
 F1: 0.543535 
 Precision: 0.671681 
 Recall: 0.456451
 IoU: 0.373188

We have finished training iteration 397
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_395_.pth
per-ex loss: 0.548962  [    2/   89]
per-ex loss: 0.506608  [    4/   89]
per-ex loss: 0.384185  [    6/   89]
per-ex loss: 0.446994  [    8/   89]
per-ex loss: 0.438529  [   10/   89]
per-ex loss: 0.447522  [   12/   89]
per-ex loss: 0.442545  [   14/   89]
per-ex loss: 0.545223  [   16/   89]
per-ex loss: 0.579246  [   18/   89]
per-ex loss: 0.413665  [   20/   89]
per-ex loss: 0.480954  [   22/   89]
per-ex loss: 0.501999  [   24/   89]
per-ex loss: 0.507500  [   26/   89]
per-ex loss: 0.486219  [   28/   89]
per-ex loss: 0.471961  [   30/   89]
per-ex loss: 0.417813  [   32/   89]
per-ex loss: 0.418354  [   34/   89]
per-ex loss: 0.392839  [   36/   89]
per-ex loss: 0.562416  [   38/   89]
per-ex loss: 0.380680  [   40/   89]
per-ex loss: 0.622039  [   42/   89]
per-ex loss: 0.525504  [   44/   89]
per-ex loss: 0.408382  [   46/   89]
per-ex loss: 0.386342  [   48/   89]
per-ex loss: 0.467852  [   50/   89]
per-ex loss: 0.430399  [   52/   89]
per-ex loss: 0.390197  [   54/   89]
per-ex loss: 0.357069  [   56/   89]
per-ex loss: 0.611735  [   58/   89]
per-ex loss: 0.422901  [   60/   89]
per-ex loss: 0.372429  [   62/   89]
per-ex loss: 0.431230  [   64/   89]
per-ex loss: 0.429360  [   66/   89]
per-ex loss: 0.414149  [   68/   89]
per-ex loss: 0.511708  [   70/   89]
per-ex loss: 0.480154  [   72/   89]
per-ex loss: 0.446976  [   74/   89]
per-ex loss: 0.485006  [   76/   89]
per-ex loss: 0.411973  [   78/   89]
per-ex loss: 0.512659  [   80/   89]
per-ex loss: 0.359276  [   82/   89]
per-ex loss: 0.604704  [   84/   89]
per-ex loss: 0.591708  [   86/   89]
per-ex loss: 0.442258  [   88/   89]
per-ex loss: 0.625714  [   89/   89]
Train Error: Avg loss: 0.46924302
validation Error: 
 Avg loss: 0.51002174 
 F1: 0.513413 
 Precision: 0.615637 
 Recall: 0.440302
 IoU: 0.345364

test Error: 
 Avg loss: 0.47684926 
 F1: 0.559763 
 Precision: 0.683517 
 Recall: 0.473952
 IoU: 0.388661

We have finished training iteration 398
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_396_.pth
per-ex loss: 0.518238  [    2/   89]
per-ex loss: 0.384391  [    4/   89]
per-ex loss: 0.398994  [    6/   89]
per-ex loss: 0.430629  [    8/   89]
per-ex loss: 0.583867  [   10/   89]
per-ex loss: 0.654781  [   12/   89]
per-ex loss: 0.464894  [   14/   89]
per-ex loss: 0.520102  [   16/   89]
per-ex loss: 0.588269  [   18/   89]
per-ex loss: 0.343176  [   20/   89]
per-ex loss: 0.398550  [   22/   89]
per-ex loss: 0.474400  [   24/   89]
per-ex loss: 0.585414  [   26/   89]
per-ex loss: 0.549801  [   28/   89]
per-ex loss: 0.414967  [   30/   89]
per-ex loss: 0.623952  [   32/   89]
per-ex loss: 0.558607  [   34/   89]
per-ex loss: 0.437463  [   36/   89]
per-ex loss: 0.375907  [   38/   89]
per-ex loss: 0.388369  [   40/   89]
per-ex loss: 0.635717  [   42/   89]
per-ex loss: 0.617176  [   44/   89]
per-ex loss: 0.514706  [   46/   89]
per-ex loss: 0.456781  [   48/   89]
per-ex loss: 0.416817  [   50/   89]
per-ex loss: 0.446986  [   52/   89]
per-ex loss: 0.480424  [   54/   89]
per-ex loss: 0.374563  [   56/   89]
per-ex loss: 0.409428  [   58/   89]
per-ex loss: 0.390011  [   60/   89]
per-ex loss: 0.518503  [   62/   89]
per-ex loss: 0.521460  [   64/   89]
per-ex loss: 0.568973  [   66/   89]
per-ex loss: 0.447982  [   68/   89]
per-ex loss: 0.385581  [   70/   89]
per-ex loss: 0.497275  [   72/   89]
per-ex loss: 0.426183  [   74/   89]
per-ex loss: 0.378803  [   76/   89]
per-ex loss: 0.365584  [   78/   89]
per-ex loss: 0.402898  [   80/   89]
per-ex loss: 0.608869  [   82/   89]
per-ex loss: 0.535879  [   84/   89]
per-ex loss: 0.585756  [   86/   89]
per-ex loss: 0.371571  [   88/   89]
per-ex loss: 0.648138  [   89/   89]
Train Error: Avg loss: 0.48224080
validation Error: 
 Avg loss: 0.50005705 
 F1: 0.511669 
 Precision: 0.626222 
 Recall: 0.432545
 IoU: 0.343787

test Error: 
 Avg loss: 0.48163296 
 F1: 0.554586 
 Precision: 0.675839 
 Recall: 0.470222
 IoU: 0.383686

We have finished training iteration 399
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_397_.pth
per-ex loss: 0.397673  [    2/   89]
per-ex loss: 0.346646  [    4/   89]
per-ex loss: 0.366958  [    6/   89]
per-ex loss: 0.376282  [    8/   89]
per-ex loss: 0.350095  [   10/   89]
per-ex loss: 0.547550  [   12/   89]
per-ex loss: 0.572887  [   14/   89]
per-ex loss: 0.483877  [   16/   89]
per-ex loss: 0.399140  [   18/   89]
per-ex loss: 0.435539  [   20/   89]
per-ex loss: 0.591963  [   22/   89]
per-ex loss: 0.468726  [   24/   89]
per-ex loss: 0.495931  [   26/   89]
per-ex loss: 0.424936  [   28/   89]
per-ex loss: 0.500921  [   30/   89]
per-ex loss: 0.368168  [   32/   89]
per-ex loss: 0.568138  [   34/   89]
per-ex loss: 0.500843  [   36/   89]
per-ex loss: 0.441756  [   38/   89]
per-ex loss: 0.506407  [   40/   89]
per-ex loss: 0.459267  [   42/   89]
per-ex loss: 0.519336  [   44/   89]
per-ex loss: 0.413038  [   46/   89]
per-ex loss: 0.439198  [   48/   89]
per-ex loss: 0.645286  [   50/   89]
per-ex loss: 0.473388  [   52/   89]
per-ex loss: 0.523074  [   54/   89]
per-ex loss: 0.370515  [   56/   89]
per-ex loss: 0.559504  [   58/   89]
per-ex loss: 0.547321  [   60/   89]
per-ex loss: 0.366586  [   62/   89]
per-ex loss: 0.527164  [   64/   89]
per-ex loss: 0.369707  [   66/   89]
per-ex loss: 0.421329  [   68/   89]
per-ex loss: 0.422919  [   70/   89]
per-ex loss: 0.397327  [   72/   89]
per-ex loss: 0.525565  [   74/   89]
per-ex loss: 0.404271  [   76/   89]
per-ex loss: 0.431881  [   78/   89]
per-ex loss: 0.375046  [   80/   89]
per-ex loss: 0.381868  [   82/   89]
per-ex loss: 0.647589  [   84/   89]
per-ex loss: 0.606311  [   86/   89]
per-ex loss: 0.546134  [   88/   89]
per-ex loss: 0.548705  [   89/   89]
Train Error: Avg loss: 0.46815035
validation Error: 
 Avg loss: 0.53877575 
 F1: 0.488199 
 Precision: 0.641908 
 Recall: 0.393881
 IoU: 0.322925

test Error: 
 Avg loss: 0.51568439 
 F1: 0.520224 
 Precision: 0.669207 
 Recall: 0.425498
 IoU: 0.351556

We have finished training iteration 400
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_398_.pth
per-ex loss: 0.429607  [    2/   89]
per-ex loss: 0.577467  [    4/   89]
per-ex loss: 0.553250  [    6/   89]
per-ex loss: 0.416949  [    8/   89]
per-ex loss: 0.380096  [   10/   89]
per-ex loss: 0.517717  [   12/   89]
per-ex loss: 0.376486  [   14/   89]
per-ex loss: 0.475079  [   16/   89]
per-ex loss: 0.464692  [   18/   89]
per-ex loss: 0.585864  [   20/   89]
per-ex loss: 0.374966  [   22/   89]
per-ex loss: 0.556588  [   24/   89]
per-ex loss: 0.561139  [   26/   89]
per-ex loss: 0.593532  [   28/   89]
per-ex loss: 0.553265  [   30/   89]
per-ex loss: 0.376950  [   32/   89]
per-ex loss: 0.380069  [   34/   89]
per-ex loss: 0.569748  [   36/   89]
per-ex loss: 0.378125  [   38/   89]
per-ex loss: 0.437870  [   40/   89]
per-ex loss: 0.470303  [   42/   89]
per-ex loss: 0.350004  [   44/   89]
per-ex loss: 0.520499  [   46/   89]
per-ex loss: 0.412278  [   48/   89]
per-ex loss: 0.354643  [   50/   89]
per-ex loss: 0.456810  [   52/   89]
per-ex loss: 0.462860  [   54/   89]
per-ex loss: 0.412682  [   56/   89]
per-ex loss: 0.503985  [   58/   89]
per-ex loss: 0.561658  [   60/   89]
per-ex loss: 0.544143  [   62/   89]
per-ex loss: 0.400913  [   64/   89]
per-ex loss: 0.479222  [   66/   89]
per-ex loss: 0.373962  [   68/   89]
per-ex loss: 0.409548  [   70/   89]
per-ex loss: 0.561959  [   72/   89]
per-ex loss: 0.364448  [   74/   89]
per-ex loss: 0.505525  [   76/   89]
per-ex loss: 0.549298  [   78/   89]
per-ex loss: 0.396633  [   80/   89]
per-ex loss: 0.564968  [   82/   89]
per-ex loss: 0.432672  [   84/   89]
per-ex loss: 0.479331  [   86/   89]
per-ex loss: 0.463817  [   88/   89]
per-ex loss: 0.610636  [   89/   89]
Train Error: Avg loss: 0.47116127
validation Error: 
 Avg loss: 0.57690931 
 F1: 0.450026 
 Precision: 0.700259 
 Recall: 0.331549
 IoU: 0.290344

test Error: 
 Avg loss: 0.55248937 
 F1: 0.480125 
 Precision: 0.713146 
 Recall: 0.361880
 IoU: 0.315897

We have finished training iteration 401
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_352_.pth
per-ex loss: 0.432266  [    2/   89]
per-ex loss: 0.375564  [    4/   89]
per-ex loss: 0.380663  [    6/   89]
per-ex loss: 0.524454  [    8/   89]
per-ex loss: 0.562808  [   10/   89]
per-ex loss: 0.465661  [   12/   89]
per-ex loss: 0.490107  [   14/   89]
per-ex loss: 0.661773  [   16/   89]
per-ex loss: 0.418927  [   18/   89]
per-ex loss: 0.455422  [   20/   89]
per-ex loss: 0.499696  [   22/   89]
per-ex loss: 0.494335  [   24/   89]
per-ex loss: 0.398627  [   26/   89]
per-ex loss: 0.455471  [   28/   89]
per-ex loss: 0.385335  [   30/   89]
per-ex loss: 0.488998  [   32/   89]
per-ex loss: 0.399169  [   34/   89]
per-ex loss: 0.398069  [   36/   89]
per-ex loss: 0.587073  [   38/   89]
per-ex loss: 0.462301  [   40/   89]
per-ex loss: 0.564109  [   42/   89]
per-ex loss: 0.412734  [   44/   89]
per-ex loss: 0.392991  [   46/   89]
per-ex loss: 0.408030  [   48/   89]
per-ex loss: 0.380772  [   50/   89]
per-ex loss: 0.363609  [   52/   89]
per-ex loss: 0.669588  [   54/   89]
per-ex loss: 0.422236  [   56/   89]
per-ex loss: 0.622899  [   58/   89]
per-ex loss: 0.378533  [   60/   89]
per-ex loss: 0.404308  [   62/   89]
per-ex loss: 0.539014  [   64/   89]
per-ex loss: 0.420802  [   66/   89]
per-ex loss: 0.432550  [   68/   89]
per-ex loss: 0.495691  [   70/   89]
per-ex loss: 0.442425  [   72/   89]
per-ex loss: 0.405002  [   74/   89]
per-ex loss: 0.468141  [   76/   89]
per-ex loss: 0.495178  [   78/   89]
per-ex loss: 0.711069  [   80/   89]
per-ex loss: 0.459077  [   82/   89]
per-ex loss: 0.362356  [   84/   89]
per-ex loss: 0.414846  [   86/   89]
per-ex loss: 0.539889  [   88/   89]
per-ex loss: 0.521635  [   89/   89]
Train Error: Avg loss: 0.46809341
validation Error: 
 Avg loss: 0.51219378 
 F1: 0.511692 
 Precision: 0.607838 
 Recall: 0.441808
 IoU: 0.343808

test Error: 
 Avg loss: 0.48320784 
 F1: 0.552973 
 Precision: 0.658618 
 Recall: 0.476536
 IoU: 0.382145

We have finished training iteration 402
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_400_.pth
Error in cropping the image to the non-zero values in the fourth channel. Returned the original image.
per-ex loss: 0.546378  [    2/   89]
per-ex loss: 0.502410  [    4/   89]
per-ex loss: 0.512003  [    6/   89]
per-ex loss: 0.430319  [    8/   89]
per-ex loss: 0.510939  [   10/   89]
per-ex loss: 0.347485  [   12/   89]
per-ex loss: 0.419298  [   14/   89]
per-ex loss: 0.428248  [   16/   89]
per-ex loss: 0.391553  [   18/   89]
per-ex loss: 0.581789  [   20/   89]
per-ex loss: 0.377055  [   22/   89]
per-ex loss: 0.552323  [   24/   89]
per-ex loss: 0.508305  [   26/   89]
per-ex loss: 0.385035  [   28/   89]
per-ex loss: 0.389006  [   30/   89]
per-ex loss: 0.369088  [   32/   89]
per-ex loss: 0.421655  [   34/   89]
per-ex loss: 0.481402  [   36/   89]
per-ex loss: 0.383280  [   38/   89]
per-ex loss: 0.577634  [   40/   89]
per-ex loss: 0.570400  [   42/   89]
per-ex loss: 0.399257  [   44/   89]
per-ex loss: 0.382226  [   46/   89]
per-ex loss: 0.395456  [   48/   89]
per-ex loss: 0.420345  [   50/   89]
per-ex loss: 0.495196  [   52/   89]
per-ex loss: 0.352459  [   54/   89]
per-ex loss: 0.521293  [   56/   89]
per-ex loss: 0.511842  [   58/   89]
per-ex loss: 0.550756  [   60/   89]
per-ex loss: 0.420270  [   62/   89]
per-ex loss: 0.417790  [   64/   89]
per-ex loss: 0.553516  [   66/   89]
per-ex loss: 0.558114  [   68/   89]
per-ex loss: 0.355250  [   70/   89]
per-ex loss: 0.624027  [   72/   89]
per-ex loss: 0.497021  [   74/   89]
per-ex loss: 0.464735  [   76/   89]
per-ex loss: 0.369884  [   78/   89]
per-ex loss: 0.417035  [   80/   89]
per-ex loss: 0.454738  [   82/   89]
per-ex loss: 0.642881  [   84/   89]
per-ex loss: 0.569271  [   86/   89]
per-ex loss: 0.385749  [   88/   89]
per-ex loss: 0.356175  [   89/   89]
Train Error: Avg loss: 0.46224205
validation Error: 
 Avg loss: 0.53717592 
 F1: 0.484316 
 Precision: 0.646725 
 Recall: 0.387104
 IoU: 0.319536

test Error: 
 Avg loss: 0.51870031 
 F1: 0.516195 
 Precision: 0.668258 
 Recall: 0.420508
 IoU: 0.347886

We have finished training iteration 403
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_401_.pth
per-ex loss: 0.409773  [    2/   89]
per-ex loss: 0.415007  [    4/   89]
per-ex loss: 0.480140  [    6/   89]
per-ex loss: 0.396365  [    8/   89]
per-ex loss: 0.501795  [   10/   89]
per-ex loss: 0.514388  [   12/   89]
per-ex loss: 0.335749  [   14/   89]
per-ex loss: 0.590398  [   16/   89]
per-ex loss: 0.511332  [   18/   89]
per-ex loss: 0.597491  [   20/   89]
per-ex loss: 0.426493  [   22/   89]
per-ex loss: 0.624622  [   24/   89]
per-ex loss: 0.354489  [   26/   89]
per-ex loss: 0.404082  [   28/   89]
per-ex loss: 0.410446  [   30/   89]
per-ex loss: 0.584013  [   32/   89]
per-ex loss: 0.428583  [   34/   89]
per-ex loss: 0.560828  [   36/   89]
per-ex loss: 0.375154  [   38/   89]
per-ex loss: 0.480412  [   40/   89]
per-ex loss: 0.401195  [   42/   89]
per-ex loss: 0.446687  [   44/   89]
per-ex loss: 0.422286  [   46/   89]
per-ex loss: 0.670742  [   48/   89]
per-ex loss: 0.401816  [   50/   89]
per-ex loss: 0.478825  [   52/   89]
per-ex loss: 0.373287  [   54/   89]
per-ex loss: 0.468798  [   56/   89]
per-ex loss: 0.429712  [   58/   89]
per-ex loss: 0.449985  [   60/   89]
per-ex loss: 0.469582  [   62/   89]
per-ex loss: 0.447526  [   64/   89]
per-ex loss: 0.410158  [   66/   89]
per-ex loss: 0.449904  [   68/   89]
per-ex loss: 0.408452  [   70/   89]
per-ex loss: 0.623427  [   72/   89]
per-ex loss: 0.577397  [   74/   89]
per-ex loss: 0.393727  [   76/   89]
per-ex loss: 0.486133  [   78/   89]
per-ex loss: 0.420524  [   80/   89]
per-ex loss: 0.415309  [   82/   89]
per-ex loss: 0.357130  [   84/   89]
per-ex loss: 0.517373  [   86/   89]
per-ex loss: 0.419271  [   88/   89]
per-ex loss: 0.647152  [   89/   89]
Train Error: Avg loss: 0.46639906
validation Error: 
 Avg loss: 0.55631125 
 F1: 0.459944 
 Precision: 0.696814 
 Recall: 0.343259
 IoU: 0.298654

test Error: 
 Avg loss: 0.54214694 
 F1: 0.491598 
 Precision: 0.706077 
 Recall: 0.377062
 IoU: 0.325907

We have finished training iteration 404
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_402_.pth
per-ex loss: 0.429851  [    2/   89]
per-ex loss: 0.452744  [    4/   89]
per-ex loss: 0.443747  [    6/   89]
per-ex loss: 0.601726  [    8/   89]
per-ex loss: 0.586293  [   10/   89]
per-ex loss: 0.360180  [   12/   89]
per-ex loss: 0.438769  [   14/   89]
per-ex loss: 0.438292  [   16/   89]
per-ex loss: 0.596948  [   18/   89]
per-ex loss: 0.567695  [   20/   89]
per-ex loss: 0.557820  [   22/   89]
per-ex loss: 0.456448  [   24/   89]
per-ex loss: 0.397063  [   26/   89]
per-ex loss: 0.477497  [   28/   89]
per-ex loss: 0.423922  [   30/   89]
per-ex loss: 0.520832  [   32/   89]
per-ex loss: 0.491084  [   34/   89]
per-ex loss: 0.418445  [   36/   89]
per-ex loss: 0.344782  [   38/   89]
per-ex loss: 0.430389  [   40/   89]
per-ex loss: 0.524777  [   42/   89]
per-ex loss: 0.574850  [   44/   89]
per-ex loss: 0.483709  [   46/   89]
per-ex loss: 0.513545  [   48/   89]
per-ex loss: 0.377745  [   50/   89]
per-ex loss: 0.354564  [   52/   89]
per-ex loss: 0.399890  [   54/   89]
per-ex loss: 0.490429  [   56/   89]
per-ex loss: 0.588988  [   58/   89]
per-ex loss: 0.383128  [   60/   89]
per-ex loss: 0.411536  [   62/   89]
per-ex loss: 0.480885  [   64/   89]
per-ex loss: 0.489474  [   66/   89]
per-ex loss: 0.578126  [   68/   89]
per-ex loss: 0.418524  [   70/   89]
per-ex loss: 0.423179  [   72/   89]
per-ex loss: 0.545680  [   74/   89]
per-ex loss: 0.477189  [   76/   89]
per-ex loss: 0.407006  [   78/   89]
per-ex loss: 0.435428  [   80/   89]
per-ex loss: 0.394268  [   82/   89]
per-ex loss: 0.385563  [   84/   89]
per-ex loss: 0.406685  [   86/   89]
per-ex loss: 0.562735  [   88/   89]
per-ex loss: 0.393752  [   89/   89]
Train Error: Avg loss: 0.46524838
validation Error: 
 Avg loss: 0.52138748 
 F1: 0.507175 
 Precision: 0.640881 
 Recall: 0.419628
 IoU: 0.339741

test Error: 
 Avg loss: 0.49133594 
 F1: 0.544587 
 Precision: 0.689205 
 Recall: 0.450134
 IoU: 0.374180

We have finished training iteration 405
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_403_.pth
per-ex loss: 0.419813  [    2/   89]
per-ex loss: 0.528467  [    4/   89]
per-ex loss: 0.704611  [    6/   89]
per-ex loss: 0.375907  [    8/   89]
per-ex loss: 0.412839  [   10/   89]
per-ex loss: 0.337623  [   12/   89]
per-ex loss: 0.432377  [   14/   89]
per-ex loss: 0.481509  [   16/   89]
per-ex loss: 0.546692  [   18/   89]
per-ex loss: 0.624778  [   20/   89]
per-ex loss: 0.498759  [   22/   89]
per-ex loss: 0.387035  [   24/   89]
per-ex loss: 0.403866  [   26/   89]
per-ex loss: 0.383035  [   28/   89]
per-ex loss: 0.356015  [   30/   89]
per-ex loss: 0.423037  [   32/   89]
per-ex loss: 0.447517  [   34/   89]
per-ex loss: 0.413051  [   36/   89]
per-ex loss: 0.359221  [   38/   89]
per-ex loss: 0.396984  [   40/   89]
per-ex loss: 0.374110  [   42/   89]
per-ex loss: 0.419157  [   44/   89]
per-ex loss: 0.410598  [   46/   89]
per-ex loss: 0.363089  [   48/   89]
per-ex loss: 0.522836  [   50/   89]
per-ex loss: 0.632112  [   52/   89]
per-ex loss: 0.488380  [   54/   89]
per-ex loss: 0.462812  [   56/   89]
per-ex loss: 0.503479  [   58/   89]
per-ex loss: 0.559410  [   60/   89]
per-ex loss: 0.467466  [   62/   89]
per-ex loss: 0.569737  [   64/   89]
per-ex loss: 0.616497  [   66/   89]
per-ex loss: 0.542077  [   68/   89]
per-ex loss: 0.384222  [   70/   89]
per-ex loss: 0.463864  [   72/   89]
per-ex loss: 0.391722  [   74/   89]
per-ex loss: 0.616129  [   76/   89]
per-ex loss: 0.615896  [   78/   89]
per-ex loss: 0.431869  [   80/   89]
per-ex loss: 0.583499  [   82/   89]
per-ex loss: 0.439013  [   84/   89]
per-ex loss: 0.588523  [   86/   89]
per-ex loss: 0.443101  [   88/   89]
per-ex loss: 0.450029  [   89/   89]
Train Error: Avg loss: 0.47272806
validation Error: 
 Avg loss: 0.51259504 
 F1: 0.510595 
 Precision: 0.610397 
 Recall: 0.438843
 IoU: 0.342818

test Error: 
 Avg loss: 0.47787338 
 F1: 0.558983 
 Precision: 0.681659 
 Recall: 0.473728
 IoU: 0.387909

We have finished training iteration 406
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_404_.pth
per-ex loss: 0.408819  [    2/   89]
per-ex loss: 0.468735  [    4/   89]
per-ex loss: 0.489424  [    6/   89]
per-ex loss: 0.398535  [    8/   89]
per-ex loss: 0.541454  [   10/   89]
per-ex loss: 0.461341  [   12/   89]
per-ex loss: 0.381133  [   14/   89]
per-ex loss: 0.625042  [   16/   89]
per-ex loss: 0.400037  [   18/   89]
per-ex loss: 0.466330  [   20/   89]
per-ex loss: 0.457850  [   22/   89]
per-ex loss: 0.532598  [   24/   89]
per-ex loss: 0.428435  [   26/   89]
per-ex loss: 0.494174  [   28/   89]
per-ex loss: 0.489784  [   30/   89]
per-ex loss: 0.384649  [   32/   89]
per-ex loss: 0.373873  [   34/   89]
per-ex loss: 0.563099  [   36/   89]
per-ex loss: 0.408617  [   38/   89]
per-ex loss: 0.386896  [   40/   89]
per-ex loss: 0.450912  [   42/   89]
per-ex loss: 0.487014  [   44/   89]
per-ex loss: 0.572884  [   46/   89]
per-ex loss: 0.414455  [   48/   89]
per-ex loss: 0.568521  [   50/   89]
per-ex loss: 0.499991  [   52/   89]
per-ex loss: 0.407400  [   54/   89]
per-ex loss: 0.506406  [   56/   89]
per-ex loss: 0.599770  [   58/   89]
per-ex loss: 0.383175  [   60/   89]
per-ex loss: 0.533654  [   62/   89]
per-ex loss: 0.361419  [   64/   89]
per-ex loss: 0.578384  [   66/   89]
per-ex loss: 0.447200  [   68/   89]
per-ex loss: 0.583344  [   70/   89]
per-ex loss: 0.485806  [   72/   89]
per-ex loss: 0.556132  [   74/   89]
per-ex loss: 0.386074  [   76/   89]
per-ex loss: 0.436733  [   78/   89]
per-ex loss: 0.492192  [   80/   89]
per-ex loss: 0.407492  [   82/   89]
per-ex loss: 0.444907  [   84/   89]
per-ex loss: 0.347619  [   86/   89]
per-ex loss: 0.386712  [   88/   89]
per-ex loss: 0.626207  [   89/   89]
Train Error: Avg loss: 0.46944951
validation Error: 
 Avg loss: 0.51523018 
 F1: 0.507213 
 Precision: 0.635712 
 Recall: 0.421927
 IoU: 0.339776

test Error: 
 Avg loss: 0.48930985 
 F1: 0.546656 
 Precision: 0.688239 
 Recall: 0.453387
 IoU: 0.376137

We have finished training iteration 407
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_405_.pth
per-ex loss: 0.403079  [    2/   89]
per-ex loss: 0.463197  [    4/   89]
per-ex loss: 0.426178  [    6/   89]
per-ex loss: 0.553651  [    8/   89]
per-ex loss: 0.361801  [   10/   89]
per-ex loss: 0.551936  [   12/   89]
per-ex loss: 0.628887  [   14/   89]
per-ex loss: 0.467265  [   16/   89]
per-ex loss: 0.442138  [   18/   89]
per-ex loss: 0.510295  [   20/   89]
per-ex loss: 0.412111  [   22/   89]
per-ex loss: 0.399526  [   24/   89]
per-ex loss: 0.519583  [   26/   89]
per-ex loss: 0.559922  [   28/   89]
per-ex loss: 0.434611  [   30/   89]
per-ex loss: 0.397776  [   32/   89]
per-ex loss: 0.366119  [   34/   89]
per-ex loss: 0.484350  [   36/   89]
per-ex loss: 0.650359  [   38/   89]
per-ex loss: 0.415828  [   40/   89]
per-ex loss: 0.615063  [   42/   89]
per-ex loss: 0.388089  [   44/   89]
per-ex loss: 0.518100  [   46/   89]
per-ex loss: 0.507029  [   48/   89]
per-ex loss: 0.381726  [   50/   89]
per-ex loss: 0.519442  [   52/   89]
per-ex loss: 0.417778  [   54/   89]
per-ex loss: 0.390895  [   56/   89]
per-ex loss: 0.371878  [   58/   89]
per-ex loss: 0.415543  [   60/   89]
per-ex loss: 0.372960  [   62/   89]
per-ex loss: 0.531135  [   64/   89]
per-ex loss: 0.363270  [   66/   89]
per-ex loss: 0.678094  [   68/   89]
per-ex loss: 0.520032  [   70/   89]
per-ex loss: 0.487408  [   72/   89]
per-ex loss: 0.411626  [   74/   89]
per-ex loss: 0.624150  [   76/   89]
per-ex loss: 0.381546  [   78/   89]
per-ex loss: 0.467294  [   80/   89]
per-ex loss: 0.375101  [   82/   89]
per-ex loss: 0.457907  [   84/   89]
per-ex loss: 0.428226  [   86/   89]
per-ex loss: 0.443734  [   88/   89]
per-ex loss: 0.417382  [   89/   89]
Train Error: Avg loss: 0.46520047
validation Error: 
 Avg loss: 0.55220516 
 F1: 0.474557 
 Precision: 0.670495 
 Recall: 0.367239
 IoU: 0.311095

test Error: 
 Avg loss: 0.52887462 
 F1: 0.504727 
 Precision: 0.693586 
 Recall: 0.396707
 IoU: 0.337548

We have finished training iteration 408
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_406_.pth
per-ex loss: 0.623704  [    2/   89]
per-ex loss: 0.481049  [    4/   89]
per-ex loss: 0.383183  [    6/   89]
per-ex loss: 0.410608  [    8/   89]
per-ex loss: 0.374456  [   10/   89]
per-ex loss: 0.563155  [   12/   89]
per-ex loss: 0.426192  [   14/   89]
per-ex loss: 0.659580  [   16/   89]
per-ex loss: 0.379307  [   18/   89]
per-ex loss: 0.576069  [   20/   89]
per-ex loss: 0.570887  [   22/   89]
per-ex loss: 0.416688  [   24/   89]
per-ex loss: 0.446485  [   26/   89]
per-ex loss: 0.453102  [   28/   89]
per-ex loss: 0.472135  [   30/   89]
per-ex loss: 0.636782  [   32/   89]
per-ex loss: 0.577906  [   34/   89]
per-ex loss: 0.475649  [   36/   89]
per-ex loss: 0.421118  [   38/   89]
per-ex loss: 0.403670  [   40/   89]
per-ex loss: 0.413765  [   42/   89]
per-ex loss: 0.378348  [   44/   89]
per-ex loss: 0.457862  [   46/   89]
per-ex loss: 0.390677  [   48/   89]
per-ex loss: 0.358488  [   50/   89]
per-ex loss: 0.547311  [   52/   89]
per-ex loss: 0.621717  [   54/   89]
per-ex loss: 0.519042  [   56/   89]
per-ex loss: 0.619104  [   58/   89]
per-ex loss: 0.470594  [   60/   89]
per-ex loss: 0.504958  [   62/   89]
per-ex loss: 0.374461  [   64/   89]
per-ex loss: 0.395941  [   66/   89]
per-ex loss: 0.402515  [   68/   89]
per-ex loss: 0.487165  [   70/   89]
per-ex loss: 0.411273  [   72/   89]
per-ex loss: 0.400172  [   74/   89]
per-ex loss: 0.383607  [   76/   89]
per-ex loss: 0.439149  [   78/   89]
per-ex loss: 0.379493  [   80/   89]
per-ex loss: 0.479907  [   82/   89]
per-ex loss: 0.421597  [   84/   89]
per-ex loss: 0.758521  [   86/   89]
per-ex loss: 0.417136  [   88/   89]
per-ex loss: 0.657607  [   89/   89]
Train Error: Avg loss: 0.47649190
validation Error: 
 Avg loss: 0.56771089 
 F1: 0.450027 
 Precision: 0.688842 
 Recall: 0.334172
 IoU: 0.290345

test Error: 
 Avg loss: 0.55360772 
 F1: 0.479039 
 Precision: 0.714165 
 Recall: 0.360388
 IoU: 0.314958

We have finished training iteration 409
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_407_.pth
Error in cropping the image to the non-zero values in the fourth channel. Returned the original image.
per-ex loss: 0.412321  [    2/   89]
per-ex loss: 0.409060  [    4/   89]
per-ex loss: 0.433078  [    6/   89]
per-ex loss: 0.375222  [    8/   89]
per-ex loss: 0.374364  [   10/   89]
per-ex loss: 0.565542  [   12/   89]
per-ex loss: 0.423867  [   14/   89]
per-ex loss: 0.405704  [   16/   89]
per-ex loss: 0.371123  [   18/   89]
per-ex loss: 0.423084  [   20/   89]
per-ex loss: 0.395030  [   22/   89]
per-ex loss: 0.436557  [   24/   89]
per-ex loss: 0.381054  [   26/   89]
per-ex loss: 0.596105  [   28/   89]
per-ex loss: 0.381844  [   30/   89]
per-ex loss: 0.414488  [   32/   89]
per-ex loss: 0.406697  [   34/   89]
per-ex loss: 0.497045  [   36/   89]
per-ex loss: 0.557807  [   38/   89]
per-ex loss: 0.505650  [   40/   89]
per-ex loss: 0.543996  [   42/   89]
per-ex loss: 0.579589  [   44/   89]
per-ex loss: 0.628817  [   46/   89]
per-ex loss: 0.651294  [   48/   89]
per-ex loss: 0.380990  [   50/   89]
per-ex loss: 0.440722  [   52/   89]
per-ex loss: 0.510021  [   54/   89]
per-ex loss: 0.447361  [   56/   89]
per-ex loss: 0.572886  [   58/   89]
per-ex loss: 0.437843  [   60/   89]
per-ex loss: 0.469947  [   62/   89]
per-ex loss: 0.579372  [   64/   89]
per-ex loss: 0.449346  [   66/   89]
per-ex loss: 0.405950  [   68/   89]
per-ex loss: 0.345635  [   70/   89]
per-ex loss: 0.454030  [   72/   89]
per-ex loss: 0.426472  [   74/   89]
per-ex loss: 0.465025  [   76/   89]
per-ex loss: 0.463084  [   78/   89]
per-ex loss: 0.402479  [   80/   89]
per-ex loss: 0.435402  [   82/   89]
per-ex loss: 0.428487  [   84/   89]
per-ex loss: 0.443830  [   86/   89]
per-ex loss: 0.412557  [   88/   89]
per-ex loss: 0.589365  [   89/   89]
Train Error: Avg loss: 0.46066981
validation Error: 
 Avg loss: 0.51556359 
 F1: 0.510653 
 Precision: 0.614456 
 Recall: 0.436854
 IoU: 0.342871

test Error: 
 Avg loss: 0.47938073 
 F1: 0.558219 
 Precision: 0.678572 
 Recall: 0.474127
 IoU: 0.387173

We have finished training iteration 410
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_408_.pth
per-ex loss: 0.524573  [    2/   89]
per-ex loss: 0.651367  [    4/   89]
per-ex loss: 0.523585  [    6/   89]
per-ex loss: 0.416780  [    8/   89]
per-ex loss: 0.462700  [   10/   89]
per-ex loss: 0.554993  [   12/   89]
per-ex loss: 0.340972  [   14/   89]
per-ex loss: 0.580094  [   16/   89]
per-ex loss: 0.492180  [   18/   89]
per-ex loss: 0.462544  [   20/   89]
per-ex loss: 0.403424  [   22/   89]
per-ex loss: 0.371000  [   24/   89]
per-ex loss: 0.591205  [   26/   89]
per-ex loss: 0.475654  [   28/   89]
per-ex loss: 0.449583  [   30/   89]
per-ex loss: 0.428307  [   32/   89]
per-ex loss: 0.467179  [   34/   89]
per-ex loss: 0.439533  [   36/   89]
per-ex loss: 0.367830  [   38/   89]
per-ex loss: 0.500235  [   40/   89]
per-ex loss: 0.408392  [   42/   89]
per-ex loss: 0.390512  [   44/   89]
per-ex loss: 0.385756  [   46/   89]
per-ex loss: 0.444313  [   48/   89]
per-ex loss: 0.501140  [   50/   89]
per-ex loss: 0.481895  [   52/   89]
per-ex loss: 0.589775  [   54/   89]
per-ex loss: 0.481785  [   56/   89]
per-ex loss: 0.424119  [   58/   89]
per-ex loss: 0.521046  [   60/   89]
per-ex loss: 0.520535  [   62/   89]
per-ex loss: 0.418413  [   64/   89]
per-ex loss: 0.426718  [   66/   89]
per-ex loss: 0.537530  [   68/   89]
per-ex loss: 0.505951  [   70/   89]
per-ex loss: 0.372555  [   72/   89]
per-ex loss: 0.491367  [   74/   89]
per-ex loss: 0.627072  [   76/   89]
per-ex loss: 0.399009  [   78/   89]
per-ex loss: 0.368929  [   80/   89]
per-ex loss: 0.647042  [   82/   89]
per-ex loss: 0.430769  [   84/   89]
per-ex loss: 0.436179  [   86/   89]
per-ex loss: 0.402858  [   88/   89]
per-ex loss: 0.429861  [   89/   89]
Train Error: Avg loss: 0.46993905
validation Error: 
 Avg loss: 0.51134552 
 F1: 0.512884 
 Precision: 0.616150 
 Recall: 0.439264
 IoU: 0.344885

test Error: 
 Avg loss: 0.47600032 
 F1: 0.561244 
 Precision: 0.693280 
 Recall: 0.471454
 IoU: 0.390089

We have finished training iteration 411
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_409_.pth
per-ex loss: 0.469665  [    2/   89]
per-ex loss: 0.463943  [    4/   89]
per-ex loss: 0.407693  [    6/   89]
per-ex loss: 0.471343  [    8/   89]
per-ex loss: 0.434008  [   10/   89]
per-ex loss: 0.456414  [   12/   89]
per-ex loss: 0.663759  [   14/   89]
per-ex loss: 0.418348  [   16/   89]
per-ex loss: 0.470289  [   18/   89]
per-ex loss: 0.352834  [   20/   89]
per-ex loss: 0.499267  [   22/   89]
per-ex loss: 0.352647  [   24/   89]
per-ex loss: 0.503815  [   26/   89]
per-ex loss: 0.429754  [   28/   89]
per-ex loss: 0.523986  [   30/   89]
per-ex loss: 0.370658  [   32/   89]
per-ex loss: 0.584361  [   34/   89]
per-ex loss: 0.410455  [   36/   89]
per-ex loss: 0.466752  [   38/   89]
per-ex loss: 0.405521  [   40/   89]
per-ex loss: 0.462112  [   42/   89]
per-ex loss: 0.575160  [   44/   89]
per-ex loss: 0.421827  [   46/   89]
per-ex loss: 0.433420  [   48/   89]
per-ex loss: 0.477605  [   50/   89]
per-ex loss: 0.576113  [   52/   89]
per-ex loss: 0.557331  [   54/   89]
per-ex loss: 0.401666  [   56/   89]
per-ex loss: 0.617704  [   58/   89]
per-ex loss: 0.330018  [   60/   89]
per-ex loss: 0.403290  [   62/   89]
per-ex loss: 0.464529  [   64/   89]
per-ex loss: 0.411379  [   66/   89]
per-ex loss: 0.664088  [   68/   89]
per-ex loss: 0.463943  [   70/   89]
per-ex loss: 0.485398  [   72/   89]
per-ex loss: 0.351692  [   74/   89]
per-ex loss: 0.445334  [   76/   89]
per-ex loss: 0.432803  [   78/   89]
per-ex loss: 0.604313  [   80/   89]
per-ex loss: 0.406664  [   82/   89]
per-ex loss: 0.387767  [   84/   89]
per-ex loss: 0.400846  [   86/   89]
per-ex loss: 0.406705  [   88/   89]
per-ex loss: 0.424374  [   89/   89]
Train Error: Avg loss: 0.46136873
validation Error: 
 Avg loss: 0.53324541 
 F1: 0.486103 
 Precision: 0.649083 
 Recall: 0.388543
 IoU: 0.321094

test Error: 
 Avg loss: 0.51649822 
 F1: 0.519054 
 Precision: 0.671904 
 Recall: 0.422859
 IoU: 0.350488

We have finished training iteration 412
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_410_.pth
per-ex loss: 0.432196  [    2/   89]
per-ex loss: 0.403893  [    4/   89]
per-ex loss: 0.540370  [    6/   89]
per-ex loss: 0.505638  [    8/   89]
per-ex loss: 0.448512  [   10/   89]
per-ex loss: 0.351239  [   12/   89]
per-ex loss: 0.469894  [   14/   89]
per-ex loss: 0.588818  [   16/   89]
per-ex loss: 0.436198  [   18/   89]
per-ex loss: 0.360992  [   20/   89]
per-ex loss: 0.350312  [   22/   89]
per-ex loss: 0.523118  [   24/   89]
per-ex loss: 0.402839  [   26/   89]
per-ex loss: 0.475919  [   28/   89]
per-ex loss: 0.445391  [   30/   89]
per-ex loss: 0.422300  [   32/   89]
per-ex loss: 0.592370  [   34/   89]
per-ex loss: 0.408444  [   36/   89]
per-ex loss: 0.603166  [   38/   89]
per-ex loss: 0.475357  [   40/   89]
per-ex loss: 0.401502  [   42/   89]
per-ex loss: 0.546315  [   44/   89]
per-ex loss: 0.559291  [   46/   89]
per-ex loss: 0.599075  [   48/   89]
per-ex loss: 0.443204  [   50/   89]
per-ex loss: 0.633577  [   52/   89]
per-ex loss: 0.471007  [   54/   89]
per-ex loss: 0.381673  [   56/   89]
per-ex loss: 0.525023  [   58/   89]
per-ex loss: 0.384543  [   60/   89]
per-ex loss: 0.450769  [   62/   89]
per-ex loss: 0.421179  [   64/   89]
per-ex loss: 0.341088  [   66/   89]
per-ex loss: 0.431456  [   68/   89]
per-ex loss: 0.428987  [   70/   89]
per-ex loss: 0.494380  [   72/   89]
per-ex loss: 0.440247  [   74/   89]
per-ex loss: 0.445609  [   76/   89]
per-ex loss: 0.494301  [   78/   89]
per-ex loss: 0.502407  [   80/   89]
per-ex loss: 0.378600  [   82/   89]
per-ex loss: 0.439497  [   84/   89]
per-ex loss: 0.378695  [   86/   89]
per-ex loss: 0.531076  [   88/   89]
per-ex loss: 0.421455  [   89/   89]
Train Error: Avg loss: 0.46182045
validation Error: 
 Avg loss: 0.51394502 
 F1: 0.511245 
 Precision: 0.601226 
 Recall: 0.444691
 IoU: 0.343404

test Error: 
 Avg loss: 0.47658022 
 F1: 0.559853 
 Precision: 0.668074 
 Recall: 0.481805
 IoU: 0.388747

We have finished training iteration 413
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_411_.pth
per-ex loss: 0.396319  [    2/   89]
per-ex loss: 0.465402  [    4/   89]
per-ex loss: 0.434601  [    6/   89]
per-ex loss: 0.505305  [    8/   89]
per-ex loss: 0.521620  [   10/   89]
per-ex loss: 0.542273  [   12/   89]
per-ex loss: 0.453174  [   14/   89]
per-ex loss: 0.590417  [   16/   89]
per-ex loss: 0.421917  [   18/   89]
per-ex loss: 0.469246  [   20/   89]
per-ex loss: 0.519516  [   22/   89]
per-ex loss: 0.531110  [   24/   89]
per-ex loss: 0.434526  [   26/   89]
per-ex loss: 0.450188  [   28/   89]
per-ex loss: 0.535269  [   30/   89]
per-ex loss: 0.381214  [   32/   89]
per-ex loss: 0.519163  [   34/   89]
per-ex loss: 0.505748  [   36/   89]
per-ex loss: 0.404096  [   38/   89]
per-ex loss: 0.357489  [   40/   89]
per-ex loss: 0.351416  [   42/   89]
per-ex loss: 0.393819  [   44/   89]
per-ex loss: 0.379997  [   46/   89]
per-ex loss: 0.437448  [   48/   89]
per-ex loss: 0.408876  [   50/   89]
per-ex loss: 0.496903  [   52/   89]
per-ex loss: 0.441690  [   54/   89]
per-ex loss: 0.355627  [   56/   89]
per-ex loss: 0.494357  [   58/   89]
per-ex loss: 0.605648  [   60/   89]
per-ex loss: 0.367534  [   62/   89]
per-ex loss: 0.525240  [   64/   89]
per-ex loss: 0.568175  [   66/   89]
per-ex loss: 0.499839  [   68/   89]
per-ex loss: 0.490637  [   70/   89]
per-ex loss: 0.390209  [   72/   89]
per-ex loss: 0.440104  [   74/   89]
per-ex loss: 0.413546  [   76/   89]
per-ex loss: 0.565433  [   78/   89]
per-ex loss: 0.619727  [   80/   89]
per-ex loss: 0.650996  [   82/   89]
per-ex loss: 0.586039  [   84/   89]
per-ex loss: 0.370376  [   86/   89]
per-ex loss: 0.431530  [   88/   89]
per-ex loss: 0.426730  [   89/   89]
Train Error: Avg loss: 0.47001085
validation Error: 
 Avg loss: 0.50885957 
 F1: 0.512741 
 Precision: 0.617794 
 Recall: 0.438224
 IoU: 0.344756

test Error: 
 Avg loss: 0.47697578 
 F1: 0.560126 
 Precision: 0.679862 
 Recall: 0.476250
 IoU: 0.389011

We have finished training iteration 414
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_412_.pth
per-ex loss: 0.387406  [    2/   89]
per-ex loss: 0.535815  [    4/   89]
per-ex loss: 0.428881  [    6/   89]
per-ex loss: 0.504622  [    8/   89]
per-ex loss: 0.396994  [   10/   89]
per-ex loss: 0.613295  [   12/   89]
per-ex loss: 0.406320  [   14/   89]
per-ex loss: 0.401240  [   16/   89]
per-ex loss: 0.488201  [   18/   89]
per-ex loss: 0.403150  [   20/   89]
per-ex loss: 0.414223  [   22/   89]
per-ex loss: 0.431662  [   24/   89]
per-ex loss: 0.406950  [   26/   89]
per-ex loss: 0.357745  [   28/   89]
per-ex loss: 0.377762  [   30/   89]
per-ex loss: 0.509764  [   32/   89]
per-ex loss: 0.412972  [   34/   89]
per-ex loss: 0.624321  [   36/   89]
per-ex loss: 0.420927  [   38/   89]
per-ex loss: 0.465646  [   40/   89]
per-ex loss: 0.374395  [   42/   89]
per-ex loss: 0.469068  [   44/   89]
per-ex loss: 0.385438  [   46/   89]
per-ex loss: 0.547002  [   48/   89]
per-ex loss: 0.519464  [   50/   89]
per-ex loss: 0.539431  [   52/   89]
per-ex loss: 0.489185  [   54/   89]
per-ex loss: 0.426376  [   56/   89]
per-ex loss: 0.432141  [   58/   89]
per-ex loss: 0.415914  [   60/   89]
per-ex loss: 0.474794  [   62/   89]
per-ex loss: 0.450451  [   64/   89]
per-ex loss: 0.489254  [   66/   89]
per-ex loss: 0.342014  [   68/   89]
per-ex loss: 0.397677  [   70/   89]
per-ex loss: 0.479523  [   72/   89]
per-ex loss: 0.480693  [   74/   89]
per-ex loss: 0.411190  [   76/   89]
per-ex loss: 0.653505  [   78/   89]
per-ex loss: 0.569998  [   80/   89]
per-ex loss: 0.379473  [   82/   89]
per-ex loss: 0.647793  [   84/   89]
per-ex loss: 0.403729  [   86/   89]
per-ex loss: 0.424955  [   88/   89]
per-ex loss: 0.548132  [   89/   89]
Train Error: Avg loss: 0.46087757
validation Error: 
 Avg loss: 0.51273451 
 F1: 0.512858 
 Precision: 0.627100 
 Recall: 0.433825
 IoU: 0.344861

test Error: 
 Avg loss: 0.48054742 
 F1: 0.556203 
 Precision: 0.677689 
 Recall: 0.471653
 IoU: 0.385237

We have finished training iteration 415
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_413_.pth
per-ex loss: 0.486357  [    2/   89]
per-ex loss: 0.546291  [    4/   89]
per-ex loss: 0.400822  [    6/   89]
per-ex loss: 0.339008  [    8/   89]
per-ex loss: 0.370939  [   10/   89]
per-ex loss: 0.493877  [   12/   89]
per-ex loss: 0.560655  [   14/   89]
per-ex loss: 0.389911  [   16/   89]
per-ex loss: 0.381305  [   18/   89]
per-ex loss: 0.525410  [   20/   89]
per-ex loss: 0.459260  [   22/   89]
per-ex loss: 0.389555  [   24/   89]
per-ex loss: 0.491027  [   26/   89]
per-ex loss: 0.580118  [   28/   89]
per-ex loss: 0.395720  [   30/   89]
per-ex loss: 0.395111  [   32/   89]
per-ex loss: 0.424962  [   34/   89]
per-ex loss: 0.555116  [   36/   89]
per-ex loss: 0.534943  [   38/   89]
per-ex loss: 0.637823  [   40/   89]
per-ex loss: 0.575987  [   42/   89]
per-ex loss: 0.479153  [   44/   89]
per-ex loss: 0.492694  [   46/   89]
per-ex loss: 0.519197  [   48/   89]
per-ex loss: 0.584986  [   50/   89]
per-ex loss: 0.398553  [   52/   89]
per-ex loss: 0.427790  [   54/   89]
per-ex loss: 0.357345  [   56/   89]
per-ex loss: 0.502594  [   58/   89]
per-ex loss: 0.537676  [   60/   89]
per-ex loss: 0.433593  [   62/   89]
per-ex loss: 0.368083  [   64/   89]
per-ex loss: 0.457518  [   66/   89]
per-ex loss: 0.476478  [   68/   89]
per-ex loss: 0.505265  [   70/   89]
per-ex loss: 0.431540  [   72/   89]
per-ex loss: 0.495625  [   74/   89]
per-ex loss: 0.402771  [   76/   89]
per-ex loss: 0.443259  [   78/   89]
per-ex loss: 0.559939  [   80/   89]
per-ex loss: 0.586686  [   82/   89]
per-ex loss: 0.377748  [   84/   89]
per-ex loss: 0.426103  [   86/   89]
per-ex loss: 0.462667  [   88/   89]
per-ex loss: 0.373722  [   89/   89]
Train Error: Avg loss: 0.46744852
validation Error: 
 Avg loss: 0.51201229 
 F1: 0.510600 
 Precision: 0.615161 
 Recall: 0.436421
 IoU: 0.342823

test Error: 
 Avg loss: 0.48385906 
 F1: 0.552454 
 Precision: 0.656187 
 Recall: 0.477042
 IoU: 0.381649

We have finished training iteration 416
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_414_.pth
per-ex loss: 0.363857  [    2/   89]
per-ex loss: 0.399158  [    4/   89]
per-ex loss: 0.451031  [    6/   89]
per-ex loss: 0.483881  [    8/   89]
per-ex loss: 0.450348  [   10/   89]
per-ex loss: 0.371773  [   12/   89]
per-ex loss: 0.367415  [   14/   89]
per-ex loss: 0.491876  [   16/   89]
per-ex loss: 0.431943  [   18/   89]
per-ex loss: 0.378798  [   20/   89]
per-ex loss: 0.625511  [   22/   89]
per-ex loss: 0.624450  [   24/   89]
per-ex loss: 0.500506  [   26/   89]
per-ex loss: 0.367910  [   28/   89]
per-ex loss: 0.485705  [   30/   89]
per-ex loss: 0.479931  [   32/   89]
per-ex loss: 0.614442  [   34/   89]
per-ex loss: 0.399767  [   36/   89]
per-ex loss: 0.584491  [   38/   89]
per-ex loss: 0.551370  [   40/   89]
per-ex loss: 0.405966  [   42/   89]
per-ex loss: 0.475873  [   44/   89]
per-ex loss: 0.524459  [   46/   89]
per-ex loss: 0.479371  [   48/   89]
per-ex loss: 0.473652  [   50/   89]
per-ex loss: 0.401339  [   52/   89]
per-ex loss: 0.346960  [   54/   89]
per-ex loss: 0.396337  [   56/   89]
per-ex loss: 0.432435  [   58/   89]
per-ex loss: 0.538923  [   60/   89]
per-ex loss: 0.395592  [   62/   89]
per-ex loss: 0.598200  [   64/   89]
per-ex loss: 0.463394  [   66/   89]
per-ex loss: 0.496093  [   68/   89]
per-ex loss: 0.552469  [   70/   89]
per-ex loss: 0.416018  [   72/   89]
per-ex loss: 0.610167  [   74/   89]
per-ex loss: 0.472131  [   76/   89]
per-ex loss: 0.569366  [   78/   89]
per-ex loss: 0.391258  [   80/   89]
per-ex loss: 0.403959  [   82/   89]
per-ex loss: 0.598369  [   84/   89]
per-ex loss: 0.556846  [   86/   89]
per-ex loss: 0.404055  [   88/   89]
per-ex loss: 0.418057  [   89/   89]
Train Error: Avg loss: 0.47212114
validation Error: 
 Avg loss: 0.51515595 
 F1: 0.512945 
 Precision: 0.625682 
 Recall: 0.434632
 IoU: 0.344940

test Error: 
 Avg loss: 0.48086149 
 F1: 0.555461 
 Precision: 0.680705 
 Recall: 0.469143
 IoU: 0.384525

We have finished training iteration 417
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_415_.pth
per-ex loss: 0.443182  [    2/   89]
per-ex loss: 0.467398  [    4/   89]
per-ex loss: 0.543267  [    6/   89]
per-ex loss: 0.397382  [    8/   89]
per-ex loss: 0.455991  [   10/   89]
per-ex loss: 0.579546  [   12/   89]
per-ex loss: 0.394411  [   14/   89]
per-ex loss: 0.387270  [   16/   89]
per-ex loss: 0.479228  [   18/   89]
per-ex loss: 0.399132  [   20/   89]
per-ex loss: 0.650527  [   22/   89]
per-ex loss: 0.420266  [   24/   89]
per-ex loss: 0.495188  [   26/   89]
per-ex loss: 0.508884  [   28/   89]
per-ex loss: 0.663703  [   30/   89]
per-ex loss: 0.504868  [   32/   89]
per-ex loss: 0.475786  [   34/   89]
per-ex loss: 0.519213  [   36/   89]
per-ex loss: 0.482766  [   38/   89]
per-ex loss: 0.400175  [   40/   89]
per-ex loss: 0.539698  [   42/   89]
per-ex loss: 0.453332  [   44/   89]
per-ex loss: 0.440223  [   46/   89]
per-ex loss: 0.407560  [   48/   89]
per-ex loss: 0.394843  [   50/   89]
per-ex loss: 0.398472  [   52/   89]
per-ex loss: 0.492885  [   54/   89]
per-ex loss: 0.474131  [   56/   89]
per-ex loss: 0.580995  [   58/   89]
per-ex loss: 0.530078  [   60/   89]
per-ex loss: 0.407885  [   62/   89]
per-ex loss: 0.363772  [   64/   89]
per-ex loss: 0.447343  [   66/   89]
per-ex loss: 0.359356  [   68/   89]
per-ex loss: 0.669452  [   70/   89]
per-ex loss: 0.475056  [   72/   89]
per-ex loss: 0.455768  [   74/   89]
per-ex loss: 0.495115  [   76/   89]
per-ex loss: 0.533423  [   78/   89]
per-ex loss: 0.495048  [   80/   89]
per-ex loss: 0.504800  [   82/   89]
per-ex loss: 0.459500  [   84/   89]
per-ex loss: 0.341140  [   86/   89]
per-ex loss: 0.497036  [   88/   89]
per-ex loss: 0.338001  [   89/   89]
Train Error: Avg loss: 0.47162429
validation Error: 
 Avg loss: 0.51072687 
 F1: 0.513209 
 Precision: 0.618889 
 Recall: 0.438357
 IoU: 0.345179

test Error: 
 Avg loss: 0.48027075 
 F1: 0.554967 
 Precision: 0.673784 
 Recall: 0.471773
 IoU: 0.384052

We have finished training iteration 418
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_416_.pth
per-ex loss: 0.381721  [    2/   89]
per-ex loss: 0.643206  [    4/   89]
per-ex loss: 0.424331  [    6/   89]
per-ex loss: 0.461858  [    8/   89]
per-ex loss: 0.563202  [   10/   89]
per-ex loss: 0.564887  [   12/   89]
per-ex loss: 0.516375  [   14/   89]
per-ex loss: 0.556568  [   16/   89]
per-ex loss: 0.431999  [   18/   89]
per-ex loss: 0.371883  [   20/   89]
per-ex loss: 0.388858  [   22/   89]
per-ex loss: 0.571126  [   24/   89]
per-ex loss: 0.436031  [   26/   89]
per-ex loss: 0.364290  [   28/   89]
per-ex loss: 0.399587  [   30/   89]
per-ex loss: 0.389593  [   32/   89]
per-ex loss: 0.395675  [   34/   89]
per-ex loss: 0.590400  [   36/   89]
per-ex loss: 0.406955  [   38/   89]
per-ex loss: 0.445271  [   40/   89]
per-ex loss: 0.551095  [   42/   89]
per-ex loss: 0.545150  [   44/   89]
per-ex loss: 0.359014  [   46/   89]
per-ex loss: 0.555270  [   48/   89]
per-ex loss: 0.618393  [   50/   89]
per-ex loss: 0.572723  [   52/   89]
per-ex loss: 0.540847  [   54/   89]
per-ex loss: 0.555297  [   56/   89]
per-ex loss: 0.623386  [   58/   89]
per-ex loss: 0.478443  [   60/   89]
per-ex loss: 0.353026  [   62/   89]
per-ex loss: 0.440315  [   64/   89]
per-ex loss: 0.563109  [   66/   89]
per-ex loss: 0.410382  [   68/   89]
per-ex loss: 0.389672  [   70/   89]
per-ex loss: 0.464414  [   72/   89]
per-ex loss: 0.441003  [   74/   89]
per-ex loss: 0.378451  [   76/   89]
per-ex loss: 0.572062  [   78/   89]
per-ex loss: 0.382866  [   80/   89]
per-ex loss: 0.372719  [   82/   89]
per-ex loss: 0.376969  [   84/   89]
per-ex loss: 0.723112  [   86/   89]
per-ex loss: 0.559506  [   88/   89]
per-ex loss: 0.678440  [   89/   89]
Train Error: Avg loss: 0.48465504
validation Error: 
 Avg loss: 0.56574079 
 F1: 0.447476 
 Precision: 0.711112 
 Recall: 0.326449
 IoU: 0.288225

test Error: 
 Avg loss: 0.55654182 
 F1: 0.475199 
 Precision: 0.728051 
 Recall: 0.352704
 IoU: 0.311646

We have finished training iteration 419
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_417_.pth
per-ex loss: 0.539714  [    2/   89]
per-ex loss: 0.493795  [    4/   89]
per-ex loss: 0.464763  [    6/   89]
per-ex loss: 0.396892  [    8/   89]
per-ex loss: 0.383257  [   10/   89]
per-ex loss: 0.391754  [   12/   89]
per-ex loss: 0.589824  [   14/   89]
per-ex loss: 0.400254  [   16/   89]
per-ex loss: 0.447423  [   18/   89]
per-ex loss: 0.467160  [   20/   89]
per-ex loss: 0.508359  [   22/   89]
per-ex loss: 0.428161  [   24/   89]
per-ex loss: 0.508984  [   26/   89]
per-ex loss: 0.395556  [   28/   89]
per-ex loss: 0.529384  [   30/   89]
per-ex loss: 0.356310  [   32/   89]
per-ex loss: 0.582174  [   34/   89]
per-ex loss: 0.407505  [   36/   89]
per-ex loss: 0.426434  [   38/   89]
per-ex loss: 0.430077  [   40/   89]
per-ex loss: 0.413629  [   42/   89]
per-ex loss: 0.566647  [   44/   89]
per-ex loss: 0.417737  [   46/   89]
per-ex loss: 0.454699  [   48/   89]
per-ex loss: 0.391052  [   50/   89]
per-ex loss: 0.394634  [   52/   89]
per-ex loss: 0.441935  [   54/   89]
per-ex loss: 0.440365  [   56/   89]
per-ex loss: 0.416996  [   58/   89]
per-ex loss: 0.439695  [   60/   89]
per-ex loss: 0.570825  [   62/   89]
per-ex loss: 0.400260  [   64/   89]
per-ex loss: 0.603988  [   66/   89]
per-ex loss: 0.369752  [   68/   89]
per-ex loss: 0.416647  [   70/   89]
per-ex loss: 0.559587  [   72/   89]
per-ex loss: 0.486177  [   74/   89]
per-ex loss: 0.506106  [   76/   89]
per-ex loss: 0.390542  [   78/   89]
per-ex loss: 0.634735  [   80/   89]
per-ex loss: 0.426001  [   82/   89]
per-ex loss: 0.399274  [   84/   89]
per-ex loss: 0.592449  [   86/   89]
per-ex loss: 0.452911  [   88/   89]
per-ex loss: 0.561976  [   89/   89]
Train Error: Avg loss: 0.46436442
validation Error: 
 Avg loss: 0.53671178 
 F1: 0.480702 
 Precision: 0.662006 
 Recall: 0.377356
 IoU: 0.316397

test Error: 
 Avg loss: 0.52245802 
 F1: 0.512395 
 Precision: 0.674628 
 Recall: 0.413063
 IoU: 0.344443

We have finished training iteration 420
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_418_.pth
Error in cropping the image to the non-zero values in the fourth channel. Returned the original image.
per-ex loss: 0.397793  [    2/   89]
per-ex loss: 0.676207  [    4/   89]
per-ex loss: 0.427463  [    6/   89]
per-ex loss: 0.386508  [    8/   89]
per-ex loss: 0.392327  [   10/   89]
per-ex loss: 0.490119  [   12/   89]
per-ex loss: 0.526551  [   14/   89]
per-ex loss: 0.422083  [   16/   89]
per-ex loss: 0.406836  [   18/   89]
per-ex loss: 0.428128  [   20/   89]
per-ex loss: 0.481800  [   22/   89]
per-ex loss: 0.528724  [   24/   89]
per-ex loss: 0.384615  [   26/   89]
per-ex loss: 0.474869  [   28/   89]
per-ex loss: 0.366978  [   30/   89]
per-ex loss: 0.594831  [   32/   89]
per-ex loss: 0.609338  [   34/   89]
per-ex loss: 0.610912  [   36/   89]
per-ex loss: 0.493505  [   38/   89]
per-ex loss: 0.477400  [   40/   89]
per-ex loss: 0.494658  [   42/   89]
per-ex loss: 0.414945  [   44/   89]
per-ex loss: 0.497554  [   46/   89]
per-ex loss: 0.430861  [   48/   89]
per-ex loss: 0.596775  [   50/   89]
per-ex loss: 0.360497  [   52/   89]
per-ex loss: 0.441851  [   54/   89]
per-ex loss: 0.355010  [   56/   89]
per-ex loss: 0.433197  [   58/   89]
per-ex loss: 0.450503  [   60/   89]
per-ex loss: 0.408635  [   62/   89]
per-ex loss: 0.460439  [   64/   89]
per-ex loss: 0.395406  [   66/   89]
per-ex loss: 0.612990  [   68/   89]
per-ex loss: 0.516300  [   70/   89]
per-ex loss: 0.554221  [   72/   89]
per-ex loss: 0.532483  [   74/   89]
per-ex loss: 0.473741  [   76/   89]
per-ex loss: 0.571624  [   78/   89]
per-ex loss: 0.384722  [   80/   89]
per-ex loss: 0.499493  [   82/   89]
per-ex loss: 0.539921  [   84/   89]
per-ex loss: 0.463934  [   86/   89]
per-ex loss: 0.467969  [   88/   89]
per-ex loss: 0.360083  [   89/   89]
Train Error: Avg loss: 0.47321769
validation Error: 
 Avg loss: 0.52053939 
 F1: 0.506014 
 Precision: 0.620794 
 Recall: 0.427055
 IoU: 0.338700

test Error: 
 Avg loss: 0.49216916 
 F1: 0.543725 
 Precision: 0.670243 
 Recall: 0.457387
 IoU: 0.373367

We have finished training iteration 421
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_419_.pth
per-ex loss: 0.500087  [    2/   89]
per-ex loss: 0.420847  [    4/   89]
per-ex loss: 0.655400  [    6/   89]
per-ex loss: 0.592969  [    8/   89]
per-ex loss: 0.458774  [   10/   89]
per-ex loss: 0.552574  [   12/   89]
per-ex loss: 0.396930  [   14/   89]
per-ex loss: 0.438996  [   16/   89]
per-ex loss: 0.544734  [   18/   89]
per-ex loss: 0.527691  [   20/   89]
per-ex loss: 0.386370  [   22/   89]
per-ex loss: 0.420268  [   24/   89]
per-ex loss: 0.385666  [   26/   89]
per-ex loss: 0.477491  [   28/   89]
per-ex loss: 0.710678  [   30/   89]
per-ex loss: 0.452779  [   32/   89]
per-ex loss: 0.461159  [   34/   89]
per-ex loss: 0.497822  [   36/   89]
per-ex loss: 0.391984  [   38/   89]
per-ex loss: 0.396489  [   40/   89]
per-ex loss: 0.417549  [   42/   89]
per-ex loss: 0.400567  [   44/   89]
per-ex loss: 0.409604  [   46/   89]
per-ex loss: 0.528526  [   48/   89]
per-ex loss: 0.603482  [   50/   89]
per-ex loss: 0.362632  [   52/   89]
per-ex loss: 0.588530  [   54/   89]
per-ex loss: 0.395764  [   56/   89]
per-ex loss: 0.356158  [   58/   89]
per-ex loss: 0.393501  [   60/   89]
per-ex loss: 0.516494  [   62/   89]
per-ex loss: 0.465283  [   64/   89]
per-ex loss: 0.417542  [   66/   89]
per-ex loss: 0.396904  [   68/   89]
per-ex loss: 0.374459  [   70/   89]
per-ex loss: 0.389131  [   72/   89]
per-ex loss: 0.547244  [   74/   89]
per-ex loss: 0.469061  [   76/   89]
per-ex loss: 0.402293  [   78/   89]
per-ex loss: 0.370597  [   80/   89]
per-ex loss: 0.415564  [   82/   89]
per-ex loss: 0.678836  [   84/   89]
per-ex loss: 0.567037  [   86/   89]
per-ex loss: 0.544839  [   88/   89]
per-ex loss: 0.612048  [   89/   89]
Train Error: Avg loss: 0.47318566
validation Error: 
 Avg loss: 0.51751560 
 F1: 0.512527 
 Precision: 0.628876 
 Recall: 0.432509
 IoU: 0.344562

test Error: 
 Avg loss: 0.48082425 
 F1: 0.555026 
 Precision: 0.684557 
 Recall: 0.466715
 IoU: 0.384108

We have finished training iteration 422
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_420_.pth
per-ex loss: 0.410872  [    2/   89]
per-ex loss: 0.631797  [    4/   89]
per-ex loss: 0.446034  [    6/   89]
per-ex loss: 0.359445  [    8/   89]
per-ex loss: 0.561372  [   10/   89]
per-ex loss: 0.395614  [   12/   89]
per-ex loss: 0.376891  [   14/   89]
per-ex loss: 0.478834  [   16/   89]
per-ex loss: 0.477981  [   18/   89]
per-ex loss: 0.481798  [   20/   89]
per-ex loss: 0.461042  [   22/   89]
per-ex loss: 0.461905  [   24/   89]
per-ex loss: 0.691751  [   26/   89]
per-ex loss: 0.469032  [   28/   89]
per-ex loss: 0.414280  [   30/   89]
per-ex loss: 0.620401  [   32/   89]
per-ex loss: 0.415898  [   34/   89]
per-ex loss: 0.392785  [   36/   89]
per-ex loss: 0.407908  [   38/   89]
per-ex loss: 0.397839  [   40/   89]
per-ex loss: 0.462590  [   42/   89]
per-ex loss: 0.525818  [   44/   89]
per-ex loss: 0.382508  [   46/   89]
per-ex loss: 0.365764  [   48/   89]
per-ex loss: 0.539697  [   50/   89]
per-ex loss: 0.360900  [   52/   89]
per-ex loss: 0.377049  [   54/   89]
per-ex loss: 0.586753  [   56/   89]
per-ex loss: 0.376403  [   58/   89]
per-ex loss: 0.362397  [   60/   89]
per-ex loss: 0.454011  [   62/   89]
per-ex loss: 0.508752  [   64/   89]
per-ex loss: 0.487682  [   66/   89]
per-ex loss: 0.504951  [   68/   89]
per-ex loss: 0.608235  [   70/   89]
per-ex loss: 0.490480  [   72/   89]
per-ex loss: 0.498517  [   74/   89]
per-ex loss: 0.372819  [   76/   89]
per-ex loss: 0.379428  [   78/   89]
per-ex loss: 0.616805  [   80/   89]
per-ex loss: 0.583859  [   82/   89]
per-ex loss: 0.529490  [   84/   89]
per-ex loss: 0.484866  [   86/   89]
per-ex loss: 0.373726  [   88/   89]
per-ex loss: 0.529550  [   89/   89]
Train Error: Avg loss: 0.46925627
validation Error: 
 Avg loss: 0.50220338 
 F1: 0.513618 
 Precision: 0.613083 
 Recall: 0.441923
 IoU: 0.345549

test Error: 
 Avg loss: 0.47662093 
 F1: 0.559746 
 Precision: 0.675455 
 Recall: 0.477882
 IoU: 0.388643

We have finished training iteration 423
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_421_.pth
per-ex loss: 0.391832  [    2/   89]
per-ex loss: 0.510734  [    4/   89]
per-ex loss: 0.435611  [    6/   89]
per-ex loss: 0.549344  [    8/   89]
per-ex loss: 0.542060  [   10/   89]
per-ex loss: 0.398491  [   12/   89]
per-ex loss: 0.384354  [   14/   89]
per-ex loss: 0.470796  [   16/   89]
per-ex loss: 0.350869  [   18/   89]
per-ex loss: 0.468647  [   20/   89]
per-ex loss: 0.617881  [   22/   89]
per-ex loss: 0.398384  [   24/   89]
per-ex loss: 0.447220  [   26/   89]
per-ex loss: 0.629745  [   28/   89]
per-ex loss: 0.470257  [   30/   89]
per-ex loss: 0.629938  [   32/   89]
per-ex loss: 0.551500  [   34/   89]
per-ex loss: 0.437529  [   36/   89]
per-ex loss: 0.384144  [   38/   89]
per-ex loss: 0.476306  [   40/   89]
per-ex loss: 0.356068  [   42/   89]
per-ex loss: 0.427732  [   44/   89]
per-ex loss: 0.655632  [   46/   89]
per-ex loss: 0.656790  [   48/   89]
per-ex loss: 0.404776  [   50/   89]
per-ex loss: 0.437998  [   52/   89]
per-ex loss: 0.510319  [   54/   89]
per-ex loss: 0.487018  [   56/   89]
per-ex loss: 0.391336  [   58/   89]
per-ex loss: 0.441882  [   60/   89]
per-ex loss: 0.405503  [   62/   89]
per-ex loss: 0.389085  [   64/   89]
per-ex loss: 0.442187  [   66/   89]
per-ex loss: 0.396883  [   68/   89]
per-ex loss: 0.353236  [   70/   89]
per-ex loss: 0.559678  [   72/   89]
per-ex loss: 0.371826  [   74/   89]
per-ex loss: 0.412427  [   76/   89]
per-ex loss: 0.557661  [   78/   89]
per-ex loss: 0.484992  [   80/   89]
per-ex loss: 0.472744  [   82/   89]
per-ex loss: 0.463254  [   84/   89]
per-ex loss: 0.578534  [   86/   89]
per-ex loss: 0.349650  [   88/   89]
per-ex loss: 0.520981  [   89/   89]
Train Error: Avg loss: 0.46830744
validation Error: 
 Avg loss: 0.50273325 
 F1: 0.512049 
 Precision: 0.606901 
 Recall: 0.442838
 IoU: 0.344130

test Error: 
 Avg loss: 0.47916530 
 F1: 0.556956 
 Precision: 0.666334 
 Recall: 0.478423
 IoU: 0.385959

We have finished training iteration 424
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_422_.pth
per-ex loss: 0.500726  [    2/   89]
per-ex loss: 0.479444  [    4/   89]
per-ex loss: 0.612301  [    6/   89]
per-ex loss: 0.505193  [    8/   89]
per-ex loss: 0.373907  [   10/   89]
per-ex loss: 0.374856  [   12/   89]
per-ex loss: 0.471499  [   14/   89]
per-ex loss: 0.380501  [   16/   89]
per-ex loss: 0.580111  [   18/   89]
per-ex loss: 0.392103  [   20/   89]
per-ex loss: 0.379122  [   22/   89]
per-ex loss: 0.591136  [   24/   89]
per-ex loss: 0.437689  [   26/   89]
per-ex loss: 0.451452  [   28/   89]
per-ex loss: 0.483333  [   30/   89]
per-ex loss: 0.403029  [   32/   89]
per-ex loss: 0.478203  [   34/   89]
per-ex loss: 0.451734  [   36/   89]
per-ex loss: 0.386538  [   38/   89]
per-ex loss: 0.402052  [   40/   89]
per-ex loss: 0.371669  [   42/   89]
per-ex loss: 0.422349  [   44/   89]
per-ex loss: 0.537802  [   46/   89]
per-ex loss: 0.396549  [   48/   89]
per-ex loss: 0.558490  [   50/   89]
per-ex loss: 0.499969  [   52/   89]
per-ex loss: 0.374172  [   54/   89]
per-ex loss: 0.430988  [   56/   89]
per-ex loss: 0.447299  [   58/   89]
per-ex loss: 0.377492  [   60/   89]
per-ex loss: 0.631300  [   62/   89]
per-ex loss: 0.414587  [   64/   89]
per-ex loss: 0.551739  [   66/   89]
per-ex loss: 0.487252  [   68/   89]
per-ex loss: 0.492846  [   70/   89]
per-ex loss: 0.405210  [   72/   89]
per-ex loss: 0.415208  [   74/   89]
per-ex loss: 0.392457  [   76/   89]
per-ex loss: 0.477419  [   78/   89]
per-ex loss: 0.679848  [   80/   89]
per-ex loss: 0.407070  [   82/   89]
per-ex loss: 0.593502  [   84/   89]
per-ex loss: 0.406828  [   86/   89]
per-ex loss: 0.598683  [   88/   89]
per-ex loss: 0.368561  [   89/   89]
Train Error: Avg loss: 0.46387153
validation Error: 
 Avg loss: 0.53591368 
 F1: 0.483705 
 Precision: 0.635686 
 Recall: 0.390373
 IoU: 0.319004

test Error: 
 Avg loss: 0.52085982 
 F1: 0.514504 
 Precision: 0.658194 
 Recall: 0.422311
 IoU: 0.346352

We have finished training iteration 425
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_423_.pth
per-ex loss: 0.379049  [    2/   89]
per-ex loss: 0.606474  [    4/   89]
per-ex loss: 0.526149  [    6/   89]
per-ex loss: 0.493847  [    8/   89]
per-ex loss: 0.463975  [   10/   89]
per-ex loss: 0.523936  [   12/   89]
per-ex loss: 0.505120  [   14/   89]
per-ex loss: 0.411497  [   16/   89]
per-ex loss: 0.382320  [   18/   89]
per-ex loss: 0.419936  [   20/   89]
per-ex loss: 0.564202  [   22/   89]
per-ex loss: 0.443655  [   24/   89]
per-ex loss: 0.594743  [   26/   89]
per-ex loss: 0.639067  [   28/   89]
per-ex loss: 0.547777  [   30/   89]
per-ex loss: 0.498284  [   32/   89]
per-ex loss: 0.387063  [   34/   89]
per-ex loss: 0.433056  [   36/   89]
per-ex loss: 0.404181  [   38/   89]
per-ex loss: 0.476945  [   40/   89]
per-ex loss: 0.508431  [   42/   89]
per-ex loss: 0.445589  [   44/   89]
per-ex loss: 0.495229  [   46/   89]
per-ex loss: 0.442317  [   48/   89]
per-ex loss: 0.431330  [   50/   89]
per-ex loss: 0.397713  [   52/   89]
per-ex loss: 0.392084  [   54/   89]
per-ex loss: 0.417695  [   56/   89]
per-ex loss: 0.416223  [   58/   89]
per-ex loss: 0.476200  [   60/   89]
per-ex loss: 0.556632  [   62/   89]
per-ex loss: 0.385962  [   64/   89]
per-ex loss: 0.461810  [   66/   89]
per-ex loss: 0.370524  [   68/   89]
per-ex loss: 0.348929  [   70/   89]
per-ex loss: 0.356478  [   72/   89]
per-ex loss: 0.457554  [   74/   89]
per-ex loss: 0.365435  [   76/   89]
per-ex loss: 0.422032  [   78/   89]
per-ex loss: 0.498150  [   80/   89]
per-ex loss: 0.438073  [   82/   89]
per-ex loss: 0.387358  [   84/   89]
per-ex loss: 0.544132  [   86/   89]
per-ex loss: 0.696163  [   88/   89]
per-ex loss: 0.411834  [   89/   89]
Train Error: Avg loss: 0.46278117
validation Error: 
 Avg loss: 0.56447185 
 F1: 0.456117 
 Precision: 0.703441 
 Recall: 0.337467
 IoU: 0.295435

test Error: 
 Avg loss: 0.54775947 
 F1: 0.485041 
 Precision: 0.716937 
 Recall: 0.366496
 IoU: 0.320168

We have finished training iteration 426
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_424_.pth
per-ex loss: 0.521996  [    2/   89]
per-ex loss: 0.363131  [    4/   89]
per-ex loss: 0.529544  [    6/   89]
per-ex loss: 0.354295  [    8/   89]
per-ex loss: 0.351626  [   10/   89]
per-ex loss: 0.445145  [   12/   89]
per-ex loss: 0.405008  [   14/   89]
per-ex loss: 0.476231  [   16/   89]
per-ex loss: 0.445007  [   18/   89]
per-ex loss: 0.631323  [   20/   89]
per-ex loss: 0.360949  [   22/   89]
per-ex loss: 0.401646  [   24/   89]
per-ex loss: 0.408653  [   26/   89]
per-ex loss: 0.537897  [   28/   89]
per-ex loss: 0.354510  [   30/   89]
per-ex loss: 0.540545  [   32/   89]
per-ex loss: 0.500045  [   34/   89]
per-ex loss: 0.402599  [   36/   89]
per-ex loss: 0.397607  [   38/   89]
per-ex loss: 0.520014  [   40/   89]
per-ex loss: 0.665627  [   42/   89]
per-ex loss: 0.474561  [   44/   89]
per-ex loss: 0.562568  [   46/   89]
per-ex loss: 0.470611  [   48/   89]
per-ex loss: 0.438654  [   50/   89]
per-ex loss: 0.459722  [   52/   89]
per-ex loss: 0.430708  [   54/   89]
per-ex loss: 0.393721  [   56/   89]
per-ex loss: 0.471520  [   58/   89]
per-ex loss: 0.481585  [   60/   89]
per-ex loss: 0.517188  [   62/   89]
per-ex loss: 0.435430  [   64/   89]
per-ex loss: 0.484826  [   66/   89]
per-ex loss: 0.444574  [   68/   89]
per-ex loss: 0.434328  [   70/   89]
per-ex loss: 0.406825  [   72/   89]
per-ex loss: 0.440575  [   74/   89]
per-ex loss: 0.372070  [   76/   89]
per-ex loss: 0.655666  [   78/   89]
per-ex loss: 0.387010  [   80/   89]
per-ex loss: 0.430023  [   82/   89]
per-ex loss: 0.540514  [   84/   89]
per-ex loss: 0.466940  [   86/   89]
per-ex loss: 0.437335  [   88/   89]
per-ex loss: 0.590781  [   89/   89]
Train Error: Avg loss: 0.46313636
validation Error: 
 Avg loss: 0.53137735 
 F1: 0.507766 
 Precision: 0.630475 
 Recall: 0.425040
 IoU: 0.340272

test Error: 
 Avg loss: 0.48845838 
 F1: 0.547015 
 Precision: 0.682900 
 Recall: 0.456233
 IoU: 0.376477

We have finished training iteration 427
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_425_.pth
per-ex loss: 0.443697  [    2/   89]
per-ex loss: 0.414474  [    4/   89]
per-ex loss: 0.640133  [    6/   89]
per-ex loss: 0.704089  [    8/   89]
per-ex loss: 0.452911  [   10/   89]
per-ex loss: 0.590009  [   12/   89]
per-ex loss: 0.569518  [   14/   89]
per-ex loss: 0.336846  [   16/   89]
per-ex loss: 0.519141  [   18/   89]
per-ex loss: 0.398765  [   20/   89]
per-ex loss: 0.404203  [   22/   89]
per-ex loss: 0.379624  [   24/   89]
per-ex loss: 0.447896  [   26/   89]
per-ex loss: 0.368034  [   28/   89]
per-ex loss: 0.606582  [   30/   89]
per-ex loss: 0.473786  [   32/   89]
per-ex loss: 0.376880  [   34/   89]
per-ex loss: 0.527955  [   36/   89]
per-ex loss: 0.568481  [   38/   89]
per-ex loss: 0.403375  [   40/   89]
per-ex loss: 0.431540  [   42/   89]
per-ex loss: 0.499877  [   44/   89]
per-ex loss: 0.609594  [   46/   89]
per-ex loss: 0.582353  [   48/   89]
per-ex loss: 0.583455  [   50/   89]
per-ex loss: 0.359340  [   52/   89]
per-ex loss: 0.515254  [   54/   89]
per-ex loss: 0.413804  [   56/   89]
per-ex loss: 0.555554  [   58/   89]
per-ex loss: 0.672392  [   60/   89]
per-ex loss: 0.345021  [   62/   89]
per-ex loss: 0.448067  [   64/   89]
per-ex loss: 0.383751  [   66/   89]
per-ex loss: 0.562337  [   68/   89]
per-ex loss: 0.518043  [   70/   89]
per-ex loss: 0.468074  [   72/   89]
per-ex loss: 0.432490  [   74/   89]
per-ex loss: 0.412544  [   76/   89]
per-ex loss: 0.447649  [   78/   89]
per-ex loss: 0.472505  [   80/   89]
per-ex loss: 0.412033  [   82/   89]
per-ex loss: 0.480617  [   84/   89]
per-ex loss: 0.376788  [   86/   89]
per-ex loss: 0.584442  [   88/   89]
per-ex loss: 0.382807  [   89/   89]
Train Error: Avg loss: 0.47948286
validation Error: 
 Avg loss: 0.53447168 
 F1: 0.491852 
 Precision: 0.652412 
 Recall: 0.394712
 IoU: 0.326130

test Error: 
 Avg loss: 0.50942115 
 F1: 0.525663 
 Precision: 0.679477 
 Recall: 0.428633
 IoU: 0.356542

We have finished training iteration 428
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_426_.pth
Error in cropping the image to the non-zero values in the fourth channel. Returned the original image.
per-ex loss: 0.566321  [    2/   89]
per-ex loss: 0.412858  [    4/   89]
per-ex loss: 0.435789  [    6/   89]
per-ex loss: 0.501922  [    8/   89]
per-ex loss: 0.662100  [   10/   89]
per-ex loss: 0.388625  [   12/   89]
per-ex loss: 0.450682  [   14/   89]
per-ex loss: 0.402345  [   16/   89]
per-ex loss: 0.518980  [   18/   89]
per-ex loss: 0.550050  [   20/   89]
per-ex loss: 0.574883  [   22/   89]
per-ex loss: 0.555625  [   24/   89]
per-ex loss: 0.520483  [   26/   89]
per-ex loss: 0.533627  [   28/   89]
per-ex loss: 0.401868  [   30/   89]
per-ex loss: 0.473269  [   32/   89]
per-ex loss: 0.498979  [   34/   89]
per-ex loss: 0.600781  [   36/   89]
per-ex loss: 0.415933  [   38/   89]
per-ex loss: 0.460355  [   40/   89]
per-ex loss: 0.407101  [   42/   89]
per-ex loss: 0.432257  [   44/   89]
per-ex loss: 0.601860  [   46/   89]
per-ex loss: 0.490716  [   48/   89]
per-ex loss: 0.431317  [   50/   89]
per-ex loss: 0.461905  [   52/   89]
per-ex loss: 0.495575  [   54/   89]
per-ex loss: 0.390961  [   56/   89]
per-ex loss: 0.514418  [   58/   89]
per-ex loss: 0.342650  [   60/   89]
per-ex loss: 0.459334  [   62/   89]
per-ex loss: 0.405896  [   64/   89]
per-ex loss: 0.357199  [   66/   89]
per-ex loss: 0.492059  [   68/   89]
per-ex loss: 0.428406  [   70/   89]
per-ex loss: 0.569226  [   72/   89]
per-ex loss: 0.467862  [   74/   89]
per-ex loss: 0.487882  [   76/   89]
per-ex loss: 0.402988  [   78/   89]
per-ex loss: 0.375870  [   80/   89]
per-ex loss: 0.575975  [   82/   89]
per-ex loss: 0.430790  [   84/   89]
per-ex loss: 0.487696  [   86/   89]
per-ex loss: 0.377701  [   88/   89]
per-ex loss: 0.535497  [   89/   89]
Train Error: Avg loss: 0.47441373
validation Error: 
 Avg loss: 0.51076579 
 F1: 0.513127 
 Precision: 0.602992 
 Recall: 0.446573
 IoU: 0.345104

test Error: 
 Avg loss: 0.47725262 
 F1: 0.558413 
 Precision: 0.664389 
 Recall: 0.481595
 IoU: 0.387360

We have finished training iteration 429
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_427_.pth
per-ex loss: 0.375041  [    2/   89]
per-ex loss: 0.371813  [    4/   89]
per-ex loss: 0.401520  [    6/   89]
per-ex loss: 0.447382  [    8/   89]
per-ex loss: 0.449769  [   10/   89]
per-ex loss: 0.439898  [   12/   89]
per-ex loss: 0.478553  [   14/   89]
per-ex loss: 0.450374  [   16/   89]
per-ex loss: 0.425750  [   18/   89]
per-ex loss: 0.667260  [   20/   89]
per-ex loss: 0.608236  [   22/   89]
per-ex loss: 0.424892  [   24/   89]
per-ex loss: 0.388280  [   26/   89]
per-ex loss: 0.546300  [   28/   89]
per-ex loss: 0.491154  [   30/   89]
per-ex loss: 0.375675  [   32/   89]
per-ex loss: 0.573286  [   34/   89]
per-ex loss: 0.486375  [   36/   89]
per-ex loss: 0.666634  [   38/   89]
per-ex loss: 0.379962  [   40/   89]
per-ex loss: 0.379655  [   42/   89]
per-ex loss: 0.529953  [   44/   89]
per-ex loss: 0.422776  [   46/   89]
per-ex loss: 0.438498  [   48/   89]
per-ex loss: 0.430786  [   50/   89]
per-ex loss: 0.363448  [   52/   89]
per-ex loss: 0.384999  [   54/   89]
per-ex loss: 0.456160  [   56/   89]
per-ex loss: 0.531955  [   58/   89]
per-ex loss: 0.561445  [   60/   89]
per-ex loss: 0.544335  [   62/   89]
per-ex loss: 0.468679  [   64/   89]
per-ex loss: 0.398451  [   66/   89]
per-ex loss: 0.448960  [   68/   89]
per-ex loss: 0.404596  [   70/   89]
per-ex loss: 0.379831  [   72/   89]
per-ex loss: 0.400402  [   74/   89]
per-ex loss: 0.401617  [   76/   89]
per-ex loss: 0.384575  [   78/   89]
per-ex loss: 0.550957  [   80/   89]
per-ex loss: 0.511970  [   82/   89]
per-ex loss: 0.371325  [   84/   89]
per-ex loss: 0.552806  [   86/   89]
per-ex loss: 0.371199  [   88/   89]
per-ex loss: 0.394875  [   89/   89]
Train Error: Avg loss: 0.45627572
validation Error: 
 Avg loss: 0.50946477 
 F1: 0.509618 
 Precision: 0.615832 
 Recall: 0.434652
 IoU: 0.341937

test Error: 
 Avg loss: 0.48438539 
 F1: 0.551866 
 Precision: 0.668459 
 Recall: 0.469905
 IoU: 0.381088

We have finished training iteration 430
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_428_.pth
per-ex loss: 0.372719  [    2/   89]
per-ex loss: 0.491758  [    4/   89]
per-ex loss: 0.435847  [    6/   89]
per-ex loss: 0.597782  [    8/   89]
per-ex loss: 0.367823  [   10/   89]
per-ex loss: 0.541141  [   12/   89]
per-ex loss: 0.433798  [   14/   89]
per-ex loss: 0.367915  [   16/   89]
per-ex loss: 0.377547  [   18/   89]
per-ex loss: 0.497437  [   20/   89]
per-ex loss: 0.528843  [   22/   89]
per-ex loss: 0.375595  [   24/   89]
per-ex loss: 0.380716  [   26/   89]
per-ex loss: 0.458173  [   28/   89]
per-ex loss: 0.429022  [   30/   89]
per-ex loss: 0.475271  [   32/   89]
per-ex loss: 0.366159  [   34/   89]
per-ex loss: 0.552239  [   36/   89]
per-ex loss: 0.668644  [   38/   89]
per-ex loss: 0.368179  [   40/   89]
per-ex loss: 0.582118  [   42/   89]
per-ex loss: 0.398446  [   44/   89]
per-ex loss: 0.562788  [   46/   89]
per-ex loss: 0.523538  [   48/   89]
per-ex loss: 0.379509  [   50/   89]
per-ex loss: 0.374416  [   52/   89]
per-ex loss: 0.478195  [   54/   89]
per-ex loss: 0.401150  [   56/   89]
per-ex loss: 0.359608  [   58/   89]
per-ex loss: 0.441339  [   60/   89]
per-ex loss: 0.514592  [   62/   89]
per-ex loss: 0.471270  [   64/   89]
per-ex loss: 0.449194  [   66/   89]
per-ex loss: 0.419776  [   68/   89]
per-ex loss: 0.545578  [   70/   89]
per-ex loss: 0.396652  [   72/   89]
per-ex loss: 0.633560  [   74/   89]
per-ex loss: 0.570822  [   76/   89]
per-ex loss: 0.382199  [   78/   89]
per-ex loss: 0.415531  [   80/   89]
per-ex loss: 0.607447  [   82/   89]
per-ex loss: 0.461392  [   84/   89]
per-ex loss: 0.399722  [   86/   89]
per-ex loss: 0.355265  [   88/   89]
per-ex loss: 0.583049  [   89/   89]
Train Error: Avg loss: 0.46208370
validation Error: 
 Avg loss: 0.53533195 
 F1: 0.489398 
 Precision: 0.655495 
 Recall: 0.390459
 IoU: 0.323975

test Error: 
 Avg loss: 0.51268633 
 F1: 0.522650 
 Precision: 0.679206 
 Recall: 0.424746
 IoU: 0.353775

We have finished training iteration 431
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_429_.pth
Error in cropping the image to the non-zero values in the fourth channel. Returned the original image.
per-ex loss: 0.494728  [    2/   89]
per-ex loss: 0.430298  [    4/   89]
per-ex loss: 0.585360  [    6/   89]
per-ex loss: 0.457415  [    8/   89]
per-ex loss: 0.458409  [   10/   89]
per-ex loss: 0.383367  [   12/   89]
per-ex loss: 0.582313  [   14/   89]
per-ex loss: 0.389279  [   16/   89]
per-ex loss: 0.431227  [   18/   89]
per-ex loss: 0.558780  [   20/   89]
per-ex loss: 0.486938  [   22/   89]
per-ex loss: 0.456911  [   24/   89]
per-ex loss: 0.411087  [   26/   89]
per-ex loss: 0.440243  [   28/   89]
per-ex loss: 0.362956  [   30/   89]
per-ex loss: 0.389046  [   32/   89]
per-ex loss: 0.479581  [   34/   89]
per-ex loss: 0.662147  [   36/   89]
per-ex loss: 0.469537  [   38/   89]
per-ex loss: 0.365312  [   40/   89]
per-ex loss: 0.609415  [   42/   89]
per-ex loss: 0.522334  [   44/   89]
per-ex loss: 0.482840  [   46/   89]
per-ex loss: 0.433484  [   48/   89]
per-ex loss: 0.430073  [   50/   89]
per-ex loss: 0.398402  [   52/   89]
per-ex loss: 0.650671  [   54/   89]
per-ex loss: 0.397354  [   56/   89]
per-ex loss: 0.353554  [   58/   89]
per-ex loss: 0.483724  [   60/   89]
per-ex loss: 0.440428  [   62/   89]
per-ex loss: 0.625389  [   64/   89]
per-ex loss: 0.627082  [   66/   89]
per-ex loss: 0.441671  [   68/   89]
per-ex loss: 0.483355  [   70/   89]
per-ex loss: 0.424335  [   72/   89]
per-ex loss: 0.376747  [   74/   89]
per-ex loss: 0.398324  [   76/   89]
per-ex loss: 0.543241  [   78/   89]
per-ex loss: 0.402840  [   80/   89]
per-ex loss: 0.462401  [   82/   89]
per-ex loss: 0.353886  [   84/   89]
per-ex loss: 0.402037  [   86/   89]
per-ex loss: 0.406461  [   88/   89]
per-ex loss: 0.327199  [   89/   89]
Train Error: Avg loss: 0.46160407
validation Error: 
 Avg loss: 0.50398483 
 F1: 0.514216 
 Precision: 0.593377 
 Recall: 0.453690
 IoU: 0.346091

test Error: 
 Avg loss: 0.47560959 
 F1: 0.560735 
 Precision: 0.660944 
 Recall: 0.486912
 IoU: 0.389598

We have finished training iteration 432
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_430_.pth
per-ex loss: 0.560778  [    2/   89]
per-ex loss: 0.463625  [    4/   89]
per-ex loss: 0.391692  [    6/   89]
per-ex loss: 0.435569  [    8/   89]
per-ex loss: 0.441990  [   10/   89]
per-ex loss: 0.402047  [   12/   89]
per-ex loss: 0.600876  [   14/   89]
per-ex loss: 0.406341  [   16/   89]
per-ex loss: 0.429918  [   18/   89]
per-ex loss: 0.440617  [   20/   89]
per-ex loss: 0.595000  [   22/   89]
per-ex loss: 0.421095  [   24/   89]
per-ex loss: 0.443575  [   26/   89]
per-ex loss: 0.413226  [   28/   89]
per-ex loss: 0.479609  [   30/   89]
per-ex loss: 0.544063  [   32/   89]
per-ex loss: 0.382858  [   34/   89]
per-ex loss: 0.518814  [   36/   89]
per-ex loss: 0.534632  [   38/   89]
per-ex loss: 0.458350  [   40/   89]
per-ex loss: 0.383120  [   42/   89]
per-ex loss: 0.451431  [   44/   89]
per-ex loss: 0.502679  [   46/   89]
per-ex loss: 0.559936  [   48/   89]
per-ex loss: 0.385351  [   50/   89]
per-ex loss: 0.368894  [   52/   89]
per-ex loss: 0.392881  [   54/   89]
per-ex loss: 0.462357  [   56/   89]
per-ex loss: 0.412980  [   58/   89]
per-ex loss: 0.341423  [   60/   89]
per-ex loss: 0.628990  [   62/   89]
per-ex loss: 0.464108  [   64/   89]
per-ex loss: 0.487902  [   66/   89]
per-ex loss: 0.369362  [   68/   89]
per-ex loss: 0.462609  [   70/   89]
per-ex loss: 0.358623  [   72/   89]
per-ex loss: 0.557844  [   74/   89]
per-ex loss: 0.553381  [   76/   89]
per-ex loss: 0.461496  [   78/   89]
per-ex loss: 0.545531  [   80/   89]
per-ex loss: 0.569846  [   82/   89]
per-ex loss: 0.418951  [   84/   89]
per-ex loss: 0.526899  [   86/   89]
per-ex loss: 0.523961  [   88/   89]
per-ex loss: 0.356636  [   89/   89]
Train Error: Avg loss: 0.46470813
validation Error: 
 Avg loss: 0.50165786 
 F1: 0.515246 
 Precision: 0.620640 
 Recall: 0.440451
 IoU: 0.347024

test Error: 
 Avg loss: 0.47694878 
 F1: 0.559265 
 Precision: 0.690289 
 Recall: 0.470046
 IoU: 0.388180

We have finished training iteration 433
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_431_.pth
per-ex loss: 0.473321  [    2/   89]
per-ex loss: 0.362929  [    4/   89]
per-ex loss: 0.371157  [    6/   89]
per-ex loss: 0.354928  [    8/   89]
per-ex loss: 0.442372  [   10/   89]
per-ex loss: 0.440146  [   12/   89]
per-ex loss: 0.620248  [   14/   89]
per-ex loss: 0.545713  [   16/   89]
per-ex loss: 0.425294  [   18/   89]
per-ex loss: 0.579954  [   20/   89]
per-ex loss: 0.509886  [   22/   89]
per-ex loss: 0.414204  [   24/   89]
per-ex loss: 0.398505  [   26/   89]
per-ex loss: 0.495478  [   28/   89]
per-ex loss: 0.654681  [   30/   89]
per-ex loss: 0.599837  [   32/   89]
per-ex loss: 0.461788  [   34/   89]
per-ex loss: 0.461610  [   36/   89]
per-ex loss: 0.417371  [   38/   89]
per-ex loss: 0.587287  [   40/   89]
per-ex loss: 0.362727  [   42/   89]
per-ex loss: 0.436908  [   44/   89]
per-ex loss: 0.565988  [   46/   89]
per-ex loss: 0.464666  [   48/   89]
per-ex loss: 0.440911  [   50/   89]
per-ex loss: 0.518263  [   52/   89]
per-ex loss: 0.419973  [   54/   89]
per-ex loss: 0.564874  [   56/   89]
per-ex loss: 0.486194  [   58/   89]
per-ex loss: 0.415878  [   60/   89]
per-ex loss: 0.345201  [   62/   89]
per-ex loss: 0.507578  [   64/   89]
per-ex loss: 0.457726  [   66/   89]
per-ex loss: 0.460048  [   68/   89]
per-ex loss: 0.560355  [   70/   89]
per-ex loss: 0.544183  [   72/   89]
per-ex loss: 0.630174  [   74/   89]
per-ex loss: 0.584971  [   76/   89]
per-ex loss: 0.461640  [   78/   89]
per-ex loss: 0.358205  [   80/   89]
per-ex loss: 0.363089  [   82/   89]
per-ex loss: 0.468248  [   84/   89]
per-ex loss: 0.345719  [   86/   89]
per-ex loss: 0.520739  [   88/   89]
per-ex loss: 0.394093  [   89/   89]
Train Error: Avg loss: 0.47322361
validation Error: 
 Avg loss: 0.51528202 
 F1: 0.514311 
 Precision: 0.597205 
 Recall: 0.451625
 IoU: 0.346177

test Error: 
 Avg loss: 0.47347112 
 F1: 0.563419 
 Precision: 0.666780 
 Recall: 0.487802
 IoU: 0.392195

We have finished training iteration 434
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_432_.pth
per-ex loss: 0.358974  [    2/   89]
per-ex loss: 0.483341  [    4/   89]
per-ex loss: 0.399983  [    6/   89]
per-ex loss: 0.401219  [    8/   89]
per-ex loss: 0.609907  [   10/   89]
per-ex loss: 0.489413  [   12/   89]
per-ex loss: 0.385902  [   14/   89]
per-ex loss: 0.376307  [   16/   89]
per-ex loss: 0.505955  [   18/   89]
per-ex loss: 0.471184  [   20/   89]
per-ex loss: 0.599377  [   22/   89]
per-ex loss: 0.485664  [   24/   89]
per-ex loss: 0.554669  [   26/   89]
per-ex loss: 0.607521  [   28/   89]
per-ex loss: 0.480046  [   30/   89]
per-ex loss: 0.426692  [   32/   89]
per-ex loss: 0.381431  [   34/   89]
per-ex loss: 0.492552  [   36/   89]
per-ex loss: 0.575084  [   38/   89]
per-ex loss: 0.457538  [   40/   89]
per-ex loss: 0.433936  [   42/   89]
per-ex loss: 0.390832  [   44/   89]
per-ex loss: 0.419624  [   46/   89]
per-ex loss: 0.439709  [   48/   89]
per-ex loss: 0.464790  [   50/   89]
per-ex loss: 0.407118  [   52/   89]
per-ex loss: 0.491452  [   54/   89]
per-ex loss: 0.419368  [   56/   89]
per-ex loss: 0.409943  [   58/   89]
per-ex loss: 0.387702  [   60/   89]
per-ex loss: 0.353495  [   62/   89]
per-ex loss: 0.457934  [   64/   89]
per-ex loss: 0.435305  [   66/   89]
per-ex loss: 0.498084  [   68/   89]
per-ex loss: 0.375550  [   70/   89]
per-ex loss: 0.484551  [   72/   89]
per-ex loss: 0.464187  [   74/   89]
per-ex loss: 0.510372  [   76/   89]
per-ex loss: 0.491983  [   78/   89]
per-ex loss: 0.361694  [   80/   89]
per-ex loss: 0.525709  [   82/   89]
per-ex loss: 0.371749  [   84/   89]
per-ex loss: 0.593671  [   86/   89]
per-ex loss: 0.404998  [   88/   89]
per-ex loss: 0.449495  [   89/   89]
Train Error: Avg loss: 0.45746691
validation Error: 
 Avg loss: 0.49814076 
 F1: 0.515878 
 Precision: 0.601205 
 Recall: 0.451761
 IoU: 0.347598

test Error: 
 Avg loss: 0.47693228 
 F1: 0.558664 
 Precision: 0.652029 
 Recall: 0.488688
 IoU: 0.387602

We have finished training iteration 435
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_433_.pth
per-ex loss: 0.470144  [    2/   89]
per-ex loss: 0.348946  [    4/   89]
per-ex loss: 0.357137  [    6/   89]
per-ex loss: 0.399925  [    8/   89]
per-ex loss: 0.489382  [   10/   89]
per-ex loss: 0.378364  [   12/   89]
per-ex loss: 0.452320  [   14/   89]
per-ex loss: 0.403865  [   16/   89]
per-ex loss: 0.502674  [   18/   89]
per-ex loss: 0.340040  [   20/   89]
per-ex loss: 0.648068  [   22/   89]
per-ex loss: 0.579620  [   24/   89]
per-ex loss: 0.601879  [   26/   89]
per-ex loss: 0.481316  [   28/   89]
per-ex loss: 0.546017  [   30/   89]
per-ex loss: 0.476115  [   32/   89]
per-ex loss: 0.449165  [   34/   89]
per-ex loss: 0.446211  [   36/   89]
per-ex loss: 0.476429  [   38/   89]
per-ex loss: 0.585477  [   40/   89]
per-ex loss: 0.555623  [   42/   89]
per-ex loss: 0.391315  [   44/   89]
per-ex loss: 0.362127  [   46/   89]
per-ex loss: 0.418141  [   48/   89]
per-ex loss: 0.522073  [   50/   89]
per-ex loss: 0.444417  [   52/   89]
per-ex loss: 0.410261  [   54/   89]
per-ex loss: 0.379876  [   56/   89]
per-ex loss: 0.369405  [   58/   89]
per-ex loss: 0.355072  [   60/   89]
per-ex loss: 0.432714  [   62/   89]
per-ex loss: 0.487037  [   64/   89]
per-ex loss: 0.528305  [   66/   89]
per-ex loss: 0.583843  [   68/   89]
per-ex loss: 0.527305  [   70/   89]
per-ex loss: 0.530809  [   72/   89]
per-ex loss: 0.360830  [   74/   89]
per-ex loss: 0.488005  [   76/   89]
per-ex loss: 0.540621  [   78/   89]
per-ex loss: 0.410156  [   80/   89]
per-ex loss: 0.537356  [   82/   89]
per-ex loss: 0.529455  [   84/   89]
per-ex loss: 0.434100  [   86/   89]
per-ex loss: 0.440049  [   88/   89]
per-ex loss: 0.688971  [   89/   89]
Train Error: Avg loss: 0.47024356
validation Error: 
 Avg loss: 0.51368411 
 F1: 0.513544 
 Precision: 0.627475 
 Recall: 0.434628
 IoU: 0.345482

test Error: 
 Avg loss: 0.47936731 
 F1: 0.556393 
 Precision: 0.687067 
 Recall: 0.467483
 IoU: 0.385419

We have finished training iteration 436
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_434_.pth
per-ex loss: 0.497874  [    2/   89]
per-ex loss: 0.414535  [    4/   89]
per-ex loss: 0.456335  [    6/   89]
per-ex loss: 0.437647  [    8/   89]
per-ex loss: 0.455476  [   10/   89]
per-ex loss: 0.408292  [   12/   89]
per-ex loss: 0.592685  [   14/   89]
per-ex loss: 0.458518  [   16/   89]
per-ex loss: 0.444759  [   18/   89]
per-ex loss: 0.396845  [   20/   89]
per-ex loss: 0.425256  [   22/   89]
per-ex loss: 0.424334  [   24/   89]
per-ex loss: 0.518126  [   26/   89]
per-ex loss: 0.557004  [   28/   89]
per-ex loss: 0.591233  [   30/   89]
per-ex loss: 0.543014  [   32/   89]
per-ex loss: 0.469536  [   34/   89]
per-ex loss: 0.472882  [   36/   89]
per-ex loss: 0.371873  [   38/   89]
per-ex loss: 0.455634  [   40/   89]
per-ex loss: 0.439197  [   42/   89]
per-ex loss: 0.375329  [   44/   89]
per-ex loss: 0.476802  [   46/   89]
per-ex loss: 0.470957  [   48/   89]
per-ex loss: 0.604271  [   50/   89]
per-ex loss: 0.513924  [   52/   89]
per-ex loss: 0.434390  [   54/   89]
per-ex loss: 0.415649  [   56/   89]
per-ex loss: 0.446908  [   58/   89]
per-ex loss: 0.477324  [   60/   89]
per-ex loss: 0.494152  [   62/   89]
per-ex loss: 0.380072  [   64/   89]
per-ex loss: 0.581474  [   66/   89]
per-ex loss: 0.413207  [   68/   89]
per-ex loss: 0.406056  [   70/   89]
per-ex loss: 0.393031  [   72/   89]
per-ex loss: 0.382804  [   74/   89]
per-ex loss: 0.411363  [   76/   89]
per-ex loss: 0.402298  [   78/   89]
per-ex loss: 0.361007  [   80/   89]
per-ex loss: 0.516352  [   82/   89]
per-ex loss: 0.391529  [   84/   89]
per-ex loss: 0.415830  [   86/   89]
per-ex loss: 0.439510  [   88/   89]
per-ex loss: 0.664862  [   89/   89]
Train Error: Avg loss: 0.46000346
validation Error: 
 Avg loss: 0.50769831 
 F1: 0.516235 
 Precision: 0.606568 
 Recall: 0.449320
 IoU: 0.347922

test Error: 
 Avg loss: 0.47471509 
 F1: 0.561545 
 Precision: 0.675236 
 Recall: 0.480622
 IoU: 0.390381

We have finished training iteration 437
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_340_.pth
per-ex loss: 0.676924  [    2/   89]
per-ex loss: 0.598745  [    4/   89]
per-ex loss: 0.354825  [    6/   89]
per-ex loss: 0.419114  [    8/   89]
per-ex loss: 0.529393  [   10/   89]
per-ex loss: 0.668233  [   12/   89]
per-ex loss: 0.442030  [   14/   89]
per-ex loss: 0.557737  [   16/   89]
per-ex loss: 0.495917  [   18/   89]
per-ex loss: 0.380248  [   20/   89]
per-ex loss: 0.406453  [   22/   89]
per-ex loss: 0.489379  [   24/   89]
per-ex loss: 0.470604  [   26/   89]
per-ex loss: 0.411481  [   28/   89]
per-ex loss: 0.388586  [   30/   89]
per-ex loss: 0.603594  [   32/   89]
per-ex loss: 0.599396  [   34/   89]
per-ex loss: 0.491936  [   36/   89]
per-ex loss: 0.417416  [   38/   89]
per-ex loss: 0.459131  [   40/   89]
per-ex loss: 0.431704  [   42/   89]
per-ex loss: 0.596230  [   44/   89]
per-ex loss: 0.404745  [   46/   89]
per-ex loss: 0.428075  [   48/   89]
per-ex loss: 0.448938  [   50/   89]
per-ex loss: 0.460810  [   52/   89]
per-ex loss: 0.463220  [   54/   89]
per-ex loss: 0.381652  [   56/   89]
per-ex loss: 0.417133  [   58/   89]
per-ex loss: 0.394432  [   60/   89]
per-ex loss: 0.336861  [   62/   89]
per-ex loss: 0.488191  [   64/   89]
per-ex loss: 0.519220  [   66/   89]
per-ex loss: 0.416083  [   68/   89]
per-ex loss: 0.411289  [   70/   89]
per-ex loss: 0.483205  [   72/   89]
per-ex loss: 0.432356  [   74/   89]
per-ex loss: 0.408539  [   76/   89]
per-ex loss: 0.526016  [   78/   89]
per-ex loss: 0.436707  [   80/   89]
per-ex loss: 0.400662  [   82/   89]
per-ex loss: 0.687693  [   84/   89]
per-ex loss: 0.367546  [   86/   89]
per-ex loss: 0.574599  [   88/   89]
per-ex loss: 0.607730  [   89/   89]
Train Error: Avg loss: 0.47521720
validation Error: 
 Avg loss: 0.54817041 
 F1: 0.477977 
 Precision: 0.650033 
 Recall: 0.377940
 IoU: 0.314040

test Error: 
 Avg loss: 0.52625452 
 F1: 0.509434 
 Precision: 0.660642 
 Recall: 0.414551
 IoU: 0.341772

We have finished training iteration 438
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_436_.pth
per-ex loss: 0.570461  [    2/   89]
per-ex loss: 0.541198  [    4/   89]
per-ex loss: 0.483686  [    6/   89]
per-ex loss: 0.483922  [    8/   89]
per-ex loss: 0.410653  [   10/   89]
per-ex loss: 0.612846  [   12/   89]
per-ex loss: 0.415531  [   14/   89]
per-ex loss: 0.350992  [   16/   89]
per-ex loss: 0.492037  [   18/   89]
per-ex loss: 0.582682  [   20/   89]
per-ex loss: 0.465517  [   22/   89]
per-ex loss: 0.373494  [   24/   89]
per-ex loss: 0.465499  [   26/   89]
per-ex loss: 0.396102  [   28/   89]
per-ex loss: 0.540099  [   30/   89]
per-ex loss: 0.377873  [   32/   89]
per-ex loss: 0.378783  [   34/   89]
per-ex loss: 0.410624  [   36/   89]
per-ex loss: 0.495538  [   38/   89]
per-ex loss: 0.409864  [   40/   89]
per-ex loss: 0.494116  [   42/   89]
per-ex loss: 0.607604  [   44/   89]
per-ex loss: 0.523965  [   46/   89]
per-ex loss: 0.402565  [   48/   89]
per-ex loss: 0.402450  [   50/   89]
per-ex loss: 0.407731  [   52/   89]
per-ex loss: 0.460232  [   54/   89]
per-ex loss: 0.610602  [   56/   89]
per-ex loss: 0.374000  [   58/   89]
per-ex loss: 0.379989  [   60/   89]
per-ex loss: 0.413122  [   62/   89]
per-ex loss: 0.565739  [   64/   89]
per-ex loss: 0.566881  [   66/   89]
per-ex loss: 0.371790  [   68/   89]
per-ex loss: 0.482245  [   70/   89]
per-ex loss: 0.562947  [   72/   89]
per-ex loss: 0.474255  [   74/   89]
per-ex loss: 0.451266  [   76/   89]
per-ex loss: 0.502112  [   78/   89]
per-ex loss: 0.434896  [   80/   89]
per-ex loss: 0.388339  [   82/   89]
per-ex loss: 0.620691  [   84/   89]
per-ex loss: 0.440767  [   86/   89]
per-ex loss: 0.394860  [   88/   89]
per-ex loss: 0.367343  [   89/   89]
Train Error: Avg loss: 0.46573134
validation Error: 
 Avg loss: 0.54516002 
 F1: 0.477440 
 Precision: 0.622211 
 Recall: 0.387321
 IoU: 0.313577

test Error: 
 Avg loss: 0.52906492 
 F1: 0.506986 
 Precision: 0.634064 
 Recall: 0.422342
 IoU: 0.339573

We have finished training iteration 439
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_437_.pth
per-ex loss: 0.409472  [    2/   89]
per-ex loss: 0.481568  [    4/   89]
per-ex loss: 0.564837  [    6/   89]
per-ex loss: 0.444520  [    8/   89]
per-ex loss: 0.447667  [   10/   89]
per-ex loss: 0.387376  [   12/   89]
per-ex loss: 0.361602  [   14/   89]
per-ex loss: 0.404271  [   16/   89]
per-ex loss: 0.654937  [   18/   89]
per-ex loss: 0.422503  [   20/   89]
per-ex loss: 0.566644  [   22/   89]
per-ex loss: 0.492790  [   24/   89]
per-ex loss: 0.356826  [   26/   89]
per-ex loss: 0.506533  [   28/   89]
per-ex loss: 0.730447  [   30/   89]
per-ex loss: 0.418137  [   32/   89]
per-ex loss: 0.534174  [   34/   89]
per-ex loss: 0.405728  [   36/   89]
per-ex loss: 0.498741  [   38/   89]
per-ex loss: 0.419236  [   40/   89]
per-ex loss: 0.379911  [   42/   89]
per-ex loss: 0.372349  [   44/   89]
per-ex loss: 0.391934  [   46/   89]
per-ex loss: 0.578350  [   48/   89]
per-ex loss: 0.354070  [   50/   89]
per-ex loss: 0.502550  [   52/   89]
per-ex loss: 0.612756  [   54/   89]
per-ex loss: 0.421376  [   56/   89]
per-ex loss: 0.582374  [   58/   89]
per-ex loss: 0.452027  [   60/   89]
per-ex loss: 0.503646  [   62/   89]
per-ex loss: 0.456416  [   64/   89]
per-ex loss: 0.453146  [   66/   89]
per-ex loss: 0.546469  [   68/   89]
per-ex loss: 0.360303  [   70/   89]
per-ex loss: 0.494105  [   72/   89]
per-ex loss: 0.450701  [   74/   89]
per-ex loss: 0.372479  [   76/   89]
per-ex loss: 0.509377  [   78/   89]
per-ex loss: 0.432545  [   80/   89]
per-ex loss: 0.413499  [   82/   89]
per-ex loss: 0.397136  [   84/   89]
per-ex loss: 0.396246  [   86/   89]
per-ex loss: 0.483392  [   88/   89]
per-ex loss: 0.406581  [   89/   89]
Train Error: Avg loss: 0.46292772
validation Error: 
 Avg loss: 0.50530568 
 F1: 0.512929 
 Precision: 0.626125 
 Recall: 0.434396
 IoU: 0.344926

test Error: 
 Avg loss: 0.48006738 
 F1: 0.556214 
 Precision: 0.678821 
 Recall: 0.471120
 IoU: 0.385246

We have finished training iteration 440
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_438_.pth
per-ex loss: 0.435498  [    2/   89]
per-ex loss: 0.527435  [    4/   89]
per-ex loss: 0.370077  [    6/   89]
per-ex loss: 0.499173  [    8/   89]
per-ex loss: 0.621677  [   10/   89]
per-ex loss: 0.476208  [   12/   89]
per-ex loss: 0.384298  [   14/   89]
per-ex loss: 0.469344  [   16/   89]
per-ex loss: 0.434007  [   18/   89]
per-ex loss: 0.563354  [   20/   89]
per-ex loss: 0.478329  [   22/   89]
per-ex loss: 0.427924  [   24/   89]
per-ex loss: 0.417208  [   26/   89]
per-ex loss: 0.539432  [   28/   89]
per-ex loss: 0.390010  [   30/   89]
per-ex loss: 0.456399  [   32/   89]
per-ex loss: 0.490161  [   34/   89]
per-ex loss: 0.437688  [   36/   89]
per-ex loss: 0.536309  [   38/   89]
per-ex loss: 0.548169  [   40/   89]
per-ex loss: 0.436387  [   42/   89]
per-ex loss: 0.558747  [   44/   89]
per-ex loss: 0.516286  [   46/   89]
per-ex loss: 0.417902  [   48/   89]
per-ex loss: 0.582554  [   50/   89]
per-ex loss: 0.659081  [   52/   89]
per-ex loss: 0.342079  [   54/   89]
per-ex loss: 0.405587  [   56/   89]
per-ex loss: 0.475633  [   58/   89]
per-ex loss: 0.396299  [   60/   89]
per-ex loss: 0.393412  [   62/   89]
per-ex loss: 0.352048  [   64/   89]
per-ex loss: 0.478065  [   66/   89]
per-ex loss: 0.554439  [   68/   89]
per-ex loss: 0.528287  [   70/   89]
per-ex loss: 0.378167  [   72/   89]
per-ex loss: 0.382404  [   74/   89]
per-ex loss: 0.445597  [   76/   89]
per-ex loss: 0.600840  [   78/   89]
per-ex loss: 0.379603  [   80/   89]
per-ex loss: 0.450155  [   82/   89]
per-ex loss: 0.439132  [   84/   89]
per-ex loss: 0.368105  [   86/   89]
per-ex loss: 0.645755  [   88/   89]
per-ex loss: 0.369231  [   89/   89]
Train Error: Avg loss: 0.46796655
validation Error: 
 Avg loss: 0.50914626 
 F1: 0.506759 
 Precision: 0.642189 
 Recall: 0.418502
 IoU: 0.339368

test Error: 
 Avg loss: 0.49216352 
 F1: 0.544075 
 Precision: 0.679333 
 Recall: 0.453734
 IoU: 0.373697

We have finished training iteration 441
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_439_.pth
per-ex loss: 0.437090  [    2/   89]
per-ex loss: 0.442535  [    4/   89]
per-ex loss: 0.565614  [    6/   89]
per-ex loss: 0.496541  [    8/   89]
per-ex loss: 0.410151  [   10/   89]
per-ex loss: 0.429138  [   12/   89]
per-ex loss: 0.458871  [   14/   89]
per-ex loss: 0.454871  [   16/   89]
per-ex loss: 0.392807  [   18/   89]
per-ex loss: 0.551891  [   20/   89]
per-ex loss: 0.438459  [   22/   89]
per-ex loss: 0.490309  [   24/   89]
per-ex loss: 0.353487  [   26/   89]
per-ex loss: 0.477817  [   28/   89]
per-ex loss: 0.465115  [   30/   89]
per-ex loss: 0.647344  [   32/   89]
per-ex loss: 0.442601  [   34/   89]
per-ex loss: 0.460695  [   36/   89]
per-ex loss: 0.621243  [   38/   89]
per-ex loss: 0.426778  [   40/   89]
per-ex loss: 0.444309  [   42/   89]
per-ex loss: 0.403439  [   44/   89]
per-ex loss: 0.346024  [   46/   89]
per-ex loss: 0.480460  [   48/   89]
per-ex loss: 0.385164  [   50/   89]
per-ex loss: 0.383920  [   52/   89]
per-ex loss: 0.396993  [   54/   89]
per-ex loss: 0.545624  [   56/   89]
per-ex loss: 0.434023  [   58/   89]
per-ex loss: 0.643673  [   60/   89]
per-ex loss: 0.381949  [   62/   89]
per-ex loss: 0.407819  [   64/   89]
per-ex loss: 0.472145  [   66/   89]
per-ex loss: 0.490057  [   68/   89]
per-ex loss: 0.492892  [   70/   89]
per-ex loss: 0.646626  [   72/   89]
per-ex loss: 0.560274  [   74/   89]
per-ex loss: 0.482089  [   76/   89]
per-ex loss: 0.388146  [   78/   89]
per-ex loss: 0.385483  [   80/   89]
per-ex loss: 0.478289  [   82/   89]
per-ex loss: 0.527550  [   84/   89]
per-ex loss: 0.413902  [   86/   89]
per-ex loss: 0.419910  [   88/   89]
per-ex loss: 0.511139  [   89/   89]
Train Error: Avg loss: 0.46633894
validation Error: 
 Avg loss: 0.50839369 
 F1: 0.513181 
 Precision: 0.625266 
 Recall: 0.435173
 IoU: 0.345154

test Error: 
 Avg loss: 0.48115705 
 F1: 0.554550 
 Precision: 0.678878 
 Recall: 0.468711
 IoU: 0.383652

We have finished training iteration 442
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_440_.pth
per-ex loss: 0.392988  [    2/   89]
per-ex loss: 0.464911  [    4/   89]
per-ex loss: 0.491442  [    6/   89]
per-ex loss: 0.383138  [    8/   89]
per-ex loss: 0.396483  [   10/   89]
per-ex loss: 0.402487  [   12/   89]
per-ex loss: 0.589248  [   14/   89]
per-ex loss: 0.475521  [   16/   89]
per-ex loss: 0.409471  [   18/   89]
per-ex loss: 0.385789  [   20/   89]
per-ex loss: 0.429393  [   22/   89]
per-ex loss: 0.548484  [   24/   89]
per-ex loss: 0.437953  [   26/   89]
per-ex loss: 0.516097  [   28/   89]
per-ex loss: 0.511838  [   30/   89]
per-ex loss: 0.565271  [   32/   89]
per-ex loss: 0.330787  [   34/   89]
per-ex loss: 0.612267  [   36/   89]
per-ex loss: 0.360717  [   38/   89]
per-ex loss: 0.423040  [   40/   89]
per-ex loss: 0.362177  [   42/   89]
per-ex loss: 0.558816  [   44/   89]
per-ex loss: 0.464716  [   46/   89]
per-ex loss: 0.404953  [   48/   89]
per-ex loss: 0.458698  [   50/   89]
per-ex loss: 0.409179  [   52/   89]
per-ex loss: 0.497296  [   54/   89]
per-ex loss: 0.579600  [   56/   89]
per-ex loss: 0.483520  [   58/   89]
per-ex loss: 0.384641  [   60/   89]
per-ex loss: 0.383363  [   62/   89]
per-ex loss: 0.548376  [   64/   89]
per-ex loss: 0.352623  [   66/   89]
per-ex loss: 0.391223  [   68/   89]
per-ex loss: 0.515626  [   70/   89]
per-ex loss: 0.435393  [   72/   89]
per-ex loss: 0.644937  [   74/   89]
per-ex loss: 0.413270  [   76/   89]
per-ex loss: 0.477182  [   78/   89]
per-ex loss: 0.597558  [   80/   89]
per-ex loss: 0.389675  [   82/   89]
per-ex loss: 0.376292  [   84/   89]
per-ex loss: 0.622818  [   86/   89]
per-ex loss: 0.575200  [   88/   89]
per-ex loss: 0.679196  [   89/   89]
Train Error: Avg loss: 0.46963675
validation Error: 
 Avg loss: 0.50630604 
 F1: 0.517296 
 Precision: 0.613445 
 Recall: 0.447202
 IoU: 0.348887

test Error: 
 Avg loss: 0.47403058 
 F1: 0.562673 
 Precision: 0.673771 
 Recall: 0.483026
 IoU: 0.391471

We have finished training iteration 443
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_441_.pth
per-ex loss: 0.417801  [    2/   89]
per-ex loss: 0.356644  [    4/   89]
per-ex loss: 0.432641  [    6/   89]
per-ex loss: 0.563088  [    8/   89]
per-ex loss: 0.381389  [   10/   89]
per-ex loss: 0.404503  [   12/   89]
per-ex loss: 0.470003  [   14/   89]
per-ex loss: 0.543631  [   16/   89]
per-ex loss: 0.562467  [   18/   89]
per-ex loss: 0.390990  [   20/   89]
per-ex loss: 0.570986  [   22/   89]
per-ex loss: 0.374807  [   24/   89]
per-ex loss: 0.484124  [   26/   89]
per-ex loss: 0.552210  [   28/   89]
per-ex loss: 0.547969  [   30/   89]
per-ex loss: 0.398079  [   32/   89]
per-ex loss: 0.403870  [   34/   89]
per-ex loss: 0.365065  [   36/   89]
per-ex loss: 0.569816  [   38/   89]
per-ex loss: 0.529193  [   40/   89]
per-ex loss: 0.562889  [   42/   89]
per-ex loss: 0.398780  [   44/   89]
per-ex loss: 0.396626  [   46/   89]
per-ex loss: 0.649280  [   48/   89]
per-ex loss: 0.392540  [   50/   89]
per-ex loss: 0.421206  [   52/   89]
per-ex loss: 0.332603  [   54/   89]
per-ex loss: 0.432465  [   56/   89]
per-ex loss: 0.447676  [   58/   89]
per-ex loss: 0.679715  [   60/   89]
per-ex loss: 0.559583  [   62/   89]
per-ex loss: 0.573785  [   64/   89]
per-ex loss: 0.441869  [   66/   89]
per-ex loss: 0.464965  [   68/   89]
per-ex loss: 0.547718  [   70/   89]
per-ex loss: 0.414981  [   72/   89]
per-ex loss: 0.401154  [   74/   89]
per-ex loss: 0.527569  [   76/   89]
per-ex loss: 0.366353  [   78/   89]
per-ex loss: 0.532538  [   80/   89]
per-ex loss: 0.420673  [   82/   89]
per-ex loss: 0.479662  [   84/   89]
per-ex loss: 0.578368  [   86/   89]
per-ex loss: 0.349347  [   88/   89]
per-ex loss: 0.377828  [   89/   89]
Train Error: Avg loss: 0.46820996
validation Error: 
 Avg loss: 0.50276428 
 F1: 0.511269 
 Precision: 0.602817 
 Recall: 0.443862
 IoU: 0.343426

test Error: 
 Avg loss: 0.48453650 
 F1: 0.551184 
 Precision: 0.656567 
 Recall: 0.474951
 IoU: 0.380438

We have finished training iteration 444
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_442_.pth
per-ex loss: 0.519068  [    2/   89]
per-ex loss: 0.435699  [    4/   89]
per-ex loss: 0.403214  [    6/   89]
per-ex loss: 0.503540  [    8/   89]
per-ex loss: 0.430916  [   10/   89]
per-ex loss: 0.442544  [   12/   89]
per-ex loss: 0.513411  [   14/   89]
per-ex loss: 0.538750  [   16/   89]
per-ex loss: 0.518554  [   18/   89]
per-ex loss: 0.594363  [   20/   89]
per-ex loss: 0.556074  [   22/   89]
per-ex loss: 0.343106  [   24/   89]
per-ex loss: 0.398816  [   26/   89]
per-ex loss: 0.459912  [   28/   89]
per-ex loss: 0.439645  [   30/   89]
per-ex loss: 0.434843  [   32/   89]
per-ex loss: 0.352970  [   34/   89]
per-ex loss: 0.596786  [   36/   89]
per-ex loss: 0.395806  [   38/   89]
per-ex loss: 0.427814  [   40/   89]
per-ex loss: 0.487569  [   42/   89]
per-ex loss: 0.463050  [   44/   89]
per-ex loss: 0.519330  [   46/   89]
per-ex loss: 0.686337  [   48/   89]
per-ex loss: 0.629297  [   50/   89]
per-ex loss: 0.484501  [   52/   89]
per-ex loss: 0.384942  [   54/   89]
per-ex loss: 0.653620  [   56/   89]
per-ex loss: 0.445088  [   58/   89]
per-ex loss: 0.355885  [   60/   89]
per-ex loss: 0.509481  [   62/   89]
per-ex loss: 0.402310  [   64/   89]
per-ex loss: 0.507276  [   66/   89]
per-ex loss: 0.374170  [   68/   89]
per-ex loss: 0.446241  [   70/   89]
per-ex loss: 0.430803  [   72/   89]
per-ex loss: 0.587453  [   74/   89]
per-ex loss: 0.369039  [   76/   89]
per-ex loss: 0.350061  [   78/   89]
per-ex loss: 0.385870  [   80/   89]
per-ex loss: 0.545930  [   82/   89]
per-ex loss: 0.477635  [   84/   89]
per-ex loss: 0.458646  [   86/   89]
per-ex loss: 0.457872  [   88/   89]
per-ex loss: 0.534426  [   89/   89]
Train Error: Avg loss: 0.47228138
validation Error: 
 Avg loss: 0.54151633 
 F1: 0.479876 
 Precision: 0.671561 
 Recall: 0.373319
 IoU: 0.315682

test Error: 
 Avg loss: 0.52142070 
 F1: 0.511816 
 Precision: 0.693533 
 Recall: 0.405554
 IoU: 0.343919

We have finished training iteration 445
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_443_.pth
Error in cropping the image to the non-zero values in the fourth channel. Returned the original image.
per-ex loss: 0.495881  [    2/   89]
per-ex loss: 0.483233  [    4/   89]
per-ex loss: 0.518000  [    6/   89]
per-ex loss: 0.454547  [    8/   89]
per-ex loss: 0.366873  [   10/   89]
per-ex loss: 0.484214  [   12/   89]
per-ex loss: 0.438502  [   14/   89]
per-ex loss: 0.400827  [   16/   89]
per-ex loss: 0.455909  [   18/   89]
per-ex loss: 0.401696  [   20/   89]
per-ex loss: 0.462770  [   22/   89]
per-ex loss: 0.373452  [   24/   89]
per-ex loss: 0.446247  [   26/   89]
per-ex loss: 0.387456  [   28/   89]
per-ex loss: 0.496195  [   30/   89]
per-ex loss: 0.352286  [   32/   89]
per-ex loss: 0.360656  [   34/   89]
per-ex loss: 0.361147  [   36/   89]
per-ex loss: 0.546900  [   38/   89]
per-ex loss: 0.539909  [   40/   89]
per-ex loss: 0.410843  [   42/   89]
per-ex loss: 0.431504  [   44/   89]
per-ex loss: 0.433133  [   46/   89]
per-ex loss: 0.500652  [   48/   89]
per-ex loss: 0.618821  [   50/   89]
per-ex loss: 0.493828  [   52/   89]
per-ex loss: 0.569057  [   54/   89]
per-ex loss: 0.550170  [   56/   89]
per-ex loss: 0.451993  [   58/   89]
per-ex loss: 0.379218  [   60/   89]
per-ex loss: 0.365138  [   62/   89]
per-ex loss: 0.520168  [   64/   89]
per-ex loss: 0.438697  [   66/   89]
per-ex loss: 0.471437  [   68/   89]
per-ex loss: 0.557683  [   70/   89]
per-ex loss: 0.570380  [   72/   89]
per-ex loss: 0.411224  [   74/   89]
per-ex loss: 0.642915  [   76/   89]
per-ex loss: 0.381897  [   78/   89]
per-ex loss: 0.524956  [   80/   89]
per-ex loss: 0.533675  [   82/   89]
per-ex loss: 0.397391  [   84/   89]
per-ex loss: 0.529259  [   86/   89]
per-ex loss: 0.557523  [   88/   89]
per-ex loss: 0.356130  [   89/   89]
Train Error: Avg loss: 0.46498644
validation Error: 
 Avg loss: 0.53754920 
 F1: 0.488122 
 Precision: 0.640938 
 Recall: 0.394148
 IoU: 0.322858

test Error: 
 Avg loss: 0.51700941 
 F1: 0.517856 
 Precision: 0.659217 
 Recall: 0.426417
 IoU: 0.349397

We have finished training iteration 446
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_444_.pth
per-ex loss: 0.517200  [    2/   89]
per-ex loss: 0.460015  [    4/   89]
per-ex loss: 0.457065  [    6/   89]
per-ex loss: 0.436295  [    8/   89]
per-ex loss: 0.453519  [   10/   89]
per-ex loss: 0.457904  [   12/   89]
per-ex loss: 0.382436  [   14/   89]
per-ex loss: 0.573705  [   16/   89]
per-ex loss: 0.583760  [   18/   89]
per-ex loss: 0.389972  [   20/   89]
per-ex loss: 0.437688  [   22/   89]
per-ex loss: 0.402444  [   24/   89]
per-ex loss: 0.469463  [   26/   89]
per-ex loss: 0.433335  [   28/   89]
per-ex loss: 0.401243  [   30/   89]
per-ex loss: 0.395194  [   32/   89]
per-ex loss: 0.408067  [   34/   89]
per-ex loss: 0.424277  [   36/   89]
per-ex loss: 0.499336  [   38/   89]
per-ex loss: 0.631131  [   40/   89]
per-ex loss: 0.357101  [   42/   89]
per-ex loss: 0.535241  [   44/   89]
per-ex loss: 0.463708  [   46/   89]
per-ex loss: 0.509417  [   48/   89]
per-ex loss: 0.420669  [   50/   89]
per-ex loss: 0.481578  [   52/   89]
per-ex loss: 0.535302  [   54/   89]
per-ex loss: 0.601129  [   56/   89]
per-ex loss: 0.401236  [   58/   89]
per-ex loss: 0.561621  [   60/   89]
per-ex loss: 0.555496  [   62/   89]
per-ex loss: 0.382792  [   64/   89]
per-ex loss: 0.390969  [   66/   89]
per-ex loss: 0.418269  [   68/   89]
per-ex loss: 0.378210  [   70/   89]
per-ex loss: 0.365071  [   72/   89]
per-ex loss: 0.426405  [   74/   89]
per-ex loss: 0.396955  [   76/   89]
per-ex loss: 0.397373  [   78/   89]
per-ex loss: 0.572314  [   80/   89]
per-ex loss: 0.536319  [   82/   89]
per-ex loss: 0.427591  [   84/   89]
per-ex loss: 0.611249  [   86/   89]
per-ex loss: 0.375189  [   88/   89]
per-ex loss: 0.400866  [   89/   89]
Train Error: Avg loss: 0.46035822
validation Error: 
 Avg loss: 0.51646284 
 F1: 0.505167 
 Precision: 0.623990 
 Recall: 0.424358
 IoU: 0.337942

test Error: 
 Avg loss: 0.49522265 
 F1: 0.540406 
 Precision: 0.666710 
 Recall: 0.454335
 IoU: 0.370244

We have finished training iteration 447
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_445_.pth
per-ex loss: 0.377645  [    2/   89]
per-ex loss: 0.447383  [    4/   89]
per-ex loss: 0.484987  [    6/   89]
per-ex loss: 0.388804  [    8/   89]
per-ex loss: 0.538005  [   10/   89]
per-ex loss: 0.563568  [   12/   89]
per-ex loss: 0.410522  [   14/   89]
per-ex loss: 0.489215  [   16/   89]
per-ex loss: 0.463581  [   18/   89]
per-ex loss: 0.424198  [   20/   89]
per-ex loss: 0.465522  [   22/   89]
per-ex loss: 0.430573  [   24/   89]
per-ex loss: 0.426489  [   26/   89]
per-ex loss: 0.409168  [   28/   89]
per-ex loss: 0.532403  [   30/   89]
per-ex loss: 0.384044  [   32/   89]
per-ex loss: 0.484880  [   34/   89]
per-ex loss: 0.590377  [   36/   89]
per-ex loss: 0.490634  [   38/   89]
per-ex loss: 0.475794  [   40/   89]
per-ex loss: 0.572872  [   42/   89]
per-ex loss: 0.469985  [   44/   89]
per-ex loss: 0.426823  [   46/   89]
per-ex loss: 0.419164  [   48/   89]
per-ex loss: 0.410790  [   50/   89]
per-ex loss: 0.399430  [   52/   89]
per-ex loss: 0.544371  [   54/   89]
per-ex loss: 0.488739  [   56/   89]
per-ex loss: 0.554180  [   58/   89]
per-ex loss: 0.632898  [   60/   89]
per-ex loss: 0.487199  [   62/   89]
per-ex loss: 0.552400  [   64/   89]
per-ex loss: 0.361231  [   66/   89]
per-ex loss: 0.410236  [   68/   89]
per-ex loss: 0.504544  [   70/   89]
per-ex loss: 0.365777  [   72/   89]
per-ex loss: 0.356050  [   74/   89]
per-ex loss: 0.552821  [   76/   89]
per-ex loss: 0.383490  [   78/   89]
per-ex loss: 0.364818  [   80/   89]
per-ex loss: 0.470377  [   82/   89]
per-ex loss: 0.449389  [   84/   89]
per-ex loss: 0.554825  [   86/   89]
per-ex loss: 0.756198  [   88/   89]
per-ex loss: 0.607848  [   89/   89]
Train Error: Avg loss: 0.47498328
validation Error: 
 Avg loss: 0.57366642 
 F1: 0.449708 
 Precision: 0.702964 
 Recall: 0.330602
 IoU: 0.290080

test Error: 
 Avg loss: 0.55402918 
 F1: 0.477780 
 Precision: 0.721073 
 Recall: 0.357245
 IoU: 0.313871

We have finished training iteration 448
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_446_.pth
Error in cropping the image to the non-zero values in the fourth channel. Returned the original image.
per-ex loss: 0.381707  [    2/   89]
per-ex loss: 0.454902  [    4/   89]
per-ex loss: 0.579835  [    6/   89]
per-ex loss: 0.576907  [    8/   89]
per-ex loss: 0.415055  [   10/   89]
per-ex loss: 0.464791  [   12/   89]
per-ex loss: 0.372423  [   14/   89]
per-ex loss: 0.492906  [   16/   89]
per-ex loss: 0.464722  [   18/   89]
per-ex loss: 0.561554  [   20/   89]
per-ex loss: 0.416741  [   22/   89]
per-ex loss: 0.487485  [   24/   89]
per-ex loss: 0.408651  [   26/   89]
per-ex loss: 0.358484  [   28/   89]
per-ex loss: 0.665207  [   30/   89]
per-ex loss: 0.509198  [   32/   89]
per-ex loss: 0.392502  [   34/   89]
per-ex loss: 0.566947  [   36/   89]
per-ex loss: 0.480542  [   38/   89]
per-ex loss: 0.399933  [   40/   89]
per-ex loss: 0.488160  [   42/   89]
per-ex loss: 0.482751  [   44/   89]
per-ex loss: 0.424319  [   46/   89]
per-ex loss: 0.393203  [   48/   89]
per-ex loss: 0.447056  [   50/   89]
per-ex loss: 0.376932  [   52/   89]
per-ex loss: 0.477591  [   54/   89]
per-ex loss: 0.344115  [   56/   89]
per-ex loss: 0.381010  [   58/   89]
per-ex loss: 0.467000  [   60/   89]
per-ex loss: 0.448781  [   62/   89]
per-ex loss: 0.667608  [   64/   89]
per-ex loss: 0.376722  [   66/   89]
per-ex loss: 0.395326  [   68/   89]
per-ex loss: 0.643472  [   70/   89]
per-ex loss: 0.555196  [   72/   89]
per-ex loss: 0.518792  [   74/   89]
per-ex loss: 0.454902  [   76/   89]
per-ex loss: 0.555495  [   78/   89]
per-ex loss: 0.342625  [   80/   89]
per-ex loss: 0.382635  [   82/   89]
per-ex loss: 0.612835  [   84/   89]
per-ex loss: 0.398972  [   86/   89]
per-ex loss: 0.480090  [   88/   89]
per-ex loss: 0.591194  [   89/   89]
Train Error: Avg loss: 0.47016168
validation Error: 
 Avg loss: 0.51569334 
 F1: 0.499787 
 Precision: 0.628477 
 Recall: 0.414842
 IoU: 0.333144

test Error: 
 Avg loss: 0.50429813 
 F1: 0.530762 
 Precision: 0.660550 
 Recall: 0.443601
 IoU: 0.361250

We have finished training iteration 449
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_447_.pth
per-ex loss: 0.627185  [    2/   89]
per-ex loss: 0.355014  [    4/   89]
per-ex loss: 0.343420  [    6/   89]
per-ex loss: 0.552702  [    8/   89]
per-ex loss: 0.412069  [   10/   89]
per-ex loss: 0.443728  [   12/   89]
per-ex loss: 0.434361  [   14/   89]
per-ex loss: 0.443671  [   16/   89]
per-ex loss: 0.379656  [   18/   89]
per-ex loss: 0.514569  [   20/   89]
per-ex loss: 0.451729  [   22/   89]
per-ex loss: 0.350464  [   24/   89]
per-ex loss: 0.389731  [   26/   89]
per-ex loss: 0.359238  [   28/   89]
per-ex loss: 0.553438  [   30/   89]
per-ex loss: 0.454071  [   32/   89]
per-ex loss: 0.638610  [   34/   89]
per-ex loss: 0.427002  [   36/   89]
per-ex loss: 0.425388  [   38/   89]
per-ex loss: 0.575968  [   40/   89]
per-ex loss: 0.521714  [   42/   89]
per-ex loss: 0.409280  [   44/   89]
per-ex loss: 0.347266  [   46/   89]
per-ex loss: 0.465339  [   48/   89]
per-ex loss: 0.496544  [   50/   89]
per-ex loss: 0.573835  [   52/   89]
per-ex loss: 0.388870  [   54/   89]
per-ex loss: 0.584845  [   56/   89]
per-ex loss: 0.583148  [   58/   89]
per-ex loss: 0.533350  [   60/   89]
per-ex loss: 0.480548  [   62/   89]
per-ex loss: 0.387737  [   64/   89]
per-ex loss: 0.552445  [   66/   89]
per-ex loss: 0.434569  [   68/   89]
per-ex loss: 0.590118  [   70/   89]
per-ex loss: 0.392256  [   72/   89]
per-ex loss: 0.387185  [   74/   89]
per-ex loss: 0.421001  [   76/   89]
per-ex loss: 0.519006  [   78/   89]
per-ex loss: 0.509314  [   80/   89]
per-ex loss: 0.374597  [   82/   89]
per-ex loss: 0.390683  [   84/   89]
per-ex loss: 0.377586  [   86/   89]
per-ex loss: 0.411049  [   88/   89]
per-ex loss: 0.568212  [   89/   89]
Train Error: Avg loss: 0.46294468
validation Error: 
 Avg loss: 0.51076471 
 F1: 0.511678 
 Precision: 0.609471 
 Recall: 0.440929
 IoU: 0.343795

test Error: 
 Avg loss: 0.47939698 
 F1: 0.557012 
 Precision: 0.680863 
 Recall: 0.471283
 IoU: 0.386012

We have finished training iteration 450
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_448_.pth
per-ex loss: 0.424585  [    2/   89]
per-ex loss: 0.501266  [    4/   89]
per-ex loss: 0.364707  [    6/   89]
per-ex loss: 0.532718  [    8/   89]
per-ex loss: 0.365675  [   10/   89]
per-ex loss: 0.469982  [   12/   89]
per-ex loss: 0.366040  [   14/   89]
per-ex loss: 0.512036  [   16/   89]
per-ex loss: 0.430157  [   18/   89]
per-ex loss: 0.392155  [   20/   89]
per-ex loss: 0.406935  [   22/   89]
per-ex loss: 0.558575  [   24/   89]
per-ex loss: 0.556843  [   26/   89]
per-ex loss: 0.511566  [   28/   89]
per-ex loss: 0.506876  [   30/   89]
per-ex loss: 0.479854  [   32/   89]
per-ex loss: 0.684043  [   34/   89]
per-ex loss: 0.579398  [   36/   89]
per-ex loss: 0.575457  [   38/   89]
per-ex loss: 0.349108  [   40/   89]
per-ex loss: 0.388254  [   42/   89]
per-ex loss: 0.445971  [   44/   89]
per-ex loss: 0.402213  [   46/   89]
per-ex loss: 0.556727  [   48/   89]
per-ex loss: 0.395106  [   50/   89]
per-ex loss: 0.525254  [   52/   89]
per-ex loss: 0.459959  [   54/   89]
per-ex loss: 0.422748  [   56/   89]
per-ex loss: 0.357155  [   58/   89]
per-ex loss: 0.580384  [   60/   89]
per-ex loss: 0.574842  [   62/   89]
per-ex loss: 0.377182  [   64/   89]
per-ex loss: 0.455619  [   66/   89]
per-ex loss: 0.383431  [   68/   89]
per-ex loss: 0.373935  [   70/   89]
per-ex loss: 0.426008  [   72/   89]
per-ex loss: 0.435077  [   74/   89]
per-ex loss: 0.562746  [   76/   89]
per-ex loss: 0.405405  [   78/   89]
per-ex loss: 0.739952  [   80/   89]
per-ex loss: 0.451255  [   82/   89]
per-ex loss: 0.527696  [   84/   89]
per-ex loss: 0.408854  [   86/   89]
per-ex loss: 0.482028  [   88/   89]
per-ex loss: 0.648573  [   89/   89]
Train Error: Avg loss: 0.47454111
validation Error: 
 Avg loss: 0.54672130 
 F1: 0.471903 
 Precision: 0.689738 
 Recall: 0.358638
 IoU: 0.308818

test Error: 
 Avg loss: 0.52794525 
 F1: 0.505338 
 Precision: 0.701206 
 Recall: 0.395002
 IoU: 0.338095

We have finished training iteration 451
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_449_.pth
per-ex loss: 0.394921  [    2/   89]
per-ex loss: 0.563899  [    4/   89]
per-ex loss: 0.457565  [    6/   89]
per-ex loss: 0.374687  [    8/   89]
per-ex loss: 0.578838  [   10/   89]
per-ex loss: 0.528760  [   12/   89]
per-ex loss: 0.643208  [   14/   89]
per-ex loss: 0.427398  [   16/   89]
per-ex loss: 0.399715  [   18/   89]
per-ex loss: 0.616924  [   20/   89]
per-ex loss: 0.419765  [   22/   89]
per-ex loss: 0.371221  [   24/   89]
per-ex loss: 0.646988  [   26/   89]
per-ex loss: 0.419334  [   28/   89]
per-ex loss: 0.516709  [   30/   89]
per-ex loss: 0.364744  [   32/   89]
per-ex loss: 0.386508  [   34/   89]
per-ex loss: 0.402821  [   36/   89]
per-ex loss: 0.561933  [   38/   89]
per-ex loss: 0.392979  [   40/   89]
per-ex loss: 0.408628  [   42/   89]
per-ex loss: 0.406819  [   44/   89]
per-ex loss: 0.416412  [   46/   89]
per-ex loss: 0.416700  [   48/   89]
per-ex loss: 0.445728  [   50/   89]
per-ex loss: 0.450599  [   52/   89]
per-ex loss: 0.362576  [   54/   89]
per-ex loss: 0.473253  [   56/   89]
per-ex loss: 0.497507  [   58/   89]
per-ex loss: 0.415607  [   60/   89]
per-ex loss: 0.399304  [   62/   89]
per-ex loss: 0.490141  [   64/   89]
per-ex loss: 0.562529  [   66/   89]
per-ex loss: 0.391705  [   68/   89]
per-ex loss: 0.492252  [   70/   89]
per-ex loss: 0.421577  [   72/   89]
per-ex loss: 0.472190  [   74/   89]
per-ex loss: 0.410409  [   76/   89]
per-ex loss: 0.437941  [   78/   89]
per-ex loss: 0.418840  [   80/   89]
per-ex loss: 0.558636  [   82/   89]
per-ex loss: 0.337398  [   84/   89]
per-ex loss: 0.494373  [   86/   89]
per-ex loss: 0.412587  [   88/   89]
per-ex loss: 0.543998  [   89/   89]
Train Error: Avg loss: 0.45792502
validation Error: 
 Avg loss: 0.50451244 
 F1: 0.516230 
 Precision: 0.596964 
 Recall: 0.454731
 IoU: 0.347917

test Error: 
 Avg loss: 0.47397563 
 F1: 0.562467 
 Precision: 0.660572 
 Recall: 0.489735
 IoU: 0.391273

We have finished training iteration 452
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_450_.pth
per-ex loss: 0.620443  [    2/   89]
per-ex loss: 0.478100  [    4/   89]
per-ex loss: 0.373455  [    6/   89]
per-ex loss: 0.468162  [    8/   89]
per-ex loss: 0.524884  [   10/   89]
per-ex loss: 0.609549  [   12/   89]
per-ex loss: 0.384156  [   14/   89]
per-ex loss: 0.403406  [   16/   89]
per-ex loss: 0.366228  [   18/   89]
per-ex loss: 0.404034  [   20/   89]
per-ex loss: 0.489454  [   22/   89]
per-ex loss: 0.421528  [   24/   89]
per-ex loss: 0.579628  [   26/   89]
per-ex loss: 0.395652  [   28/   89]
per-ex loss: 0.457462  [   30/   89]
per-ex loss: 0.556823  [   32/   89]
per-ex loss: 0.466008  [   34/   89]
per-ex loss: 0.502096  [   36/   89]
per-ex loss: 0.399198  [   38/   89]
per-ex loss: 0.364092  [   40/   89]
per-ex loss: 0.380206  [   42/   89]
per-ex loss: 0.433774  [   44/   89]
per-ex loss: 0.420980  [   46/   89]
per-ex loss: 0.493121  [   48/   89]
per-ex loss: 0.417556  [   50/   89]
per-ex loss: 0.482574  [   52/   89]
per-ex loss: 0.498164  [   54/   89]
per-ex loss: 0.421592  [   56/   89]
per-ex loss: 0.437445  [   58/   89]
per-ex loss: 0.529215  [   60/   89]
per-ex loss: 0.371551  [   62/   89]
per-ex loss: 0.441650  [   64/   89]
per-ex loss: 0.376582  [   66/   89]
per-ex loss: 0.390491  [   68/   89]
per-ex loss: 0.391601  [   70/   89]
per-ex loss: 0.554985  [   72/   89]
per-ex loss: 0.586028  [   74/   89]
per-ex loss: 0.455761  [   76/   89]
per-ex loss: 0.460002  [   78/   89]
per-ex loss: 0.453302  [   80/   89]
per-ex loss: 0.376471  [   82/   89]
per-ex loss: 0.512488  [   84/   89]
per-ex loss: 0.705466  [   86/   89]
per-ex loss: 0.378341  [   88/   89]
per-ex loss: 0.531689  [   89/   89]
Train Error: Avg loss: 0.46145318
validation Error: 
 Avg loss: 0.54544394 
 F1: 0.479313 
 Precision: 0.648210 
 Recall: 0.380238
 IoU: 0.315195

test Error: 
 Avg loss: 0.52512496 
 F1: 0.509932 
 Precision: 0.654840 
 Recall: 0.417536
 IoU: 0.342221

We have finished training iteration 453
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_451_.pth
per-ex loss: 0.380626  [    2/   89]
per-ex loss: 0.390689  [    4/   89]
per-ex loss: 0.376094  [    6/   89]
per-ex loss: 0.521669  [    8/   89]
per-ex loss: 0.469590  [   10/   89]
per-ex loss: 0.378669  [   12/   89]
per-ex loss: 0.512971  [   14/   89]
per-ex loss: 0.421626  [   16/   89]
per-ex loss: 0.496069  [   18/   89]
per-ex loss: 0.389932  [   20/   89]
per-ex loss: 0.365289  [   22/   89]
per-ex loss: 0.480978  [   24/   89]
per-ex loss: 0.497607  [   26/   89]
per-ex loss: 0.514816  [   28/   89]
per-ex loss: 0.388185  [   30/   89]
per-ex loss: 0.609541  [   32/   89]
per-ex loss: 0.561336  [   34/   89]
per-ex loss: 0.553853  [   36/   89]
per-ex loss: 0.379460  [   38/   89]
per-ex loss: 0.511944  [   40/   89]
per-ex loss: 0.390829  [   42/   89]
per-ex loss: 0.499684  [   44/   89]
per-ex loss: 0.636233  [   46/   89]
per-ex loss: 0.496116  [   48/   89]
per-ex loss: 0.512562  [   50/   89]
per-ex loss: 0.523102  [   52/   89]
per-ex loss: 0.362361  [   54/   89]
per-ex loss: 0.381212  [   56/   89]
per-ex loss: 0.632976  [   58/   89]
per-ex loss: 0.590638  [   60/   89]
per-ex loss: 0.499349  [   62/   89]
per-ex loss: 0.569026  [   64/   89]
per-ex loss: 0.499102  [   66/   89]
per-ex loss: 0.456035  [   68/   89]
per-ex loss: 0.376970  [   70/   89]
per-ex loss: 0.396117  [   72/   89]
per-ex loss: 0.406797  [   74/   89]
per-ex loss: 0.565634  [   76/   89]
per-ex loss: 0.376020  [   78/   89]
per-ex loss: 0.417401  [   80/   89]
per-ex loss: 0.635378  [   82/   89]
per-ex loss: 0.351031  [   84/   89]
per-ex loss: 0.613592  [   86/   89]
per-ex loss: 0.438455  [   88/   89]
per-ex loss: 0.360247  [   89/   89]
Train Error: Avg loss: 0.47084031
validation Error: 
 Avg loss: 0.50976052 
 F1: 0.514985 
 Precision: 0.602378 
 Recall: 0.449738
 IoU: 0.346788

test Error: 
 Avg loss: 0.47643350 
 F1: 0.559076 
 Precision: 0.663226 
 Recall: 0.483197
 IoU: 0.387999

We have finished training iteration 454
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_452_.pth
per-ex loss: 0.428423  [    2/   89]
per-ex loss: 0.420734  [    4/   89]
per-ex loss: 0.423298  [    6/   89]
per-ex loss: 0.614447  [    8/   89]
per-ex loss: 0.419666  [   10/   89]
per-ex loss: 0.621554  [   12/   89]
per-ex loss: 0.470073  [   14/   89]
per-ex loss: 0.411782  [   16/   89]
per-ex loss: 0.590620  [   18/   89]
per-ex loss: 0.474695  [   20/   89]
per-ex loss: 0.488534  [   22/   89]
per-ex loss: 0.432821  [   24/   89]
per-ex loss: 0.523499  [   26/   89]
per-ex loss: 0.499119  [   28/   89]
per-ex loss: 0.405488  [   30/   89]
per-ex loss: 0.420848  [   32/   89]
per-ex loss: 0.409874  [   34/   89]
per-ex loss: 0.459596  [   36/   89]
per-ex loss: 0.447194  [   38/   89]
per-ex loss: 0.588804  [   40/   89]
per-ex loss: 0.377681  [   42/   89]
per-ex loss: 0.465104  [   44/   89]
per-ex loss: 0.354195  [   46/   89]
per-ex loss: 0.576410  [   48/   89]
per-ex loss: 0.365317  [   50/   89]
per-ex loss: 0.346085  [   52/   89]
per-ex loss: 0.348422  [   54/   89]
per-ex loss: 0.448415  [   56/   89]
per-ex loss: 0.420468  [   58/   89]
per-ex loss: 0.555783  [   60/   89]
per-ex loss: 0.409322  [   62/   89]
per-ex loss: 0.534053  [   64/   89]
per-ex loss: 0.431224  [   66/   89]
per-ex loss: 0.376678  [   68/   89]
per-ex loss: 0.463913  [   70/   89]
per-ex loss: 0.494665  [   72/   89]
per-ex loss: 0.429478  [   74/   89]
per-ex loss: 0.670920  [   76/   89]
per-ex loss: 0.382556  [   78/   89]
per-ex loss: 0.554177  [   80/   89]
per-ex loss: 0.443947  [   82/   89]
per-ex loss: 0.351120  [   84/   89]
per-ex loss: 0.441508  [   86/   89]
per-ex loss: 0.436456  [   88/   89]
per-ex loss: 0.451973  [   89/   89]
Train Error: Avg loss: 0.45957640
validation Error: 
 Avg loss: 0.51908373 
 F1: 0.511676 
 Precision: 0.588358 
 Recall: 0.452677
 IoU: 0.343793

test Error: 
 Avg loss: 0.47540687 
 F1: 0.561436 
 Precision: 0.646074 
 Recall: 0.496406
 IoU: 0.390276

We have finished training iteration 455
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_453_.pth
per-ex loss: 0.428069  [    2/   89]
per-ex loss: 0.375949  [    4/   89]
per-ex loss: 0.392537  [    6/   89]
per-ex loss: 0.381307  [    8/   89]
per-ex loss: 0.358872  [   10/   89]
per-ex loss: 0.564595  [   12/   89]
per-ex loss: 0.602925  [   14/   89]
per-ex loss: 0.412370  [   16/   89]
per-ex loss: 0.414560  [   18/   89]
per-ex loss: 0.376490  [   20/   89]
per-ex loss: 0.482541  [   22/   89]
per-ex loss: 0.457763  [   24/   89]
per-ex loss: 0.609164  [   26/   89]
per-ex loss: 0.507183  [   28/   89]
per-ex loss: 0.497674  [   30/   89]
per-ex loss: 0.526375  [   32/   89]
per-ex loss: 0.488788  [   34/   89]
per-ex loss: 0.382778  [   36/   89]
per-ex loss: 0.518800  [   38/   89]
per-ex loss: 0.533457  [   40/   89]
per-ex loss: 0.458301  [   42/   89]
per-ex loss: 0.417330  [   44/   89]
per-ex loss: 0.395509  [   46/   89]
per-ex loss: 0.580874  [   48/   89]
per-ex loss: 0.614395  [   50/   89]
per-ex loss: 0.459514  [   52/   89]
per-ex loss: 0.435962  [   54/   89]
per-ex loss: 0.429641  [   56/   89]
per-ex loss: 0.420332  [   58/   89]
per-ex loss: 0.495027  [   60/   89]
per-ex loss: 0.421312  [   62/   89]
per-ex loss: 0.437160  [   64/   89]
per-ex loss: 0.592537  [   66/   89]
per-ex loss: 0.388830  [   68/   89]
per-ex loss: 0.444891  [   70/   89]
per-ex loss: 0.400159  [   72/   89]
per-ex loss: 0.379136  [   74/   89]
per-ex loss: 0.454071  [   76/   89]
per-ex loss: 0.384911  [   78/   89]
per-ex loss: 0.466566  [   80/   89]
per-ex loss: 0.418249  [   82/   89]
per-ex loss: 0.463206  [   84/   89]
per-ex loss: 0.529330  [   86/   89]
per-ex loss: 0.435648  [   88/   89]
per-ex loss: 0.560280  [   89/   89]
Train Error: Avg loss: 0.46211929
validation Error: 
 Avg loss: 0.50376609 
 F1: 0.513527 
 Precision: 0.622327 
 Recall: 0.437108
 IoU: 0.345467

test Error: 
 Avg loss: 0.48035932 
 F1: 0.554804 
 Precision: 0.676714 
 Recall: 0.470113
 IoU: 0.383895

We have finished training iteration 456
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_454_.pth
per-ex loss: 0.624017  [    2/   89]
per-ex loss: 0.614405  [    4/   89]
per-ex loss: 0.412778  [    6/   89]
per-ex loss: 0.432372  [    8/   89]
per-ex loss: 0.463592  [   10/   89]
per-ex loss: 0.531835  [   12/   89]
per-ex loss: 0.405151  [   14/   89]
per-ex loss: 0.594392  [   16/   89]
per-ex loss: 0.653580  [   18/   89]
per-ex loss: 0.490882  [   20/   89]
per-ex loss: 0.433198  [   22/   89]
per-ex loss: 0.449626  [   24/   89]
per-ex loss: 0.403106  [   26/   89]
per-ex loss: 0.474532  [   28/   89]
per-ex loss: 0.494783  [   30/   89]
per-ex loss: 0.608832  [   32/   89]
per-ex loss: 0.594658  [   34/   89]
per-ex loss: 0.383860  [   36/   89]
per-ex loss: 0.379436  [   38/   89]
per-ex loss: 0.463126  [   40/   89]
per-ex loss: 0.561859  [   42/   89]
per-ex loss: 0.548167  [   44/   89]
per-ex loss: 0.597986  [   46/   89]
per-ex loss: 0.360122  [   48/   89]
per-ex loss: 0.475817  [   50/   89]
per-ex loss: 0.389381  [   52/   89]
per-ex loss: 0.581352  [   54/   89]
per-ex loss: 0.478404  [   56/   89]
per-ex loss: 0.360552  [   58/   89]
per-ex loss: 0.460525  [   60/   89]
per-ex loss: 0.516185  [   62/   89]
per-ex loss: 0.397411  [   64/   89]
per-ex loss: 0.375595  [   66/   89]
per-ex loss: 0.458843  [   68/   89]
per-ex loss: 0.449915  [   70/   89]
per-ex loss: 0.368630  [   72/   89]
per-ex loss: 0.385663  [   74/   89]
per-ex loss: 0.433916  [   76/   89]
per-ex loss: 0.367301  [   78/   89]
per-ex loss: 0.396416  [   80/   89]
per-ex loss: 0.384929  [   82/   89]
per-ex loss: 0.408438  [   84/   89]
per-ex loss: 0.401154  [   86/   89]
per-ex loss: 0.499304  [   88/   89]
per-ex loss: 0.405660  [   89/   89]
Train Error: Avg loss: 0.46603744
validation Error: 
 Avg loss: 0.50076241 
 F1: 0.516728 
 Precision: 0.602131 
 Recall: 0.452542
 IoU: 0.348370

test Error: 
 Avg loss: 0.47297650 
 F1: 0.564086 
 Precision: 0.663855 
 Recall: 0.490387
 IoU: 0.392841

We have finished training iteration 457
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_455_.pth
per-ex loss: 0.501970  [    2/   89]
per-ex loss: 0.444328  [    4/   89]
per-ex loss: 0.449693  [    6/   89]
per-ex loss: 0.390797  [    8/   89]
per-ex loss: 0.359088  [   10/   89]
per-ex loss: 0.543214  [   12/   89]
per-ex loss: 0.511854  [   14/   89]
per-ex loss: 0.459318  [   16/   89]
per-ex loss: 0.583365  [   18/   89]
per-ex loss: 0.412781  [   20/   89]
per-ex loss: 0.612096  [   22/   89]
per-ex loss: 0.581814  [   24/   89]
per-ex loss: 0.499794  [   26/   89]
per-ex loss: 0.688418  [   28/   89]
per-ex loss: 0.504721  [   30/   89]
per-ex loss: 0.521990  [   32/   89]
per-ex loss: 0.348971  [   34/   89]
per-ex loss: 0.524162  [   36/   89]
per-ex loss: 0.556678  [   38/   89]
per-ex loss: 0.411935  [   40/   89]
per-ex loss: 0.400525  [   42/   89]
per-ex loss: 0.428704  [   44/   89]
per-ex loss: 0.432566  [   46/   89]
per-ex loss: 0.362935  [   48/   89]
per-ex loss: 0.371982  [   50/   89]
per-ex loss: 0.350780  [   52/   89]
per-ex loss: 0.364759  [   54/   89]
per-ex loss: 0.413389  [   56/   89]
per-ex loss: 0.529059  [   58/   89]
per-ex loss: 0.392205  [   60/   89]
per-ex loss: 0.370429  [   62/   89]
per-ex loss: 0.376228  [   64/   89]
per-ex loss: 0.495381  [   66/   89]
per-ex loss: 0.475814  [   68/   89]
per-ex loss: 0.536435  [   70/   89]
per-ex loss: 0.437412  [   72/   89]
per-ex loss: 0.477065  [   74/   89]
per-ex loss: 0.426681  [   76/   89]
per-ex loss: 0.557045  [   78/   89]
per-ex loss: 0.486183  [   80/   89]
per-ex loss: 0.455759  [   82/   89]
per-ex loss: 0.545907  [   84/   89]
per-ex loss: 0.430559  [   86/   89]
per-ex loss: 0.582519  [   88/   89]
per-ex loss: 0.562347  [   89/   89]
Train Error: Avg loss: 0.47043677
validation Error: 
 Avg loss: 0.50033332 
 F1: 0.512433 
 Precision: 0.638195 
 Recall: 0.428077
 IoU: 0.344477

test Error: 
 Avg loss: 0.48146937 
 F1: 0.554200 
 Precision: 0.697127 
 Recall: 0.459909
 IoU: 0.383318

We have finished training iteration 458
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_456_.pth
Error in cropping the image to the non-zero values in the fourth channel. Returned the original image.
per-ex loss: 0.452533  [    2/   89]
per-ex loss: 0.505727  [    4/   89]
per-ex loss: 0.486406  [    6/   89]
per-ex loss: 0.438363  [    8/   89]
per-ex loss: 0.411195  [   10/   89]
per-ex loss: 0.613949  [   12/   89]
per-ex loss: 0.573638  [   14/   89]
per-ex loss: 0.455861  [   16/   89]
per-ex loss: 0.376131  [   18/   89]
per-ex loss: 0.565831  [   20/   89]
per-ex loss: 0.525127  [   22/   89]
per-ex loss: 0.409099  [   24/   89]
per-ex loss: 0.410739  [   26/   89]
per-ex loss: 0.544113  [   28/   89]
per-ex loss: 0.632723  [   30/   89]
per-ex loss: 0.381612  [   32/   89]
per-ex loss: 0.485371  [   34/   89]
per-ex loss: 0.404821  [   36/   89]
per-ex loss: 0.618212  [   38/   89]
per-ex loss: 0.612539  [   40/   89]
per-ex loss: 0.506786  [   42/   89]
per-ex loss: 0.453006  [   44/   89]
per-ex loss: 0.400665  [   46/   89]
per-ex loss: 0.438162  [   48/   89]
per-ex loss: 0.437847  [   50/   89]
per-ex loss: 0.469694  [   52/   89]
per-ex loss: 0.556126  [   54/   89]
per-ex loss: 0.429148  [   56/   89]
per-ex loss: 0.527015  [   58/   89]
per-ex loss: 0.444166  [   60/   89]
per-ex loss: 0.444592  [   62/   89]
per-ex loss: 0.439725  [   64/   89]
per-ex loss: 0.380096  [   66/   89]
per-ex loss: 0.447036  [   68/   89]
per-ex loss: 0.411290  [   70/   89]
per-ex loss: 0.377121  [   72/   89]
per-ex loss: 0.407565  [   74/   89]
per-ex loss: 0.363662  [   76/   89]
per-ex loss: 0.366568  [   78/   89]
per-ex loss: 0.406983  [   80/   89]
per-ex loss: 0.590127  [   82/   89]
per-ex loss: 0.452990  [   84/   89]
per-ex loss: 0.478146  [   86/   89]
per-ex loss: 0.460177  [   88/   89]
per-ex loss: 0.491111  [   89/   89]
Train Error: Avg loss: 0.46852874
validation Error: 
 Avg loss: 0.50570751 
 F1: 0.515125 
 Precision: 0.613713 
 Recall: 0.443828
 IoU: 0.346915

test Error: 
 Avg loss: 0.47918682 
 F1: 0.556934 
 Precision: 0.668088 
 Recall: 0.477491
 IoU: 0.385938

We have finished training iteration 459
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_457_.pth
per-ex loss: 0.433879  [    2/   89]
per-ex loss: 0.497240  [    4/   89]
per-ex loss: 0.618725  [    6/   89]
per-ex loss: 0.704183  [    8/   89]
per-ex loss: 0.410626  [   10/   89]
per-ex loss: 0.470151  [   12/   89]
per-ex loss: 0.460959  [   14/   89]
per-ex loss: 0.560722  [   16/   89]
per-ex loss: 0.411579  [   18/   89]
per-ex loss: 0.541485  [   20/   89]
per-ex loss: 0.471872  [   22/   89]
per-ex loss: 0.440468  [   24/   89]
per-ex loss: 0.372716  [   26/   89]
per-ex loss: 0.410646  [   28/   89]
per-ex loss: 0.383068  [   30/   89]
per-ex loss: 0.390488  [   32/   89]
per-ex loss: 0.584502  [   34/   89]
per-ex loss: 0.650502  [   36/   89]
per-ex loss: 0.408239  [   38/   89]
per-ex loss: 0.390473  [   40/   89]
per-ex loss: 0.441002  [   42/   89]
per-ex loss: 0.392174  [   44/   89]
per-ex loss: 0.360357  [   46/   89]
per-ex loss: 0.417620  [   48/   89]
per-ex loss: 0.474122  [   50/   89]
per-ex loss: 0.407858  [   52/   89]
per-ex loss: 0.398063  [   54/   89]
per-ex loss: 0.510106  [   56/   89]
per-ex loss: 0.504492  [   58/   89]
per-ex loss: 0.450002  [   60/   89]
per-ex loss: 0.486641  [   62/   89]
per-ex loss: 0.414638  [   64/   89]
per-ex loss: 0.568095  [   66/   89]
per-ex loss: 0.534624  [   68/   89]
per-ex loss: 0.470655  [   70/   89]
per-ex loss: 0.520257  [   72/   89]
per-ex loss: 0.362843  [   74/   89]
per-ex loss: 0.509153  [   76/   89]
per-ex loss: 0.552052  [   78/   89]
per-ex loss: 0.596379  [   80/   89]
per-ex loss: 0.393473  [   82/   89]
per-ex loss: 0.368921  [   84/   89]
per-ex loss: 0.496146  [   86/   89]
per-ex loss: 0.495891  [   88/   89]
per-ex loss: 0.366783  [   89/   89]
Train Error: Avg loss: 0.46899696
validation Error: 
 Avg loss: 0.53415786 
 F1: 0.487371 
 Precision: 0.653826 
 Recall: 0.388471
 IoU: 0.322201

test Error: 
 Avg loss: 0.51645393 
 F1: 0.518241 
 Precision: 0.673360 
 Recall: 0.421209
 IoU: 0.349747

We have finished training iteration 460
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_458_.pth
per-ex loss: 0.503417  [    2/   89]
per-ex loss: 0.571171  [    4/   89]
per-ex loss: 0.360867  [    6/   89]
per-ex loss: 0.642127  [    8/   89]
per-ex loss: 0.366240  [   10/   89]
per-ex loss: 0.421985  [   12/   89]
per-ex loss: 0.391712  [   14/   89]
per-ex loss: 0.574774  [   16/   89]
per-ex loss: 0.404491  [   18/   89]
per-ex loss: 0.657741  [   20/   89]
per-ex loss: 0.420162  [   22/   89]
per-ex loss: 0.497538  [   24/   89]
per-ex loss: 0.470380  [   26/   89]
per-ex loss: 0.457816  [   28/   89]
per-ex loss: 0.391109  [   30/   89]
per-ex loss: 0.411157  [   32/   89]
per-ex loss: 0.522363  [   34/   89]
per-ex loss: 0.451792  [   36/   89]
per-ex loss: 0.429127  [   38/   89]
per-ex loss: 0.429353  [   40/   89]
per-ex loss: 0.548309  [   42/   89]
per-ex loss: 0.405551  [   44/   89]
per-ex loss: 0.422226  [   46/   89]
per-ex loss: 0.592108  [   48/   89]
per-ex loss: 0.490166  [   50/   89]
per-ex loss: 0.394124  [   52/   89]
per-ex loss: 0.413202  [   54/   89]
per-ex loss: 0.369321  [   56/   89]
per-ex loss: 0.607709  [   58/   89]
per-ex loss: 0.470623  [   60/   89]
per-ex loss: 0.346329  [   62/   89]
per-ex loss: 0.455542  [   64/   89]
per-ex loss: 0.549306  [   66/   89]
per-ex loss: 0.402923  [   68/   89]
per-ex loss: 0.383080  [   70/   89]
per-ex loss: 0.408975  [   72/   89]
per-ex loss: 0.502549  [   74/   89]
per-ex loss: 0.504261  [   76/   89]
per-ex loss: 0.632945  [   78/   89]
per-ex loss: 0.475930  [   80/   89]
per-ex loss: 0.508547  [   82/   89]
per-ex loss: 0.431075  [   84/   89]
per-ex loss: 0.412654  [   86/   89]
per-ex loss: 0.623704  [   88/   89]
per-ex loss: 0.403079  [   89/   89]
Train Error: Avg loss: 0.46954578
validation Error: 
 Avg loss: 0.50393903 
 F1: 0.514746 
 Precision: 0.627188 
 Recall: 0.436491
 IoU: 0.346571

test Error: 
 Avg loss: 0.47761839 
 F1: 0.559040 
 Precision: 0.682944 
 Recall: 0.473191
 IoU: 0.387964

We have finished training iteration 461
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_459_.pth
per-ex loss: 0.573816  [    2/   89]
per-ex loss: 0.546817  [    4/   89]
per-ex loss: 0.555515  [    6/   89]
per-ex loss: 0.424274  [    8/   89]
per-ex loss: 0.394317  [   10/   89]
per-ex loss: 0.474089  [   12/   89]
per-ex loss: 0.440588  [   14/   89]
per-ex loss: 0.375735  [   16/   89]
per-ex loss: 0.452616  [   18/   89]
per-ex loss: 0.380033  [   20/   89]
per-ex loss: 0.499113  [   22/   89]
per-ex loss: 0.382692  [   24/   89]
per-ex loss: 0.436114  [   26/   89]
per-ex loss: 0.459511  [   28/   89]
per-ex loss: 0.440036  [   30/   89]
per-ex loss: 0.390813  [   32/   89]
per-ex loss: 0.401984  [   34/   89]
per-ex loss: 0.455017  [   36/   89]
per-ex loss: 0.466078  [   38/   89]
per-ex loss: 0.400472  [   40/   89]
per-ex loss: 0.401996  [   42/   89]
per-ex loss: 0.613356  [   44/   89]
per-ex loss: 0.401614  [   46/   89]
per-ex loss: 0.427762  [   48/   89]
per-ex loss: 0.407921  [   50/   89]
per-ex loss: 0.567425  [   52/   89]
per-ex loss: 0.555219  [   54/   89]
per-ex loss: 0.382741  [   56/   89]
per-ex loss: 0.413130  [   58/   89]
per-ex loss: 0.432728  [   60/   89]
per-ex loss: 0.373305  [   62/   89]
per-ex loss: 0.396200  [   64/   89]
per-ex loss: 0.451847  [   66/   89]
per-ex loss: 0.349115  [   68/   89]
per-ex loss: 0.479177  [   70/   89]
per-ex loss: 0.523245  [   72/   89]
per-ex loss: 0.586961  [   74/   89]
per-ex loss: 0.452586  [   76/   89]
per-ex loss: 0.557998  [   78/   89]
per-ex loss: 0.415575  [   80/   89]
per-ex loss: 0.417097  [   82/   89]
per-ex loss: 0.473994  [   84/   89]
per-ex loss: 0.487732  [   86/   89]
per-ex loss: 0.593714  [   88/   89]
per-ex loss: 0.640230  [   89/   89]
Train Error: Avg loss: 0.46116220
validation Error: 
 Avg loss: 0.52366334 
 F1: 0.504617 
 Precision: 0.637568 
 Recall: 0.417547
 IoU: 0.337450

test Error: 
 Avg loss: 0.49606288 
 F1: 0.539152 
 Precision: 0.669950 
 Recall: 0.451085
 IoU: 0.369068

We have finished training iteration 462
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_460_.pth
per-ex loss: 0.555839  [    2/   89]
per-ex loss: 0.398110  [    4/   89]
per-ex loss: 0.366740  [    6/   89]
per-ex loss: 0.520069  [    8/   89]
per-ex loss: 0.356627  [   10/   89]
per-ex loss: 0.409515  [   12/   89]
per-ex loss: 0.386665  [   14/   89]
per-ex loss: 0.432401  [   16/   89]
per-ex loss: 0.572898  [   18/   89]
per-ex loss: 0.597065  [   20/   89]
per-ex loss: 0.440625  [   22/   89]
per-ex loss: 0.376605  [   24/   89]
per-ex loss: 0.477662  [   26/   89]
per-ex loss: 0.390237  [   28/   89]
per-ex loss: 0.453008  [   30/   89]
per-ex loss: 0.479860  [   32/   89]
per-ex loss: 0.398190  [   34/   89]
per-ex loss: 0.422448  [   36/   89]
per-ex loss: 0.505868  [   38/   89]
per-ex loss: 0.433281  [   40/   89]
per-ex loss: 0.447724  [   42/   89]
per-ex loss: 0.419025  [   44/   89]
per-ex loss: 0.418225  [   46/   89]
per-ex loss: 0.645427  [   48/   89]
per-ex loss: 0.439761  [   50/   89]
per-ex loss: 0.403620  [   52/   89]
per-ex loss: 0.510342  [   54/   89]
per-ex loss: 0.468641  [   56/   89]
per-ex loss: 0.445770  [   58/   89]
per-ex loss: 0.360584  [   60/   89]
per-ex loss: 0.477031  [   62/   89]
per-ex loss: 0.434485  [   64/   89]
per-ex loss: 0.628121  [   66/   89]
per-ex loss: 0.577605  [   68/   89]
per-ex loss: 0.425529  [   70/   89]
per-ex loss: 0.507414  [   72/   89]
per-ex loss: 0.597100  [   74/   89]
per-ex loss: 0.544281  [   76/   89]
per-ex loss: 0.404258  [   78/   89]
per-ex loss: 0.534563  [   80/   89]
per-ex loss: 0.399135  [   82/   89]
per-ex loss: 0.402549  [   84/   89]
per-ex loss: 0.636780  [   86/   89]
per-ex loss: 0.566370  [   88/   89]
per-ex loss: 0.355433  [   89/   89]
Train Error: Avg loss: 0.46718851
validation Error: 
 Avg loss: 0.53861823 
 F1: 0.484116 
 Precision: 0.668636 
 Recall: 0.379412
 IoU: 0.319362

test Error: 
 Avg loss: 0.51888777 
 F1: 0.514551 
 Precision: 0.691846 
 Recall: 0.409589
 IoU: 0.346395

We have finished training iteration 463
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_461_.pth
per-ex loss: 0.490171  [    2/   89]
per-ex loss: 0.428906  [    4/   89]
per-ex loss: 0.654044  [    6/   89]
per-ex loss: 0.431114  [    8/   89]
per-ex loss: 0.581523  [   10/   89]
per-ex loss: 0.380312  [   12/   89]
per-ex loss: 0.508964  [   14/   89]
per-ex loss: 0.581472  [   16/   89]
per-ex loss: 0.411334  [   18/   89]
per-ex loss: 0.436409  [   20/   89]
per-ex loss: 0.474685  [   22/   89]
per-ex loss: 0.383339  [   24/   89]
per-ex loss: 0.492121  [   26/   89]
per-ex loss: 0.614779  [   28/   89]
per-ex loss: 0.481372  [   30/   89]
per-ex loss: 0.581754  [   32/   89]
per-ex loss: 0.378315  [   34/   89]
per-ex loss: 0.506758  [   36/   89]
per-ex loss: 0.456277  [   38/   89]
per-ex loss: 0.425218  [   40/   89]
per-ex loss: 0.447673  [   42/   89]
per-ex loss: 0.367023  [   44/   89]
per-ex loss: 0.620766  [   46/   89]
per-ex loss: 0.577696  [   48/   89]
per-ex loss: 0.488319  [   50/   89]
per-ex loss: 0.356300  [   52/   89]
per-ex loss: 0.480760  [   54/   89]
per-ex loss: 0.406044  [   56/   89]
per-ex loss: 0.428826  [   58/   89]
per-ex loss: 0.476269  [   60/   89]
per-ex loss: 0.439040  [   62/   89]
per-ex loss: 0.376908  [   64/   89]
per-ex loss: 0.373883  [   66/   89]
per-ex loss: 0.463497  [   68/   89]
per-ex loss: 0.612758  [   70/   89]
per-ex loss: 0.418917  [   72/   89]
per-ex loss: 0.365915  [   74/   89]
per-ex loss: 0.419866  [   76/   89]
per-ex loss: 0.529315  [   78/   89]
per-ex loss: 0.437375  [   80/   89]
per-ex loss: 0.384244  [   82/   89]
per-ex loss: 0.588762  [   84/   89]
per-ex loss: 0.354249  [   86/   89]
per-ex loss: 0.598650  [   88/   89]
per-ex loss: 0.641562  [   89/   89]
Train Error: Avg loss: 0.47452185
validation Error: 
 Avg loss: 0.50774348 
 F1: 0.508385 
 Precision: 0.620941 
 Recall: 0.430372
 IoU: 0.340828

test Error: 
 Avg loss: 0.48766317 
 F1: 0.547653 
 Precision: 0.675236 
 Recall: 0.460621
 IoU: 0.377081

We have finished training iteration 464
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_462_.pth
per-ex loss: 0.637986  [    2/   89]
per-ex loss: 0.439350  [    4/   89]
per-ex loss: 0.427758  [    6/   89]
per-ex loss: 0.388836  [    8/   89]
per-ex loss: 0.541632  [   10/   89]
per-ex loss: 0.646142  [   12/   89]
per-ex loss: 0.521931  [   14/   89]
per-ex loss: 0.461424  [   16/   89]
per-ex loss: 0.411798  [   18/   89]
per-ex loss: 0.398131  [   20/   89]
per-ex loss: 0.459500  [   22/   89]
per-ex loss: 0.552061  [   24/   89]
per-ex loss: 0.657791  [   26/   89]
per-ex loss: 0.391280  [   28/   89]
per-ex loss: 0.413136  [   30/   89]
per-ex loss: 0.453841  [   32/   89]
per-ex loss: 0.336000  [   34/   89]
per-ex loss: 0.501882  [   36/   89]
per-ex loss: 0.592110  [   38/   89]
per-ex loss: 0.384940  [   40/   89]
per-ex loss: 0.466242  [   42/   89]
per-ex loss: 0.550100  [   44/   89]
per-ex loss: 0.407648  [   46/   89]
per-ex loss: 0.579791  [   48/   89]
per-ex loss: 0.467097  [   50/   89]
per-ex loss: 0.393663  [   52/   89]
per-ex loss: 0.406789  [   54/   89]
per-ex loss: 0.430147  [   56/   89]
per-ex loss: 0.459221  [   58/   89]
per-ex loss: 0.490096  [   60/   89]
per-ex loss: 0.361231  [   62/   89]
per-ex loss: 0.433876  [   64/   89]
per-ex loss: 0.498707  [   66/   89]
per-ex loss: 0.506591  [   68/   89]
per-ex loss: 0.395987  [   70/   89]
per-ex loss: 0.400796  [   72/   89]
per-ex loss: 0.438571  [   74/   89]
per-ex loss: 0.452944  [   76/   89]
per-ex loss: 0.397370  [   78/   89]
per-ex loss: 0.428688  [   80/   89]
per-ex loss: 0.518891  [   82/   89]
per-ex loss: 0.397642  [   84/   89]
per-ex loss: 0.355906  [   86/   89]
per-ex loss: 0.380766  [   88/   89]
per-ex loss: 0.589218  [   89/   89]
Train Error: Avg loss: 0.46278909
validation Error: 
 Avg loss: 0.53563306 
 F1: 0.494771 
 Precision: 0.639026 
 Recall: 0.403650
 IoU: 0.328701

test Error: 
 Avg loss: 0.51033955 
 F1: 0.523650 
 Precision: 0.672486 
 Recall: 0.428757
 IoU: 0.354692

We have finished training iteration 465
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_463_.pth
per-ex loss: 0.394640  [    2/   89]
per-ex loss: 0.413222  [    4/   89]
per-ex loss: 0.511738  [    6/   89]
per-ex loss: 0.443904  [    8/   89]
per-ex loss: 0.374954  [   10/   89]
per-ex loss: 0.570202  [   12/   89]
per-ex loss: 0.372052  [   14/   89]
per-ex loss: 0.411153  [   16/   89]
per-ex loss: 0.433485  [   18/   89]
per-ex loss: 0.552788  [   20/   89]
per-ex loss: 0.477645  [   22/   89]
per-ex loss: 0.626504  [   24/   89]
per-ex loss: 0.349417  [   26/   89]
per-ex loss: 0.374108  [   28/   89]
per-ex loss: 0.422746  [   30/   89]
per-ex loss: 0.465488  [   32/   89]
per-ex loss: 0.453284  [   34/   89]
per-ex loss: 0.391166  [   36/   89]
per-ex loss: 0.430333  [   38/   89]
per-ex loss: 0.461980  [   40/   89]
per-ex loss: 0.334971  [   42/   89]
per-ex loss: 0.447192  [   44/   89]
per-ex loss: 0.422555  [   46/   89]
per-ex loss: 0.442033  [   48/   89]
per-ex loss: 0.457431  [   50/   89]
per-ex loss: 0.434150  [   52/   89]
per-ex loss: 0.398959  [   54/   89]
per-ex loss: 0.597859  [   56/   89]
per-ex loss: 0.513523  [   58/   89]
per-ex loss: 0.561614  [   60/   89]
per-ex loss: 0.682166  [   62/   89]
per-ex loss: 0.507711  [   64/   89]
per-ex loss: 0.478302  [   66/   89]
per-ex loss: 0.645056  [   68/   89]
per-ex loss: 0.401455  [   70/   89]
per-ex loss: 0.409365  [   72/   89]
per-ex loss: 0.453603  [   74/   89]
per-ex loss: 0.403470  [   76/   89]
per-ex loss: 0.375183  [   78/   89]
per-ex loss: 0.624393  [   80/   89]
per-ex loss: 0.398814  [   82/   89]
per-ex loss: 0.390109  [   84/   89]
per-ex loss: 0.455158  [   86/   89]
per-ex loss: 0.387307  [   88/   89]
per-ex loss: 0.539832  [   89/   89]
Train Error: Avg loss: 0.45984492
validation Error: 
 Avg loss: 0.53530840 
 F1: 0.484879 
 Precision: 0.679130 
 Recall: 0.377036
 IoU: 0.320027

test Error: 
 Avg loss: 0.52085206 
 F1: 0.512016 
 Precision: 0.698907 
 Recall: 0.403988
 IoU: 0.344100

We have finished training iteration 466
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_464_.pth
per-ex loss: 0.415385  [    2/   89]
per-ex loss: 0.574538  [    4/   89]
per-ex loss: 0.525548  [    6/   89]
per-ex loss: 0.440714  [    8/   89]
per-ex loss: 0.400936  [   10/   89]
per-ex loss: 0.469832  [   12/   89]
per-ex loss: 0.532456  [   14/   89]
per-ex loss: 0.396319  [   16/   89]
per-ex loss: 0.396874  [   18/   89]
per-ex loss: 0.375562  [   20/   89]
per-ex loss: 0.439325  [   22/   89]
per-ex loss: 0.552653  [   24/   89]
per-ex loss: 0.494216  [   26/   89]
per-ex loss: 0.380904  [   28/   89]
per-ex loss: 0.370759  [   30/   89]
per-ex loss: 0.376003  [   32/   89]
per-ex loss: 0.397883  [   34/   89]
per-ex loss: 0.611270  [   36/   89]
per-ex loss: 0.378078  [   38/   89]
per-ex loss: 0.458753  [   40/   89]
per-ex loss: 0.498928  [   42/   89]
per-ex loss: 0.572020  [   44/   89]
per-ex loss: 0.575743  [   46/   89]
per-ex loss: 0.553848  [   48/   89]
per-ex loss: 0.649691  [   50/   89]
per-ex loss: 0.655625  [   52/   89]
per-ex loss: 0.607343  [   54/   89]
per-ex loss: 0.443464  [   56/   89]
per-ex loss: 0.439708  [   58/   89]
per-ex loss: 0.351370  [   60/   89]
per-ex loss: 0.482573  [   62/   89]
per-ex loss: 0.476186  [   64/   89]
per-ex loss: 0.500821  [   66/   89]
per-ex loss: 0.478976  [   68/   89]
per-ex loss: 0.414125  [   70/   89]
per-ex loss: 0.391726  [   72/   89]
per-ex loss: 0.421925  [   74/   89]
per-ex loss: 0.436379  [   76/   89]
per-ex loss: 0.609731  [   78/   89]
per-ex loss: 0.481995  [   80/   89]
per-ex loss: 0.431012  [   82/   89]
per-ex loss: 0.410961  [   84/   89]
per-ex loss: 0.482877  [   86/   89]
per-ex loss: 0.344119  [   88/   89]
per-ex loss: 0.399808  [   89/   89]
Train Error: Avg loss: 0.46886587
validation Error: 
 Avg loss: 0.53940252 
 F1: 0.497260 
 Precision: 0.644206 
 Recall: 0.404901
 IoU: 0.330903

test Error: 
 Avg loss: 0.50579982 
 F1: 0.528831 
 Precision: 0.686770 
 Recall: 0.429953
 IoU: 0.359463

We have finished training iteration 467
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_465_.pth
per-ex loss: 0.407842  [    2/   89]
per-ex loss: 0.524826  [    4/   89]
per-ex loss: 0.475358  [    6/   89]
per-ex loss: 0.377357  [    8/   89]
per-ex loss: 0.472060  [   10/   89]
per-ex loss: 0.480537  [   12/   89]
per-ex loss: 0.469080  [   14/   89]
per-ex loss: 0.643347  [   16/   89]
per-ex loss: 0.528578  [   18/   89]
per-ex loss: 0.408396  [   20/   89]
per-ex loss: 0.438728  [   22/   89]
per-ex loss: 0.364250  [   24/   89]
per-ex loss: 0.416426  [   26/   89]
per-ex loss: 0.371406  [   28/   89]
per-ex loss: 0.372212  [   30/   89]
per-ex loss: 0.521383  [   32/   89]
per-ex loss: 0.540881  [   34/   89]
per-ex loss: 0.369049  [   36/   89]
per-ex loss: 0.486025  [   38/   89]
per-ex loss: 0.553125  [   40/   89]
per-ex loss: 0.705728  [   42/   89]
per-ex loss: 0.649363  [   44/   89]
per-ex loss: 0.392997  [   46/   89]
per-ex loss: 0.438529  [   48/   89]
per-ex loss: 0.398766  [   50/   89]
per-ex loss: 0.414315  [   52/   89]
per-ex loss: 0.569259  [   54/   89]
per-ex loss: 0.396816  [   56/   89]
per-ex loss: 0.378328  [   58/   89]
per-ex loss: 0.385400  [   60/   89]
per-ex loss: 0.583227  [   62/   89]
per-ex loss: 0.551933  [   64/   89]
per-ex loss: 0.382767  [   66/   89]
per-ex loss: 0.381905  [   68/   89]
per-ex loss: 0.488910  [   70/   89]
per-ex loss: 0.574613  [   72/   89]
per-ex loss: 0.438027  [   74/   89]
per-ex loss: 0.399840  [   76/   89]
per-ex loss: 0.493404  [   78/   89]
per-ex loss: 0.477803  [   80/   89]
per-ex loss: 0.374700  [   82/   89]
per-ex loss: 0.399685  [   84/   89]
per-ex loss: 0.489880  [   86/   89]
per-ex loss: 0.584705  [   88/   89]
per-ex loss: 0.532869  [   89/   89]
Train Error: Avg loss: 0.46899190
validation Error: 
 Avg loss: 0.51614465 
 F1: 0.510237 
 Precision: 0.610642 
 Recall: 0.438189
 IoU: 0.342496

test Error: 
 Avg loss: 0.48398137 
 F1: 0.551580 
 Precision: 0.662815 
 Recall: 0.472316
 IoU: 0.380815

We have finished training iteration 468
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_466_.pth
per-ex loss: 0.512937  [    2/   89]
per-ex loss: 0.556031  [    4/   89]
per-ex loss: 0.590493  [    6/   89]
per-ex loss: 0.486739  [    8/   89]
per-ex loss: 0.466658  [   10/   89]
per-ex loss: 0.389950  [   12/   89]
per-ex loss: 0.452182  [   14/   89]
per-ex loss: 0.612722  [   16/   89]
per-ex loss: 0.398691  [   18/   89]
per-ex loss: 0.570610  [   20/   89]
per-ex loss: 0.354083  [   22/   89]
per-ex loss: 0.515795  [   24/   89]
per-ex loss: 0.395282  [   26/   89]
per-ex loss: 0.542162  [   28/   89]
per-ex loss: 0.462406  [   30/   89]
per-ex loss: 0.431656  [   32/   89]
per-ex loss: 0.400933  [   34/   89]
per-ex loss: 0.390426  [   36/   89]
per-ex loss: 0.384583  [   38/   89]
per-ex loss: 0.406184  [   40/   89]
per-ex loss: 0.387447  [   42/   89]
per-ex loss: 0.358190  [   44/   89]
per-ex loss: 0.363217  [   46/   89]
per-ex loss: 0.374374  [   48/   89]
per-ex loss: 0.477424  [   50/   89]
per-ex loss: 0.551290  [   52/   89]
per-ex loss: 0.473961  [   54/   89]
per-ex loss: 0.572291  [   56/   89]
per-ex loss: 0.374852  [   58/   89]
per-ex loss: 0.411916  [   60/   89]
per-ex loss: 0.414538  [   62/   89]
per-ex loss: 0.554393  [   64/   89]
per-ex loss: 0.500796  [   66/   89]
per-ex loss: 0.570085  [   68/   89]
per-ex loss: 0.605408  [   70/   89]
per-ex loss: 0.458844  [   72/   89]
per-ex loss: 0.590945  [   74/   89]
per-ex loss: 0.439329  [   76/   89]
per-ex loss: 0.353420  [   78/   89]
per-ex loss: 0.443349  [   80/   89]
per-ex loss: 0.451352  [   82/   89]
per-ex loss: 0.468518  [   84/   89]
per-ex loss: 0.411081  [   86/   89]
per-ex loss: 0.481072  [   88/   89]
per-ex loss: 0.423427  [   89/   89]
Train Error: Avg loss: 0.46293433
validation Error: 
 Avg loss: 0.50671756 
 F1: 0.513667 
 Precision: 0.613121 
 Recall: 0.441975
 IoU: 0.345594

test Error: 
 Avg loss: 0.47710329 
 F1: 0.559776 
 Precision: 0.677689 
 Recall: 0.476813
 IoU: 0.388673

We have finished training iteration 469
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_467_.pth
per-ex loss: 0.407573  [    2/   89]
per-ex loss: 0.407089  [    4/   89]
per-ex loss: 0.532282  [    6/   89]
per-ex loss: 0.382054  [    8/   89]
per-ex loss: 0.549855  [   10/   89]
per-ex loss: 0.629108  [   12/   89]
per-ex loss: 0.554595  [   14/   89]
per-ex loss: 0.439470  [   16/   89]
per-ex loss: 0.382975  [   18/   89]
per-ex loss: 0.374762  [   20/   89]
per-ex loss: 0.544654  [   22/   89]
per-ex loss: 0.672417  [   24/   89]
per-ex loss: 0.441576  [   26/   89]
per-ex loss: 0.536057  [   28/   89]
per-ex loss: 0.531082  [   30/   89]
per-ex loss: 0.395472  [   32/   89]
per-ex loss: 0.408694  [   34/   89]
per-ex loss: 0.436449  [   36/   89]
per-ex loss: 0.498850  [   38/   89]
per-ex loss: 0.342280  [   40/   89]
per-ex loss: 0.398588  [   42/   89]
per-ex loss: 0.523226  [   44/   89]
per-ex loss: 0.419947  [   46/   89]
per-ex loss: 0.520193  [   48/   89]
per-ex loss: 0.372525  [   50/   89]
per-ex loss: 0.580093  [   52/   89]
per-ex loss: 0.435275  [   54/   89]
per-ex loss: 0.429431  [   56/   89]
per-ex loss: 0.368147  [   58/   89]
per-ex loss: 0.527327  [   60/   89]
per-ex loss: 0.413621  [   62/   89]
per-ex loss: 0.381017  [   64/   89]
per-ex loss: 0.609579  [   66/   89]
per-ex loss: 0.495884  [   68/   89]
per-ex loss: 0.401082  [   70/   89]
per-ex loss: 0.443890  [   72/   89]
per-ex loss: 0.398175  [   74/   89]
per-ex loss: 0.478894  [   76/   89]
per-ex loss: 0.349582  [   78/   89]
per-ex loss: 0.431426  [   80/   89]
per-ex loss: 0.375166  [   82/   89]
per-ex loss: 0.416713  [   84/   89]
per-ex loss: 0.397328  [   86/   89]
per-ex loss: 0.567562  [   88/   89]
per-ex loss: 0.638255  [   89/   89]
Train Error: Avg loss: 0.46311599
validation Error: 
 Avg loss: 0.52696469 
 F1: 0.512132 
 Precision: 0.615433 
 Recall: 0.438526
 IoU: 0.344206

test Error: 
 Avg loss: 0.47877493 
 F1: 0.558035 
 Precision: 0.680758 
 Recall: 0.472802
 IoU: 0.386997

We have finished training iteration 470
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_468_.pth
per-ex loss: 0.341743  [    2/   89]
per-ex loss: 0.463674  [    4/   89]
per-ex loss: 0.477467  [    6/   89]
per-ex loss: 0.432283  [    8/   89]
per-ex loss: 0.436656  [   10/   89]
per-ex loss: 0.639168  [   12/   89]
per-ex loss: 0.617505  [   14/   89]
per-ex loss: 0.422947  [   16/   89]
per-ex loss: 0.491588  [   18/   89]
per-ex loss: 0.365063  [   20/   89]
per-ex loss: 0.364923  [   22/   89]
per-ex loss: 0.602234  [   24/   89]
per-ex loss: 0.481872  [   26/   89]
per-ex loss: 0.380577  [   28/   89]
per-ex loss: 0.418564  [   30/   89]
per-ex loss: 0.471929  [   32/   89]
per-ex loss: 0.391126  [   34/   89]
per-ex loss: 0.504261  [   36/   89]
per-ex loss: 0.481190  [   38/   89]
per-ex loss: 0.476040  [   40/   89]
per-ex loss: 0.387529  [   42/   89]
per-ex loss: 0.530273  [   44/   89]
per-ex loss: 0.562498  [   46/   89]
per-ex loss: 0.379430  [   48/   89]
per-ex loss: 0.474617  [   50/   89]
per-ex loss: 0.487972  [   52/   89]
per-ex loss: 0.362040  [   54/   89]
per-ex loss: 0.507281  [   56/   89]
per-ex loss: 0.425470  [   58/   89]
per-ex loss: 0.459055  [   60/   89]
per-ex loss: 0.407433  [   62/   89]
per-ex loss: 0.393945  [   64/   89]
per-ex loss: 0.384375  [   66/   89]
per-ex loss: 0.508370  [   68/   89]
per-ex loss: 0.477917  [   70/   89]
per-ex loss: 0.555146  [   72/   89]
per-ex loss: 0.570525  [   74/   89]
per-ex loss: 0.381618  [   76/   89]
per-ex loss: 0.426583  [   78/   89]
per-ex loss: 0.433045  [   80/   89]
per-ex loss: 0.357977  [   82/   89]
per-ex loss: 0.459347  [   84/   89]
per-ex loss: 0.500612  [   86/   89]
per-ex loss: 0.356507  [   88/   89]
per-ex loss: 0.647580  [   89/   89]
Train Error: Avg loss: 0.45995457
validation Error: 
 Avg loss: 0.51672835 
 F1: 0.504234 
 Precision: 0.628036 
 Recall: 0.421203
 IoU: 0.337107

test Error: 
 Avg loss: 0.49625822 
 F1: 0.539048 
 Precision: 0.671362 
 Recall: 0.450302
 IoU: 0.368971

We have finished training iteration 471
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_469_.pth
per-ex loss: 0.425090  [    2/   89]
per-ex loss: 0.571377  [    4/   89]
per-ex loss: 0.429621  [    6/   89]
per-ex loss: 0.673728  [    8/   89]
per-ex loss: 0.471711  [   10/   89]
per-ex loss: 0.466685  [   12/   89]
per-ex loss: 0.356450  [   14/   89]
per-ex loss: 0.646544  [   16/   89]
per-ex loss: 0.377792  [   18/   89]
per-ex loss: 0.426078  [   20/   89]
per-ex loss: 0.453801  [   22/   89]
per-ex loss: 0.464641  [   24/   89]
per-ex loss: 0.414838  [   26/   89]
per-ex loss: 0.474146  [   28/   89]
per-ex loss: 0.586419  [   30/   89]
per-ex loss: 0.482921  [   32/   89]
per-ex loss: 0.390246  [   34/   89]
per-ex loss: 0.462409  [   36/   89]
per-ex loss: 0.380220  [   38/   89]
per-ex loss: 0.579067  [   40/   89]
per-ex loss: 0.423881  [   42/   89]
per-ex loss: 0.529412  [   44/   89]
per-ex loss: 0.364621  [   46/   89]
per-ex loss: 0.403883  [   48/   89]
per-ex loss: 0.440240  [   50/   89]
per-ex loss: 0.361813  [   52/   89]
per-ex loss: 0.477793  [   54/   89]
per-ex loss: 0.410190  [   56/   89]
per-ex loss: 0.433473  [   58/   89]
per-ex loss: 0.401242  [   60/   89]
per-ex loss: 0.409173  [   62/   89]
per-ex loss: 0.417697  [   64/   89]
per-ex loss: 0.387575  [   66/   89]
per-ex loss: 0.464815  [   68/   89]
per-ex loss: 0.518667  [   70/   89]
per-ex loss: 0.608796  [   72/   89]
per-ex loss: 0.638779  [   74/   89]
per-ex loss: 0.523180  [   76/   89]
per-ex loss: 0.364788  [   78/   89]
per-ex loss: 0.527459  [   80/   89]
per-ex loss: 0.430369  [   82/   89]
per-ex loss: 0.519926  [   84/   89]
per-ex loss: 0.433287  [   86/   89]
per-ex loss: 0.381388  [   88/   89]
per-ex loss: 0.384967  [   89/   89]
Train Error: Avg loss: 0.46202673
validation Error: 
 Avg loss: 0.50942141 
 F1: 0.512701 
 Precision: 0.627665 
 Recall: 0.433332
 IoU: 0.344720

test Error: 
 Avg loss: 0.47827465 
 F1: 0.557710 
 Precision: 0.684653 
 Recall: 0.470477
 IoU: 0.386684

We have finished training iteration 472
Deleting model ./unet_b_train/saved_model_wrapper/models/UNet_470_.pth
per-ex loss: 0.437903  [    2/   89]
per-ex loss: 0.598267  [    4/   89]
per-ex loss: 0.602414  [    6/   89]
per-ex loss: 0.393624  [    8/   89]
per-ex loss: 0.423886  [   10/   89]
per-ex loss: 0.547492  [   12/   89]
per-ex loss: 0.544139  [   14/   89]
per-ex loss: 0.395759  [   16/   89]
per-ex loss: 0.654235  [   18/   89]
per-ex loss: 0.459467  [   20/   89]
per-ex loss: 0.519625  [   22/   89]
per-ex loss: 0.401120  [   24/   89]
per-ex loss: 0.462037  [   26/   89]
per-ex loss: 0.524458  [   28/   89]
per-ex loss: 0.372706  [   30/   89]
per-ex loss: 0.406805  [   32/   89]
per-ex loss: 0.429497  [   34/   89]
per-ex loss: 0.415210  [   36/   89]
per-ex loss: 0.371594  [   38/   89]
per-ex loss: 0.405819  [   40/   89]
per-ex loss: 0.426532  [   42/   89]
per-ex loss: 0.407534  [   44/   89]
per-ex loss: 0.465393  [   46/   89]
per-ex loss: 0.524098  [   48/   89]
per-ex loss: 0.414167  [   50/   89]
per-ex loss: 0.354790  [   52/   89]
per-ex loss: 0.586800  [   54/   89]
per-ex loss: 0.630507  [   56/   89]
per-ex loss: 0.429154  [   58/   89]
per-ex loss: 0.412722  [   60/   89]
per-ex loss: 0.416941  [   62/   89]
per-ex loss: 0.417076  [   64/   89]
per-ex loss: 0.377933  [   66/   89]
per-ex loss: 0.636836  [   68/   89]
per-ex loss: 0.434618  [   70/   89]
per-ex loss: 0.406689  [   72/   89]
per-ex loss: 0.556812  [   74/   89]
per-ex loss: 0.603540  [   76/   89]
per-ex loss: 0.445418  [   78/   89]
per-ex loss: 0.423407  [   80/   89]
per-ex loss: 0.573568  [   82/   89]
per-ex loss: 0.400505  [   84/   89]
per-ex loss: 0.375958  [   86/   89]
per-ex loss: 0.517622  [   88/   89]
per-ex loss: 0.509796  [   89/   89]
Train Error: Avg loss: 0.46921039
validation Error: 
 Avg loss: 0.51914101 
 F1: 0.502830 
 Precision: 0.644919 
 Recall: 0.412047
 IoU: 0.335853

slurmstepd: error: *** STEP 16561.0 ON aga1 CANCELLED AT 2025-01-08T13:11:58 ***
