/shared/home/matevz.vidovic/Diplomska/Prototip/Delo/model_wrapper.py:111: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.model = torch.load(self.prev_model_path, map_location=torch.device(device))
unet_original_main.py do_log: True
Log file name: log_07_18-23-40_01-2025.log.
            Add print_log_file_name=False to file_handler_setup() to disable this printout.
min_resource_percentage.py do_log: False
model_wrapper.py do_log: True
training_wrapper.py do_log: True
helper_img_and_fig_tools.py do_log: False
conv_resource_calc.py do_log: False
pruner.py do_log: False
helper_model_vizualization.py do_log: False
training_support.py do_log: True
helper_model_eval_graphs.py do_log: False
losses.py do_log: False
Args: Namespace(ptd='./Data/vein_and_sclera_data', sd='unet_zscwzo_train', mti=200, mtti=1000000000.0, pruning_phase=False, ifn='IPAD_eq', ips=1000000000.0, tras=-1, tp=False, yaml='z_pipeline_unet/unet_original_zscwzo.yaml', ntibp=None, ptp=None, map=None)
YAML: {'batch_size': 2, 'learning_rate': 1e-06, 'num_of_dataloader_workers': 7, 'train_epoch_size_limit': 400, 'num_epochs_per_training_iteration': 1, 'cleanup_k': 3, 'dataset_option': 'aug_with_zero_out_sclera', 'optimizer_used': 'Adam', 'zero_out_non_sclera_on_predictions': True, 'loss_fn_name': 'MCDL', 'alphas': [], 'model': '64_2_6', 'input_width': 2048, 'input_height': 1024, 'input_channels': 3, 'output_channels': 2, 'num_train_iters_between_prunings': 10, 'max_auto_prunings': 70, 'proportion_to_prune': 0.01, 'prune_by_original_percent': True, 'num_filters_to_prune': -1, 'prune_n_kernels_at_once': 100, 'resource_name_to_prune_by': 'flops_num', 'importance_func': 'IPAD_eq'}
Validation phase: False
Namespace(ptd='./Data/vein_and_sclera_data', sd='unet_zscwzo_train', mti=200, mtti=1000000000.0, pruning_phase=False, ifn='IPAD_eq', ips=1000000000.0, tras=-1, tp=False, yaml='z_pipeline_unet/unet_original_zscwzo.yaml', ntibp=None, ptp=None, map=None)
Device: cuda
dataset_aug_with_zero_out_sclera.py do_log: False
img_augments.py do_log: False
path to file: ./Data/vein_and_sclera_data
summary for train
valid images: 89
summary for val
valid images: 27
summary for test
valid images: 12
train dataset len: 89
val dataset len: 27
test dataset len: 12
train dataloader num of batches: 45
val dataloader num of batches: 14
test dataloader num of batches: 6
Loaded model path:  ./unet_zscwzo_train/saved_model_wrapper/models/UNet_46_.pth
per-ex loss: 0.431910  [    2/   89]
per-ex loss: 0.540448  [    4/   89]
per-ex loss: 0.495453  [    6/   89]
per-ex loss: 0.511710  [    8/   89]
per-ex loss: 0.412823  [   10/   89]
per-ex loss: 0.395381  [   12/   89]
per-ex loss: 0.475005  [   14/   89]
per-ex loss: 0.438429  [   16/   89]
per-ex loss: 0.648569  [   18/   89]
per-ex loss: 0.494324  [   20/   89]
per-ex loss: 0.433760  [   22/   89]
per-ex loss: 0.399832  [   24/   89]
per-ex loss: 0.621049  [   26/   89]
per-ex loss: 0.436906  [   28/   89]
per-ex loss: 0.449603  [   30/   89]
per-ex loss: 0.613497  [   32/   89]
per-ex loss: 0.619215  [   34/   89]
per-ex loss: 0.400304  [   36/   89]
per-ex loss: 0.608210  [   38/   89]
per-ex loss: 0.468233  [   40/   89]
per-ex loss: 0.613968  [   42/   89]
per-ex loss: 0.375611  [   44/   89]
per-ex loss: 0.470280  [   46/   89]
per-ex loss: 0.584756  [   48/   89]
per-ex loss: 0.518172  [   50/   89]
per-ex loss: 0.486560  [   52/   89]
per-ex loss: 0.416990  [   54/   89]
per-ex loss: 0.653600  [   56/   89]
per-ex loss: 0.460623  [   58/   89]
per-ex loss: 0.558313  [   60/   89]
per-ex loss: 0.426168  [   62/   89]
per-ex loss: 0.482197  [   64/   89]
per-ex loss: 0.378120  [   66/   89]
per-ex loss: 0.454459  [   68/   89]
per-ex loss: 0.547675  [   70/   89]
per-ex loss: 0.387732  [   72/   89]
per-ex loss: 0.644097  [   74/   89]
per-ex loss: 0.557383  [   76/   89]
per-ex loss: 0.381685  [   78/   89]
per-ex loss: 0.474499  [   80/   89]
per-ex loss: 0.529402  [   82/   89]
per-ex loss: 0.379539  [   84/   89]
per-ex loss: 0.419512  [   86/   89]
per-ex loss: 0.583604  [   88/   89]
per-ex loss: 0.583343  [   89/   89]
Train Error: Avg loss: 0.49473222
validation Error: 
 Avg loss: 0.98271389 
 F1: 0.503936 
 Precision: 0.595297 
 Recall: 0.436887
 IoU: 0.336841

test Error: 
 Avg loss: 0.97943827 
 F1: 0.522027 
 Precision: 0.631100 
 Recall: 0.445101
 IoU: 0.353205

We have finished training iteration 47
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_45_.pth
per-ex loss: 0.549914  [    2/   89]
per-ex loss: 0.414289  [    4/   89]
per-ex loss: 0.400050  [    6/   89]
per-ex loss: 0.409073  [    8/   89]
per-ex loss: 0.564913  [   10/   89]
per-ex loss: 0.489093  [   12/   89]
per-ex loss: 0.507698  [   14/   89]
per-ex loss: 0.383541  [   16/   89]
per-ex loss: 0.448766  [   18/   89]
per-ex loss: 0.554483  [   20/   89]
per-ex loss: 0.605212  [   22/   89]
per-ex loss: 0.407714  [   24/   89]
per-ex loss: 0.599022  [   26/   89]
per-ex loss: 0.635189  [   28/   89]
per-ex loss: 0.394960  [   30/   89]
per-ex loss: 0.420122  [   32/   89]
per-ex loss: 0.464029  [   34/   89]
per-ex loss: 0.602367  [   36/   89]
per-ex loss: 0.481439  [   38/   89]
per-ex loss: 0.578539  [   40/   89]
per-ex loss: 0.397109  [   42/   89]
per-ex loss: 0.461552  [   44/   89]
per-ex loss: 0.424627  [   46/   89]
per-ex loss: 0.591926  [   48/   89]
per-ex loss: 0.514509  [   50/   89]
per-ex loss: 0.500727  [   52/   89]
per-ex loss: 0.419498  [   54/   89]
per-ex loss: 0.376384  [   56/   89]
per-ex loss: 0.558729  [   58/   89]
per-ex loss: 0.465791  [   60/   89]
per-ex loss: 0.386994  [   62/   89]
per-ex loss: 0.549224  [   64/   89]
per-ex loss: 0.439873  [   66/   89]
per-ex loss: 0.416382  [   68/   89]
per-ex loss: 0.510456  [   70/   89]
per-ex loss: 0.544579  [   72/   89]
per-ex loss: 0.598889  [   74/   89]
per-ex loss: 0.418187  [   76/   89]
per-ex loss: 0.538238  [   78/   89]
per-ex loss: 0.433268  [   80/   89]
per-ex loss: 0.438829  [   82/   89]
per-ex loss: 0.637552  [   84/   89]
per-ex loss: 0.484013  [   86/   89]
per-ex loss: 0.629817  [   88/   89]
per-ex loss: 0.392192  [   89/   89]
Train Error: Avg loss: 0.48977242
validation Error: 
 Avg loss: 0.98157522 
 F1: 0.505903 
 Precision: 0.571371 
 Recall: 0.453896
 IoU: 0.338602

test Error: 
 Avg loss: 0.97988737 
 F1: 0.523823 
 Precision: 0.600958 
 Recall: 0.464237
 IoU: 0.354851

We have finished training iteration 48
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_46_.pth
per-ex loss: 0.389714  [    2/   89]
per-ex loss: 0.505343  [    4/   89]
per-ex loss: 0.370364  [    6/   89]
per-ex loss: 0.495373  [    8/   89]
per-ex loss: 0.433632  [   10/   89]
per-ex loss: 0.390414  [   12/   89]
per-ex loss: 0.663155  [   14/   89]
per-ex loss: 0.505292  [   16/   89]
per-ex loss: 0.436124  [   18/   89]
per-ex loss: 0.428482  [   20/   89]
per-ex loss: 0.522652  [   22/   89]
per-ex loss: 0.420155  [   24/   89]
per-ex loss: 0.468535  [   26/   89]
per-ex loss: 0.532795  [   28/   89]
per-ex loss: 0.548204  [   30/   89]
per-ex loss: 0.529931  [   32/   89]
per-ex loss: 0.459184  [   34/   89]
per-ex loss: 0.522422  [   36/   89]
per-ex loss: 0.499837  [   38/   89]
per-ex loss: 0.365799  [   40/   89]
per-ex loss: 0.461800  [   42/   89]
per-ex loss: 0.394375  [   44/   89]
per-ex loss: 0.421022  [   46/   89]
per-ex loss: 0.352873  [   48/   89]
per-ex loss: 0.486909  [   50/   89]
per-ex loss: 0.513952  [   52/   89]
per-ex loss: 0.470812  [   54/   89]
per-ex loss: 0.391864  [   56/   89]
per-ex loss: 0.447939  [   58/   89]
per-ex loss: 0.428986  [   60/   89]
per-ex loss: 0.470441  [   62/   89]
per-ex loss: 0.678716  [   64/   89]
per-ex loss: 0.427133  [   66/   89]
per-ex loss: 0.413712  [   68/   89]
per-ex loss: 0.536827  [   70/   89]
per-ex loss: 0.556556  [   72/   89]
per-ex loss: 0.591106  [   74/   89]
per-ex loss: 0.547584  [   76/   89]
per-ex loss: 0.461525  [   78/   89]
per-ex loss: 0.402138  [   80/   89]
per-ex loss: 0.495423  [   82/   89]
per-ex loss: 0.602309  [   84/   89]
per-ex loss: 0.474197  [   86/   89]
per-ex loss: 0.472650  [   88/   89]
per-ex loss: 0.525999  [   89/   89]
Train Error: Avg loss: 0.47809448
validation Error: 
 Avg loss: 0.98298934 
 F1: 0.504607 
 Precision: 0.570090 
 Recall: 0.452617
 IoU: 0.337441

test Error: 
 Avg loss: 0.97987080 
 F1: 0.523839 
 Precision: 0.609908 
 Recall: 0.459058
 IoU: 0.354866

We have finished training iteration 49
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_47_.pth
per-ex loss: 0.505552  [    2/   89]
per-ex loss: 0.366804  [    4/   89]
per-ex loss: 0.608761  [    6/   89]
per-ex loss: 0.415887  [    8/   89]
per-ex loss: 0.449176  [   10/   89]
per-ex loss: 0.443738  [   12/   89]
per-ex loss: 0.405230  [   14/   89]
per-ex loss: 0.604031  [   16/   89]
per-ex loss: 0.383061  [   18/   89]
per-ex loss: 0.639159  [   20/   89]
per-ex loss: 0.406431  [   22/   89]
per-ex loss: 0.453557  [   24/   89]
per-ex loss: 0.553580  [   26/   89]
per-ex loss: 0.518257  [   28/   89]
per-ex loss: 0.485907  [   30/   89]
per-ex loss: 0.493898  [   32/   89]
per-ex loss: 0.544067  [   34/   89]
per-ex loss: 0.405437  [   36/   89]
per-ex loss: 0.494689  [   38/   89]
per-ex loss: 0.555155  [   40/   89]
per-ex loss: 0.607054  [   42/   89]
per-ex loss: 0.390972  [   44/   89]
per-ex loss: 0.383369  [   46/   89]
per-ex loss: 0.396509  [   48/   89]
per-ex loss: 0.394080  [   50/   89]
per-ex loss: 0.630955  [   52/   89]
per-ex loss: 0.629356  [   54/   89]
per-ex loss: 0.480689  [   56/   89]
per-ex loss: 0.485461  [   58/   89]
per-ex loss: 0.462877  [   60/   89]
per-ex loss: 0.486915  [   62/   89]
per-ex loss: 0.428854  [   64/   89]
per-ex loss: 0.467147  [   66/   89]
per-ex loss: 0.383815  [   68/   89]
per-ex loss: 0.470604  [   70/   89]
per-ex loss: 0.583589  [   72/   89]
per-ex loss: 0.392611  [   74/   89]
per-ex loss: 0.440335  [   76/   89]
per-ex loss: 0.411143  [   78/   89]
per-ex loss: 0.548116  [   80/   89]
per-ex loss: 0.606776  [   82/   89]
per-ex loss: 0.424136  [   84/   89]
per-ex loss: 0.470647  [   86/   89]
per-ex loss: 0.390085  [   88/   89]
per-ex loss: 0.457131  [   89/   89]
Train Error: Avg loss: 0.47901340
validation Error: 
 Avg loss: 0.98329258 
 F1: 0.504859 
 Precision: 0.569664 
 Recall: 0.453292
 IoU: 0.337666

test Error: 
 Avg loss: 0.97982704 
 F1: 0.524801 
 Precision: 0.608330 
 Recall: 0.461442
 IoU: 0.355750

We have finished training iteration 50
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_48_.pth
per-ex loss: 0.353698  [    2/   89]
per-ex loss: 0.493423  [    4/   89]
per-ex loss: 0.569116  [    6/   89]
per-ex loss: 0.589576  [    8/   89]
per-ex loss: 0.444403  [   10/   89]
per-ex loss: 0.501812  [   12/   89]
per-ex loss: 0.412046  [   14/   89]
per-ex loss: 0.463514  [   16/   89]
per-ex loss: 0.697551  [   18/   89]
per-ex loss: 0.528042  [   20/   89]
per-ex loss: 0.520015  [   22/   89]
per-ex loss: 0.480535  [   24/   89]
per-ex loss: 0.592585  [   26/   89]
per-ex loss: 0.373356  [   28/   89]
per-ex loss: 0.567109  [   30/   89]
per-ex loss: 0.491947  [   32/   89]
per-ex loss: 0.428682  [   34/   89]
per-ex loss: 0.415517  [   36/   89]
per-ex loss: 0.453274  [   38/   89]
per-ex loss: 0.529519  [   40/   89]
per-ex loss: 0.566819  [   42/   89]
per-ex loss: 0.406277  [   44/   89]
per-ex loss: 0.476859  [   46/   89]
per-ex loss: 0.592074  [   48/   89]
per-ex loss: 0.488467  [   50/   89]
per-ex loss: 0.377447  [   52/   89]
per-ex loss: 0.618159  [   54/   89]
per-ex loss: 0.389276  [   56/   89]
per-ex loss: 0.462503  [   58/   89]
per-ex loss: 0.404691  [   60/   89]
per-ex loss: 0.635171  [   62/   89]
per-ex loss: 0.416222  [   64/   89]
per-ex loss: 0.412788  [   66/   89]
per-ex loss: 0.567907  [   68/   89]
per-ex loss: 0.427772  [   70/   89]
per-ex loss: 0.460184  [   72/   89]
per-ex loss: 0.460899  [   74/   89]
per-ex loss: 0.349743  [   76/   89]
per-ex loss: 0.443293  [   78/   89]
per-ex loss: 0.384174  [   80/   89]
per-ex loss: 0.441850  [   82/   89]
per-ex loss: 0.578519  [   84/   89]
per-ex loss: 0.493645  [   86/   89]
per-ex loss: 0.390819  [   88/   89]
per-ex loss: 0.622824  [   89/   89]
Train Error: Avg loss: 0.48386892
validation Error: 
 Avg loss: 0.98247477 
 F1: 0.505822 
 Precision: 0.582938 
 Recall: 0.446726
 IoU: 0.338529

test Error: 
 Avg loss: 0.97947745 
 F1: 0.521068 
 Precision: 0.606419 
 Recall: 0.456778
 IoU: 0.352327

We have finished training iteration 51
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_49_.pth
per-ex loss: 0.371842  [    2/   89]
per-ex loss: 0.437329  [    4/   89]
per-ex loss: 0.617606  [    6/   89]
per-ex loss: 0.461327  [    8/   89]
per-ex loss: 0.363459  [   10/   89]
per-ex loss: 0.419995  [   12/   89]
per-ex loss: 0.523281  [   14/   89]
per-ex loss: 0.393521  [   16/   89]
per-ex loss: 0.523593  [   18/   89]
per-ex loss: 0.425469  [   20/   89]
per-ex loss: 0.409229  [   22/   89]
per-ex loss: 0.539751  [   24/   89]
per-ex loss: 0.553384  [   26/   89]
per-ex loss: 0.668921  [   28/   89]
per-ex loss: 0.457758  [   30/   89]
per-ex loss: 0.514349  [   32/   89]
per-ex loss: 0.527695  [   34/   89]
per-ex loss: 0.420376  [   36/   89]
per-ex loss: 0.404396  [   38/   89]
per-ex loss: 0.501208  [   40/   89]
per-ex loss: 0.515485  [   42/   89]
per-ex loss: 0.569950  [   44/   89]
per-ex loss: 0.385088  [   46/   89]
per-ex loss: 0.557692  [   48/   89]
per-ex loss: 0.488744  [   50/   89]
per-ex loss: 0.448067  [   52/   89]
per-ex loss: 0.444475  [   54/   89]
per-ex loss: 0.649874  [   56/   89]
per-ex loss: 0.410059  [   58/   89]
per-ex loss: 0.519277  [   60/   89]
per-ex loss: 0.446874  [   62/   89]
per-ex loss: 0.526308  [   64/   89]
per-ex loss: 0.434559  [   66/   89]
per-ex loss: 0.416535  [   68/   89]
per-ex loss: 0.399721  [   70/   89]
per-ex loss: 0.623785  [   72/   89]
per-ex loss: 0.404230  [   74/   89]
per-ex loss: 0.573109  [   76/   89]
per-ex loss: 0.482400  [   78/   89]
per-ex loss: 0.635207  [   80/   89]
per-ex loss: 0.611707  [   82/   89]
per-ex loss: 0.431087  [   84/   89]
per-ex loss: 0.380729  [   86/   89]
per-ex loss: 0.480588  [   88/   89]
per-ex loss: 0.397937  [   89/   89]
Train Error: Avg loss: 0.48373278
validation Error: 
 Avg loss: 0.98168382 
 F1: 0.506541 
 Precision: 0.580860 
 Recall: 0.449083
 IoU: 0.339173

test Error: 
 Avg loss: 0.97991563 
 F1: 0.523911 
 Precision: 0.606655 
 Recall: 0.461029
 IoU: 0.354932

We have finished training iteration 52
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_50_.pth
per-ex loss: 0.524086  [    2/   89]
per-ex loss: 0.579013  [    4/   89]
per-ex loss: 0.451983  [    6/   89]
per-ex loss: 0.565327  [    8/   89]
per-ex loss: 0.503247  [   10/   89]
per-ex loss: 0.449103  [   12/   89]
per-ex loss: 0.640308  [   14/   89]
per-ex loss: 0.460360  [   16/   89]
per-ex loss: 0.467321  [   18/   89]
per-ex loss: 0.393638  [   20/   89]
per-ex loss: 0.623769  [   22/   89]
per-ex loss: 0.560701  [   24/   89]
per-ex loss: 0.443613  [   26/   89]
per-ex loss: 0.595382  [   28/   89]
per-ex loss: 0.448797  [   30/   89]
per-ex loss: 0.413529  [   32/   89]
per-ex loss: 0.630115  [   34/   89]
per-ex loss: 0.562567  [   36/   89]
per-ex loss: 0.380738  [   38/   89]
per-ex loss: 0.452053  [   40/   89]
per-ex loss: 0.353781  [   42/   89]
per-ex loss: 0.472775  [   44/   89]
per-ex loss: 0.375058  [   46/   89]
per-ex loss: 0.539481  [   48/   89]
per-ex loss: 0.499793  [   50/   89]
per-ex loss: 0.427547  [   52/   89]
per-ex loss: 0.402404  [   54/   89]
per-ex loss: 0.614272  [   56/   89]
per-ex loss: 0.451396  [   58/   89]
per-ex loss: 0.422644  [   60/   89]
per-ex loss: 0.508466  [   62/   89]
per-ex loss: 0.516850  [   64/   89]
per-ex loss: 0.481485  [   66/   89]
per-ex loss: 0.597576  [   68/   89]
per-ex loss: 0.491687  [   70/   89]
per-ex loss: 0.550075  [   72/   89]
per-ex loss: 0.372765  [   74/   89]
per-ex loss: 0.416609  [   76/   89]
per-ex loss: 0.507951  [   78/   89]
per-ex loss: 0.454827  [   80/   89]
per-ex loss: 0.427907  [   82/   89]
per-ex loss: 0.441982  [   84/   89]
per-ex loss: 0.396051  [   86/   89]
per-ex loss: 0.426108  [   88/   89]
per-ex loss: 0.499279  [   89/   89]
Train Error: Avg loss: 0.48432051
validation Error: 
 Avg loss: 0.98329969 
 F1: 0.506903 
 Precision: 0.562584 
 Recall: 0.461252
 IoU: 0.339498

test Error: 
 Avg loss: 0.98017753 
 F1: 0.524595 
 Precision: 0.590374 
 Recall: 0.472005
 IoU: 0.355560

We have finished training iteration 53
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_51_.pth
per-ex loss: 0.364413  [    2/   89]
per-ex loss: 0.577108  [    4/   89]
per-ex loss: 0.497898  [    6/   89]
per-ex loss: 0.655127  [    8/   89]
per-ex loss: 0.573638  [   10/   89]
per-ex loss: 0.393273  [   12/   89]
per-ex loss: 0.419866  [   14/   89]
per-ex loss: 0.452544  [   16/   89]
per-ex loss: 0.396627  [   18/   89]
per-ex loss: 0.391082  [   20/   89]
per-ex loss: 0.667395  [   22/   89]
per-ex loss: 0.385535  [   24/   89]
per-ex loss: 0.434491  [   26/   89]
per-ex loss: 0.361244  [   28/   89]
per-ex loss: 0.531266  [   30/   89]
per-ex loss: 0.474028  [   32/   89]
per-ex loss: 0.597565  [   34/   89]
per-ex loss: 0.463511  [   36/   89]
per-ex loss: 0.417514  [   38/   89]
per-ex loss: 0.434194  [   40/   89]
per-ex loss: 0.387829  [   42/   89]
per-ex loss: 0.551785  [   44/   89]
per-ex loss: 0.418884  [   46/   89]
per-ex loss: 0.438979  [   48/   89]
per-ex loss: 0.528941  [   50/   89]
per-ex loss: 0.516194  [   52/   89]
per-ex loss: 0.633631  [   54/   89]
per-ex loss: 0.438643  [   56/   89]
per-ex loss: 0.573468  [   58/   89]
per-ex loss: 0.382690  [   60/   89]
per-ex loss: 0.411147  [   62/   89]
per-ex loss: 0.393294  [   64/   89]
per-ex loss: 0.603238  [   66/   89]
per-ex loss: 0.404925  [   68/   89]
per-ex loss: 0.522380  [   70/   89]
per-ex loss: 0.435360  [   72/   89]
per-ex loss: 0.442316  [   74/   89]
per-ex loss: 0.622413  [   76/   89]
per-ex loss: 0.515724  [   78/   89]
per-ex loss: 0.507581  [   80/   89]
per-ex loss: 0.435895  [   82/   89]
per-ex loss: 0.436632  [   84/   89]
per-ex loss: 0.608403  [   86/   89]
per-ex loss: 0.527090  [   88/   89]
per-ex loss: 0.438789  [   89/   89]
Train Error: Avg loss: 0.48143434
validation Error: 
 Avg loss: 0.98119244 
 F1: 0.504677 
 Precision: 0.611709 
 Recall: 0.429522
 IoU: 0.337504

test Error: 
 Avg loss: 0.97888308 
 F1: 0.521811 
 Precision: 0.641785 
 Recall: 0.439628
 IoU: 0.353007

We have finished training iteration 54
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_52_.pth
per-ex loss: 0.396065  [    2/   89]
per-ex loss: 0.639384  [    4/   89]
per-ex loss: 0.573561  [    6/   89]
per-ex loss: 0.385613  [    8/   89]
per-ex loss: 0.348646  [   10/   89]
per-ex loss: 0.504472  [   12/   89]
per-ex loss: 0.563173  [   14/   89]
per-ex loss: 0.433662  [   16/   89]
per-ex loss: 0.459218  [   18/   89]
per-ex loss: 0.526144  [   20/   89]
per-ex loss: 0.451791  [   22/   89]
per-ex loss: 0.440134  [   24/   89]
per-ex loss: 0.449783  [   26/   89]
per-ex loss: 0.433195  [   28/   89]
per-ex loss: 0.548923  [   30/   89]
per-ex loss: 0.657568  [   32/   89]
per-ex loss: 0.583961  [   34/   89]
per-ex loss: 0.640619  [   36/   89]
per-ex loss: 0.560024  [   38/   89]
per-ex loss: 0.402132  [   40/   89]
per-ex loss: 0.451959  [   42/   89]
per-ex loss: 0.560856  [   44/   89]
per-ex loss: 0.632239  [   46/   89]
per-ex loss: 0.495735  [   48/   89]
per-ex loss: 0.604720  [   50/   89]
per-ex loss: 0.551551  [   52/   89]
per-ex loss: 0.486127  [   54/   89]
per-ex loss: 0.436121  [   56/   89]
per-ex loss: 0.533571  [   58/   89]
per-ex loss: 0.501545  [   60/   89]
per-ex loss: 0.429902  [   62/   89]
per-ex loss: 0.396522  [   64/   89]
per-ex loss: 0.545171  [   66/   89]
per-ex loss: 0.500401  [   68/   89]
per-ex loss: 0.531677  [   70/   89]
per-ex loss: 0.538045  [   72/   89]
per-ex loss: 0.452417  [   74/   89]
per-ex loss: 0.460017  [   76/   89]
per-ex loss: 0.378672  [   78/   89]
per-ex loss: 0.419934  [   80/   89]
per-ex loss: 0.396955  [   82/   89]
per-ex loss: 0.423744  [   84/   89]
per-ex loss: 0.437155  [   86/   89]
per-ex loss: 0.509546  [   88/   89]
per-ex loss: 0.530654  [   89/   89]
Train Error: Avg loss: 0.49340676
validation Error: 
 Avg loss: 0.98239888 
 F1: 0.505955 
 Precision: 0.592989 
 Recall: 0.441199
 IoU: 0.338648

test Error: 
 Avg loss: 0.97980579 
 F1: 0.521624 
 Precision: 0.625919 
 Recall: 0.447121
 IoU: 0.352836

We have finished training iteration 55
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_53_.pth
per-ex loss: 0.433645  [    2/   89]
per-ex loss: 0.364612  [    4/   89]
per-ex loss: 0.521197  [    6/   89]
per-ex loss: 0.446479  [    8/   89]
per-ex loss: 0.480366  [   10/   89]
per-ex loss: 0.394591  [   12/   89]
per-ex loss: 0.549733  [   14/   89]
per-ex loss: 0.446658  [   16/   89]
per-ex loss: 0.560966  [   18/   89]
per-ex loss: 0.428154  [   20/   89]
per-ex loss: 0.389705  [   22/   89]
per-ex loss: 0.499932  [   24/   89]
per-ex loss: 0.473443  [   26/   89]
per-ex loss: 0.579534  [   28/   89]
per-ex loss: 0.633351  [   30/   89]
per-ex loss: 0.589555  [   32/   89]
per-ex loss: 0.447464  [   34/   89]
per-ex loss: 0.425251  [   36/   89]
per-ex loss: 0.434052  [   38/   89]
per-ex loss: 0.380618  [   40/   89]
per-ex loss: 0.402464  [   42/   89]
per-ex loss: 0.364291  [   44/   89]
per-ex loss: 0.586481  [   46/   89]
per-ex loss: 0.531139  [   48/   89]
per-ex loss: 0.379450  [   50/   89]
per-ex loss: 0.544679  [   52/   89]
per-ex loss: 0.522153  [   54/   89]
per-ex loss: 0.611815  [   56/   89]
per-ex loss: 0.380536  [   58/   89]
per-ex loss: 0.593345  [   60/   89]
per-ex loss: 0.398630  [   62/   89]
per-ex loss: 0.388355  [   64/   89]
per-ex loss: 0.404465  [   66/   89]
per-ex loss: 0.373482  [   68/   89]
per-ex loss: 0.375598  [   70/   89]
per-ex loss: 0.530169  [   72/   89]
per-ex loss: 0.418442  [   74/   89]
per-ex loss: 0.422693  [   76/   89]
per-ex loss: 0.538547  [   78/   89]
per-ex loss: 0.437435  [   80/   89]
per-ex loss: 0.456568  [   82/   89]
per-ex loss: 0.551364  [   84/   89]
per-ex loss: 0.396169  [   86/   89]
per-ex loss: 0.457933  [   88/   89]
per-ex loss: 0.496035  [   89/   89]
Train Error: Avg loss: 0.46758986
validation Error: 
 Avg loss: 0.98259560 
 F1: 0.507729 
 Precision: 0.575394 
 Recall: 0.454303
 IoU: 0.340239

test Error: 
 Avg loss: 0.98016576 
 F1: 0.525985 
 Precision: 0.606275 
 Recall: 0.464473
 IoU: 0.356838

We have finished training iteration 56
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_54_.pth
per-ex loss: 0.457639  [    2/   89]
per-ex loss: 0.459195  [    4/   89]
per-ex loss: 0.442485  [    6/   89]
per-ex loss: 0.425838  [    8/   89]
per-ex loss: 0.381629  [   10/   89]
per-ex loss: 0.418948  [   12/   89]
per-ex loss: 0.550389  [   14/   89]
per-ex loss: 0.393323  [   16/   89]
per-ex loss: 0.444377  [   18/   89]
per-ex loss: 0.529148  [   20/   89]
per-ex loss: 0.431277  [   22/   89]
per-ex loss: 0.394209  [   24/   89]
per-ex loss: 0.438324  [   26/   89]
per-ex loss: 0.515499  [   28/   89]
per-ex loss: 0.464200  [   30/   89]
per-ex loss: 0.512558  [   32/   89]
per-ex loss: 0.445625  [   34/   89]
per-ex loss: 0.415945  [   36/   89]
per-ex loss: 0.476308  [   38/   89]
per-ex loss: 0.449342  [   40/   89]
per-ex loss: 0.596144  [   42/   89]
per-ex loss: 0.489497  [   44/   89]
per-ex loss: 0.504593  [   46/   89]
per-ex loss: 0.424528  [   48/   89]
per-ex loss: 0.573230  [   50/   89]
per-ex loss: 0.525418  [   52/   89]
per-ex loss: 0.591253  [   54/   89]
per-ex loss: 0.395270  [   56/   89]
per-ex loss: 0.516646  [   58/   89]
per-ex loss: 0.426420  [   60/   89]
per-ex loss: 0.526909  [   62/   89]
per-ex loss: 0.428549  [   64/   89]
per-ex loss: 0.465972  [   66/   89]
per-ex loss: 0.610279  [   68/   89]
per-ex loss: 0.604192  [   70/   89]
per-ex loss: 0.367914  [   72/   89]
per-ex loss: 0.454009  [   74/   89]
per-ex loss: 0.387166  [   76/   89]
per-ex loss: 0.448792  [   78/   89]
per-ex loss: 0.471557  [   80/   89]
per-ex loss: 0.606667  [   82/   89]
per-ex loss: 0.483881  [   84/   89]
per-ex loss: 0.433876  [   86/   89]
per-ex loss: 0.444393  [   88/   89]
per-ex loss: 0.571240  [   89/   89]
Train Error: Avg loss: 0.47543674
validation Error: 
 Avg loss: 0.98302408 
 F1: 0.507779 
 Precision: 0.573751 
 Recall: 0.455414
 IoU: 0.340284

test Error: 
 Avg loss: 0.98012677 
 F1: 0.527348 
 Precision: 0.608789 
 Recall: 0.465125
 IoU: 0.358094

We have finished training iteration 57
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_55_.pth
per-ex loss: 0.425816  [    2/   89]
per-ex loss: 0.512861  [    4/   89]
per-ex loss: 0.377610  [    6/   89]
per-ex loss: 0.565805  [    8/   89]
per-ex loss: 0.537929  [   10/   89]
per-ex loss: 0.418925  [   12/   89]
per-ex loss: 0.580343  [   14/   89]
per-ex loss: 0.473150  [   16/   89]
per-ex loss: 0.503510  [   18/   89]
per-ex loss: 0.434084  [   20/   89]
per-ex loss: 0.356418  [   22/   89]
per-ex loss: 0.432921  [   24/   89]
per-ex loss: 0.642943  [   26/   89]
per-ex loss: 0.467167  [   28/   89]
per-ex loss: 0.377150  [   30/   89]
per-ex loss: 0.427789  [   32/   89]
per-ex loss: 0.446224  [   34/   89]
per-ex loss: 0.586852  [   36/   89]
per-ex loss: 0.616537  [   38/   89]
per-ex loss: 0.442451  [   40/   89]
per-ex loss: 0.378681  [   42/   89]
per-ex loss: 0.496343  [   44/   89]
per-ex loss: 0.459226  [   46/   89]
per-ex loss: 0.437271  [   48/   89]
per-ex loss: 0.461653  [   50/   89]
per-ex loss: 0.362568  [   52/   89]
per-ex loss: 0.454704  [   54/   89]
per-ex loss: 0.477154  [   56/   89]
per-ex loss: 0.471350  [   58/   89]
per-ex loss: 0.433396  [   60/   89]
per-ex loss: 0.554058  [   62/   89]
per-ex loss: 0.625704  [   64/   89]
per-ex loss: 0.463073  [   66/   89]
per-ex loss: 0.528625  [   68/   89]
per-ex loss: 0.454863  [   70/   89]
per-ex loss: 0.475232  [   72/   89]
per-ex loss: 0.475005  [   74/   89]
per-ex loss: 0.467080  [   76/   89]
per-ex loss: 0.603001  [   78/   89]
per-ex loss: 0.394368  [   80/   89]
per-ex loss: 0.428374  [   82/   89]
per-ex loss: 0.403410  [   84/   89]
per-ex loss: 0.349443  [   86/   89]
per-ex loss: 0.400436  [   88/   89]
per-ex loss: 0.672533  [   89/   89]
Train Error: Avg loss: 0.47453416
validation Error: 
 Avg loss: 0.98386036 
 F1: 0.508686 
 Precision: 0.554910 
 Recall: 0.469570
 IoU: 0.341099

test Error: 
 Avg loss: 0.98082523 
 F1: 0.526919 
 Precision: 0.584585 
 Recall: 0.479608
 IoU: 0.357698

We have finished training iteration 58
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_56_.pth
per-ex loss: 0.442731  [    2/   89]
per-ex loss: 0.517126  [    4/   89]
per-ex loss: 0.492618  [    6/   89]
per-ex loss: 0.423520  [    8/   89]
per-ex loss: 0.477746  [   10/   89]
per-ex loss: 0.413119  [   12/   89]
per-ex loss: 0.444997  [   14/   89]
per-ex loss: 0.484079  [   16/   89]
per-ex loss: 0.526416  [   18/   89]
per-ex loss: 0.606999  [   20/   89]
per-ex loss: 0.590706  [   22/   89]
per-ex loss: 0.571361  [   24/   89]
per-ex loss: 0.540561  [   26/   89]
per-ex loss: 0.378009  [   28/   89]
per-ex loss: 0.383043  [   30/   89]
per-ex loss: 0.610083  [   32/   89]
per-ex loss: 0.602861  [   34/   89]
per-ex loss: 0.652095  [   36/   89]
per-ex loss: 0.420499  [   38/   89]
per-ex loss: 0.420142  [   40/   89]
per-ex loss: 0.395827  [   42/   89]
per-ex loss: 0.509814  [   44/   89]
per-ex loss: 0.579098  [   46/   89]
per-ex loss: 0.391790  [   48/   89]
per-ex loss: 0.473237  [   50/   89]
per-ex loss: 0.596273  [   52/   89]
per-ex loss: 0.534065  [   54/   89]
per-ex loss: 0.511316  [   56/   89]
per-ex loss: 0.468046  [   58/   89]
per-ex loss: 0.444654  [   60/   89]
per-ex loss: 0.400606  [   62/   89]
per-ex loss: 0.394275  [   64/   89]
per-ex loss: 0.485478  [   66/   89]
per-ex loss: 0.511940  [   68/   89]
per-ex loss: 0.519319  [   70/   89]
per-ex loss: 0.436603  [   72/   89]
per-ex loss: 0.445425  [   74/   89]
per-ex loss: 0.361743  [   76/   89]
per-ex loss: 0.427149  [   78/   89]
per-ex loss: 0.421337  [   80/   89]
per-ex loss: 0.445886  [   82/   89]
per-ex loss: 0.502709  [   84/   89]
per-ex loss: 0.583262  [   86/   89]
per-ex loss: 0.381723  [   88/   89]
per-ex loss: 0.392784  [   89/   89]
Train Error: Avg loss: 0.48029047
validation Error: 
 Avg loss: 0.98313137 
 F1: 0.509145 
 Precision: 0.570413 
 Recall: 0.459762
 IoU: 0.341512

test Error: 
 Avg loss: 0.97999931 
 F1: 0.527468 
 Precision: 0.598694 
 Recall: 0.471388
 IoU: 0.358205

We have finished training iteration 59
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_57_.pth
per-ex loss: 0.416284  [    2/   89]
per-ex loss: 0.409922  [    4/   89]
per-ex loss: 0.470901  [    6/   89]
per-ex loss: 0.567432  [    8/   89]
per-ex loss: 0.582972  [   10/   89]
per-ex loss: 0.463394  [   12/   89]
per-ex loss: 0.416116  [   14/   89]
per-ex loss: 0.432612  [   16/   89]
per-ex loss: 0.393527  [   18/   89]
per-ex loss: 0.430105  [   20/   89]
per-ex loss: 0.606293  [   22/   89]
per-ex loss: 0.447786  [   24/   89]
per-ex loss: 0.611897  [   26/   89]
per-ex loss: 0.451995  [   28/   89]
per-ex loss: 0.431400  [   30/   89]
per-ex loss: 0.567418  [   32/   89]
per-ex loss: 0.377821  [   34/   89]
per-ex loss: 0.480400  [   36/   89]
per-ex loss: 0.484904  [   38/   89]
per-ex loss: 0.379068  [   40/   89]
per-ex loss: 0.572311  [   42/   89]
per-ex loss: 0.660979  [   44/   89]
per-ex loss: 0.533717  [   46/   89]
per-ex loss: 0.435259  [   48/   89]
per-ex loss: 0.562179  [   50/   89]
per-ex loss: 0.426699  [   52/   89]
per-ex loss: 0.675892  [   54/   89]
per-ex loss: 0.525846  [   56/   89]
per-ex loss: 0.673646  [   58/   89]
per-ex loss: 0.640582  [   60/   89]
per-ex loss: 0.449107  [   62/   89]
per-ex loss: 0.495472  [   64/   89]
per-ex loss: 0.402241  [   66/   89]
per-ex loss: 0.463715  [   68/   89]
per-ex loss: 0.429447  [   70/   89]
per-ex loss: 0.397972  [   72/   89]
per-ex loss: 0.373377  [   74/   89]
per-ex loss: 0.359996  [   76/   89]
per-ex loss: 0.576253  [   78/   89]
per-ex loss: 0.480332  [   80/   89]
per-ex loss: 0.485545  [   82/   89]
per-ex loss: 0.401594  [   84/   89]
per-ex loss: 0.468208  [   86/   89]
per-ex loss: 0.426052  [   88/   89]
per-ex loss: 0.479503  [   89/   89]
Train Error: Avg loss: 0.48484823
validation Error: 
 Avg loss: 0.98274614 
 F1: 0.508287 
 Precision: 0.590304 
 Recall: 0.446281
 IoU: 0.340740

test Error: 
 Avg loss: 0.97985040 
 F1: 0.522697 
 Precision: 0.621756 
 Recall: 0.450865
 IoU: 0.353819

We have finished training iteration 60
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_58_.pth
per-ex loss: 0.657346  [    2/   89]
per-ex loss: 0.486736  [    4/   89]
per-ex loss: 0.477930  [    6/   89]
per-ex loss: 0.535495  [    8/   89]
per-ex loss: 0.423920  [   10/   89]
per-ex loss: 0.518359  [   12/   89]
per-ex loss: 0.531993  [   14/   89]
per-ex loss: 0.454852  [   16/   89]
per-ex loss: 0.478519  [   18/   89]
per-ex loss: 0.501654  [   20/   89]
per-ex loss: 0.562131  [   22/   89]
per-ex loss: 0.580125  [   24/   89]
per-ex loss: 0.520336  [   26/   89]
per-ex loss: 0.437117  [   28/   89]
per-ex loss: 0.398488  [   30/   89]
per-ex loss: 0.464249  [   32/   89]
per-ex loss: 0.479000  [   34/   89]
per-ex loss: 0.564349  [   36/   89]
per-ex loss: 0.404281  [   38/   89]
per-ex loss: 0.548787  [   40/   89]
per-ex loss: 0.508726  [   42/   89]
per-ex loss: 0.376593  [   44/   89]
per-ex loss: 0.576188  [   46/   89]
per-ex loss: 0.468919  [   48/   89]
per-ex loss: 0.420035  [   50/   89]
per-ex loss: 0.457402  [   52/   89]
per-ex loss: 0.456798  [   54/   89]
per-ex loss: 0.397004  [   56/   89]
per-ex loss: 0.403663  [   58/   89]
per-ex loss: 0.535560  [   60/   89]
per-ex loss: 0.636103  [   62/   89]
per-ex loss: 0.350363  [   64/   89]
per-ex loss: 0.430145  [   66/   89]
per-ex loss: 0.409918  [   68/   89]
per-ex loss: 0.493957  [   70/   89]
per-ex loss: 0.528430  [   72/   89]
per-ex loss: 0.430171  [   74/   89]
per-ex loss: 0.387095  [   76/   89]
per-ex loss: 0.443936  [   78/   89]
per-ex loss: 0.534176  [   80/   89]
per-ex loss: 0.533002  [   82/   89]
per-ex loss: 0.482973  [   84/   89]
per-ex loss: 0.364364  [   86/   89]
per-ex loss: 0.570007  [   88/   89]
per-ex loss: 0.418814  [   89/   89]
Train Error: Avg loss: 0.48088904
validation Error: 
 Avg loss: 0.98276832 
 F1: 0.509594 
 Precision: 0.588744 
 Recall: 0.449204
 IoU: 0.341917

test Error: 
 Avg loss: 0.97949830 
 F1: 0.528796 
 Precision: 0.622159 
 Recall: 0.459798
 IoU: 0.359431

We have finished training iteration 61
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_59_.pth
per-ex loss: 0.395903  [    2/   89]
per-ex loss: 0.384620  [    4/   89]
per-ex loss: 0.417675  [    6/   89]
per-ex loss: 0.385311  [    8/   89]
per-ex loss: 0.577564  [   10/   89]
per-ex loss: 0.414604  [   12/   89]
per-ex loss: 0.459541  [   14/   89]
per-ex loss: 0.449102  [   16/   89]
per-ex loss: 0.373214  [   18/   89]
per-ex loss: 0.587061  [   20/   89]
per-ex loss: 0.446884  [   22/   89]
per-ex loss: 0.574067  [   24/   89]
per-ex loss: 0.595781  [   26/   89]
per-ex loss: 0.574224  [   28/   89]
per-ex loss: 0.570246  [   30/   89]
per-ex loss: 0.592684  [   32/   89]
per-ex loss: 0.467387  [   34/   89]
per-ex loss: 0.430070  [   36/   89]
per-ex loss: 0.503216  [   38/   89]
per-ex loss: 0.445410  [   40/   89]
per-ex loss: 0.592200  [   42/   89]
per-ex loss: 0.628805  [   44/   89]
per-ex loss: 0.463797  [   46/   89]
per-ex loss: 0.521915  [   48/   89]
per-ex loss: 0.561832  [   50/   89]
per-ex loss: 0.441247  [   52/   89]
per-ex loss: 0.484291  [   54/   89]
per-ex loss: 0.373199  [   56/   89]
per-ex loss: 0.583373  [   58/   89]
per-ex loss: 0.380116  [   60/   89]
per-ex loss: 0.619672  [   62/   89]
per-ex loss: 0.410766  [   64/   89]
per-ex loss: 0.586553  [   66/   89]
per-ex loss: 0.505005  [   68/   89]
per-ex loss: 0.379309  [   70/   89]
per-ex loss: 0.380831  [   72/   89]
per-ex loss: 0.422121  [   74/   89]
per-ex loss: 0.424176  [   76/   89]
per-ex loss: 0.366760  [   78/   89]
per-ex loss: 0.378120  [   80/   89]
per-ex loss: 0.417022  [   82/   89]
per-ex loss: 0.460030  [   84/   89]
per-ex loss: 0.564890  [   86/   89]
per-ex loss: 0.412337  [   88/   89]
per-ex loss: 0.424088  [   89/   89]
Train Error: Avg loss: 0.47615597
validation Error: 
 Avg loss: 0.98242115 
 F1: 0.506854 
 Precision: 0.567120 
 Recall: 0.458167
 IoU: 0.339454

test Error: 
 Avg loss: 0.97997370 
 F1: 0.523604 
 Precision: 0.597841 
 Recall: 0.465767
 IoU: 0.354650

We have finished training iteration 62
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_60_.pth
per-ex loss: 0.541752  [    2/   89]
per-ex loss: 0.541489  [    4/   89]
per-ex loss: 0.456407  [    6/   89]
per-ex loss: 0.529312  [    8/   89]
per-ex loss: 0.440234  [   10/   89]
per-ex loss: 0.379260  [   12/   89]
per-ex loss: 0.441388  [   14/   89]
per-ex loss: 0.421386  [   16/   89]
per-ex loss: 0.547899  [   18/   89]
per-ex loss: 0.448554  [   20/   89]
per-ex loss: 0.371903  [   22/   89]
per-ex loss: 0.426726  [   24/   89]
per-ex loss: 0.430798  [   26/   89]
per-ex loss: 0.465178  [   28/   89]
per-ex loss: 0.418907  [   30/   89]
per-ex loss: 0.425222  [   32/   89]
per-ex loss: 0.578232  [   34/   89]
per-ex loss: 0.433617  [   36/   89]
per-ex loss: 0.545304  [   38/   89]
per-ex loss: 0.453237  [   40/   89]
per-ex loss: 0.482270  [   42/   89]
per-ex loss: 0.414792  [   44/   89]
per-ex loss: 0.466824  [   46/   89]
per-ex loss: 0.656033  [   48/   89]
per-ex loss: 0.398713  [   50/   89]
per-ex loss: 0.401556  [   52/   89]
per-ex loss: 0.431710  [   54/   89]
per-ex loss: 0.525554  [   56/   89]
per-ex loss: 0.413379  [   58/   89]
per-ex loss: 0.400774  [   60/   89]
per-ex loss: 0.551823  [   62/   89]
per-ex loss: 0.470474  [   64/   89]
per-ex loss: 0.473829  [   66/   89]
per-ex loss: 0.416534  [   68/   89]
per-ex loss: 0.547893  [   70/   89]
per-ex loss: 0.418661  [   72/   89]
per-ex loss: 0.476941  [   74/   89]
per-ex loss: 0.630208  [   76/   89]
per-ex loss: 0.595325  [   78/   89]
per-ex loss: 0.417876  [   80/   89]
per-ex loss: 0.586493  [   82/   89]
per-ex loss: 0.398175  [   84/   89]
per-ex loss: 0.417022  [   86/   89]
per-ex loss: 0.456387  [   88/   89]
per-ex loss: 0.504130  [   89/   89]
Train Error: Avg loss: 0.47222627
validation Error: 
 Avg loss: 0.98288529 
 F1: 0.509464 
 Precision: 0.584816 
 Recall: 0.451314
 IoU: 0.341799

test Error: 
 Avg loss: 0.97977254 
 F1: 0.525899 
 Precision: 0.611207 
 Recall: 0.461487
 IoU: 0.356759

We have finished training iteration 63
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_61_.pth
per-ex loss: 0.548189  [    2/   89]
per-ex loss: 0.506123  [    4/   89]
per-ex loss: 0.588716  [    6/   89]
per-ex loss: 0.436158  [    8/   89]
per-ex loss: 0.410545  [   10/   89]
per-ex loss: 0.443543  [   12/   89]
per-ex loss: 0.391969  [   14/   89]
per-ex loss: 0.455435  [   16/   89]
per-ex loss: 0.614627  [   18/   89]
per-ex loss: 0.558645  [   20/   89]
per-ex loss: 0.509711  [   22/   89]
per-ex loss: 0.534743  [   24/   89]
per-ex loss: 0.399940  [   26/   89]
per-ex loss: 0.390866  [   28/   89]
per-ex loss: 0.516700  [   30/   89]
per-ex loss: 0.439231  [   32/   89]
per-ex loss: 0.473908  [   34/   89]
per-ex loss: 0.587945  [   36/   89]
per-ex loss: 0.479270  [   38/   89]
per-ex loss: 0.665871  [   40/   89]
per-ex loss: 0.425958  [   42/   89]
per-ex loss: 0.580117  [   44/   89]
per-ex loss: 0.420909  [   46/   89]
per-ex loss: 0.419622  [   48/   89]
per-ex loss: 0.422872  [   50/   89]
per-ex loss: 0.507729  [   52/   89]
per-ex loss: 0.456745  [   54/   89]
per-ex loss: 0.411201  [   56/   89]
per-ex loss: 0.451769  [   58/   89]
per-ex loss: 0.524165  [   60/   89]
per-ex loss: 0.594343  [   62/   89]
per-ex loss: 0.484455  [   64/   89]
per-ex loss: 0.488837  [   66/   89]
per-ex loss: 0.434850  [   68/   89]
per-ex loss: 0.423990  [   70/   89]
per-ex loss: 0.487092  [   72/   89]
per-ex loss: 0.379536  [   74/   89]
per-ex loss: 0.586657  [   76/   89]
per-ex loss: 0.613342  [   78/   89]
per-ex loss: 0.466797  [   80/   89]
per-ex loss: 0.450259  [   82/   89]
per-ex loss: 0.386478  [   84/   89]
per-ex loss: 0.488376  [   86/   89]
per-ex loss: 0.519092  [   88/   89]
per-ex loss: 0.446780  [   89/   89]
Train Error: Avg loss: 0.48498018
validation Error: 
 Avg loss: 0.98216820 
 F1: 0.512467 
 Precision: 0.560913 
 Recall: 0.471725
 IoU: 0.344508

test Error: 
 Avg loss: 0.98078166 
 F1: 0.532294 
 Precision: 0.584344 
 Recall: 0.488759
 IoU: 0.362671

We have finished training iteration 64
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_62_.pth
per-ex loss: 0.524673  [    2/   89]
per-ex loss: 0.409224  [    4/   89]
per-ex loss: 0.458862  [    6/   89]
per-ex loss: 0.593157  [    8/   89]
per-ex loss: 0.453604  [   10/   89]
per-ex loss: 0.419171  [   12/   89]
per-ex loss: 0.452245  [   14/   89]
per-ex loss: 0.472363  [   16/   89]
per-ex loss: 0.408954  [   18/   89]
per-ex loss: 0.379447  [   20/   89]
per-ex loss: 0.512079  [   22/   89]
per-ex loss: 0.456213  [   24/   89]
per-ex loss: 0.430103  [   26/   89]
per-ex loss: 0.595375  [   28/   89]
per-ex loss: 0.449652  [   30/   89]
per-ex loss: 0.568384  [   32/   89]
per-ex loss: 0.409832  [   34/   89]
per-ex loss: 0.442724  [   36/   89]
per-ex loss: 0.408414  [   38/   89]
per-ex loss: 0.388442  [   40/   89]
per-ex loss: 0.466618  [   42/   89]
per-ex loss: 0.408439  [   44/   89]
per-ex loss: 0.417989  [   46/   89]
per-ex loss: 0.536142  [   48/   89]
per-ex loss: 0.512054  [   50/   89]
per-ex loss: 0.430483  [   52/   89]
per-ex loss: 0.485846  [   54/   89]
per-ex loss: 0.416983  [   56/   89]
per-ex loss: 0.464081  [   58/   89]
per-ex loss: 0.615590  [   60/   89]
per-ex loss: 0.445223  [   62/   89]
per-ex loss: 0.469309  [   64/   89]
per-ex loss: 0.620489  [   66/   89]
per-ex loss: 0.427710  [   68/   89]
per-ex loss: 0.412192  [   70/   89]
per-ex loss: 0.549818  [   72/   89]
per-ex loss: 0.408696  [   74/   89]
per-ex loss: 0.595798  [   76/   89]
per-ex loss: 0.436271  [   78/   89]
per-ex loss: 0.370664  [   80/   89]
per-ex loss: 0.538337  [   82/   89]
per-ex loss: 0.417535  [   84/   89]
per-ex loss: 0.478137  [   86/   89]
per-ex loss: 0.451399  [   88/   89]
per-ex loss: 0.352221  [   89/   89]
Train Error: Avg loss: 0.46579876
validation Error: 
 Avg loss: 0.98409302 
 F1: 0.509705 
 Precision: 0.564111 
 Recall: 0.464870
 IoU: 0.342016

test Error: 
 Avg loss: 0.98115945 
 F1: 0.526963 
 Precision: 0.591641 
 Recall: 0.475032
 IoU: 0.357739

We have finished training iteration 65
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_63_.pth
per-ex loss: 0.679234  [    2/   89]
per-ex loss: 0.448808  [    4/   89]
per-ex loss: 0.407844  [    6/   89]
per-ex loss: 0.460084  [    8/   89]
per-ex loss: 0.449937  [   10/   89]
per-ex loss: 0.381518  [   12/   89]
per-ex loss: 0.442498  [   14/   89]
per-ex loss: 0.444160  [   16/   89]
per-ex loss: 0.412600  [   18/   89]
per-ex loss: 0.405346  [   20/   89]
per-ex loss: 0.525014  [   22/   89]
per-ex loss: 0.713130  [   24/   89]
per-ex loss: 0.473222  [   26/   89]
per-ex loss: 0.534863  [   28/   89]
per-ex loss: 0.410994  [   30/   89]
per-ex loss: 0.462013  [   32/   89]
per-ex loss: 0.374639  [   34/   89]
per-ex loss: 0.450130  [   36/   89]
per-ex loss: 0.552145  [   38/   89]
per-ex loss: 0.509916  [   40/   89]
per-ex loss: 0.662331  [   42/   89]
per-ex loss: 0.342610  [   44/   89]
per-ex loss: 0.503167  [   46/   89]
per-ex loss: 0.401078  [   48/   89]
per-ex loss: 0.707297  [   50/   89]
per-ex loss: 0.521697  [   52/   89]
per-ex loss: 0.367846  [   54/   89]
per-ex loss: 0.527071  [   56/   89]
per-ex loss: 0.444510  [   58/   89]
per-ex loss: 0.369014  [   60/   89]
per-ex loss: 0.423066  [   62/   89]
per-ex loss: 0.527097  [   64/   89]
per-ex loss: 0.538244  [   66/   89]
per-ex loss: 0.476247  [   68/   89]
per-ex loss: 0.454969  [   70/   89]
per-ex loss: 0.560301  [   72/   89]
per-ex loss: 0.481822  [   74/   89]
per-ex loss: 0.353740  [   76/   89]
per-ex loss: 0.581793  [   78/   89]
per-ex loss: 0.485558  [   80/   89]
per-ex loss: 0.417225  [   82/   89]
per-ex loss: 0.475347  [   84/   89]
per-ex loss: 0.420217  [   86/   89]
per-ex loss: 0.505594  [   88/   89]
per-ex loss: 0.523749  [   89/   89]
Train Error: Avg loss: 0.48021521
validation Error: 
 Avg loss: 0.98165386 
 F1: 0.511630 
 Precision: 0.602011 
 Recall: 0.444845
 IoU: 0.343752

test Error: 
 Avg loss: 0.97929483 
 F1: 0.527564 
 Precision: 0.626981 
 Recall: 0.455359
 IoU: 0.358293

We have finished training iteration 66
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_64_.pth
per-ex loss: 0.433832  [    2/   89]
per-ex loss: 0.401142  [    4/   89]
per-ex loss: 0.559818  [    6/   89]
per-ex loss: 0.567932  [    8/   89]
per-ex loss: 0.565157  [   10/   89]
per-ex loss: 0.585090  [   12/   89]
per-ex loss: 0.441876  [   14/   89]
per-ex loss: 0.441847  [   16/   89]
per-ex loss: 0.508476  [   18/   89]
per-ex loss: 0.495682  [   20/   89]
per-ex loss: 0.431463  [   22/   89]
per-ex loss: 0.609898  [   24/   89]
per-ex loss: 0.604388  [   26/   89]
per-ex loss: 0.494707  [   28/   89]
per-ex loss: 0.568650  [   30/   89]
per-ex loss: 0.452932  [   32/   89]
per-ex loss: 0.478630  [   34/   89]
per-ex loss: 0.387236  [   36/   89]
per-ex loss: 0.334881  [   38/   89]
per-ex loss: 0.470088  [   40/   89]
per-ex loss: 0.428359  [   42/   89]
per-ex loss: 0.426114  [   44/   89]
per-ex loss: 0.555022  [   46/   89]
per-ex loss: 0.424672  [   48/   89]
per-ex loss: 0.445808  [   50/   89]
per-ex loss: 0.458935  [   52/   89]
per-ex loss: 0.501015  [   54/   89]
per-ex loss: 0.405919  [   56/   89]
per-ex loss: 0.542404  [   58/   89]
per-ex loss: 0.414386  [   60/   89]
per-ex loss: 0.496036  [   62/   89]
per-ex loss: 0.509872  [   64/   89]
per-ex loss: 0.468656  [   66/   89]
per-ex loss: 0.380826  [   68/   89]
per-ex loss: 0.619153  [   70/   89]
per-ex loss: 0.542731  [   72/   89]
per-ex loss: 0.473857  [   74/   89]
per-ex loss: 0.378743  [   76/   89]
per-ex loss: 0.502140  [   78/   89]
per-ex loss: 0.522246  [   80/   89]
per-ex loss: 0.560561  [   82/   89]
per-ex loss: 0.360420  [   84/   89]
per-ex loss: 0.580006  [   86/   89]
per-ex loss: 0.398165  [   88/   89]
per-ex loss: 0.447944  [   89/   89]
Train Error: Avg loss: 0.48172693
validation Error: 
 Avg loss: 0.98225931 
 F1: 0.511231 
 Precision: 0.563955 
 Recall: 0.467522
 IoU: 0.343392

test Error: 
 Avg loss: 0.98071478 
 F1: 0.529784 
 Precision: 0.592393 
 Recall: 0.479143
 IoU: 0.360344

We have finished training iteration 67
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_65_.pth
per-ex loss: 0.412074  [    2/   89]
per-ex loss: 0.407156  [    4/   89]
per-ex loss: 0.474449  [    6/   89]
per-ex loss: 0.395911  [    8/   89]
per-ex loss: 0.484992  [   10/   89]
per-ex loss: 0.519601  [   12/   89]
per-ex loss: 0.580333  [   14/   89]
per-ex loss: 0.400448  [   16/   89]
per-ex loss: 0.410693  [   18/   89]
per-ex loss: 0.604677  [   20/   89]
per-ex loss: 0.432343  [   22/   89]
per-ex loss: 0.620885  [   24/   89]
per-ex loss: 0.561332  [   26/   89]
per-ex loss: 0.487006  [   28/   89]
per-ex loss: 0.366048  [   30/   89]
per-ex loss: 0.408042  [   32/   89]
per-ex loss: 0.427293  [   34/   89]
per-ex loss: 0.462791  [   36/   89]
per-ex loss: 0.562115  [   38/   89]
per-ex loss: 0.327263  [   40/   89]
per-ex loss: 0.520999  [   42/   89]
per-ex loss: 0.480753  [   44/   89]
per-ex loss: 0.484399  [   46/   89]
per-ex loss: 0.502245  [   48/   89]
per-ex loss: 0.399897  [   50/   89]
per-ex loss: 0.494377  [   52/   89]
per-ex loss: 0.610717  [   54/   89]
per-ex loss: 0.367195  [   56/   89]
per-ex loss: 0.448466  [   58/   89]
per-ex loss: 0.549127  [   60/   89]
per-ex loss: 0.556611  [   62/   89]
per-ex loss: 0.463621  [   64/   89]
per-ex loss: 0.393249  [   66/   89]
per-ex loss: 0.435995  [   68/   89]
per-ex loss: 0.419044  [   70/   89]
per-ex loss: 0.566032  [   72/   89]
per-ex loss: 0.421377  [   74/   89]
per-ex loss: 0.379417  [   76/   89]
per-ex loss: 0.578670  [   78/   89]
per-ex loss: 0.477336  [   80/   89]
per-ex loss: 0.425670  [   82/   89]
per-ex loss: 0.520964  [   84/   89]
per-ex loss: 0.445430  [   86/   89]
per-ex loss: 0.613898  [   88/   89]
per-ex loss: 0.480415  [   89/   89]
Train Error: Avg loss: 0.47514122
validation Error: 
 Avg loss: 0.98217574 
 F1: 0.511647 
 Precision: 0.597044 
 Recall: 0.447621
 IoU: 0.343767

test Error: 
 Avg loss: 0.97916414 
 F1: 0.532340 
 Precision: 0.623230 
 Recall: 0.464586
 IoU: 0.362713

We have finished training iteration 68
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_66_.pth
per-ex loss: 0.566181  [    2/   89]
per-ex loss: 0.365644  [    4/   89]
per-ex loss: 0.564858  [    6/   89]
per-ex loss: 0.443382  [    8/   89]
per-ex loss: 0.479292  [   10/   89]
per-ex loss: 0.408485  [   12/   89]
per-ex loss: 0.526160  [   14/   89]
per-ex loss: 0.367024  [   16/   89]
per-ex loss: 0.436987  [   18/   89]
per-ex loss: 0.452654  [   20/   89]
per-ex loss: 0.403122  [   22/   89]
per-ex loss: 0.700205  [   24/   89]
per-ex loss: 0.581852  [   26/   89]
per-ex loss: 0.510842  [   28/   89]
per-ex loss: 0.385237  [   30/   89]
per-ex loss: 0.441376  [   32/   89]
per-ex loss: 0.489390  [   34/   89]
per-ex loss: 0.357876  [   36/   89]
per-ex loss: 0.432613  [   38/   89]
per-ex loss: 0.609037  [   40/   89]
per-ex loss: 0.339898  [   42/   89]
per-ex loss: 0.428435  [   44/   89]
per-ex loss: 0.409328  [   46/   89]
per-ex loss: 0.400203  [   48/   89]
per-ex loss: 0.425177  [   50/   89]
per-ex loss: 0.649135  [   52/   89]
per-ex loss: 0.500340  [   54/   89]
per-ex loss: 0.500801  [   56/   89]
per-ex loss: 0.448646  [   58/   89]
per-ex loss: 0.394183  [   60/   89]
per-ex loss: 0.470730  [   62/   89]
per-ex loss: 0.390837  [   64/   89]
per-ex loss: 0.549528  [   66/   89]
per-ex loss: 0.381449  [   68/   89]
per-ex loss: 0.620879  [   70/   89]
per-ex loss: 0.479190  [   72/   89]
per-ex loss: 0.499766  [   74/   89]
per-ex loss: 0.628439  [   76/   89]
per-ex loss: 0.571258  [   78/   89]
per-ex loss: 0.446829  [   80/   89]
per-ex loss: 0.468105  [   82/   89]
per-ex loss: 0.443713  [   84/   89]
per-ex loss: 0.576872  [   86/   89]
per-ex loss: 0.533161  [   88/   89]
per-ex loss: 0.381698  [   89/   89]
Train Error: Avg loss: 0.47690710
validation Error: 
 Avg loss: 0.98389708 
 F1: 0.511212 
 Precision: 0.559174 
 Recall: 0.470827
 IoU: 0.343374

test Error: 
 Avg loss: 0.98099811 
 F1: 0.532470 
 Precision: 0.585451 
 Recall: 0.488282
 IoU: 0.362834

We have finished training iteration 69
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_67_.pth
per-ex loss: 0.416317  [    2/   89]
per-ex loss: 0.433383  [    4/   89]
per-ex loss: 0.371115  [    6/   89]
per-ex loss: 0.381401  [    8/   89]
per-ex loss: 0.475098  [   10/   89]
per-ex loss: 0.531861  [   12/   89]
per-ex loss: 0.405543  [   14/   89]
per-ex loss: 0.459039  [   16/   89]
per-ex loss: 0.563500  [   18/   89]
per-ex loss: 0.527768  [   20/   89]
per-ex loss: 0.405899  [   22/   89]
per-ex loss: 0.471362  [   24/   89]
per-ex loss: 0.403974  [   26/   89]
per-ex loss: 0.375153  [   28/   89]
per-ex loss: 0.515146  [   30/   89]
per-ex loss: 0.487915  [   32/   89]
per-ex loss: 0.530446  [   34/   89]
per-ex loss: 0.483349  [   36/   89]
per-ex loss: 0.641535  [   38/   89]
per-ex loss: 0.623932  [   40/   89]
per-ex loss: 0.554515  [   42/   89]
per-ex loss: 0.583544  [   44/   89]
per-ex loss: 0.456066  [   46/   89]
per-ex loss: 0.557843  [   48/   89]
per-ex loss: 0.470967  [   50/   89]
per-ex loss: 0.516406  [   52/   89]
per-ex loss: 0.434854  [   54/   89]
per-ex loss: 0.374042  [   56/   89]
per-ex loss: 0.376414  [   58/   89]
per-ex loss: 0.438543  [   60/   89]
per-ex loss: 0.376769  [   62/   89]
per-ex loss: 0.412719  [   64/   89]
per-ex loss: 0.566035  [   66/   89]
per-ex loss: 0.592616  [   68/   89]
per-ex loss: 0.442568  [   70/   89]
per-ex loss: 0.456686  [   72/   89]
per-ex loss: 0.503746  [   74/   89]
per-ex loss: 0.451806  [   76/   89]
per-ex loss: 0.672881  [   78/   89]
per-ex loss: 0.406007  [   80/   89]
per-ex loss: 0.612298  [   82/   89]
per-ex loss: 0.601614  [   84/   89]
per-ex loss: 0.424974  [   86/   89]
per-ex loss: 0.457822  [   88/   89]
per-ex loss: 0.509410  [   89/   89]
Train Error: Avg loss: 0.48344181
validation Error: 
 Avg loss: 0.98035968 
 F1: 0.504344 
 Precision: 0.636539 
 Recall: 0.417616
 IoU: 0.337206

test Error: 
 Avg loss: 0.97769951 
 F1: 0.518416 
 Precision: 0.664992 
 Recall: 0.424785
 IoU: 0.349906

We have finished training iteration 70
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_68_.pth
per-ex loss: 0.392402  [    2/   89]
per-ex loss: 0.593754  [    4/   89]
per-ex loss: 0.410839  [    6/   89]
per-ex loss: 0.425101  [    8/   89]
per-ex loss: 0.403073  [   10/   89]
per-ex loss: 0.368392  [   12/   89]
per-ex loss: 0.584477  [   14/   89]
per-ex loss: 0.470875  [   16/   89]
per-ex loss: 0.545446  [   18/   89]
per-ex loss: 0.329954  [   20/   89]
per-ex loss: 0.407380  [   22/   89]
per-ex loss: 0.458597  [   24/   89]
per-ex loss: 0.550116  [   26/   89]
per-ex loss: 0.509549  [   28/   89]
per-ex loss: 0.472915  [   30/   89]
per-ex loss: 0.693579  [   32/   89]
per-ex loss: 0.398414  [   34/   89]
per-ex loss: 0.495028  [   36/   89]
per-ex loss: 0.409010  [   38/   89]
per-ex loss: 0.383655  [   40/   89]
per-ex loss: 0.422969  [   42/   89]
per-ex loss: 0.393334  [   44/   89]
per-ex loss: 0.477626  [   46/   89]
per-ex loss: 0.368238  [   48/   89]
per-ex loss: 0.450587  [   50/   89]
per-ex loss: 0.477323  [   52/   89]
per-ex loss: 0.497716  [   54/   89]
per-ex loss: 0.653631  [   56/   89]
per-ex loss: 0.600734  [   58/   89]
per-ex loss: 0.495260  [   60/   89]
per-ex loss: 0.425343  [   62/   89]
per-ex loss: 0.463890  [   64/   89]
per-ex loss: 0.596546  [   66/   89]
per-ex loss: 0.645087  [   68/   89]
per-ex loss: 0.430469  [   70/   89]
per-ex loss: 0.609199  [   72/   89]
per-ex loss: 0.457150  [   74/   89]
per-ex loss: 0.442955  [   76/   89]
per-ex loss: 0.442960  [   78/   89]
per-ex loss: 0.554897  [   80/   89]
per-ex loss: 0.386093  [   82/   89]
per-ex loss: 0.387482  [   84/   89]
per-ex loss: 0.436430  [   86/   89]
per-ex loss: 0.391087  [   88/   89]
per-ex loss: 0.396113  [   89/   89]
Train Error: Avg loss: 0.47123716
validation Error: 
 Avg loss: 0.98258173 
 F1: 0.510320 
 Precision: 0.580027 
 Recall: 0.455571
 IoU: 0.342571

test Error: 
 Avg loss: 0.98031803 
 F1: 0.527822 
 Precision: 0.603805 
 Recall: 0.468825
 IoU: 0.358531

We have finished training iteration 71
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_69_.pth
per-ex loss: 0.461697  [    2/   89]
per-ex loss: 0.421878  [    4/   89]
per-ex loss: 0.384939  [    6/   89]
per-ex loss: 0.597272  [    8/   89]
per-ex loss: 0.551779  [   10/   89]
per-ex loss: 0.417748  [   12/   89]
per-ex loss: 0.447624  [   14/   89]
per-ex loss: 0.562009  [   16/   89]
per-ex loss: 0.470152  [   18/   89]
per-ex loss: 0.521054  [   20/   89]
per-ex loss: 0.595552  [   22/   89]
per-ex loss: 0.498159  [   24/   89]
per-ex loss: 0.430961  [   26/   89]
per-ex loss: 0.532039  [   28/   89]
per-ex loss: 0.356544  [   30/   89]
per-ex loss: 0.601215  [   32/   89]
per-ex loss: 0.369297  [   34/   89]
per-ex loss: 0.609265  [   36/   89]
per-ex loss: 0.408452  [   38/   89]
per-ex loss: 0.585397  [   40/   89]
per-ex loss: 0.403793  [   42/   89]
per-ex loss: 0.436518  [   44/   89]
per-ex loss: 0.593260  [   46/   89]
per-ex loss: 0.448324  [   48/   89]
per-ex loss: 0.456088  [   50/   89]
per-ex loss: 0.502155  [   52/   89]
per-ex loss: 0.508004  [   54/   89]
per-ex loss: 0.455719  [   56/   89]
per-ex loss: 0.372753  [   58/   89]
per-ex loss: 0.499263  [   60/   89]
per-ex loss: 0.452605  [   62/   89]
per-ex loss: 0.476645  [   64/   89]
per-ex loss: 0.513696  [   66/   89]
per-ex loss: 0.598011  [   68/   89]
per-ex loss: 0.370520  [   70/   89]
per-ex loss: 0.390160  [   72/   89]
per-ex loss: 0.560802  [   74/   89]
per-ex loss: 0.386436  [   76/   89]
per-ex loss: 0.469377  [   78/   89]
per-ex loss: 0.409828  [   80/   89]
per-ex loss: 0.404193  [   82/   89]
per-ex loss: 0.416909  [   84/   89]
per-ex loss: 0.438837  [   86/   89]
per-ex loss: 0.496017  [   88/   89]
per-ex loss: 0.499196  [   89/   89]
Train Error: Avg loss: 0.47515872
validation Error: 
 Avg loss: 0.98330836 
 F1: 0.511907 
 Precision: 0.570974 
 Recall: 0.463915
 IoU: 0.344002

test Error: 
 Avg loss: 0.98067964 
 F1: 0.533260 
 Precision: 0.597509 
 Recall: 0.481488
 IoU: 0.363569

We have finished training iteration 72
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_70_.pth
per-ex loss: 0.408603  [    2/   89]
per-ex loss: 0.375475  [    4/   89]
per-ex loss: 0.483249  [    6/   89]
per-ex loss: 0.386137  [    8/   89]
per-ex loss: 0.531786  [   10/   89]
per-ex loss: 0.520865  [   12/   89]
per-ex loss: 0.369443  [   14/   89]
per-ex loss: 0.529136  [   16/   89]
per-ex loss: 0.603108  [   18/   89]
per-ex loss: 0.402871  [   20/   89]
per-ex loss: 0.486854  [   22/   89]
per-ex loss: 0.463229  [   24/   89]
per-ex loss: 0.589720  [   26/   89]
per-ex loss: 0.522779  [   28/   89]
per-ex loss: 0.428129  [   30/   89]
per-ex loss: 0.458814  [   32/   89]
per-ex loss: 0.388101  [   34/   89]
per-ex loss: 0.400046  [   36/   89]
per-ex loss: 0.559185  [   38/   89]
per-ex loss: 0.552186  [   40/   89]
per-ex loss: 0.537259  [   42/   89]
per-ex loss: 0.585862  [   44/   89]
per-ex loss: 0.464194  [   46/   89]
per-ex loss: 0.534538  [   48/   89]
per-ex loss: 0.472018  [   50/   89]
per-ex loss: 0.479623  [   52/   89]
per-ex loss: 0.412014  [   54/   89]
per-ex loss: 0.611446  [   56/   89]
per-ex loss: 0.531565  [   58/   89]
per-ex loss: 0.604118  [   60/   89]
per-ex loss: 0.426253  [   62/   89]
per-ex loss: 0.480507  [   64/   89]
per-ex loss: 0.434921  [   66/   89]
per-ex loss: 0.566100  [   68/   89]
per-ex loss: 0.504583  [   70/   89]
per-ex loss: 0.389297  [   72/   89]
per-ex loss: 0.487851  [   74/   89]
per-ex loss: 0.546962  [   76/   89]
per-ex loss: 0.476829  [   78/   89]
per-ex loss: 0.626309  [   80/   89]
per-ex loss: 0.451808  [   82/   89]
per-ex loss: 0.488015  [   84/   89]
per-ex loss: 0.623375  [   86/   89]
per-ex loss: 0.540969  [   88/   89]
per-ex loss: 0.453116  [   89/   89]
Train Error: Avg loss: 0.49309436
validation Error: 
 Avg loss: 0.98327920 
 F1: 0.509096 
 Precision: 0.576025 
 Recall: 0.456101
 IoU: 0.341468

test Error: 
 Avg loss: 0.98011821 
 F1: 0.527056 
 Precision: 0.608229 
 Recall: 0.464999
 IoU: 0.357825

We have finished training iteration 73
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_71_.pth
per-ex loss: 0.402121  [    2/   89]
per-ex loss: 0.573805  [    4/   89]
per-ex loss: 0.398575  [    6/   89]
per-ex loss: 0.537675  [    8/   89]
per-ex loss: 0.488096  [   10/   89]
per-ex loss: 0.581499  [   12/   89]
per-ex loss: 0.490953  [   14/   89]
per-ex loss: 0.485122  [   16/   89]
per-ex loss: 0.398371  [   18/   89]
per-ex loss: 0.400808  [   20/   89]
per-ex loss: 0.529560  [   22/   89]
per-ex loss: 0.400363  [   24/   89]
per-ex loss: 0.427741  [   26/   89]
per-ex loss: 0.439959  [   28/   89]
per-ex loss: 0.392378  [   30/   89]
per-ex loss: 0.373677  [   32/   89]
per-ex loss: 0.604955  [   34/   89]
per-ex loss: 0.520275  [   36/   89]
per-ex loss: 0.431913  [   38/   89]
per-ex loss: 0.468093  [   40/   89]
per-ex loss: 0.506854  [   42/   89]
per-ex loss: 0.411774  [   44/   89]
per-ex loss: 0.502034  [   46/   89]
per-ex loss: 0.783368  [   48/   89]
per-ex loss: 0.529687  [   50/   89]
per-ex loss: 0.552982  [   52/   89]
per-ex loss: 0.485115  [   54/   89]
per-ex loss: 0.357844  [   56/   89]
per-ex loss: 0.583239  [   58/   89]
per-ex loss: 0.435803  [   60/   89]
per-ex loss: 0.402711  [   62/   89]
per-ex loss: 0.385634  [   64/   89]
per-ex loss: 0.371612  [   66/   89]
per-ex loss: 0.543670  [   68/   89]
per-ex loss: 0.387372  [   70/   89]
per-ex loss: 0.423649  [   72/   89]
per-ex loss: 0.668285  [   74/   89]
per-ex loss: 0.524386  [   76/   89]
per-ex loss: 0.527919  [   78/   89]
per-ex loss: 0.368396  [   80/   89]
per-ex loss: 0.378085  [   82/   89]
per-ex loss: 0.453036  [   84/   89]
per-ex loss: 0.493331  [   86/   89]
per-ex loss: 0.501883  [   88/   89]
per-ex loss: 0.619903  [   89/   89]
Train Error: Avg loss: 0.47876698
validation Error: 
 Avg loss: 0.98327750 
 F1: 0.509037 
 Precision: 0.577850 
 Recall: 0.454869
 IoU: 0.341415

test Error: 
 Avg loss: 0.98072473 
 F1: 0.519874 
 Precision: 0.599817 
 Recall: 0.458735
 IoU: 0.351237

We have finished training iteration 74
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_72_.pth
per-ex loss: 0.380473  [    2/   89]
per-ex loss: 0.523727  [    4/   89]
per-ex loss: 0.535113  [    6/   89]
per-ex loss: 0.453213  [    8/   89]
per-ex loss: 0.488676  [   10/   89]
per-ex loss: 0.464765  [   12/   89]
per-ex loss: 0.431184  [   14/   89]
per-ex loss: 0.406919  [   16/   89]
per-ex loss: 0.498028  [   18/   89]
per-ex loss: 0.647748  [   20/   89]
per-ex loss: 0.456379  [   22/   89]
per-ex loss: 0.527846  [   24/   89]
per-ex loss: 0.417960  [   26/   89]
per-ex loss: 0.376276  [   28/   89]
per-ex loss: 0.469113  [   30/   89]
per-ex loss: 0.490903  [   32/   89]
per-ex loss: 0.400618  [   34/   89]
per-ex loss: 0.475754  [   36/   89]
per-ex loss: 0.516138  [   38/   89]
per-ex loss: 0.504446  [   40/   89]
per-ex loss: 0.389143  [   42/   89]
per-ex loss: 0.508817  [   44/   89]
per-ex loss: 0.397229  [   46/   89]
per-ex loss: 0.537224  [   48/   89]
per-ex loss: 0.424481  [   50/   89]
per-ex loss: 0.405394  [   52/   89]
per-ex loss: 0.602129  [   54/   89]
per-ex loss: 0.636383  [   56/   89]
per-ex loss: 0.581731  [   58/   89]
per-ex loss: 0.483208  [   60/   89]
per-ex loss: 0.418736  [   62/   89]
per-ex loss: 0.372414  [   64/   89]
per-ex loss: 0.447358  [   66/   89]
per-ex loss: 0.402364  [   68/   89]
per-ex loss: 0.627264  [   70/   89]
per-ex loss: 0.653466  [   72/   89]
per-ex loss: 0.470128  [   74/   89]
per-ex loss: 0.433929  [   76/   89]
per-ex loss: 0.412317  [   78/   89]
per-ex loss: 0.512199  [   80/   89]
per-ex loss: 0.474550  [   82/   89]
per-ex loss: 0.438536  [   84/   89]
per-ex loss: 0.417193  [   86/   89]
per-ex loss: 0.518638  [   88/   89]
per-ex loss: 0.374117  [   89/   89]
Train Error: Avg loss: 0.47564946
validation Error: 
 Avg loss: 0.98249730 
 F1: 0.507300 
 Precision: 0.608272 
 Recall: 0.435078
 IoU: 0.339854

test Error: 
 Avg loss: 0.97945125 
 F1: 0.520344 
 Precision: 0.639577 
 Recall: 0.438581
 IoU: 0.351665

We have finished training iteration 75
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_73_.pth
per-ex loss: 0.394988  [    2/   89]
per-ex loss: 0.513395  [    4/   89]
per-ex loss: 0.592733  [    6/   89]
per-ex loss: 0.465054  [    8/   89]
per-ex loss: 0.600482  [   10/   89]
per-ex loss: 0.413522  [   12/   89]
per-ex loss: 0.683461  [   14/   89]
per-ex loss: 0.417217  [   16/   89]
per-ex loss: 0.454615  [   18/   89]
per-ex loss: 0.495498  [   20/   89]
per-ex loss: 0.630048  [   22/   89]
per-ex loss: 0.450648  [   24/   89]
per-ex loss: 0.465411  [   26/   89]
per-ex loss: 0.499167  [   28/   89]
per-ex loss: 0.547126  [   30/   89]
per-ex loss: 0.622201  [   32/   89]
per-ex loss: 0.521254  [   34/   89]
per-ex loss: 0.424334  [   36/   89]
per-ex loss: 0.459187  [   38/   89]
per-ex loss: 0.403637  [   40/   89]
per-ex loss: 0.440749  [   42/   89]
per-ex loss: 0.597010  [   44/   89]
per-ex loss: 0.432573  [   46/   89]
per-ex loss: 0.423699  [   48/   89]
per-ex loss: 0.400263  [   50/   89]
per-ex loss: 0.546205  [   52/   89]
per-ex loss: 0.428284  [   54/   89]
per-ex loss: 0.564822  [   56/   89]
per-ex loss: 0.523955  [   58/   89]
per-ex loss: 0.413576  [   60/   89]
per-ex loss: 0.659929  [   62/   89]
per-ex loss: 0.483368  [   64/   89]
per-ex loss: 0.509993  [   66/   89]
per-ex loss: 0.553120  [   68/   89]
per-ex loss: 0.428991  [   70/   89]
per-ex loss: 0.414964  [   72/   89]
per-ex loss: 0.377469  [   74/   89]
per-ex loss: 0.501776  [   76/   89]
per-ex loss: 0.423922  [   78/   89]
per-ex loss: 0.432474  [   80/   89]
per-ex loss: 0.432861  [   82/   89]
per-ex loss: 0.405571  [   84/   89]
per-ex loss: 0.533075  [   86/   89]
per-ex loss: 0.595611  [   88/   89]
per-ex loss: 0.472896  [   89/   89]
Train Error: Avg loss: 0.49002518
validation Error: 
 Avg loss: 0.98207344 
 F1: 0.512615 
 Precision: 0.595675 
 Recall: 0.449884
 IoU: 0.344642

test Error: 
 Avg loss: 0.97970215 
 F1: 0.531847 
 Precision: 0.622600 
 Recall: 0.464185
 IoU: 0.362256

We have finished training iteration 76
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_74_.pth
per-ex loss: 0.620201  [    2/   89]
per-ex loss: 0.488370  [    4/   89]
per-ex loss: 0.394698  [    6/   89]
per-ex loss: 0.490038  [    8/   89]
per-ex loss: 0.389363  [   10/   89]
per-ex loss: 0.594403  [   12/   89]
per-ex loss: 0.691539  [   14/   89]
per-ex loss: 0.417082  [   16/   89]
per-ex loss: 0.342958  [   18/   89]
per-ex loss: 0.456485  [   20/   89]
per-ex loss: 0.408804  [   22/   89]
per-ex loss: 0.507175  [   24/   89]
per-ex loss: 0.384969  [   26/   89]
per-ex loss: 0.495730  [   28/   89]
per-ex loss: 0.419830  [   30/   89]
per-ex loss: 0.484482  [   32/   89]
per-ex loss: 0.413992  [   34/   89]
per-ex loss: 0.490428  [   36/   89]
per-ex loss: 0.655174  [   38/   89]
per-ex loss: 0.559079  [   40/   89]
per-ex loss: 0.538471  [   42/   89]
per-ex loss: 0.504423  [   44/   89]
per-ex loss: 0.598019  [   46/   89]
per-ex loss: 0.384644  [   48/   89]
per-ex loss: 0.507004  [   50/   89]
per-ex loss: 0.459612  [   52/   89]
per-ex loss: 0.422735  [   54/   89]
per-ex loss: 0.396970  [   56/   89]
per-ex loss: 0.418346  [   58/   89]
per-ex loss: 0.370561  [   60/   89]
per-ex loss: 0.372212  [   62/   89]
per-ex loss: 0.509078  [   64/   89]
per-ex loss: 0.458115  [   66/   89]
per-ex loss: 0.552089  [   68/   89]
per-ex loss: 0.429195  [   70/   89]
per-ex loss: 0.494429  [   72/   89]
per-ex loss: 0.441753  [   74/   89]
per-ex loss: 0.564212  [   76/   89]
per-ex loss: 0.579029  [   78/   89]
per-ex loss: 0.486000  [   80/   89]
per-ex loss: 0.507069  [   82/   89]
per-ex loss: 0.365135  [   84/   89]
per-ex loss: 0.517838  [   86/   89]
per-ex loss: 0.446626  [   88/   89]
per-ex loss: 0.598813  [   89/   89]
Train Error: Avg loss: 0.48060397
validation Error: 
 Avg loss: 0.98348175 
 F1: 0.509974 
 Precision: 0.580582 
 Recall: 0.454678
 IoU: 0.342258

test Error: 
 Avg loss: 0.98054468 
 F1: 0.529976 
 Precision: 0.607495 
 Recall: 0.470002
 IoU: 0.360522

We have finished training iteration 77
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_75_.pth
per-ex loss: 0.387083  [    2/   89]
per-ex loss: 0.404726  [    4/   89]
per-ex loss: 0.393208  [    6/   89]
per-ex loss: 0.454904  [    8/   89]
per-ex loss: 0.407939  [   10/   89]
per-ex loss: 0.411829  [   12/   89]
per-ex loss: 0.578710  [   14/   89]
per-ex loss: 0.567503  [   16/   89]
per-ex loss: 0.341936  [   18/   89]
per-ex loss: 0.590773  [   20/   89]
per-ex loss: 0.413592  [   22/   89]
per-ex loss: 0.405479  [   24/   89]
per-ex loss: 0.431327  [   26/   89]
per-ex loss: 0.503058  [   28/   89]
per-ex loss: 0.431007  [   30/   89]
per-ex loss: 0.418853  [   32/   89]
per-ex loss: 0.612194  [   34/   89]
per-ex loss: 0.614250  [   36/   89]
per-ex loss: 0.467688  [   38/   89]
per-ex loss: 0.515147  [   40/   89]
per-ex loss: 0.565503  [   42/   89]
per-ex loss: 0.412334  [   44/   89]
per-ex loss: 0.450933  [   46/   89]
per-ex loss: 0.578985  [   48/   89]
per-ex loss: 0.569593  [   50/   89]
per-ex loss: 0.381086  [   52/   89]
per-ex loss: 0.496260  [   54/   89]
per-ex loss: 0.506315  [   56/   89]
per-ex loss: 0.579544  [   58/   89]
per-ex loss: 0.483453  [   60/   89]
per-ex loss: 0.529853  [   62/   89]
per-ex loss: 0.444424  [   64/   89]
per-ex loss: 0.336969  [   66/   89]
per-ex loss: 0.427488  [   68/   89]
per-ex loss: 0.566274  [   70/   89]
per-ex loss: 0.488844  [   72/   89]
per-ex loss: 0.509731  [   74/   89]
per-ex loss: 0.406716  [   76/   89]
per-ex loss: 0.499688  [   78/   89]
per-ex loss: 0.545541  [   80/   89]
per-ex loss: 0.506297  [   82/   89]
per-ex loss: 0.385260  [   84/   89]
per-ex loss: 0.484151  [   86/   89]
per-ex loss: 0.507092  [   88/   89]
per-ex loss: 0.477053  [   89/   89]
Train Error: Avg loss: 0.47756880
validation Error: 
 Avg loss: 0.98352668 
 F1: 0.511426 
 Precision: 0.566847 
 Recall: 0.465877
 IoU: 0.343568

test Error: 
 Avg loss: 0.98156569 
 F1: 0.528036 
 Precision: 0.584939 
 Recall: 0.481223
 IoU: 0.358729

We have finished training iteration 78
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_76_.pth
per-ex loss: 0.359825  [    2/   89]
per-ex loss: 0.582825  [    4/   89]
per-ex loss: 0.484405  [    6/   89]
per-ex loss: 0.499607  [    8/   89]
per-ex loss: 0.432417  [   10/   89]
per-ex loss: 0.386250  [   12/   89]
per-ex loss: 0.407820  [   14/   89]
per-ex loss: 0.510130  [   16/   89]
per-ex loss: 0.606588  [   18/   89]
per-ex loss: 0.483144  [   20/   89]
per-ex loss: 0.471547  [   22/   89]
per-ex loss: 0.470020  [   24/   89]
per-ex loss: 0.494440  [   26/   89]
per-ex loss: 0.418156  [   28/   89]
per-ex loss: 0.429331  [   30/   89]
per-ex loss: 0.435652  [   32/   89]
per-ex loss: 0.501341  [   34/   89]
per-ex loss: 0.392455  [   36/   89]
per-ex loss: 0.570999  [   38/   89]
per-ex loss: 0.382480  [   40/   89]
per-ex loss: 0.396125  [   42/   89]
per-ex loss: 0.590334  [   44/   89]
per-ex loss: 0.417384  [   46/   89]
per-ex loss: 0.561148  [   48/   89]
per-ex loss: 0.532803  [   50/   89]
per-ex loss: 0.449409  [   52/   89]
per-ex loss: 0.430912  [   54/   89]
per-ex loss: 0.495053  [   56/   89]
per-ex loss: 0.561494  [   58/   89]
per-ex loss: 0.519670  [   60/   89]
per-ex loss: 0.560152  [   62/   89]
per-ex loss: 0.405681  [   64/   89]
per-ex loss: 0.401808  [   66/   89]
per-ex loss: 0.430781  [   68/   89]
per-ex loss: 0.438770  [   70/   89]
per-ex loss: 0.513928  [   72/   89]
per-ex loss: 0.450631  [   74/   89]
per-ex loss: 0.573140  [   76/   89]
per-ex loss: 0.702431  [   78/   89]
per-ex loss: 0.426853  [   80/   89]
per-ex loss: 0.456066  [   82/   89]
per-ex loss: 0.623634  [   84/   89]
per-ex loss: 0.563336  [   86/   89]
per-ex loss: 0.394297  [   88/   89]
per-ex loss: 0.602316  [   89/   89]
Train Error: Avg loss: 0.48483531
validation Error: 
 Avg loss: 0.98364161 
 F1: 0.511336 
 Precision: 0.558330 
 Recall: 0.471638
 IoU: 0.343486

test Error: 
 Avg loss: 0.98111720 
 F1: 0.526446 
 Precision: 0.579758 
 Recall: 0.482112
 IoU: 0.357262

We have finished training iteration 79
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_77_.pth
per-ex loss: 0.424613  [    2/   89]
per-ex loss: 0.447538  [    4/   89]
per-ex loss: 0.393116  [    6/   89]
per-ex loss: 0.456803  [    8/   89]
per-ex loss: 0.692744  [   10/   89]
per-ex loss: 0.406004  [   12/   89]
per-ex loss: 0.547430  [   14/   89]
per-ex loss: 0.464815  [   16/   89]
per-ex loss: 0.352341  [   18/   89]
per-ex loss: 0.492726  [   20/   89]
per-ex loss: 0.440171  [   22/   89]
per-ex loss: 0.395146  [   24/   89]
per-ex loss: 0.380313  [   26/   89]
per-ex loss: 0.538401  [   28/   89]
per-ex loss: 0.467934  [   30/   89]
per-ex loss: 0.496972  [   32/   89]
per-ex loss: 0.688244  [   34/   89]
per-ex loss: 0.473142  [   36/   89]
per-ex loss: 0.421229  [   38/   89]
per-ex loss: 0.457686  [   40/   89]
per-ex loss: 0.421121  [   42/   89]
per-ex loss: 0.691122  [   44/   89]
per-ex loss: 0.401592  [   46/   89]
per-ex loss: 0.453967  [   48/   89]
per-ex loss: 0.473995  [   50/   89]
per-ex loss: 0.457085  [   52/   89]
per-ex loss: 0.540726  [   54/   89]
per-ex loss: 0.587508  [   56/   89]
per-ex loss: 0.477760  [   58/   89]
per-ex loss: 0.473188  [   60/   89]
per-ex loss: 0.495272  [   62/   89]
per-ex loss: 0.502890  [   64/   89]
per-ex loss: 0.421094  [   66/   89]
per-ex loss: 0.547251  [   68/   89]
per-ex loss: 0.405343  [   70/   89]
per-ex loss: 0.584388  [   72/   89]
per-ex loss: 0.471335  [   74/   89]
per-ex loss: 0.463244  [   76/   89]
per-ex loss: 0.388661  [   78/   89]
per-ex loss: 0.530853  [   80/   89]
per-ex loss: 0.410849  [   82/   89]
per-ex loss: 0.463145  [   84/   89]
per-ex loss: 0.412239  [   86/   89]
per-ex loss: 0.411350  [   88/   89]
per-ex loss: 0.454082  [   89/   89]
Train Error: Avg loss: 0.47505390
validation Error: 
 Avg loss: 0.98277558 
 F1: 0.509788 
 Precision: 0.587607 
 Recall: 0.450170
 IoU: 0.342091

test Error: 
 Avg loss: 0.98017753 
 F1: 0.527623 
 Precision: 0.614748 
 Recall: 0.462128
 IoU: 0.358348

We have finished training iteration 80
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_78_.pth
per-ex loss: 0.594808  [    2/   89]
per-ex loss: 0.504536  [    4/   89]
per-ex loss: 0.461607  [    6/   89]
per-ex loss: 0.476893  [    8/   89]
per-ex loss: 0.344485  [   10/   89]
per-ex loss: 0.433398  [   12/   89]
per-ex loss: 0.552728  [   14/   89]
per-ex loss: 0.398928  [   16/   89]
per-ex loss: 0.597654  [   18/   89]
per-ex loss: 0.587345  [   20/   89]
per-ex loss: 0.670665  [   22/   89]
per-ex loss: 0.513195  [   24/   89]
per-ex loss: 0.477119  [   26/   89]
per-ex loss: 0.493484  [   28/   89]
per-ex loss: 0.606573  [   30/   89]
per-ex loss: 0.434750  [   32/   89]
per-ex loss: 0.408001  [   34/   89]
per-ex loss: 0.425608  [   36/   89]
per-ex loss: 0.359641  [   38/   89]
per-ex loss: 0.409713  [   40/   89]
per-ex loss: 0.492938  [   42/   89]
per-ex loss: 0.412730  [   44/   89]
per-ex loss: 0.400305  [   46/   89]
per-ex loss: 0.630487  [   48/   89]
per-ex loss: 0.402288  [   50/   89]
per-ex loss: 0.531372  [   52/   89]
per-ex loss: 0.479872  [   54/   89]
per-ex loss: 0.492876  [   56/   89]
per-ex loss: 0.611804  [   58/   89]
per-ex loss: 0.357402  [   60/   89]
per-ex loss: 0.439201  [   62/   89]
per-ex loss: 0.420172  [   64/   89]
per-ex loss: 0.389262  [   66/   89]
per-ex loss: 0.445607  [   68/   89]
per-ex loss: 0.390440  [   70/   89]
per-ex loss: 0.371431  [   72/   89]
per-ex loss: 0.464904  [   74/   89]
per-ex loss: 0.466695  [   76/   89]
per-ex loss: 0.457580  [   78/   89]
per-ex loss: 0.431673  [   80/   89]
per-ex loss: 0.628811  [   82/   89]
per-ex loss: 0.501075  [   84/   89]
per-ex loss: 0.487131  [   86/   89]
per-ex loss: 0.445251  [   88/   89]
per-ex loss: 0.503692  [   89/   89]
Train Error: Avg loss: 0.47569180
validation Error: 
 Avg loss: 0.98152336 
 F1: 0.510371 
 Precision: 0.595517 
 Recall: 0.446527
 IoU: 0.342616

test Error: 
 Avg loss: 0.97947335 
 F1: 0.529608 
 Precision: 0.630890 
 Recall: 0.456346
 IoU: 0.360181

We have finished training iteration 81
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_79_.pth
per-ex loss: 0.413411  [    2/   89]
per-ex loss: 0.482311  [    4/   89]
per-ex loss: 0.418356  [    6/   89]
per-ex loss: 0.566855  [    8/   89]
per-ex loss: 0.454994  [   10/   89]
per-ex loss: 0.505135  [   12/   89]
per-ex loss: 0.477310  [   14/   89]
per-ex loss: 0.537784  [   16/   89]
per-ex loss: 0.508968  [   18/   89]
per-ex loss: 0.442817  [   20/   89]
per-ex loss: 0.481997  [   22/   89]
per-ex loss: 0.507573  [   24/   89]
per-ex loss: 0.400979  [   26/   89]
per-ex loss: 0.354230  [   28/   89]
per-ex loss: 0.422025  [   30/   89]
per-ex loss: 0.440968  [   32/   89]
per-ex loss: 0.375043  [   34/   89]
per-ex loss: 0.619160  [   36/   89]
per-ex loss: 0.399004  [   38/   89]
per-ex loss: 0.397328  [   40/   89]
per-ex loss: 0.388477  [   42/   89]
per-ex loss: 0.608926  [   44/   89]
per-ex loss: 0.533117  [   46/   89]
per-ex loss: 0.364116  [   48/   89]
per-ex loss: 0.607325  [   50/   89]
per-ex loss: 0.562650  [   52/   89]
per-ex loss: 0.468720  [   54/   89]
per-ex loss: 0.356114  [   56/   89]
per-ex loss: 0.521924  [   58/   89]
per-ex loss: 0.617810  [   60/   89]
per-ex loss: 0.473271  [   62/   89]
per-ex loss: 0.480478  [   64/   89]
per-ex loss: 0.450422  [   66/   89]
per-ex loss: 0.431513  [   68/   89]
per-ex loss: 0.537453  [   70/   89]
per-ex loss: 0.635404  [   72/   89]
per-ex loss: 0.423685  [   74/   89]
per-ex loss: 0.378158  [   76/   89]
per-ex loss: 0.620378  [   78/   89]
per-ex loss: 0.386995  [   80/   89]
per-ex loss: 0.550084  [   82/   89]
per-ex loss: 0.417576  [   84/   89]
per-ex loss: 0.385310  [   86/   89]
per-ex loss: 0.550270  [   88/   89]
per-ex loss: 0.431389  [   89/   89]
Train Error: Avg loss: 0.47528478
validation Error: 
 Avg loss: 0.98228911 
 F1: 0.510324 
 Precision: 0.598481 
 Recall: 0.444804
 IoU: 0.342574

test Error: 
 Avg loss: 0.98006354 
 F1: 0.528522 
 Precision: 0.624782 
 Recall: 0.457963
 IoU: 0.359177

We have finished training iteration 82
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_80_.pth
per-ex loss: 0.429148  [    2/   89]
per-ex loss: 0.594551  [    4/   89]
per-ex loss: 0.662933  [    6/   89]
per-ex loss: 0.428559  [    8/   89]
per-ex loss: 0.563917  [   10/   89]
per-ex loss: 0.419084  [   12/   89]
per-ex loss: 0.548338  [   14/   89]
per-ex loss: 0.585506  [   16/   89]
per-ex loss: 0.452586  [   18/   89]
per-ex loss: 0.583488  [   20/   89]
per-ex loss: 0.522640  [   22/   89]
per-ex loss: 0.513710  [   24/   89]
per-ex loss: 0.397109  [   26/   89]
per-ex loss: 0.428688  [   28/   89]
per-ex loss: 0.455140  [   30/   89]
per-ex loss: 0.453605  [   32/   89]
per-ex loss: 0.644396  [   34/   89]
per-ex loss: 0.414428  [   36/   89]
per-ex loss: 0.455942  [   38/   89]
per-ex loss: 0.560625  [   40/   89]
per-ex loss: 0.627021  [   42/   89]
per-ex loss: 0.439991  [   44/   89]
per-ex loss: 0.391842  [   46/   89]
per-ex loss: 0.359029  [   48/   89]
per-ex loss: 0.467326  [   50/   89]
per-ex loss: 0.409141  [   52/   89]
per-ex loss: 0.481046  [   54/   89]
per-ex loss: 0.420073  [   56/   89]
per-ex loss: 0.388133  [   58/   89]
per-ex loss: 0.446403  [   60/   89]
per-ex loss: 0.521419  [   62/   89]
per-ex loss: 0.351702  [   64/   89]
per-ex loss: 0.378845  [   66/   89]
per-ex loss: 0.419738  [   68/   89]
per-ex loss: 0.383027  [   70/   89]
per-ex loss: 0.506095  [   72/   89]
per-ex loss: 0.460321  [   74/   89]
per-ex loss: 0.395791  [   76/   89]
per-ex loss: 0.419714  [   78/   89]
per-ex loss: 0.430087  [   80/   89]
per-ex loss: 0.600132  [   82/   89]
per-ex loss: 0.396693  [   84/   89]
per-ex loss: 0.424947  [   86/   89]
per-ex loss: 0.367018  [   88/   89]
per-ex loss: 0.448393  [   89/   89]
Train Error: Avg loss: 0.46774043
validation Error: 
 Avg loss: 0.98093949 
 F1: 0.509518 
 Precision: 0.599451 
 Recall: 0.443048
 IoU: 0.341847

test Error: 
 Avg loss: 0.97951901 
 F1: 0.527181 
 Precision: 0.620633 
 Recall: 0.458189
 IoU: 0.357940

We have finished training iteration 83
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_81_.pth
per-ex loss: 0.465166  [    2/   89]
per-ex loss: 0.609038  [    4/   89]
per-ex loss: 0.404262  [    6/   89]
per-ex loss: 0.564511  [    8/   89]
per-ex loss: 0.597397  [   10/   89]
per-ex loss: 0.379180  [   12/   89]
per-ex loss: 0.539606  [   14/   89]
per-ex loss: 0.500894  [   16/   89]
per-ex loss: 0.508410  [   18/   89]
per-ex loss: 0.470976  [   20/   89]
per-ex loss: 0.364332  [   22/   89]
per-ex loss: 0.395710  [   24/   89]
per-ex loss: 0.388221  [   26/   89]
per-ex loss: 0.407345  [   28/   89]
per-ex loss: 0.445018  [   30/   89]
per-ex loss: 0.549223  [   32/   89]
per-ex loss: 0.546881  [   34/   89]
per-ex loss: 0.486202  [   36/   89]
per-ex loss: 0.375380  [   38/   89]
per-ex loss: 0.444919  [   40/   89]
per-ex loss: 0.469058  [   42/   89]
per-ex loss: 0.443857  [   44/   89]
per-ex loss: 0.429901  [   46/   89]
per-ex loss: 0.386473  [   48/   89]
per-ex loss: 0.575915  [   50/   89]
per-ex loss: 0.534983  [   52/   89]
per-ex loss: 0.549419  [   54/   89]
per-ex loss: 0.461496  [   56/   89]
per-ex loss: 0.363745  [   58/   89]
per-ex loss: 0.605151  [   60/   89]
per-ex loss: 0.440807  [   62/   89]
per-ex loss: 0.455275  [   64/   89]
per-ex loss: 0.410436  [   66/   89]
per-ex loss: 0.435770  [   68/   89]
per-ex loss: 0.487018  [   70/   89]
per-ex loss: 0.449214  [   72/   89]
per-ex loss: 0.408415  [   74/   89]
per-ex loss: 0.405421  [   76/   89]
per-ex loss: 0.670476  [   78/   89]
per-ex loss: 0.443155  [   80/   89]
per-ex loss: 0.721697  [   82/   89]
per-ex loss: 0.553594  [   84/   89]
per-ex loss: 0.441616  [   86/   89]
per-ex loss: 0.497038  [   88/   89]
per-ex loss: 0.442739  [   89/   89]
Train Error: Avg loss: 0.47834082
validation Error: 
 Avg loss: 0.98353251 
 F1: 0.509158 
 Precision: 0.558486 
 Recall: 0.467836
 IoU: 0.341524

test Error: 
 Avg loss: 0.98089490 
 F1: 0.531993 
 Precision: 0.582040 
 Recall: 0.489871
 IoU: 0.362392

We have finished training iteration 84
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_82_.pth
per-ex loss: 0.413050  [    2/   89]
per-ex loss: 0.494989  [    4/   89]
per-ex loss: 0.494331  [    6/   89]
per-ex loss: 0.391312  [    8/   89]
per-ex loss: 0.438524  [   10/   89]
per-ex loss: 0.487105  [   12/   89]
per-ex loss: 0.505106  [   14/   89]
per-ex loss: 0.506465  [   16/   89]
per-ex loss: 0.543358  [   18/   89]
per-ex loss: 0.515194  [   20/   89]
per-ex loss: 0.421191  [   22/   89]
per-ex loss: 0.465574  [   24/   89]
per-ex loss: 0.511135  [   26/   89]
per-ex loss: 0.595844  [   28/   89]
per-ex loss: 0.428493  [   30/   89]
per-ex loss: 0.368743  [   32/   89]
per-ex loss: 0.450041  [   34/   89]
per-ex loss: 0.487655  [   36/   89]
per-ex loss: 0.601361  [   38/   89]
per-ex loss: 0.583381  [   40/   89]
per-ex loss: 0.363639  [   42/   89]
per-ex loss: 0.467061  [   44/   89]
per-ex loss: 0.398647  [   46/   89]
per-ex loss: 0.451351  [   48/   89]
per-ex loss: 0.415416  [   50/   89]
per-ex loss: 0.431217  [   52/   89]
per-ex loss: 0.465139  [   54/   89]
per-ex loss: 0.736924  [   56/   89]
per-ex loss: 0.496258  [   58/   89]
per-ex loss: 0.598869  [   60/   89]
per-ex loss: 0.417931  [   62/   89]
per-ex loss: 0.366142  [   64/   89]
per-ex loss: 0.437057  [   66/   89]
per-ex loss: 0.392245  [   68/   89]
per-ex loss: 0.403330  [   70/   89]
per-ex loss: 0.459494  [   72/   89]
per-ex loss: 0.501247  [   74/   89]
per-ex loss: 0.412969  [   76/   89]
per-ex loss: 0.432190  [   78/   89]
per-ex loss: 0.471960  [   80/   89]
per-ex loss: 0.543821  [   82/   89]
per-ex loss: 0.385546  [   84/   89]
per-ex loss: 0.428074  [   86/   89]
per-ex loss: 0.438386  [   88/   89]
per-ex loss: 0.396342  [   89/   89]
Train Error: Avg loss: 0.46698021
validation Error: 
 Avg loss: 0.98054601 
 F1: 0.503974 
 Precision: 0.624541 
 Recall: 0.422425
 IoU: 0.336875

test Error: 
 Avg loss: 0.97826516 
 F1: 0.518225 
 Precision: 0.647250 
 Recall: 0.432090
 IoU: 0.349732

We have finished training iteration 85
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_83_.pth
per-ex loss: 0.364365  [    2/   89]
per-ex loss: 0.462400  [    4/   89]
per-ex loss: 0.520157  [    6/   89]
per-ex loss: 0.563081  [    8/   89]
per-ex loss: 0.554027  [   10/   89]
per-ex loss: 0.394789  [   12/   89]
per-ex loss: 0.520709  [   14/   89]
per-ex loss: 0.447166  [   16/   89]
per-ex loss: 0.400619  [   18/   89]
per-ex loss: 0.396266  [   20/   89]
per-ex loss: 0.503787  [   22/   89]
per-ex loss: 0.415617  [   24/   89]
per-ex loss: 0.438446  [   26/   89]
per-ex loss: 0.441601  [   28/   89]
per-ex loss: 0.483535  [   30/   89]
per-ex loss: 0.398562  [   32/   89]
per-ex loss: 0.481407  [   34/   89]
per-ex loss: 0.430825  [   36/   89]
per-ex loss: 0.413312  [   38/   89]
per-ex loss: 0.548596  [   40/   89]
per-ex loss: 0.370918  [   42/   89]
per-ex loss: 0.455758  [   44/   89]
per-ex loss: 0.561599  [   46/   89]
per-ex loss: 0.494755  [   48/   89]
per-ex loss: 0.509622  [   50/   89]
per-ex loss: 0.395281  [   52/   89]
per-ex loss: 0.489409  [   54/   89]
per-ex loss: 0.602059  [   56/   89]
per-ex loss: 0.448701  [   58/   89]
per-ex loss: 0.459109  [   60/   89]
per-ex loss: 0.395204  [   62/   89]
per-ex loss: 0.591552  [   64/   89]
per-ex loss: 0.370833  [   66/   89]
per-ex loss: 0.415309  [   68/   89]
per-ex loss: 0.450472  [   70/   89]
per-ex loss: 0.395254  [   72/   89]
per-ex loss: 0.488995  [   74/   89]
per-ex loss: 0.502193  [   76/   89]
per-ex loss: 0.557470  [   78/   89]
per-ex loss: 0.570918  [   80/   89]
per-ex loss: 0.464996  [   82/   89]
per-ex loss: 0.432185  [   84/   89]
per-ex loss: 0.636561  [   86/   89]
per-ex loss: 0.360796  [   88/   89]
per-ex loss: 0.406877  [   89/   89]
Train Error: Avg loss: 0.46680197
validation Error: 
 Avg loss: 0.98264222 
 F1: 0.513090 
 Precision: 0.580717 
 Recall: 0.459571
 IoU: 0.345071

test Error: 
 Avg loss: 0.97971707 
 F1: 0.535717 
 Precision: 0.609908 
 Recall: 0.477619
 IoU: 0.365857

We have finished training iteration 86
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_84_.pth
per-ex loss: 0.360908  [    2/   89]
per-ex loss: 0.543371  [    4/   89]
per-ex loss: 0.502586  [    6/   89]
per-ex loss: 0.393893  [    8/   89]
per-ex loss: 0.564783  [   10/   89]
per-ex loss: 0.408517  [   12/   89]
per-ex loss: 0.425369  [   14/   89]
per-ex loss: 0.612036  [   16/   89]
per-ex loss: 0.374590  [   18/   89]
per-ex loss: 0.546953  [   20/   89]
per-ex loss: 0.469611  [   22/   89]
per-ex loss: 0.365067  [   24/   89]
per-ex loss: 0.568929  [   26/   89]
per-ex loss: 0.501120  [   28/   89]
per-ex loss: 0.574829  [   30/   89]
per-ex loss: 0.418256  [   32/   89]
per-ex loss: 0.528664  [   34/   89]
per-ex loss: 0.452291  [   36/   89]
per-ex loss: 0.349192  [   38/   89]
per-ex loss: 0.519707  [   40/   89]
per-ex loss: 0.532413  [   42/   89]
per-ex loss: 0.396191  [   44/   89]
per-ex loss: 0.414215  [   46/   89]
per-ex loss: 0.576336  [   48/   89]
per-ex loss: 0.374232  [   50/   89]
per-ex loss: 0.492545  [   52/   89]
per-ex loss: 0.436393  [   54/   89]
per-ex loss: 0.446097  [   56/   89]
per-ex loss: 0.583042  [   58/   89]
per-ex loss: 0.569082  [   60/   89]
per-ex loss: 0.447904  [   62/   89]
per-ex loss: 0.501439  [   64/   89]
per-ex loss: 0.579420  [   66/   89]
per-ex loss: 0.541696  [   68/   89]
per-ex loss: 0.365809  [   70/   89]
per-ex loss: 0.388685  [   72/   89]
per-ex loss: 0.363414  [   74/   89]
per-ex loss: 0.404566  [   76/   89]
per-ex loss: 0.544779  [   78/   89]
per-ex loss: 0.537709  [   80/   89]
per-ex loss: 0.605457  [   82/   89]
per-ex loss: 0.587478  [   84/   89]
per-ex loss: 0.403855  [   86/   89]
per-ex loss: 0.429858  [   88/   89]
per-ex loss: 0.428934  [   89/   89]
Train Error: Avg loss: 0.47627156
validation Error: 
 Avg loss: 0.98272123 
 F1: 0.512827 
 Precision: 0.591255 
 Recall: 0.452768
 IoU: 0.344833

test Error: 
 Avg loss: 0.98000912 
 F1: 0.533193 
 Precision: 0.615032 
 Recall: 0.470576
 IoU: 0.363506

We have finished training iteration 87
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_85_.pth
per-ex loss: 0.501701  [    2/   89]
per-ex loss: 0.455871  [    4/   89]
per-ex loss: 0.638787  [    6/   89]
per-ex loss: 0.452208  [    8/   89]
per-ex loss: 0.457422  [   10/   89]
per-ex loss: 0.586025  [   12/   89]
per-ex loss: 0.451079  [   14/   89]
per-ex loss: 0.391573  [   16/   89]
per-ex loss: 0.589119  [   18/   89]
per-ex loss: 0.443698  [   20/   89]
per-ex loss: 0.467518  [   22/   89]
per-ex loss: 0.536523  [   24/   89]
per-ex loss: 0.431019  [   26/   89]
per-ex loss: 0.450681  [   28/   89]
per-ex loss: 0.449108  [   30/   89]
per-ex loss: 0.584588  [   32/   89]
per-ex loss: 0.444887  [   34/   89]
per-ex loss: 0.357639  [   36/   89]
per-ex loss: 0.496125  [   38/   89]
per-ex loss: 0.434909  [   40/   89]
per-ex loss: 0.393177  [   42/   89]
per-ex loss: 0.451385  [   44/   89]
per-ex loss: 0.449543  [   46/   89]
per-ex loss: 0.464568  [   48/   89]
per-ex loss: 0.605983  [   50/   89]
per-ex loss: 0.428083  [   52/   89]
per-ex loss: 0.432591  [   54/   89]
per-ex loss: 0.502112  [   56/   89]
per-ex loss: 0.515922  [   58/   89]
per-ex loss: 0.443622  [   60/   89]
per-ex loss: 0.420059  [   62/   89]
per-ex loss: 0.364042  [   64/   89]
per-ex loss: 0.374854  [   66/   89]
per-ex loss: 0.542594  [   68/   89]
per-ex loss: 0.514854  [   70/   89]
per-ex loss: 0.435515  [   72/   89]
per-ex loss: 0.404625  [   74/   89]
per-ex loss: 0.482508  [   76/   89]
per-ex loss: 0.410803  [   78/   89]
per-ex loss: 0.459905  [   80/   89]
per-ex loss: 0.413438  [   82/   89]
per-ex loss: 0.558264  [   84/   89]
per-ex loss: 0.394065  [   86/   89]
per-ex loss: 0.393971  [   88/   89]
per-ex loss: 0.327082  [   89/   89]
Train Error: Avg loss: 0.46231210
validation Error: 
 Avg loss: 0.98326655 
 F1: 0.510393 
 Precision: 0.553088 
 Recall: 0.473817
 IoU: 0.342636

test Error: 
 Avg loss: 0.98084269 
 F1: 0.529530 
 Precision: 0.571062 
 Recall: 0.493630
 IoU: 0.360110

We have finished training iteration 88
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_86_.pth
per-ex loss: 0.541926  [    2/   89]
per-ex loss: 0.485339  [    4/   89]
per-ex loss: 0.660064  [    6/   89]
per-ex loss: 0.592713  [    8/   89]
per-ex loss: 0.563203  [   10/   89]
per-ex loss: 0.425906  [   12/   89]
per-ex loss: 0.535938  [   14/   89]
per-ex loss: 0.610033  [   16/   89]
per-ex loss: 0.595161  [   18/   89]
per-ex loss: 0.437200  [   20/   89]
per-ex loss: 0.397093  [   22/   89]
per-ex loss: 0.428153  [   24/   89]
per-ex loss: 0.378474  [   26/   89]
per-ex loss: 0.440196  [   28/   89]
per-ex loss: 0.563122  [   30/   89]
per-ex loss: 0.368163  [   32/   89]
per-ex loss: 0.587869  [   34/   89]
per-ex loss: 0.355080  [   36/   89]
per-ex loss: 0.443287  [   38/   89]
per-ex loss: 0.466673  [   40/   89]
per-ex loss: 0.440968  [   42/   89]
per-ex loss: 0.516890  [   44/   89]
per-ex loss: 0.386561  [   46/   89]
per-ex loss: 0.440965  [   48/   89]
per-ex loss: 0.463090  [   50/   89]
per-ex loss: 0.346931  [   52/   89]
per-ex loss: 0.473657  [   54/   89]
per-ex loss: 0.465720  [   56/   89]
per-ex loss: 0.331111  [   58/   89]
per-ex loss: 0.358218  [   60/   89]
per-ex loss: 0.415959  [   62/   89]
per-ex loss: 0.453334  [   64/   89]
per-ex loss: 0.424880  [   66/   89]
per-ex loss: 0.458229  [   68/   89]
per-ex loss: 0.449094  [   70/   89]
per-ex loss: 0.496147  [   72/   89]
per-ex loss: 0.415818  [   74/   89]
per-ex loss: 0.482199  [   76/   89]
per-ex loss: 0.493966  [   78/   89]
per-ex loss: 0.491379  [   80/   89]
per-ex loss: 0.525869  [   82/   89]
per-ex loss: 0.451370  [   84/   89]
per-ex loss: 0.399795  [   86/   89]
per-ex loss: 0.514314  [   88/   89]
per-ex loss: 0.534617  [   89/   89]
Train Error: Avg loss: 0.46903716
validation Error: 
 Avg loss: 0.98377113 
 F1: 0.507760 
 Precision: 0.554488 
 Recall: 0.468296
 IoU: 0.340267

test Error: 
 Avg loss: 0.98129671 
 F1: 0.526772 
 Precision: 0.575176 
 Recall: 0.485882
 IoU: 0.357563

We have finished training iteration 89
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_87_.pth
per-ex loss: 0.578425  [    2/   89]
per-ex loss: 0.516797  [    4/   89]
per-ex loss: 0.420591  [    6/   89]
per-ex loss: 0.378488  [    8/   89]
per-ex loss: 0.387551  [   10/   89]
per-ex loss: 0.376875  [   12/   89]
per-ex loss: 0.390758  [   14/   89]
per-ex loss: 0.606290  [   16/   89]
per-ex loss: 0.492168  [   18/   89]
per-ex loss: 0.460092  [   20/   89]
per-ex loss: 0.563639  [   22/   89]
per-ex loss: 0.421439  [   24/   89]
per-ex loss: 0.646578  [   26/   89]
per-ex loss: 0.563230  [   28/   89]
per-ex loss: 0.630820  [   30/   89]
per-ex loss: 0.502328  [   32/   89]
per-ex loss: 0.439289  [   34/   89]
per-ex loss: 0.387744  [   36/   89]
per-ex loss: 0.545983  [   38/   89]
per-ex loss: 0.577142  [   40/   89]
per-ex loss: 0.631174  [   42/   89]
per-ex loss: 0.393264  [   44/   89]
per-ex loss: 0.430402  [   46/   89]
per-ex loss: 0.392939  [   48/   89]
per-ex loss: 0.444791  [   50/   89]
per-ex loss: 0.406218  [   52/   89]
per-ex loss: 0.566518  [   54/   89]
per-ex loss: 0.480060  [   56/   89]
per-ex loss: 0.519413  [   58/   89]
per-ex loss: 0.559595  [   60/   89]
per-ex loss: 0.462895  [   62/   89]
per-ex loss: 0.547072  [   64/   89]
per-ex loss: 0.369194  [   66/   89]
per-ex loss: 0.486829  [   68/   89]
per-ex loss: 0.388206  [   70/   89]
per-ex loss: 0.592905  [   72/   89]
per-ex loss: 0.511159  [   74/   89]
per-ex loss: 0.434143  [   76/   89]
per-ex loss: 0.492018  [   78/   89]
per-ex loss: 0.459434  [   80/   89]
per-ex loss: 0.353048  [   82/   89]
per-ex loss: 0.356601  [   84/   89]
per-ex loss: 0.540301  [   86/   89]
per-ex loss: 0.383948  [   88/   89]
per-ex loss: 0.417185  [   89/   89]
Train Error: Avg loss: 0.47790088
validation Error: 
 Avg loss: 0.98264751 
 F1: 0.513540 
 Precision: 0.581149 
 Recall: 0.460022
 IoU: 0.345479

test Error: 
 Avg loss: 0.98017357 
 F1: 0.532777 
 Precision: 0.606472 
 Recall: 0.475051
 IoU: 0.363119

We have finished training iteration 90
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_88_.pth
per-ex loss: 0.358890  [    2/   89]
per-ex loss: 0.415123  [    4/   89]
per-ex loss: 0.398774  [    6/   89]
per-ex loss: 0.487581  [    8/   89]
per-ex loss: 0.554457  [   10/   89]
per-ex loss: 0.558848  [   12/   89]
per-ex loss: 0.515849  [   14/   89]
per-ex loss: 0.362813  [   16/   89]
per-ex loss: 0.540785  [   18/   89]
per-ex loss: 0.458302  [   20/   89]
per-ex loss: 0.477197  [   22/   89]
per-ex loss: 0.619625  [   24/   89]
per-ex loss: 0.398103  [   26/   89]
per-ex loss: 0.634186  [   28/   89]
per-ex loss: 0.527721  [   30/   89]
per-ex loss: 0.394715  [   32/   89]
per-ex loss: 0.484211  [   34/   89]
per-ex loss: 0.489227  [   36/   89]
per-ex loss: 0.540868  [   38/   89]
per-ex loss: 0.464538  [   40/   89]
per-ex loss: 0.615583  [   42/   89]
per-ex loss: 0.430638  [   44/   89]
per-ex loss: 0.443847  [   46/   89]
per-ex loss: 0.421610  [   48/   89]
per-ex loss: 0.384460  [   50/   89]
per-ex loss: 0.468026  [   52/   89]
per-ex loss: 0.576694  [   54/   89]
per-ex loss: 0.485101  [   56/   89]
per-ex loss: 0.392923  [   58/   89]
per-ex loss: 0.569222  [   60/   89]
per-ex loss: 0.361955  [   62/   89]
per-ex loss: 0.436381  [   64/   89]
per-ex loss: 0.503171  [   66/   89]
per-ex loss: 0.394483  [   68/   89]
per-ex loss: 0.516248  [   70/   89]
per-ex loss: 0.661925  [   72/   89]
per-ex loss: 0.398698  [   74/   89]
per-ex loss: 0.381676  [   76/   89]
per-ex loss: 0.440029  [   78/   89]
per-ex loss: 0.625053  [   80/   89]
per-ex loss: 0.480935  [   82/   89]
per-ex loss: 0.551428  [   84/   89]
per-ex loss: 0.392217  [   86/   89]
per-ex loss: 0.434076  [   88/   89]
per-ex loss: 0.628726  [   89/   89]
Train Error: Avg loss: 0.48170934
validation Error: 
 Avg loss: 0.98149134 
 F1: 0.509853 
 Precision: 0.627906 
 Recall: 0.429165
 IoU: 0.342149

test Error: 
 Avg loss: 0.97865820 
 F1: 0.523460 
 Precision: 0.644915 
 Recall: 0.440501
 IoU: 0.354518

We have finished training iteration 91
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_89_.pth
per-ex loss: 0.415803  [    2/   89]
per-ex loss: 0.657456  [    4/   89]
per-ex loss: 0.498852  [    6/   89]
per-ex loss: 0.384519  [    8/   89]
per-ex loss: 0.346956  [   10/   89]
per-ex loss: 0.449580  [   12/   89]
per-ex loss: 0.359342  [   14/   89]
per-ex loss: 0.578763  [   16/   89]
per-ex loss: 0.645159  [   18/   89]
per-ex loss: 0.365753  [   20/   89]
per-ex loss: 0.498991  [   22/   89]
per-ex loss: 0.597120  [   24/   89]
per-ex loss: 0.464344  [   26/   89]
per-ex loss: 0.417640  [   28/   89]
per-ex loss: 0.412061  [   30/   89]
per-ex loss: 0.411964  [   32/   89]
per-ex loss: 0.379272  [   34/   89]
per-ex loss: 0.433807  [   36/   89]
per-ex loss: 0.486011  [   38/   89]
per-ex loss: 0.636839  [   40/   89]
per-ex loss: 0.448943  [   42/   89]
per-ex loss: 0.460203  [   44/   89]
per-ex loss: 0.546489  [   46/   89]
per-ex loss: 0.501773  [   48/   89]
per-ex loss: 0.482223  [   50/   89]
per-ex loss: 0.524812  [   52/   89]
per-ex loss: 0.408484  [   54/   89]
per-ex loss: 0.653248  [   56/   89]
per-ex loss: 0.410191  [   58/   89]
per-ex loss: 0.549101  [   60/   89]
per-ex loss: 0.458742  [   62/   89]
per-ex loss: 0.487554  [   64/   89]
per-ex loss: 0.370739  [   66/   89]
per-ex loss: 0.530336  [   68/   89]
per-ex loss: 0.484451  [   70/   89]
per-ex loss: 0.548120  [   72/   89]
per-ex loss: 0.411839  [   74/   89]
per-ex loss: 0.353382  [   76/   89]
per-ex loss: 0.401571  [   78/   89]
per-ex loss: 0.519558  [   80/   89]
per-ex loss: 0.390954  [   82/   89]
per-ex loss: 0.451110  [   84/   89]
per-ex loss: 0.631599  [   86/   89]
per-ex loss: 0.498262  [   88/   89]
per-ex loss: 0.422724  [   89/   89]
Train Error: Avg loss: 0.47525864
validation Error: 
 Avg loss: 0.98387294 
 F1: 0.514322 
 Precision: 0.556375 
 Recall: 0.478180
 IoU: 0.346187

test Error: 
 Avg loss: 0.98106938 
 F1: 0.535742 
 Precision: 0.579054 
 Recall: 0.498459
 IoU: 0.365880

We have finished training iteration 92
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_90_.pth
per-ex loss: 0.399753  [    2/   89]
per-ex loss: 0.390029  [    4/   89]
per-ex loss: 0.715871  [    6/   89]
per-ex loss: 0.354947  [    8/   89]
per-ex loss: 0.487472  [   10/   89]
per-ex loss: 0.470584  [   12/   89]
per-ex loss: 0.407918  [   14/   89]
per-ex loss: 0.463478  [   16/   89]
per-ex loss: 0.369359  [   18/   89]
per-ex loss: 0.531336  [   20/   89]
per-ex loss: 0.505783  [   22/   89]
per-ex loss: 0.361914  [   24/   89]
per-ex loss: 0.456678  [   26/   89]
per-ex loss: 0.501268  [   28/   89]
per-ex loss: 0.384661  [   30/   89]
per-ex loss: 0.412789  [   32/   89]
per-ex loss: 0.478740  [   34/   89]
per-ex loss: 0.461041  [   36/   89]
per-ex loss: 0.391742  [   38/   89]
per-ex loss: 0.613093  [   40/   89]
per-ex loss: 0.563544  [   42/   89]
per-ex loss: 0.446427  [   44/   89]
per-ex loss: 0.425133  [   46/   89]
per-ex loss: 0.434008  [   48/   89]
per-ex loss: 0.379390  [   50/   89]
per-ex loss: 0.480066  [   52/   89]
per-ex loss: 0.570216  [   54/   89]
per-ex loss: 0.458268  [   56/   89]
per-ex loss: 0.444648  [   58/   89]
per-ex loss: 0.388765  [   60/   89]
per-ex loss: 0.483658  [   62/   89]
per-ex loss: 0.500035  [   64/   89]
per-ex loss: 0.610591  [   66/   89]
per-ex loss: 0.502700  [   68/   89]
per-ex loss: 0.368735  [   70/   89]
per-ex loss: 0.577835  [   72/   89]
per-ex loss: 0.416070  [   74/   89]
per-ex loss: 0.519652  [   76/   89]
per-ex loss: 0.455504  [   78/   89]
per-ex loss: 0.384856  [   80/   89]
per-ex loss: 0.505763  [   82/   89]
per-ex loss: 0.422579  [   84/   89]
per-ex loss: 0.428998  [   86/   89]
per-ex loss: 0.425431  [   88/   89]
per-ex loss: 0.421798  [   89/   89]
Train Error: Avg loss: 0.46162508
validation Error: 
 Avg loss: 0.98325969 
 F1: 0.515153 
 Precision: 0.585149 
 Recall: 0.460114
 IoU: 0.346941

test Error: 
 Avg loss: 0.98064544 
 F1: 0.535558 
 Precision: 0.602209 
 Recall: 0.482190
 IoU: 0.365708

We have finished training iteration 93
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_91_.pth
per-ex loss: 0.537179  [    2/   89]
per-ex loss: 0.345338  [    4/   89]
per-ex loss: 0.481398  [    6/   89]
per-ex loss: 0.478686  [    8/   89]
per-ex loss: 0.390839  [   10/   89]
per-ex loss: 0.519125  [   12/   89]
per-ex loss: 0.457004  [   14/   89]
per-ex loss: 0.598028  [   16/   89]
per-ex loss: 0.515510  [   18/   89]
per-ex loss: 0.615980  [   20/   89]
per-ex loss: 0.431253  [   22/   89]
per-ex loss: 0.401595  [   24/   89]
per-ex loss: 0.473647  [   26/   89]
per-ex loss: 0.478919  [   28/   89]
per-ex loss: 0.464649  [   30/   89]
per-ex loss: 0.438776  [   32/   89]
per-ex loss: 0.551588  [   34/   89]
per-ex loss: 0.413007  [   36/   89]
per-ex loss: 0.523311  [   38/   89]
per-ex loss: 0.372872  [   40/   89]
per-ex loss: 0.410002  [   42/   89]
per-ex loss: 0.421962  [   44/   89]
per-ex loss: 0.354273  [   46/   89]
per-ex loss: 0.562504  [   48/   89]
per-ex loss: 0.568829  [   50/   89]
per-ex loss: 0.447840  [   52/   89]
per-ex loss: 0.392455  [   54/   89]
per-ex loss: 0.412858  [   56/   89]
per-ex loss: 0.398152  [   58/   89]
per-ex loss: 0.594396  [   60/   89]
per-ex loss: 0.587818  [   62/   89]
per-ex loss: 0.397546  [   64/   89]
per-ex loss: 0.481153  [   66/   89]
per-ex loss: 0.426583  [   68/   89]
per-ex loss: 0.491999  [   70/   89]
per-ex loss: 0.607263  [   72/   89]
per-ex loss: 0.445645  [   74/   89]
per-ex loss: 0.662854  [   76/   89]
per-ex loss: 0.476514  [   78/   89]
per-ex loss: 0.407841  [   80/   89]
per-ex loss: 0.422930  [   82/   89]
per-ex loss: 0.364427  [   84/   89]
per-ex loss: 0.418800  [   86/   89]
per-ex loss: 0.375269  [   88/   89]
per-ex loss: 0.355445  [   89/   89]
Train Error: Avg loss: 0.46609030
validation Error: 
 Avg loss: 0.98265944 
 F1: 0.514671 
 Precision: 0.578816 
 Recall: 0.463325
 IoU: 0.346503

test Error: 
 Avg loss: 0.98058871 
 F1: 0.533983 
 Precision: 0.593753 
 Recall: 0.485146
 IoU: 0.364241

We have finished training iteration 94
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_92_.pth
per-ex loss: 0.501926  [    2/   89]
per-ex loss: 0.445555  [    4/   89]
per-ex loss: 0.545440  [    6/   89]
per-ex loss: 0.431868  [    8/   89]
per-ex loss: 0.429773  [   10/   89]
per-ex loss: 0.400214  [   12/   89]
per-ex loss: 0.470070  [   14/   89]
per-ex loss: 0.500807  [   16/   89]
per-ex loss: 0.564036  [   18/   89]
per-ex loss: 0.475935  [   20/   89]
per-ex loss: 0.470356  [   22/   89]
per-ex loss: 0.548165  [   24/   89]
per-ex loss: 0.461317  [   26/   89]
per-ex loss: 0.588750  [   28/   89]
per-ex loss: 0.554073  [   30/   89]
per-ex loss: 0.461059  [   32/   89]
per-ex loss: 0.430500  [   34/   89]
per-ex loss: 0.417172  [   36/   89]
per-ex loss: 0.384370  [   38/   89]
per-ex loss: 0.559065  [   40/   89]
per-ex loss: 0.337195  [   42/   89]
per-ex loss: 0.372833  [   44/   89]
per-ex loss: 0.557749  [   46/   89]
per-ex loss: 0.498284  [   48/   89]
per-ex loss: 0.402283  [   50/   89]
per-ex loss: 0.638761  [   52/   89]
per-ex loss: 0.595415  [   54/   89]
per-ex loss: 0.403441  [   56/   89]
per-ex loss: 0.567833  [   58/   89]
per-ex loss: 0.430315  [   60/   89]
per-ex loss: 0.438577  [   62/   89]
per-ex loss: 0.406949  [   64/   89]
per-ex loss: 0.698368  [   66/   89]
per-ex loss: 0.387340  [   68/   89]
per-ex loss: 0.393081  [   70/   89]
per-ex loss: 0.476553  [   72/   89]
per-ex loss: 0.528449  [   74/   89]
per-ex loss: 0.584731  [   76/   89]
per-ex loss: 0.361016  [   78/   89]
per-ex loss: 0.605888  [   80/   89]
per-ex loss: 0.374818  [   82/   89]
per-ex loss: 0.381215  [   84/   89]
per-ex loss: 0.637679  [   86/   89]
per-ex loss: 0.379715  [   88/   89]
per-ex loss: 0.317522  [   89/   89]
Train Error: Avg loss: 0.47592134
validation Error: 
 Avg loss: 0.98309159 
 F1: 0.513824 
 Precision: 0.553170 
 Recall: 0.479703
 IoU: 0.345735

test Error: 
 Avg loss: 0.98125953 
 F1: 0.533808 
 Precision: 0.572339 
 Recall: 0.500138
 IoU: 0.364078

We have finished training iteration 95
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_93_.pth
Error in cropping the image to the non-zero values in the fourth channel. Returned the original image.
per-ex loss: 0.466579  [    2/   89]
per-ex loss: 0.545327  [    4/   89]
per-ex loss: 0.695023  [    6/   89]
per-ex loss: 0.460157  [    8/   89]
per-ex loss: 0.406774  [   10/   89]
per-ex loss: 0.372662  [   12/   89]
per-ex loss: 0.407477  [   14/   89]
per-ex loss: 0.522550  [   16/   89]
per-ex loss: 0.401708  [   18/   89]
per-ex loss: 0.459756  [   20/   89]
per-ex loss: 0.444667  [   22/   89]
per-ex loss: 0.413020  [   24/   89]
per-ex loss: 0.395549  [   26/   89]
per-ex loss: 0.516464  [   28/   89]
per-ex loss: 0.544041  [   30/   89]
per-ex loss: 0.505188  [   32/   89]
per-ex loss: 0.647288  [   34/   89]
per-ex loss: 0.453472  [   36/   89]
per-ex loss: 0.468461  [   38/   89]
per-ex loss: 0.446182  [   40/   89]
per-ex loss: 0.386973  [   42/   89]
per-ex loss: 0.463401  [   44/   89]
per-ex loss: 0.508192  [   46/   89]
per-ex loss: 0.395119  [   48/   89]
per-ex loss: 0.411485  [   50/   89]
per-ex loss: 0.459244  [   52/   89]
per-ex loss: 0.404357  [   54/   89]
per-ex loss: 0.459813  [   56/   89]
per-ex loss: 0.572288  [   58/   89]
per-ex loss: 0.459949  [   60/   89]
per-ex loss: 0.511168  [   62/   89]
per-ex loss: 0.554944  [   64/   89]
per-ex loss: 0.406428  [   66/   89]
per-ex loss: 0.583271  [   68/   89]
per-ex loss: 0.400246  [   70/   89]
per-ex loss: 0.441211  [   72/   89]
per-ex loss: 0.405443  [   74/   89]
per-ex loss: 0.473519  [   76/   89]
per-ex loss: 0.504766  [   78/   89]
per-ex loss: 0.547838  [   80/   89]
per-ex loss: 0.340507  [   82/   89]
per-ex loss: 0.421353  [   84/   89]
per-ex loss: 0.659657  [   86/   89]
per-ex loss: 0.594031  [   88/   89]
per-ex loss: 0.565802  [   89/   89]
Train Error: Avg loss: 0.47785220
validation Error: 
 Avg loss: 0.98215702 
 F1: 0.513445 
 Precision: 0.603785 
 Recall: 0.446621
 IoU: 0.345393

test Error: 
 Avg loss: 0.97980179 
 F1: 0.534061 
 Precision: 0.630776 
 Recall: 0.463061
 IoU: 0.364313

We have finished training iteration 96
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_94_.pth
per-ex loss: 0.509225  [    2/   89]
per-ex loss: 0.533231  [    4/   89]
per-ex loss: 0.416418  [    6/   89]
per-ex loss: 0.426700  [    8/   89]
per-ex loss: 0.440444  [   10/   89]
per-ex loss: 0.486665  [   12/   89]
per-ex loss: 0.520445  [   14/   89]
per-ex loss: 0.489992  [   16/   89]
per-ex loss: 0.585566  [   18/   89]
per-ex loss: 0.581945  [   20/   89]
per-ex loss: 0.571304  [   22/   89]
per-ex loss: 0.497529  [   24/   89]
per-ex loss: 0.593572  [   26/   89]
per-ex loss: 0.540649  [   28/   89]
per-ex loss: 0.436312  [   30/   89]
per-ex loss: 0.452264  [   32/   89]
per-ex loss: 0.439493  [   34/   89]
per-ex loss: 0.471834  [   36/   89]
per-ex loss: 0.401081  [   38/   89]
per-ex loss: 0.343075  [   40/   89]
per-ex loss: 0.397452  [   42/   89]
per-ex loss: 0.550618  [   44/   89]
per-ex loss: 0.391927  [   46/   89]
per-ex loss: 0.355390  [   48/   89]
per-ex loss: 0.391696  [   50/   89]
per-ex loss: 0.395422  [   52/   89]
per-ex loss: 0.599686  [   54/   89]
per-ex loss: 0.392733  [   56/   89]
per-ex loss: 0.433830  [   58/   89]
per-ex loss: 0.715065  [   60/   89]
per-ex loss: 0.450239  [   62/   89]
per-ex loss: 0.454879  [   64/   89]
per-ex loss: 0.525155  [   66/   89]
per-ex loss: 0.435058  [   68/   89]
per-ex loss: 0.486702  [   70/   89]
per-ex loss: 0.417951  [   72/   89]
per-ex loss: 0.391978  [   74/   89]
per-ex loss: 0.392851  [   76/   89]
per-ex loss: 0.493959  [   78/   89]
per-ex loss: 0.445400  [   80/   89]
per-ex loss: 0.443850  [   82/   89]
per-ex loss: 0.541465  [   84/   89]
per-ex loss: 0.610644  [   86/   89]
per-ex loss: 0.607997  [   88/   89]
per-ex loss: 0.432274  [   89/   89]
Train Error: Avg loss: 0.47759921
validation Error: 
 Avg loss: 0.98145837 
 F1: 0.516408 
 Precision: 0.595555 
 Recall: 0.455830
 IoU: 0.348080

test Error: 
 Avg loss: 0.98024108 
 F1: 0.535696 
 Precision: 0.614354 
 Recall: 0.474893
 IoU: 0.365836

We have finished training iteration 97
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_95_.pth
per-ex loss: 0.532913  [    2/   89]
per-ex loss: 0.436515  [    4/   89]
per-ex loss: 0.525913  [    6/   89]
per-ex loss: 0.406965  [    8/   89]
per-ex loss: 0.479162  [   10/   89]
per-ex loss: 0.498116  [   12/   89]
per-ex loss: 0.388938  [   14/   89]
per-ex loss: 0.448518  [   16/   89]
per-ex loss: 0.503007  [   18/   89]
per-ex loss: 0.394011  [   20/   89]
per-ex loss: 0.520832  [   22/   89]
per-ex loss: 0.470885  [   24/   89]
per-ex loss: 0.702223  [   26/   89]
per-ex loss: 0.548582  [   28/   89]
per-ex loss: 0.375717  [   30/   89]
per-ex loss: 0.398986  [   32/   89]
per-ex loss: 0.520854  [   34/   89]
per-ex loss: 0.418160  [   36/   89]
per-ex loss: 0.506571  [   38/   89]
per-ex loss: 0.714890  [   40/   89]
per-ex loss: 0.561961  [   42/   89]
per-ex loss: 0.550314  [   44/   89]
per-ex loss: 0.436407  [   46/   89]
per-ex loss: 0.420905  [   48/   89]
per-ex loss: 0.379703  [   50/   89]
per-ex loss: 0.360051  [   52/   89]
per-ex loss: 0.423803  [   54/   89]
per-ex loss: 0.445841  [   56/   89]
per-ex loss: 0.386616  [   58/   89]
per-ex loss: 0.484709  [   60/   89]
per-ex loss: 0.465316  [   62/   89]
per-ex loss: 0.462123  [   64/   89]
per-ex loss: 0.395587  [   66/   89]
per-ex loss: 0.427631  [   68/   89]
per-ex loss: 0.503447  [   70/   89]
per-ex loss: 0.571771  [   72/   89]
per-ex loss: 0.420346  [   74/   89]
per-ex loss: 0.385593  [   76/   89]
per-ex loss: 0.510966  [   78/   89]
per-ex loss: 0.626556  [   80/   89]
per-ex loss: 0.428532  [   82/   89]
per-ex loss: 0.391671  [   84/   89]
per-ex loss: 0.444841  [   86/   89]
per-ex loss: 0.417274  [   88/   89]
per-ex loss: 0.453595  [   89/   89]
Train Error: Avg loss: 0.46994034
validation Error: 
 Avg loss: 0.98333677 
 F1: 0.513204 
 Precision: 0.579348 
 Recall: 0.460615
 IoU: 0.345174

test Error: 
 Avg loss: 0.98087371 
 F1: 0.526017 
 Precision: 0.593683 
 Recall: 0.472198
 IoU: 0.356868

We have finished training iteration 98
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_96_.pth
per-ex loss: 0.524244  [    2/   89]
per-ex loss: 0.372576  [    4/   89]
per-ex loss: 0.508961  [    6/   89]
per-ex loss: 0.548822  [    8/   89]
per-ex loss: 0.422523  [   10/   89]
per-ex loss: 0.488682  [   12/   89]
per-ex loss: 0.605942  [   14/   89]
per-ex loss: 0.423737  [   16/   89]
per-ex loss: 0.495643  [   18/   89]
per-ex loss: 0.449499  [   20/   89]
per-ex loss: 0.453730  [   22/   89]
per-ex loss: 0.582710  [   24/   89]
per-ex loss: 0.388461  [   26/   89]
per-ex loss: 0.377853  [   28/   89]
per-ex loss: 0.382525  [   30/   89]
per-ex loss: 0.431683  [   32/   89]
per-ex loss: 0.648071  [   34/   89]
per-ex loss: 0.408886  [   36/   89]
per-ex loss: 0.397537  [   38/   89]
per-ex loss: 0.562530  [   40/   89]
per-ex loss: 0.475891  [   42/   89]
per-ex loss: 0.558937  [   44/   89]
per-ex loss: 0.382254  [   46/   89]
per-ex loss: 0.383865  [   48/   89]
per-ex loss: 0.534743  [   50/   89]
per-ex loss: 0.434665  [   52/   89]
per-ex loss: 0.460873  [   54/   89]
per-ex loss: 0.605528  [   56/   89]
per-ex loss: 0.459842  [   58/   89]
per-ex loss: 0.447683  [   60/   89]
per-ex loss: 0.521448  [   62/   89]
per-ex loss: 0.402683  [   64/   89]
per-ex loss: 0.544422  [   66/   89]
per-ex loss: 0.395670  [   68/   89]
per-ex loss: 0.612160  [   70/   89]
per-ex loss: 0.579180  [   72/   89]
per-ex loss: 0.582860  [   74/   89]
per-ex loss: 0.595090  [   76/   89]
per-ex loss: 0.407667  [   78/   89]
per-ex loss: 0.406903  [   80/   89]
per-ex loss: 0.491350  [   82/   89]
per-ex loss: 0.556207  [   84/   89]
per-ex loss: 0.421026  [   86/   89]
per-ex loss: 0.579378  [   88/   89]
per-ex loss: 0.576569  [   89/   89]
Train Error: Avg loss: 0.48647794
validation Error: 
 Avg loss: 0.98236147 
 F1: 0.509294 
 Precision: 0.611690 
 Recall: 0.436264
 IoU: 0.341646

test Error: 
 Avg loss: 0.97947881 
 F1: 0.525283 
 Precision: 0.633531 
 Recall: 0.448629
 IoU: 0.356192

We have finished training iteration 99
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_97_.pth
per-ex loss: 0.433222  [    2/   89]
per-ex loss: 0.403415  [    4/   89]
per-ex loss: 0.395594  [    6/   89]
per-ex loss: 0.627993  [    8/   89]
per-ex loss: 0.421288  [   10/   89]
per-ex loss: 0.409827  [   12/   89]
per-ex loss: 0.372355  [   14/   89]
per-ex loss: 0.489645  [   16/   89]
per-ex loss: 0.424424  [   18/   89]
per-ex loss: 0.376970  [   20/   89]
per-ex loss: 0.601753  [   22/   89]
per-ex loss: 0.413971  [   24/   89]
per-ex loss: 0.383724  [   26/   89]
per-ex loss: 0.405715  [   28/   89]
per-ex loss: 0.674706  [   30/   89]
per-ex loss: 0.404287  [   32/   89]
per-ex loss: 0.384121  [   34/   89]
per-ex loss: 0.381815  [   36/   89]
per-ex loss: 0.410325  [   38/   89]
per-ex loss: 0.631598  [   40/   89]
per-ex loss: 0.483456  [   42/   89]
per-ex loss: 0.469868  [   44/   89]
per-ex loss: 0.531773  [   46/   89]
per-ex loss: 0.674436  [   48/   89]
per-ex loss: 0.494417  [   50/   89]
per-ex loss: 0.499505  [   52/   89]
per-ex loss: 0.394962  [   54/   89]
per-ex loss: 0.536503  [   56/   89]
per-ex loss: 0.514160  [   58/   89]
per-ex loss: 0.411800  [   60/   89]
per-ex loss: 0.537601  [   62/   89]
per-ex loss: 0.447727  [   64/   89]
per-ex loss: 0.338333  [   66/   89]
per-ex loss: 0.546295  [   68/   89]
per-ex loss: 0.471074  [   70/   89]
per-ex loss: 0.465722  [   72/   89]
per-ex loss: 0.432615  [   74/   89]
per-ex loss: 0.358305  [   76/   89]
per-ex loss: 0.462665  [   78/   89]
per-ex loss: 0.531087  [   80/   89]
per-ex loss: 0.604339  [   82/   89]
per-ex loss: 0.410770  [   84/   89]
per-ex loss: 0.536833  [   86/   89]
per-ex loss: 0.503485  [   88/   89]
per-ex loss: 0.389432  [   89/   89]
Train Error: Avg loss: 0.46875357
validation Error: 
 Avg loss: 0.98224352 
 F1: 0.513951 
 Precision: 0.597859 
 Recall: 0.450697
 IoU: 0.345851

test Error: 
 Avg loss: 0.97960881 
 F1: 0.530353 
 Precision: 0.612527 
 Recall: 0.467619
 IoU: 0.360871

We have finished training iteration 100
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_98_.pth
Error in cropping the image to the non-zero values in the fourth channel. Returned the original image.
per-ex loss: 0.405386  [    2/   89]
per-ex loss: 0.485574  [    4/   89]
per-ex loss: 0.423800  [    6/   89]
per-ex loss: 0.563239  [    8/   89]
per-ex loss: 0.435254  [   10/   89]
per-ex loss: 0.361278  [   12/   89]
per-ex loss: 0.383610  [   14/   89]
per-ex loss: 0.434825  [   16/   89]
per-ex loss: 0.398217  [   18/   89]
per-ex loss: 0.466062  [   20/   89]
per-ex loss: 0.450350  [   22/   89]
per-ex loss: 0.363902  [   24/   89]
per-ex loss: 0.407845  [   26/   89]
per-ex loss: 0.389725  [   28/   89]
per-ex loss: 0.465237  [   30/   89]
per-ex loss: 0.485059  [   32/   89]
per-ex loss: 0.529534  [   34/   89]
per-ex loss: 0.358794  [   36/   89]
per-ex loss: 0.405133  [   38/   89]
per-ex loss: 0.382874  [   40/   89]
per-ex loss: 0.378347  [   42/   89]
per-ex loss: 0.434539  [   44/   89]
per-ex loss: 0.587402  [   46/   89]
per-ex loss: 0.668507  [   48/   89]
per-ex loss: 0.582859  [   50/   89]
per-ex loss: 0.446013  [   52/   89]
per-ex loss: 0.600513  [   54/   89]
per-ex loss: 0.539998  [   56/   89]
per-ex loss: 0.355957  [   58/   89]
per-ex loss: 0.373528  [   60/   89]
per-ex loss: 0.537725  [   62/   89]
per-ex loss: 0.455125  [   64/   89]
per-ex loss: 0.603955  [   66/   89]
per-ex loss: 0.475645  [   68/   89]
per-ex loss: 0.634804  [   70/   89]
per-ex loss: 0.437905  [   72/   89]
per-ex loss: 0.553895  [   74/   89]
per-ex loss: 0.431958  [   76/   89]
per-ex loss: 0.409224  [   78/   89]
per-ex loss: 0.501194  [   80/   89]
per-ex loss: 0.465366  [   82/   89]
per-ex loss: 0.583468  [   84/   89]
per-ex loss: 0.440279  [   86/   89]
per-ex loss: 0.459558  [   88/   89]
per-ex loss: 0.388755  [   89/   89]
Train Error: Avg loss: 0.46538260
validation Error: 
 Avg loss: 0.98362787 
 F1: 0.514891 
 Precision: 0.565579 
 Recall: 0.472541
 IoU: 0.346702

test Error: 
 Avg loss: 0.98059844 
 F1: 0.534862 
 Precision: 0.593661 
 Recall: 0.486660
 IoU: 0.365059

We have finished training iteration 101
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_99_.pth
Error in cropping the image to the non-zero values in the fourth channel. Returned the original image.
per-ex loss: 0.403366  [    2/   89]
per-ex loss: 0.425991  [    4/   89]
per-ex loss: 0.446376  [    6/   89]
per-ex loss: 0.533258  [    8/   89]
per-ex loss: 0.428112  [   10/   89]
per-ex loss: 0.464585  [   12/   89]
per-ex loss: 0.365458  [   14/   89]
per-ex loss: 0.566639  [   16/   89]
per-ex loss: 0.610046  [   18/   89]
per-ex loss: 0.370950  [   20/   89]
per-ex loss: 0.375338  [   22/   89]
per-ex loss: 0.536396  [   24/   89]
per-ex loss: 0.531821  [   26/   89]
per-ex loss: 0.507904  [   28/   89]
per-ex loss: 0.390135  [   30/   89]
per-ex loss: 0.422239  [   32/   89]
per-ex loss: 0.510831  [   34/   89]
per-ex loss: 0.452098  [   36/   89]
per-ex loss: 0.570771  [   38/   89]
per-ex loss: 0.454259  [   40/   89]
per-ex loss: 0.552321  [   42/   89]
per-ex loss: 0.659326  [   44/   89]
per-ex loss: 0.352654  [   46/   89]
per-ex loss: 0.470673  [   48/   89]
per-ex loss: 0.510304  [   50/   89]
per-ex loss: 0.442003  [   52/   89]
per-ex loss: 0.482509  [   54/   89]
per-ex loss: 0.376387  [   56/   89]
per-ex loss: 0.427081  [   58/   89]
per-ex loss: 0.413581  [   60/   89]
per-ex loss: 0.531233  [   62/   89]
per-ex loss: 0.465904  [   64/   89]
per-ex loss: 0.439266  [   66/   89]
per-ex loss: 0.443260  [   68/   89]
per-ex loss: 0.494528  [   70/   89]
per-ex loss: 0.554721  [   72/   89]
per-ex loss: 0.474488  [   74/   89]
per-ex loss: 0.471368  [   76/   89]
per-ex loss: 0.627541  [   78/   89]
per-ex loss: 0.371793  [   80/   89]
per-ex loss: 0.541062  [   82/   89]
per-ex loss: 0.555518  [   84/   89]
per-ex loss: 0.403540  [   86/   89]
per-ex loss: 0.455919  [   88/   89]
per-ex loss: 0.597355  [   89/   89]
Train Error: Avg loss: 0.47735356
validation Error: 
 Avg loss: 0.98254188 
 F1: 0.510971 
 Precision: 0.607074 
 Recall: 0.441136
 IoU: 0.343157

test Error: 
 Avg loss: 0.97989814 
 F1: 0.526486 
 Precision: 0.622163 
 Recall: 0.456313
 IoU: 0.357299

We have finished training iteration 102
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_100_.pth
per-ex loss: 0.428136  [    2/   89]
per-ex loss: 0.368680  [    4/   89]
per-ex loss: 0.356707  [    6/   89]
per-ex loss: 0.413356  [    8/   89]
per-ex loss: 0.392851  [   10/   89]
per-ex loss: 0.654571  [   12/   89]
per-ex loss: 0.583755  [   14/   89]
per-ex loss: 0.555729  [   16/   89]
per-ex loss: 0.639170  [   18/   89]
per-ex loss: 0.504715  [   20/   89]
per-ex loss: 0.425383  [   22/   89]
per-ex loss: 0.466415  [   24/   89]
per-ex loss: 0.553133  [   26/   89]
per-ex loss: 0.454661  [   28/   89]
per-ex loss: 0.438642  [   30/   89]
per-ex loss: 0.426488  [   32/   89]
per-ex loss: 0.452472  [   34/   89]
per-ex loss: 0.467351  [   36/   89]
per-ex loss: 0.379148  [   38/   89]
per-ex loss: 0.545375  [   40/   89]
per-ex loss: 0.378989  [   42/   89]
per-ex loss: 0.457664  [   44/   89]
per-ex loss: 0.343872  [   46/   89]
per-ex loss: 0.408804  [   48/   89]
per-ex loss: 0.411661  [   50/   89]
per-ex loss: 0.536489  [   52/   89]
per-ex loss: 0.447261  [   54/   89]
per-ex loss: 0.452755  [   56/   89]
per-ex loss: 0.465777  [   58/   89]
per-ex loss: 0.408337  [   60/   89]
per-ex loss: 0.426744  [   62/   89]
per-ex loss: 0.407418  [   64/   89]
per-ex loss: 0.629698  [   66/   89]
per-ex loss: 0.574938  [   68/   89]
per-ex loss: 0.577988  [   70/   89]
per-ex loss: 0.454178  [   72/   89]
per-ex loss: 0.498129  [   74/   89]
per-ex loss: 0.450552  [   76/   89]
per-ex loss: 0.461300  [   78/   89]
per-ex loss: 0.422274  [   80/   89]
per-ex loss: 0.439022  [   82/   89]
per-ex loss: 0.544086  [   84/   89]
per-ex loss: 0.424350  [   86/   89]
per-ex loss: 0.358754  [   88/   89]
per-ex loss: 0.479089  [   89/   89]
Train Error: Avg loss: 0.46593038
validation Error: 
 Avg loss: 0.98270223 
 F1: 0.514182 
 Precision: 0.594683 
 Recall: 0.452877
 IoU: 0.346060

test Error: 
 Avg loss: 0.98057679 
 F1: 0.533880 
 Precision: 0.616138 
 Recall: 0.470998
 IoU: 0.364144

We have finished training iteration 103
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_101_.pth
per-ex loss: 0.362510  [    2/   89]
per-ex loss: 0.425886  [    4/   89]
per-ex loss: 0.390137  [    6/   89]
per-ex loss: 0.532864  [    8/   89]
per-ex loss: 0.416941  [   10/   89]
per-ex loss: 0.562430  [   12/   89]
per-ex loss: 0.449177  [   14/   89]
per-ex loss: 0.391226  [   16/   89]
per-ex loss: 0.334711  [   18/   89]
per-ex loss: 0.372997  [   20/   89]
per-ex loss: 0.628187  [   22/   89]
per-ex loss: 0.482673  [   24/   89]
per-ex loss: 0.365526  [   26/   89]
per-ex loss: 0.539023  [   28/   89]
per-ex loss: 0.429581  [   30/   89]
per-ex loss: 0.444637  [   32/   89]
per-ex loss: 0.435567  [   34/   89]
per-ex loss: 0.544934  [   36/   89]
per-ex loss: 0.463137  [   38/   89]
per-ex loss: 0.444774  [   40/   89]
per-ex loss: 0.559876  [   42/   89]
per-ex loss: 0.442666  [   44/   89]
per-ex loss: 0.621813  [   46/   89]
per-ex loss: 0.446783  [   48/   89]
per-ex loss: 0.540476  [   50/   89]
per-ex loss: 0.413011  [   52/   89]
per-ex loss: 0.590520  [   54/   89]
per-ex loss: 0.453348  [   56/   89]
per-ex loss: 0.448210  [   58/   89]
per-ex loss: 0.659378  [   60/   89]
per-ex loss: 0.637063  [   62/   89]
per-ex loss: 0.501123  [   64/   89]
per-ex loss: 0.392645  [   66/   89]
per-ex loss: 0.516659  [   68/   89]
per-ex loss: 0.452658  [   70/   89]
per-ex loss: 0.362671  [   72/   89]
per-ex loss: 0.429519  [   74/   89]
per-ex loss: 0.346308  [   76/   89]
per-ex loss: 0.452496  [   78/   89]
per-ex loss: 0.412784  [   80/   89]
per-ex loss: 0.471115  [   82/   89]
per-ex loss: 0.565500  [   84/   89]
per-ex loss: 0.464646  [   86/   89]
per-ex loss: 0.400358  [   88/   89]
per-ex loss: 0.476646  [   89/   89]
Train Error: Avg loss: 0.46833758
validation Error: 
 Avg loss: 0.98404953 
 F1: 0.512566 
 Precision: 0.565721 
 Recall: 0.468543
 IoU: 0.344598

test Error: 
 Avg loss: 0.98132880 
 F1: 0.532473 
 Precision: 0.588682 
 Recall: 0.486062
 IoU: 0.362837

We have finished training iteration 104
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_102_.pth
per-ex loss: 0.498739  [    2/   89]
per-ex loss: 0.412814  [    4/   89]
per-ex loss: 0.361324  [    6/   89]
per-ex loss: 0.416934  [    8/   89]
per-ex loss: 0.496258  [   10/   89]
per-ex loss: 0.476302  [   12/   89]
per-ex loss: 0.551068  [   14/   89]
per-ex loss: 0.360931  [   16/   89]
per-ex loss: 0.400978  [   18/   89]
per-ex loss: 0.463301  [   20/   89]
per-ex loss: 0.346026  [   22/   89]
per-ex loss: 0.354429  [   24/   89]
per-ex loss: 0.387903  [   26/   89]
per-ex loss: 0.389435  [   28/   89]
per-ex loss: 0.442551  [   30/   89]
per-ex loss: 0.463926  [   32/   89]
per-ex loss: 0.448170  [   34/   89]
per-ex loss: 0.538478  [   36/   89]
per-ex loss: 0.560036  [   38/   89]
per-ex loss: 0.536384  [   40/   89]
per-ex loss: 0.471176  [   42/   89]
per-ex loss: 0.476704  [   44/   89]
per-ex loss: 0.429769  [   46/   89]
per-ex loss: 0.654642  [   48/   89]
per-ex loss: 0.362625  [   50/   89]
per-ex loss: 0.415988  [   52/   89]
per-ex loss: 0.566366  [   54/   89]
per-ex loss: 0.505075  [   56/   89]
per-ex loss: 0.522185  [   58/   89]
per-ex loss: 0.366880  [   60/   89]
per-ex loss: 0.473412  [   62/   89]
per-ex loss: 0.452339  [   64/   89]
per-ex loss: 0.449298  [   66/   89]
per-ex loss: 0.655242  [   68/   89]
per-ex loss: 0.401406  [   70/   89]
per-ex loss: 0.617635  [   72/   89]
per-ex loss: 0.440071  [   74/   89]
per-ex loss: 0.416843  [   76/   89]
per-ex loss: 0.555302  [   78/   89]
per-ex loss: 0.569095  [   80/   89]
per-ex loss: 0.403548  [   82/   89]
per-ex loss: 0.460310  [   84/   89]
per-ex loss: 0.412133  [   86/   89]
per-ex loss: 0.462599  [   88/   89]
per-ex loss: 0.571830  [   89/   89]
Train Error: Avg loss: 0.46707691
validation Error: 
 Avg loss: 0.98288995 
 F1: 0.516847 
 Precision: 0.585439 
 Recall: 0.462642
 IoU: 0.348478

test Error: 
 Avg loss: 0.98015599 
 F1: 0.535166 
 Precision: 0.606939 
 Recall: 0.478573
 IoU: 0.365342

We have finished training iteration 105
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_103_.pth
per-ex loss: 0.391263  [    2/   89]
per-ex loss: 0.481147  [    4/   89]
per-ex loss: 0.400939  [    6/   89]
per-ex loss: 0.346215  [    8/   89]
per-ex loss: 0.490539  [   10/   89]
per-ex loss: 0.359532  [   12/   89]
per-ex loss: 0.425515  [   14/   89]
per-ex loss: 0.424790  [   16/   89]
per-ex loss: 0.390339  [   18/   89]
per-ex loss: 0.412502  [   20/   89]
per-ex loss: 0.581344  [   22/   89]
per-ex loss: 0.413743  [   24/   89]
per-ex loss: 0.417351  [   26/   89]
per-ex loss: 0.632085  [   28/   89]
per-ex loss: 0.375994  [   30/   89]
per-ex loss: 0.601029  [   32/   89]
per-ex loss: 0.525928  [   34/   89]
per-ex loss: 0.420213  [   36/   89]
per-ex loss: 0.466445  [   38/   89]
per-ex loss: 0.460923  [   40/   89]
per-ex loss: 0.491332  [   42/   89]
per-ex loss: 0.534927  [   44/   89]
per-ex loss: 0.439268  [   46/   89]
per-ex loss: 0.494828  [   48/   89]
per-ex loss: 0.385550  [   50/   89]
per-ex loss: 0.511262  [   52/   89]
per-ex loss: 0.403980  [   54/   89]
per-ex loss: 0.547985  [   56/   89]
per-ex loss: 0.570747  [   58/   89]
per-ex loss: 0.407097  [   60/   89]
per-ex loss: 0.593489  [   62/   89]
per-ex loss: 0.404840  [   64/   89]
per-ex loss: 0.470608  [   66/   89]
per-ex loss: 0.564616  [   68/   89]
per-ex loss: 0.412034  [   70/   89]
per-ex loss: 0.496451  [   72/   89]
per-ex loss: 0.450458  [   74/   89]
per-ex loss: 0.505775  [   76/   89]
per-ex loss: 0.437021  [   78/   89]
per-ex loss: 0.474613  [   80/   89]
per-ex loss: 0.462235  [   82/   89]
per-ex loss: 0.436695  [   84/   89]
per-ex loss: 0.446138  [   86/   89]
per-ex loss: 0.572387  [   88/   89]
per-ex loss: 0.613981  [   89/   89]
Train Error: Avg loss: 0.46991451
validation Error: 
 Avg loss: 0.98356457 
 F1: 0.516526 
 Precision: 0.568225 
 Recall: 0.473450
 IoU: 0.348187

test Error: 
 Avg loss: 0.98089457 
 F1: 0.532447 
 Precision: 0.583772 
 Recall: 0.489418
 IoU: 0.362813

We have finished training iteration 106
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_104_.pth
per-ex loss: 0.395688  [    2/   89]
per-ex loss: 0.583611  [    4/   89]
per-ex loss: 0.513140  [    6/   89]
per-ex loss: 0.352099  [    8/   89]
per-ex loss: 0.446757  [   10/   89]
per-ex loss: 0.411297  [   12/   89]
per-ex loss: 0.422118  [   14/   89]
per-ex loss: 0.461307  [   16/   89]
per-ex loss: 0.367490  [   18/   89]
per-ex loss: 0.514966  [   20/   89]
per-ex loss: 0.612379  [   22/   89]
per-ex loss: 0.486588  [   24/   89]
per-ex loss: 0.634186  [   26/   89]
per-ex loss: 0.508826  [   28/   89]
per-ex loss: 0.594412  [   30/   89]
per-ex loss: 0.484927  [   32/   89]
per-ex loss: 0.574062  [   34/   89]
per-ex loss: 0.388986  [   36/   89]
per-ex loss: 0.368059  [   38/   89]
per-ex loss: 0.762909  [   40/   89]
per-ex loss: 0.380130  [   42/   89]
per-ex loss: 0.411317  [   44/   89]
per-ex loss: 0.515164  [   46/   89]
per-ex loss: 0.537688  [   48/   89]
per-ex loss: 0.482968  [   50/   89]
per-ex loss: 0.415569  [   52/   89]
per-ex loss: 0.396219  [   54/   89]
per-ex loss: 0.459075  [   56/   89]
per-ex loss: 0.405687  [   58/   89]
per-ex loss: 0.694343  [   60/   89]
per-ex loss: 0.516044  [   62/   89]
per-ex loss: 0.399870  [   64/   89]
per-ex loss: 0.459587  [   66/   89]
per-ex loss: 0.431358  [   68/   89]
per-ex loss: 0.391598  [   70/   89]
per-ex loss: 0.408265  [   72/   89]
per-ex loss: 0.401637  [   74/   89]
per-ex loss: 0.484117  [   76/   89]
per-ex loss: 0.614030  [   78/   89]
per-ex loss: 0.385116  [   80/   89]
per-ex loss: 0.406088  [   82/   89]
per-ex loss: 0.425200  [   84/   89]
per-ex loss: 0.602374  [   86/   89]
per-ex loss: 0.469854  [   88/   89]
per-ex loss: 0.626181  [   89/   89]
Train Error: Avg loss: 0.48007305
validation Error: 
 Avg loss: 0.98243433 
 F1: 0.517148 
 Precision: 0.593460 
 Recall: 0.458226
 IoU: 0.348752

test Error: 
 Avg loss: 0.97948955 
 F1: 0.533802 
 Precision: 0.618963 
 Recall: 0.469241
 IoU: 0.364072

We have finished training iteration 107
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_105_.pth
per-ex loss: 0.528520  [    2/   89]
per-ex loss: 0.451128  [    4/   89]
per-ex loss: 0.394508  [    6/   89]
per-ex loss: 0.580470  [    8/   89]
per-ex loss: 0.605999  [   10/   89]
per-ex loss: 0.380992  [   12/   89]
per-ex loss: 0.455589  [   14/   89]
per-ex loss: 0.395239  [   16/   89]
per-ex loss: 0.386593  [   18/   89]
per-ex loss: 0.577112  [   20/   89]
per-ex loss: 0.493379  [   22/   89]
per-ex loss: 0.524179  [   24/   89]
per-ex loss: 0.405595  [   26/   89]
per-ex loss: 0.476279  [   28/   89]
per-ex loss: 0.511367  [   30/   89]
per-ex loss: 0.434922  [   32/   89]
per-ex loss: 0.508035  [   34/   89]
per-ex loss: 0.412164  [   36/   89]
per-ex loss: 0.358709  [   38/   89]
per-ex loss: 0.485251  [   40/   89]
per-ex loss: 0.565392  [   42/   89]
per-ex loss: 0.483469  [   44/   89]
per-ex loss: 0.369362  [   46/   89]
per-ex loss: 0.384067  [   48/   89]
per-ex loss: 0.618860  [   50/   89]
per-ex loss: 0.523323  [   52/   89]
per-ex loss: 0.342215  [   54/   89]
per-ex loss: 0.518908  [   56/   89]
per-ex loss: 0.338568  [   58/   89]
per-ex loss: 0.423477  [   60/   89]
per-ex loss: 0.607005  [   62/   89]
per-ex loss: 0.537988  [   64/   89]
per-ex loss: 0.407144  [   66/   89]
per-ex loss: 0.461616  [   68/   89]
per-ex loss: 0.377287  [   70/   89]
per-ex loss: 0.417118  [   72/   89]
per-ex loss: 0.495681  [   74/   89]
per-ex loss: 0.617382  [   76/   89]
per-ex loss: 0.579020  [   78/   89]
per-ex loss: 0.550023  [   80/   89]
per-ex loss: 0.495887  [   82/   89]
per-ex loss: 0.397611  [   84/   89]
per-ex loss: 0.591869  [   86/   89]
per-ex loss: 0.407285  [   88/   89]
per-ex loss: 0.567951  [   89/   89]
Train Error: Avg loss: 0.47654531
validation Error: 
 Avg loss: 0.98240075 
 F1: 0.515094 
 Precision: 0.596534 
 Recall: 0.453220
 IoU: 0.346886

test Error: 
 Avg loss: 0.98017923 
 F1: 0.533788 
 Precision: 0.613498 
 Recall: 0.472409
 IoU: 0.364059

We have finished training iteration 108
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_106_.pth
per-ex loss: 0.387328  [    2/   89]
per-ex loss: 0.430320  [    4/   89]
per-ex loss: 0.629229  [    6/   89]
per-ex loss: 0.506525  [    8/   89]
per-ex loss: 0.415744  [   10/   89]
per-ex loss: 0.385311  [   12/   89]
per-ex loss: 0.550871  [   14/   89]
per-ex loss: 0.409363  [   16/   89]
per-ex loss: 0.434463  [   18/   89]
per-ex loss: 0.421735  [   20/   89]
per-ex loss: 0.433656  [   22/   89]
per-ex loss: 0.459196  [   24/   89]
per-ex loss: 0.475697  [   26/   89]
per-ex loss: 0.432669  [   28/   89]
per-ex loss: 0.417917  [   30/   89]
per-ex loss: 0.604319  [   32/   89]
per-ex loss: 0.476145  [   34/   89]
per-ex loss: 0.449062  [   36/   89]
per-ex loss: 0.491810  [   38/   89]
per-ex loss: 0.568446  [   40/   89]
per-ex loss: 0.378528  [   42/   89]
per-ex loss: 0.485166  [   44/   89]
per-ex loss: 0.444075  [   46/   89]
per-ex loss: 0.382281  [   48/   89]
per-ex loss: 0.580523  [   50/   89]
per-ex loss: 0.429118  [   52/   89]
per-ex loss: 0.573526  [   54/   89]
per-ex loss: 0.435869  [   56/   89]
per-ex loss: 0.499092  [   58/   89]
per-ex loss: 0.484246  [   60/   89]
per-ex loss: 0.349427  [   62/   89]
per-ex loss: 0.424790  [   64/   89]
per-ex loss: 0.478310  [   66/   89]
per-ex loss: 0.443882  [   68/   89]
per-ex loss: 0.438563  [   70/   89]
per-ex loss: 0.421976  [   72/   89]
per-ex loss: 0.512836  [   74/   89]
per-ex loss: 0.447822  [   76/   89]
per-ex loss: 0.483327  [   78/   89]
per-ex loss: 0.423049  [   80/   89]
per-ex loss: 0.423460  [   82/   89]
per-ex loss: 0.420328  [   84/   89]
per-ex loss: 0.430808  [   86/   89]
per-ex loss: 0.486001  [   88/   89]
per-ex loss: 0.546550  [   89/   89]
Train Error: Avg loss: 0.46229691
validation Error: 
 Avg loss: 0.98153528 
 F1: 0.512173 
 Precision: 0.603546 
 Recall: 0.444829
 IoU: 0.344242

test Error: 
 Avg loss: 0.97950161 
 F1: 0.526431 
 Precision: 0.626303 
 Recall: 0.454030
 IoU: 0.357249

We have finished training iteration 109
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_107_.pth
per-ex loss: 0.689459  [    2/   89]
per-ex loss: 0.414230  [    4/   89]
per-ex loss: 0.444832  [    6/   89]
per-ex loss: 0.428165  [    8/   89]
per-ex loss: 0.385715  [   10/   89]
per-ex loss: 0.536526  [   12/   89]
per-ex loss: 0.505735  [   14/   89]
per-ex loss: 0.365819  [   16/   89]
per-ex loss: 0.391569  [   18/   89]
per-ex loss: 0.581958  [   20/   89]
per-ex loss: 0.452070  [   22/   89]
per-ex loss: 0.434995  [   24/   89]
per-ex loss: 0.379393  [   26/   89]
per-ex loss: 0.413857  [   28/   89]
per-ex loss: 0.421399  [   30/   89]
per-ex loss: 0.441357  [   32/   89]
per-ex loss: 0.499268  [   34/   89]
per-ex loss: 0.378182  [   36/   89]
per-ex loss: 0.436719  [   38/   89]
per-ex loss: 0.546669  [   40/   89]
per-ex loss: 0.483222  [   42/   89]
per-ex loss: 0.563649  [   44/   89]
per-ex loss: 0.398269  [   46/   89]
per-ex loss: 0.434494  [   48/   89]
per-ex loss: 0.531911  [   50/   89]
per-ex loss: 0.399826  [   52/   89]
per-ex loss: 0.424824  [   54/   89]
per-ex loss: 0.625316  [   56/   89]
per-ex loss: 0.426941  [   58/   89]
per-ex loss: 0.435061  [   60/   89]
per-ex loss: 0.378290  [   62/   89]
per-ex loss: 0.438061  [   64/   89]
per-ex loss: 0.456123  [   66/   89]
per-ex loss: 0.520035  [   68/   89]
per-ex loss: 0.401283  [   70/   89]
per-ex loss: 0.576615  [   72/   89]
per-ex loss: 0.508961  [   74/   89]
per-ex loss: 0.391435  [   76/   89]
per-ex loss: 0.382379  [   78/   89]
per-ex loss: 0.488044  [   80/   89]
per-ex loss: 0.610294  [   82/   89]
per-ex loss: 0.409433  [   84/   89]
per-ex loss: 0.641864  [   86/   89]
per-ex loss: 0.516395  [   88/   89]
per-ex loss: 0.410698  [   89/   89]
Train Error: Avg loss: 0.46669636
validation Error: 
 Avg loss: 0.98290058 
 F1: 0.516209 
 Precision: 0.571970 
 Recall: 0.470355
 IoU: 0.347899

test Error: 
 Avg loss: 0.98032879 
 F1: 0.540318 
 Precision: 0.594252 
 Recall: 0.495361
 IoU: 0.370162

We have finished training iteration 110
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_108_.pth
per-ex loss: 0.437897  [    2/   89]
per-ex loss: 0.484548  [    4/   89]
per-ex loss: 0.477786  [    6/   89]
per-ex loss: 0.437820  [    8/   89]
per-ex loss: 0.425511  [   10/   89]
per-ex loss: 0.409543  [   12/   89]
per-ex loss: 0.395535  [   14/   89]
per-ex loss: 0.504228  [   16/   89]
per-ex loss: 0.544132  [   18/   89]
per-ex loss: 0.437031  [   20/   89]
per-ex loss: 0.371984  [   22/   89]
per-ex loss: 0.800804  [   24/   89]
per-ex loss: 0.426323  [   26/   89]
per-ex loss: 0.520459  [   28/   89]
per-ex loss: 0.401870  [   30/   89]
per-ex loss: 0.439424  [   32/   89]
per-ex loss: 0.597649  [   34/   89]
per-ex loss: 0.385048  [   36/   89]
per-ex loss: 0.576918  [   38/   89]
per-ex loss: 0.413256  [   40/   89]
per-ex loss: 0.429118  [   42/   89]
per-ex loss: 0.471864  [   44/   89]
per-ex loss: 0.472719  [   46/   89]
per-ex loss: 0.379930  [   48/   89]
per-ex loss: 0.614371  [   50/   89]
per-ex loss: 0.349100  [   52/   89]
per-ex loss: 0.473585  [   54/   89]
per-ex loss: 0.570508  [   56/   89]
per-ex loss: 0.428903  [   58/   89]
per-ex loss: 0.509555  [   60/   89]
per-ex loss: 0.548074  [   62/   89]
per-ex loss: 0.408913  [   64/   89]
per-ex loss: 0.497854  [   66/   89]
per-ex loss: 0.535835  [   68/   89]
per-ex loss: 0.465759  [   70/   89]
per-ex loss: 0.369243  [   72/   89]
per-ex loss: 0.599393  [   74/   89]
per-ex loss: 0.428074  [   76/   89]
per-ex loss: 0.503268  [   78/   89]
per-ex loss: 0.615113  [   80/   89]
per-ex loss: 0.529303  [   82/   89]
per-ex loss: 0.580024  [   84/   89]
per-ex loss: 0.580973  [   86/   89]
per-ex loss: 0.626377  [   88/   89]
per-ex loss: 0.492742  [   89/   89]
Train Error: Avg loss: 0.48818582
validation Error: 
 Avg loss: 0.98347070 
 F1: 0.518202 
 Precision: 0.574803 
 Recall: 0.471749
 IoU: 0.349712

test Error: 
 Avg loss: 0.98043576 
 F1: 0.538766 
 Precision: 0.599463 
 Recall: 0.489230
 IoU: 0.368706

We have finished training iteration 111
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_109_.pth
per-ex loss: 0.413511  [    2/   89]
per-ex loss: 0.420911  [    4/   89]
per-ex loss: 0.612247  [    6/   89]
per-ex loss: 0.558072  [    8/   89]
per-ex loss: 0.513381  [   10/   89]
per-ex loss: 0.349246  [   12/   89]
per-ex loss: 0.483005  [   14/   89]
per-ex loss: 0.410984  [   16/   89]
per-ex loss: 0.551031  [   18/   89]
per-ex loss: 0.524469  [   20/   89]
per-ex loss: 0.339893  [   22/   89]
per-ex loss: 0.508269  [   24/   89]
per-ex loss: 0.427397  [   26/   89]
per-ex loss: 0.495108  [   28/   89]
per-ex loss: 0.411975  [   30/   89]
per-ex loss: 0.633074  [   32/   89]
per-ex loss: 0.414458  [   34/   89]
per-ex loss: 0.405043  [   36/   89]
per-ex loss: 0.393952  [   38/   89]
per-ex loss: 0.456302  [   40/   89]
per-ex loss: 0.356573  [   42/   89]
per-ex loss: 0.348614  [   44/   89]
per-ex loss: 0.511000  [   46/   89]
per-ex loss: 0.592526  [   48/   89]
per-ex loss: 0.455218  [   50/   89]
per-ex loss: 0.452947  [   52/   89]
per-ex loss: 0.398462  [   54/   89]
per-ex loss: 0.678692  [   56/   89]
per-ex loss: 0.505934  [   58/   89]
per-ex loss: 0.399253  [   60/   89]
per-ex loss: 0.351276  [   62/   89]
per-ex loss: 0.539762  [   64/   89]
per-ex loss: 0.390180  [   66/   89]
per-ex loss: 0.552833  [   68/   89]
per-ex loss: 0.429817  [   70/   89]
per-ex loss: 0.714940  [   72/   89]
per-ex loss: 0.474736  [   74/   89]
per-ex loss: 0.493074  [   76/   89]
per-ex loss: 0.512299  [   78/   89]
per-ex loss: 0.427161  [   80/   89]
per-ex loss: 0.501189  [   82/   89]
per-ex loss: 0.393244  [   84/   89]
per-ex loss: 0.456876  [   86/   89]
per-ex loss: 0.611735  [   88/   89]
per-ex loss: 0.451747  [   89/   89]
Train Error: Avg loss: 0.47383140
validation Error: 
 Avg loss: 0.98284515 
 F1: 0.515884 
 Precision: 0.552640 
 Recall: 0.483712
 IoU: 0.347603

test Error: 
 Avg loss: 0.98150682 
 F1: 0.537009 
 Precision: 0.569746 
 Recall: 0.507829
 IoU: 0.367062

We have finished training iteration 112
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_110_.pth
per-ex loss: 0.528288  [    2/   89]
per-ex loss: 0.359684  [    4/   89]
per-ex loss: 0.448586  [    6/   89]
per-ex loss: 0.502451  [    8/   89]
per-ex loss: 0.377527  [   10/   89]
per-ex loss: 0.425399  [   12/   89]
per-ex loss: 0.487400  [   14/   89]
per-ex loss: 0.524513  [   16/   89]
per-ex loss: 0.418976  [   18/   89]
per-ex loss: 0.414591  [   20/   89]
per-ex loss: 0.370346  [   22/   89]
per-ex loss: 0.426587  [   24/   89]
per-ex loss: 0.470682  [   26/   89]
per-ex loss: 0.364347  [   28/   89]
per-ex loss: 0.373788  [   30/   89]
per-ex loss: 0.434560  [   32/   89]
per-ex loss: 0.573783  [   34/   89]
per-ex loss: 0.424652  [   36/   89]
per-ex loss: 0.662669  [   38/   89]
per-ex loss: 0.401356  [   40/   89]
per-ex loss: 0.405735  [   42/   89]
per-ex loss: 0.745077  [   44/   89]
per-ex loss: 0.584907  [   46/   89]
per-ex loss: 0.431562  [   48/   89]
per-ex loss: 0.438220  [   50/   89]
per-ex loss: 0.409071  [   52/   89]
per-ex loss: 0.461221  [   54/   89]
per-ex loss: 0.542390  [   56/   89]
per-ex loss: 0.506081  [   58/   89]
per-ex loss: 0.413231  [   60/   89]
per-ex loss: 0.604116  [   62/   89]
per-ex loss: 0.461700  [   64/   89]
per-ex loss: 0.417229  [   66/   89]
per-ex loss: 0.450380  [   68/   89]
per-ex loss: 0.523742  [   70/   89]
per-ex loss: 0.440640  [   72/   89]
per-ex loss: 0.376663  [   74/   89]
per-ex loss: 0.471178  [   76/   89]
per-ex loss: 0.556594  [   78/   89]
per-ex loss: 0.421271  [   80/   89]
per-ex loss: 0.489368  [   82/   89]
per-ex loss: 0.467618  [   84/   89]
per-ex loss: 0.405073  [   86/   89]
per-ex loss: 0.413201  [   88/   89]
per-ex loss: 0.354749  [   89/   89]
Train Error: Avg loss: 0.46180453
validation Error: 
 Avg loss: 0.98369007 
 F1: 0.517416 
 Precision: 0.558759 
 Recall: 0.481770
 IoU: 0.348996

test Error: 
 Avg loss: 0.98134191 
 F1: 0.538202 
 Precision: 0.570266 
 Recall: 0.509552
 IoU: 0.368178

We have finished training iteration 113
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_111_.pth
per-ex loss: 0.409531  [    2/   89]
per-ex loss: 0.436577  [    4/   89]
per-ex loss: 0.505820  [    6/   89]
per-ex loss: 0.449462  [    8/   89]
per-ex loss: 0.361438  [   10/   89]
per-ex loss: 0.418474  [   12/   89]
per-ex loss: 0.354509  [   14/   89]
per-ex loss: 0.411792  [   16/   89]
per-ex loss: 0.376365  [   18/   89]
per-ex loss: 0.470186  [   20/   89]
per-ex loss: 0.500205  [   22/   89]
per-ex loss: 0.546389  [   24/   89]
per-ex loss: 0.374486  [   26/   89]
per-ex loss: 0.468876  [   28/   89]
per-ex loss: 0.426363  [   30/   89]
per-ex loss: 0.537959  [   32/   89]
per-ex loss: 0.634567  [   34/   89]
per-ex loss: 0.452650  [   36/   89]
per-ex loss: 0.508321  [   38/   89]
per-ex loss: 0.457104  [   40/   89]
per-ex loss: 0.555621  [   42/   89]
per-ex loss: 0.622515  [   44/   89]
per-ex loss: 0.471786  [   46/   89]
per-ex loss: 0.617568  [   48/   89]
per-ex loss: 0.432416  [   50/   89]
per-ex loss: 0.441478  [   52/   89]
per-ex loss: 0.392379  [   54/   89]
per-ex loss: 0.368365  [   56/   89]
per-ex loss: 0.381202  [   58/   89]
per-ex loss: 0.489527  [   60/   89]
per-ex loss: 0.496503  [   62/   89]
per-ex loss: 0.628728  [   64/   89]
per-ex loss: 0.438299  [   66/   89]
per-ex loss: 0.437523  [   68/   89]
per-ex loss: 0.352843  [   70/   89]
per-ex loss: 0.382951  [   72/   89]
per-ex loss: 0.385697  [   74/   89]
per-ex loss: 0.647903  [   76/   89]
per-ex loss: 0.590806  [   78/   89]
per-ex loss: 0.510093  [   80/   89]
per-ex loss: 0.397082  [   82/   89]
per-ex loss: 0.476162  [   84/   89]
per-ex loss: 0.384218  [   86/   89]
per-ex loss: 0.391196  [   88/   89]
per-ex loss: 0.357812  [   89/   89]
Train Error: Avg loss: 0.46114989
validation Error: 
 Avg loss: 0.98328974 
 F1: 0.510511 
 Precision: 0.580208 
 Recall: 0.455763
 IoU: 0.342743

test Error: 
 Avg loss: 0.98129496 
 F1: 0.526482 
 Precision: 0.589705 
 Recall: 0.475504
 IoU: 0.357296

We have finished training iteration 114
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_112_.pth
per-ex loss: 0.591939  [    2/   89]
per-ex loss: 0.430560  [    4/   89]
per-ex loss: 0.610571  [    6/   89]
per-ex loss: 0.473702  [    8/   89]
per-ex loss: 0.460071  [   10/   89]
per-ex loss: 0.594616  [   12/   89]
per-ex loss: 0.424039  [   14/   89]
per-ex loss: 0.388079  [   16/   89]
per-ex loss: 0.454848  [   18/   89]
per-ex loss: 0.487261  [   20/   89]
per-ex loss: 0.387300  [   22/   89]
per-ex loss: 0.586149  [   24/   89]
per-ex loss: 0.379147  [   26/   89]
per-ex loss: 0.467714  [   28/   89]
per-ex loss: 0.358796  [   30/   89]
per-ex loss: 0.351414  [   32/   89]
per-ex loss: 0.584076  [   34/   89]
per-ex loss: 0.424695  [   36/   89]
per-ex loss: 0.561810  [   38/   89]
per-ex loss: 0.536371  [   40/   89]
per-ex loss: 0.548077  [   42/   89]
per-ex loss: 0.386617  [   44/   89]
per-ex loss: 0.489700  [   46/   89]
per-ex loss: 0.554080  [   48/   89]
per-ex loss: 0.497361  [   50/   89]
per-ex loss: 0.523796  [   52/   89]
per-ex loss: 0.460939  [   54/   89]
per-ex loss: 0.357805  [   56/   89]
per-ex loss: 0.372640  [   58/   89]
per-ex loss: 0.468974  [   60/   89]
per-ex loss: 0.449172  [   62/   89]
per-ex loss: 0.546619  [   64/   89]
per-ex loss: 0.543250  [   66/   89]
per-ex loss: 0.403079  [   68/   89]
per-ex loss: 0.498228  [   70/   89]
per-ex loss: 0.380072  [   72/   89]
per-ex loss: 0.470892  [   74/   89]
per-ex loss: 0.442381  [   76/   89]
per-ex loss: 0.458793  [   78/   89]
per-ex loss: 0.367116  [   80/   89]
per-ex loss: 0.569285  [   82/   89]
per-ex loss: 0.471746  [   84/   89]
per-ex loss: 0.381341  [   86/   89]
per-ex loss: 0.376951  [   88/   89]
per-ex loss: 0.386868  [   89/   89]
Train Error: Avg loss: 0.46575419
validation Error: 
 Avg loss: 0.98310939 
 F1: 0.515005 
 Precision: 0.574719 
 Recall: 0.466532
 IoU: 0.346806

test Error: 
 Avg loss: 0.98019999 
 F1: 0.535031 
 Precision: 0.595926 
 Recall: 0.485427
 IoU: 0.365216

We have finished training iteration 115
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_113_.pth
per-ex loss: 0.661630  [    2/   89]
per-ex loss: 0.444377  [    4/   89]
per-ex loss: 0.385815  [    6/   89]
per-ex loss: 0.521562  [    8/   89]
per-ex loss: 0.489931  [   10/   89]
per-ex loss: 0.411008  [   12/   89]
per-ex loss: 0.612682  [   14/   89]
per-ex loss: 0.437170  [   16/   89]
per-ex loss: 0.367776  [   18/   89]
per-ex loss: 0.493701  [   20/   89]
per-ex loss: 0.450805  [   22/   89]
per-ex loss: 0.453235  [   24/   89]
per-ex loss: 0.529980  [   26/   89]
per-ex loss: 0.674603  [   28/   89]
per-ex loss: 0.335796  [   30/   89]
per-ex loss: 0.422019  [   32/   89]
per-ex loss: 0.461682  [   34/   89]
per-ex loss: 0.463287  [   36/   89]
per-ex loss: 0.463719  [   38/   89]
per-ex loss: 0.545023  [   40/   89]
per-ex loss: 0.423929  [   42/   89]
per-ex loss: 0.653049  [   44/   89]
per-ex loss: 0.414414  [   46/   89]
per-ex loss: 0.404304  [   48/   89]
per-ex loss: 0.406148  [   50/   89]
per-ex loss: 0.517625  [   52/   89]
per-ex loss: 0.377702  [   54/   89]
per-ex loss: 0.585450  [   56/   89]
per-ex loss: 0.501356  [   58/   89]
per-ex loss: 0.517689  [   60/   89]
per-ex loss: 0.534023  [   62/   89]
per-ex loss: 0.393936  [   64/   89]
per-ex loss: 0.504565  [   66/   89]
per-ex loss: 0.376124  [   68/   89]
per-ex loss: 0.352009  [   70/   89]
per-ex loss: 0.424139  [   72/   89]
per-ex loss: 0.490601  [   74/   89]
per-ex loss: 0.405471  [   76/   89]
per-ex loss: 0.352166  [   78/   89]
per-ex loss: 0.488014  [   80/   89]
per-ex loss: 0.427649  [   82/   89]
per-ex loss: 0.450110  [   84/   89]
per-ex loss: 0.332800  [   86/   89]
per-ex loss: 0.414439  [   88/   89]
per-ex loss: 0.655427  [   89/   89]
Train Error: Avg loss: 0.46730975
validation Error: 
 Avg loss: 0.98374922 
 F1: 0.518706 
 Precision: 0.551645 
 Recall: 0.489479
 IoU: 0.350171

test Error: 
 Avg loss: 0.98080937 
 F1: 0.541042 
 Precision: 0.577694 
 Recall: 0.508764
 IoU: 0.370842

We have finished training iteration 116
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_114_.pth
Error in cropping the image to the non-zero values in the fourth channel. Returned the original image.
per-ex loss: 0.608550  [    2/   89]
per-ex loss: 0.545645  [    4/   89]
per-ex loss: 0.569071  [    6/   89]
per-ex loss: 0.420912  [    8/   89]
per-ex loss: 0.381918  [   10/   89]
per-ex loss: 0.443966  [   12/   89]
per-ex loss: 0.420717  [   14/   89]
per-ex loss: 0.375292  [   16/   89]
per-ex loss: 0.570753  [   18/   89]
per-ex loss: 0.448356  [   20/   89]
per-ex loss: 0.483167  [   22/   89]
per-ex loss: 0.439363  [   24/   89]
per-ex loss: 0.354429  [   26/   89]
per-ex loss: 0.429786  [   28/   89]
per-ex loss: 0.452431  [   30/   89]
per-ex loss: 0.420975  [   32/   89]
per-ex loss: 0.369376  [   34/   89]
per-ex loss: 0.617513  [   36/   89]
per-ex loss: 0.454315  [   38/   89]
per-ex loss: 0.462451  [   40/   89]
per-ex loss: 0.568087  [   42/   89]
per-ex loss: 0.452219  [   44/   89]
per-ex loss: 0.396767  [   46/   89]
per-ex loss: 0.491712  [   48/   89]
per-ex loss: 0.520181  [   50/   89]
per-ex loss: 0.497686  [   52/   89]
per-ex loss: 0.570628  [   54/   89]
per-ex loss: 0.526783  [   56/   89]
per-ex loss: 0.448005  [   58/   89]
per-ex loss: 0.723128  [   60/   89]
per-ex loss: 0.487712  [   62/   89]
per-ex loss: 0.396851  [   64/   89]
per-ex loss: 0.428494  [   66/   89]
per-ex loss: 0.355560  [   68/   89]
per-ex loss: 0.495838  [   70/   89]
per-ex loss: 0.433792  [   72/   89]
per-ex loss: 0.375329  [   74/   89]
per-ex loss: 0.359565  [   76/   89]
per-ex loss: 0.370545  [   78/   89]
per-ex loss: 0.476765  [   80/   89]
per-ex loss: 0.452731  [   82/   89]
per-ex loss: 0.516908  [   84/   89]
per-ex loss: 0.487034  [   86/   89]
per-ex loss: 0.488233  [   88/   89]
per-ex loss: 0.369817  [   89/   89]
Train Error: Avg loss: 0.46576345
validation Error: 
 Avg loss: 0.98186451 
 F1: 0.515090 
 Precision: 0.605028 
 Recall: 0.448430
 IoU: 0.346883

test Error: 
 Avg loss: 0.97934779 
 F1: 0.536965 
 Precision: 0.624109 
 Recall: 0.471175
 IoU: 0.367021

We have finished training iteration 117
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_115_.pth
per-ex loss: 0.370566  [    2/   89]
per-ex loss: 0.477761  [    4/   89]
per-ex loss: 0.399376  [    6/   89]
per-ex loss: 0.418863  [    8/   89]
per-ex loss: 0.557090  [   10/   89]
per-ex loss: 0.423755  [   12/   89]
per-ex loss: 0.350260  [   14/   89]
per-ex loss: 0.612838  [   16/   89]
per-ex loss: 0.412002  [   18/   89]
per-ex loss: 0.474108  [   20/   89]
per-ex loss: 0.352578  [   22/   89]
per-ex loss: 0.504287  [   24/   89]
per-ex loss: 0.524207  [   26/   89]
per-ex loss: 0.408981  [   28/   89]
per-ex loss: 0.503450  [   30/   89]
per-ex loss: 0.401891  [   32/   89]
per-ex loss: 0.376601  [   34/   89]
per-ex loss: 0.415727  [   36/   89]
per-ex loss: 0.589821  [   38/   89]
per-ex loss: 0.366127  [   40/   89]
per-ex loss: 0.478531  [   42/   89]
per-ex loss: 0.453884  [   44/   89]
per-ex loss: 0.466599  [   46/   89]
per-ex loss: 0.620286  [   48/   89]
per-ex loss: 0.452695  [   50/   89]
per-ex loss: 0.459904  [   52/   89]
per-ex loss: 0.478264  [   54/   89]
per-ex loss: 0.422815  [   56/   89]
per-ex loss: 0.427222  [   58/   89]
per-ex loss: 0.482310  [   60/   89]
per-ex loss: 0.493314  [   62/   89]
per-ex loss: 0.402570  [   64/   89]
per-ex loss: 0.448612  [   66/   89]
per-ex loss: 0.393310  [   68/   89]
per-ex loss: 0.533919  [   70/   89]
per-ex loss: 0.488191  [   72/   89]
per-ex loss: 0.443110  [   74/   89]
per-ex loss: 0.562593  [   76/   89]
per-ex loss: 0.601013  [   78/   89]
per-ex loss: 0.446463  [   80/   89]
per-ex loss: 0.495038  [   82/   89]
per-ex loss: 0.361285  [   84/   89]
per-ex loss: 0.601801  [   86/   89]
per-ex loss: 0.617630  [   88/   89]
per-ex loss: 0.354299  [   89/   89]
Train Error: Avg loss: 0.46502099
validation Error: 
 Avg loss: 0.98300519 
 F1: 0.518467 
 Precision: 0.574248 
 Recall: 0.472563
 IoU: 0.349953

test Error: 
 Avg loss: 0.98017433 
 F1: 0.541275 
 Precision: 0.603013 
 Recall: 0.491004
 IoU: 0.371060

We have finished training iteration 118
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_116_.pth
per-ex loss: 0.527914  [    2/   89]
per-ex loss: 0.573951  [    4/   89]
per-ex loss: 0.506630  [    6/   89]
per-ex loss: 0.434967  [    8/   89]
per-ex loss: 0.586207  [   10/   89]
per-ex loss: 0.436720  [   12/   89]
per-ex loss: 0.426070  [   14/   89]
per-ex loss: 0.387386  [   16/   89]
per-ex loss: 0.456321  [   18/   89]
per-ex loss: 0.577653  [   20/   89]
per-ex loss: 0.400877  [   22/   89]
per-ex loss: 0.536967  [   24/   89]
per-ex loss: 0.427129  [   26/   89]
per-ex loss: 0.386408  [   28/   89]
per-ex loss: 0.654226  [   30/   89]
per-ex loss: 0.546442  [   32/   89]
per-ex loss: 0.520260  [   34/   89]
per-ex loss: 0.469202  [   36/   89]
per-ex loss: 0.402237  [   38/   89]
per-ex loss: 0.358950  [   40/   89]
per-ex loss: 0.410367  [   42/   89]
per-ex loss: 0.533700  [   44/   89]
per-ex loss: 0.526032  [   46/   89]
per-ex loss: 0.386737  [   48/   89]
per-ex loss: 0.579353  [   50/   89]
per-ex loss: 0.373280  [   52/   89]
per-ex loss: 0.588733  [   54/   89]
per-ex loss: 0.432751  [   56/   89]
per-ex loss: 0.401542  [   58/   89]
per-ex loss: 0.483054  [   60/   89]
per-ex loss: 0.534444  [   62/   89]
per-ex loss: 0.430998  [   64/   89]
per-ex loss: 0.439139  [   66/   89]
per-ex loss: 0.546439  [   68/   89]
per-ex loss: 0.389350  [   70/   89]
per-ex loss: 0.444943  [   72/   89]
per-ex loss: 0.366175  [   74/   89]
per-ex loss: 0.378265  [   76/   89]
per-ex loss: 0.381818  [   78/   89]
per-ex loss: 0.586251  [   80/   89]
per-ex loss: 0.384470  [   82/   89]
per-ex loss: 0.398861  [   84/   89]
per-ex loss: 0.455488  [   86/   89]
per-ex loss: 0.486373  [   88/   89]
per-ex loss: 0.328969  [   89/   89]
Train Error: Avg loss: 0.46409003
validation Error: 
 Avg loss: 0.98375591 
 F1: 0.516628 
 Precision: 0.538370 
 Recall: 0.496574
 IoU: 0.348280

test Error: 
 Avg loss: 0.98143334 
 F1: 0.535290 
 Precision: 0.555283 
 Recall: 0.516686
 IoU: 0.365458

We have finished training iteration 119
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_117_.pth
per-ex loss: 0.624629  [    2/   89]
per-ex loss: 0.536146  [    4/   89]
per-ex loss: 0.697815  [    6/   89]
per-ex loss: 0.508259  [    8/   89]
per-ex loss: 0.397469  [   10/   89]
per-ex loss: 0.539084  [   12/   89]
per-ex loss: 0.523763  [   14/   89]
per-ex loss: 0.675407  [   16/   89]
per-ex loss: 0.401053  [   18/   89]
per-ex loss: 0.419268  [   20/   89]
per-ex loss: 0.389462  [   22/   89]
per-ex loss: 0.567822  [   24/   89]
per-ex loss: 0.375122  [   26/   89]
per-ex loss: 0.405302  [   28/   89]
per-ex loss: 0.375807  [   30/   89]
per-ex loss: 0.409490  [   32/   89]
per-ex loss: 0.413899  [   34/   89]
per-ex loss: 0.455699  [   36/   89]
per-ex loss: 0.415562  [   38/   89]
per-ex loss: 0.427006  [   40/   89]
per-ex loss: 0.466939  [   42/   89]
per-ex loss: 0.381948  [   44/   89]
per-ex loss: 0.454377  [   46/   89]
per-ex loss: 0.421767  [   48/   89]
per-ex loss: 0.672391  [   50/   89]
per-ex loss: 0.417281  [   52/   89]
per-ex loss: 0.460603  [   54/   89]
per-ex loss: 0.445352  [   56/   89]
per-ex loss: 0.423357  [   58/   89]
per-ex loss: 0.346346  [   60/   89]
per-ex loss: 0.366348  [   62/   89]
per-ex loss: 0.395973  [   64/   89]
per-ex loss: 0.395254  [   66/   89]
per-ex loss: 0.470861  [   68/   89]
per-ex loss: 0.347185  [   70/   89]
per-ex loss: 0.458766  [   72/   89]
per-ex loss: 0.489141  [   74/   89]
per-ex loss: 0.369213  [   76/   89]
per-ex loss: 0.539493  [   78/   89]
per-ex loss: 0.629651  [   80/   89]
per-ex loss: 0.502936  [   82/   89]
per-ex loss: 0.411287  [   84/   89]
per-ex loss: 0.415194  [   86/   89]
per-ex loss: 0.501991  [   88/   89]
per-ex loss: 0.556549  [   89/   89]
Train Error: Avg loss: 0.46440598
validation Error: 
 Avg loss: 0.98230980 
 F1: 0.518824 
 Precision: 0.595645 
 Recall: 0.459555
 IoU: 0.350279

test Error: 
 Avg loss: 0.98035889 
 F1: 0.536521 
 Precision: 0.615238 
 Recall: 0.475662
 IoU: 0.366607

We have finished training iteration 120
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_118_.pth
per-ex loss: 0.540953  [    2/   89]
per-ex loss: 0.367116  [    4/   89]
per-ex loss: 0.373991  [    6/   89]
per-ex loss: 0.365202  [    8/   89]
per-ex loss: 0.446889  [   10/   89]
per-ex loss: 0.470177  [   12/   89]
per-ex loss: 0.365789  [   14/   89]
per-ex loss: 0.391027  [   16/   89]
per-ex loss: 0.533503  [   18/   89]
per-ex loss: 0.534401  [   20/   89]
per-ex loss: 0.474684  [   22/   89]
per-ex loss: 0.454541  [   24/   89]
per-ex loss: 0.416135  [   26/   89]
per-ex loss: 0.506741  [   28/   89]
per-ex loss: 0.394712  [   30/   89]
per-ex loss: 0.400767  [   32/   89]
per-ex loss: 0.391264  [   34/   89]
per-ex loss: 0.545763  [   36/   89]
per-ex loss: 0.393580  [   38/   89]
per-ex loss: 0.431205  [   40/   89]
per-ex loss: 0.556868  [   42/   89]
per-ex loss: 0.474209  [   44/   89]
per-ex loss: 0.418752  [   46/   89]
per-ex loss: 0.397071  [   48/   89]
per-ex loss: 0.431141  [   50/   89]
per-ex loss: 0.412853  [   52/   89]
per-ex loss: 0.554314  [   54/   89]
per-ex loss: 0.536617  [   56/   89]
per-ex loss: 0.508970  [   58/   89]
per-ex loss: 0.425044  [   60/   89]
per-ex loss: 0.422151  [   62/   89]
per-ex loss: 0.575427  [   64/   89]
per-ex loss: 0.352626  [   66/   89]
per-ex loss: 0.553896  [   68/   89]
per-ex loss: 0.448414  [   70/   89]
per-ex loss: 0.550222  [   72/   89]
per-ex loss: 0.562297  [   74/   89]
per-ex loss: 0.472388  [   76/   89]
per-ex loss: 0.466869  [   78/   89]
per-ex loss: 0.406758  [   80/   89]
per-ex loss: 0.767215  [   82/   89]
per-ex loss: 0.562929  [   84/   89]
per-ex loss: 0.376186  [   86/   89]
per-ex loss: 0.453132  [   88/   89]
per-ex loss: 0.618410  [   89/   89]
Train Error: Avg loss: 0.46895998
validation Error: 
 Avg loss: 0.98211063 
 F1: 0.513606 
 Precision: 0.601561 
 Recall: 0.448091
 IoU: 0.345539

test Error: 
 Avg loss: 0.97987846 
 F1: 0.532824 
 Precision: 0.621761 
 Recall: 0.466146
 IoU: 0.363163

We have finished training iteration 121
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_119_.pth
Error in cropping the image to the non-zero values in the fourth channel. Returned the original image.
per-ex loss: 0.409524  [    2/   89]
per-ex loss: 0.355375  [    4/   89]
per-ex loss: 0.551111  [    6/   89]
per-ex loss: 0.572244  [    8/   89]
per-ex loss: 0.453872  [   10/   89]
per-ex loss: 0.500628  [   12/   89]
per-ex loss: 0.591910  [   14/   89]
per-ex loss: 0.449292  [   16/   89]
per-ex loss: 0.520393  [   18/   89]
per-ex loss: 0.372471  [   20/   89]
per-ex loss: 0.399112  [   22/   89]
per-ex loss: 0.402854  [   24/   89]
per-ex loss: 0.460050  [   26/   89]
per-ex loss: 0.422228  [   28/   89]
per-ex loss: 0.515019  [   30/   89]
per-ex loss: 0.391540  [   32/   89]
per-ex loss: 0.419563  [   34/   89]
per-ex loss: 0.495712  [   36/   89]
per-ex loss: 0.426014  [   38/   89]
per-ex loss: 0.532784  [   40/   89]
per-ex loss: 0.553848  [   42/   89]
per-ex loss: 0.412629  [   44/   89]
per-ex loss: 0.539533  [   46/   89]
per-ex loss: 0.445582  [   48/   89]
per-ex loss: 0.383558  [   50/   89]
per-ex loss: 0.577425  [   52/   89]
per-ex loss: 0.508859  [   54/   89]
per-ex loss: 0.403988  [   56/   89]
per-ex loss: 0.576022  [   58/   89]
per-ex loss: 0.411547  [   60/   89]
per-ex loss: 0.480482  [   62/   89]
per-ex loss: 0.332765  [   64/   89]
per-ex loss: 0.597674  [   66/   89]
per-ex loss: 0.562232  [   68/   89]
per-ex loss: 0.367233  [   70/   89]
per-ex loss: 0.407601  [   72/   89]
per-ex loss: 0.556353  [   74/   89]
per-ex loss: 0.432102  [   76/   89]
per-ex loss: 0.519047  [   78/   89]
per-ex loss: 0.365747  [   80/   89]
per-ex loss: 0.385337  [   82/   89]
per-ex loss: 0.399156  [   84/   89]
per-ex loss: 0.485100  [   86/   89]
per-ex loss: 0.413958  [   88/   89]
per-ex loss: 0.544776  [   89/   89]
Train Error: Avg loss: 0.46453887
validation Error: 
 Avg loss: 0.98327018 
 F1: 0.511936 
 Precision: 0.574751 
 Recall: 0.461498
 IoU: 0.344028

test Error: 
 Avg loss: 0.98036010 
 F1: 0.530915 
 Precision: 0.595904 
 Recall: 0.478707
 IoU: 0.361392

We have finished training iteration 122
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_120_.pth
per-ex loss: 0.425904  [    2/   89]
per-ex loss: 0.471797  [    4/   89]
per-ex loss: 0.399163  [    6/   89]
per-ex loss: 0.502374  [    8/   89]
per-ex loss: 0.488167  [   10/   89]
per-ex loss: 0.435243  [   12/   89]
per-ex loss: 0.464985  [   14/   89]
per-ex loss: 0.429149  [   16/   89]
per-ex loss: 0.586962  [   18/   89]
per-ex loss: 0.355744  [   20/   89]
per-ex loss: 0.483959  [   22/   89]
per-ex loss: 0.499720  [   24/   89]
per-ex loss: 0.372415  [   26/   89]
per-ex loss: 0.423819  [   28/   89]
per-ex loss: 0.620933  [   30/   89]
per-ex loss: 0.433338  [   32/   89]
per-ex loss: 0.515714  [   34/   89]
per-ex loss: 0.480942  [   36/   89]
per-ex loss: 0.557836  [   38/   89]
per-ex loss: 0.528200  [   40/   89]
per-ex loss: 0.414561  [   42/   89]
per-ex loss: 0.560865  [   44/   89]
per-ex loss: 0.553382  [   46/   89]
per-ex loss: 0.515030  [   48/   89]
per-ex loss: 0.545605  [   50/   89]
per-ex loss: 0.353196  [   52/   89]
per-ex loss: 0.357719  [   54/   89]
per-ex loss: 0.405632  [   56/   89]
per-ex loss: 0.383017  [   58/   89]
per-ex loss: 0.382517  [   60/   89]
per-ex loss: 0.443575  [   62/   89]
per-ex loss: 0.400731  [   64/   89]
per-ex loss: 0.570048  [   66/   89]
per-ex loss: 0.402763  [   68/   89]
per-ex loss: 0.395819  [   70/   89]
per-ex loss: 0.476741  [   72/   89]
per-ex loss: 0.400345  [   74/   89]
per-ex loss: 0.377863  [   76/   89]
per-ex loss: 0.439398  [   78/   89]
per-ex loss: 0.653334  [   80/   89]
per-ex loss: 0.415749  [   82/   89]
per-ex loss: 0.463937  [   84/   89]
per-ex loss: 0.412547  [   86/   89]
per-ex loss: 0.516449  [   88/   89]
per-ex loss: 0.357757  [   89/   89]
Train Error: Avg loss: 0.45944325
validation Error: 
 Avg loss: 0.98309219 
 F1: 0.514894 
 Precision: 0.563845 
 Recall: 0.473763
 IoU: 0.346705

test Error: 
 Avg loss: 0.98117870 
 F1: 0.534195 
 Precision: 0.579128 
 Recall: 0.495732
 IoU: 0.364438

We have finished training iteration 123
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_121_.pth
per-ex loss: 0.431850  [    2/   89]
per-ex loss: 0.505389  [    4/   89]
per-ex loss: 0.457187  [    6/   89]
per-ex loss: 0.431735  [    8/   89]
per-ex loss: 0.431852  [   10/   89]
per-ex loss: 0.388477  [   12/   89]
per-ex loss: 0.585976  [   14/   89]
per-ex loss: 0.343104  [   16/   89]
per-ex loss: 0.390630  [   18/   89]
per-ex loss: 0.432842  [   20/   89]
per-ex loss: 0.352048  [   22/   89]
per-ex loss: 0.601557  [   24/   89]
per-ex loss: 0.403464  [   26/   89]
per-ex loss: 0.485782  [   28/   89]
per-ex loss: 0.581619  [   30/   89]
per-ex loss: 0.394822  [   32/   89]
per-ex loss: 0.370824  [   34/   89]
per-ex loss: 0.447831  [   36/   89]
per-ex loss: 0.536967  [   38/   89]
per-ex loss: 0.496931  [   40/   89]
per-ex loss: 0.439661  [   42/   89]
per-ex loss: 0.546245  [   44/   89]
per-ex loss: 0.389782  [   46/   89]
per-ex loss: 0.450304  [   48/   89]
per-ex loss: 0.334732  [   50/   89]
per-ex loss: 0.379400  [   52/   89]
per-ex loss: 0.501707  [   54/   89]
per-ex loss: 0.461778  [   56/   89]
per-ex loss: 0.459559  [   58/   89]
per-ex loss: 0.445508  [   60/   89]
per-ex loss: 0.617181  [   62/   89]
per-ex loss: 0.472540  [   64/   89]
per-ex loss: 0.468038  [   66/   89]
per-ex loss: 0.400075  [   68/   89]
per-ex loss: 0.472509  [   70/   89]
per-ex loss: 0.435668  [   72/   89]
per-ex loss: 0.387588  [   74/   89]
per-ex loss: 0.356609  [   76/   89]
per-ex loss: 0.416506  [   78/   89]
per-ex loss: 0.494997  [   80/   89]
per-ex loss: 0.630175  [   82/   89]
per-ex loss: 0.395625  [   84/   89]
per-ex loss: 0.541515  [   86/   89]
per-ex loss: 0.593493  [   88/   89]
per-ex loss: 0.393753  [   89/   89]
Train Error: Avg loss: 0.45679639
validation Error: 
 Avg loss: 0.98208210 
 F1: 0.519224 
 Precision: 0.575721 
 Recall: 0.472824
 IoU: 0.350643

test Error: 
 Avg loss: 0.98072912 
 F1: 0.541748 
 Precision: 0.590688 
 Recall: 0.500296
 IoU: 0.371505

We have finished training iteration 124
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_122_.pth
per-ex loss: 0.619243  [    2/   89]
per-ex loss: 0.493122  [    4/   89]
per-ex loss: 0.340328  [    6/   89]
per-ex loss: 0.465049  [    8/   89]
per-ex loss: 0.626256  [   10/   89]
per-ex loss: 0.470379  [   12/   89]
per-ex loss: 0.358414  [   14/   89]
per-ex loss: 0.439461  [   16/   89]
per-ex loss: 0.536005  [   18/   89]
per-ex loss: 0.519602  [   20/   89]
per-ex loss: 0.377437  [   22/   89]
per-ex loss: 0.470963  [   24/   89]
per-ex loss: 0.512126  [   26/   89]
per-ex loss: 0.474275  [   28/   89]
per-ex loss: 0.528512  [   30/   89]
per-ex loss: 0.490715  [   32/   89]
per-ex loss: 0.428981  [   34/   89]
per-ex loss: 0.518372  [   36/   89]
per-ex loss: 0.464962  [   38/   89]
per-ex loss: 0.412375  [   40/   89]
per-ex loss: 0.466953  [   42/   89]
per-ex loss: 0.449555  [   44/   89]
per-ex loss: 0.538166  [   46/   89]
per-ex loss: 0.436918  [   48/   89]
per-ex loss: 0.366438  [   50/   89]
per-ex loss: 0.454841  [   52/   89]
per-ex loss: 0.399714  [   54/   89]
per-ex loss: 0.433802  [   56/   89]
per-ex loss: 0.633836  [   58/   89]
per-ex loss: 0.364650  [   60/   89]
per-ex loss: 0.392733  [   62/   89]
per-ex loss: 0.350024  [   64/   89]
per-ex loss: 0.484382  [   66/   89]
per-ex loss: 0.499278  [   68/   89]
per-ex loss: 0.539957  [   70/   89]
per-ex loss: 0.384397  [   72/   89]
per-ex loss: 0.433158  [   74/   89]
per-ex loss: 0.492548  [   76/   89]
per-ex loss: 0.471578  [   78/   89]
per-ex loss: 0.673164  [   80/   89]
per-ex loss: 0.606184  [   82/   89]
per-ex loss: 0.445025  [   84/   89]
per-ex loss: 0.592379  [   86/   89]
per-ex loss: 0.467436  [   88/   89]
per-ex loss: 0.635107  [   89/   89]
Train Error: Avg loss: 0.47908445
validation Error: 
 Avg loss: 0.98237944 
 F1: 0.516175 
 Precision: 0.609080 
 Recall: 0.447861
 IoU: 0.347868

test Error: 
 Avg loss: 0.98014478 
 F1: 0.539686 
 Precision: 0.628651 
 Recall: 0.472780
 IoU: 0.369569

We have finished training iteration 125
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_123_.pth
per-ex loss: 0.453217  [    2/   89]
per-ex loss: 0.371491  [    4/   89]
per-ex loss: 0.468630  [    6/   89]
per-ex loss: 0.391241  [    8/   89]
per-ex loss: 0.444082  [   10/   89]
per-ex loss: 0.436188  [   12/   89]
per-ex loss: 0.507436  [   14/   89]
per-ex loss: 0.441443  [   16/   89]
per-ex loss: 0.406393  [   18/   89]
per-ex loss: 0.444032  [   20/   89]
per-ex loss: 0.635489  [   22/   89]
per-ex loss: 0.407484  [   24/   89]
per-ex loss: 0.492614  [   26/   89]
per-ex loss: 0.399773  [   28/   89]
per-ex loss: 0.363910  [   30/   89]
per-ex loss: 0.433738  [   32/   89]
per-ex loss: 0.565839  [   34/   89]
per-ex loss: 0.478227  [   36/   89]
per-ex loss: 0.401578  [   38/   89]
per-ex loss: 0.518104  [   40/   89]
per-ex loss: 0.377135  [   42/   89]
per-ex loss: 0.672653  [   44/   89]
per-ex loss: 0.370440  [   46/   89]
per-ex loss: 0.482614  [   48/   89]
per-ex loss: 0.448046  [   50/   89]
per-ex loss: 0.342160  [   52/   89]
per-ex loss: 0.417933  [   54/   89]
per-ex loss: 0.601420  [   56/   89]
per-ex loss: 0.558504  [   58/   89]
per-ex loss: 0.403727  [   60/   89]
per-ex loss: 0.488584  [   62/   89]
per-ex loss: 0.493594  [   64/   89]
per-ex loss: 0.470158  [   66/   89]
per-ex loss: 0.606757  [   68/   89]
per-ex loss: 0.410229  [   70/   89]
per-ex loss: 0.375764  [   72/   89]
per-ex loss: 0.538713  [   74/   89]
per-ex loss: 0.494883  [   76/   89]
per-ex loss: 0.419626  [   78/   89]
per-ex loss: 0.389169  [   80/   89]
per-ex loss: 0.448208  [   82/   89]
per-ex loss: 0.422485  [   84/   89]
per-ex loss: 0.443136  [   86/   89]
per-ex loss: 0.382465  [   88/   89]
per-ex loss: 0.604986  [   89/   89]
Train Error: Avg loss: 0.46053997
validation Error: 
 Avg loss: 0.98329987 
 F1: 0.518177 
 Precision: 0.573472 
 Recall: 0.472608
 IoU: 0.349689

test Error: 
 Avg loss: 0.98054153 
 F1: 0.543082 
 Precision: 0.600093 
 Recall: 0.495964
 IoU: 0.372761

We have finished training iteration 126
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_124_.pth
per-ex loss: 0.457472  [    2/   89]
per-ex loss: 0.474771  [    4/   89]
per-ex loss: 0.449386  [    6/   89]
per-ex loss: 0.407794  [    8/   89]
per-ex loss: 0.438100  [   10/   89]
per-ex loss: 0.475059  [   12/   89]
per-ex loss: 0.505800  [   14/   89]
per-ex loss: 0.408974  [   16/   89]
per-ex loss: 0.369040  [   18/   89]
per-ex loss: 0.482509  [   20/   89]
per-ex loss: 0.509212  [   22/   89]
per-ex loss: 0.407549  [   24/   89]
per-ex loss: 0.405026  [   26/   89]
per-ex loss: 0.349458  [   28/   89]
per-ex loss: 0.390353  [   30/   89]
per-ex loss: 0.434583  [   32/   89]
per-ex loss: 0.373486  [   34/   89]
per-ex loss: 0.468752  [   36/   89]
per-ex loss: 0.408464  [   38/   89]
per-ex loss: 0.464500  [   40/   89]
per-ex loss: 0.607397  [   42/   89]
per-ex loss: 0.423112  [   44/   89]
per-ex loss: 0.444751  [   46/   89]
per-ex loss: 0.531207  [   48/   89]
per-ex loss: 0.430642  [   50/   89]
per-ex loss: 0.416378  [   52/   89]
per-ex loss: 0.374620  [   54/   89]
per-ex loss: 0.378906  [   56/   89]
per-ex loss: 0.653407  [   58/   89]
per-ex loss: 0.404993  [   60/   89]
per-ex loss: 0.431204  [   62/   89]
per-ex loss: 0.460490  [   64/   89]
per-ex loss: 0.507719  [   66/   89]
per-ex loss: 0.385500  [   68/   89]
per-ex loss: 0.412478  [   70/   89]
per-ex loss: 0.592707  [   72/   89]
per-ex loss: 0.437962  [   74/   89]
per-ex loss: 0.680558  [   76/   89]
per-ex loss: 0.512378  [   78/   89]
per-ex loss: 0.458284  [   80/   89]
per-ex loss: 0.449734  [   82/   89]
per-ex loss: 0.499599  [   84/   89]
per-ex loss: 0.395935  [   86/   89]
per-ex loss: 0.390540  [   88/   89]
per-ex loss: 0.359873  [   89/   89]
Train Error: Avg loss: 0.45157023
validation Error: 
 Avg loss: 0.98431219 
 F1: 0.515739 
 Precision: 0.553877 
 Recall: 0.482515
 IoU: 0.347472

test Error: 
 Avg loss: 0.98154859 
 F1: 0.542059 
 Precision: 0.579570 
 Recall: 0.509108
 IoU: 0.371797

We have finished training iteration 127
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_125_.pth
per-ex loss: 0.618905  [    2/   89]
per-ex loss: 0.367516  [    4/   89]
per-ex loss: 0.491981  [    6/   89]
per-ex loss: 0.365456  [    8/   89]
per-ex loss: 0.523890  [   10/   89]
per-ex loss: 0.401538  [   12/   89]
per-ex loss: 0.426265  [   14/   89]
per-ex loss: 0.614441  [   16/   89]
per-ex loss: 0.633326  [   18/   89]
per-ex loss: 0.563625  [   20/   89]
per-ex loss: 0.481456  [   22/   89]
per-ex loss: 0.445873  [   24/   89]
per-ex loss: 0.374414  [   26/   89]
per-ex loss: 0.571322  [   28/   89]
per-ex loss: 0.467101  [   30/   89]
per-ex loss: 0.449371  [   32/   89]
per-ex loss: 0.436915  [   34/   89]
per-ex loss: 0.591065  [   36/   89]
per-ex loss: 0.402735  [   38/   89]
per-ex loss: 0.427946  [   40/   89]
per-ex loss: 0.486530  [   42/   89]
per-ex loss: 0.448138  [   44/   89]
per-ex loss: 0.502778  [   46/   89]
per-ex loss: 0.422294  [   48/   89]
per-ex loss: 0.368518  [   50/   89]
per-ex loss: 0.601544  [   52/   89]
per-ex loss: 0.426680  [   54/   89]
per-ex loss: 0.548050  [   56/   89]
per-ex loss: 0.373298  [   58/   89]
per-ex loss: 0.328089  [   60/   89]
per-ex loss: 0.389908  [   62/   89]
per-ex loss: 0.380818  [   64/   89]
per-ex loss: 0.432033  [   66/   89]
per-ex loss: 0.449825  [   68/   89]
per-ex loss: 0.390242  [   70/   89]
per-ex loss: 0.629288  [   72/   89]
per-ex loss: 0.498168  [   74/   89]
per-ex loss: 0.372121  [   76/   89]
per-ex loss: 0.465017  [   78/   89]
per-ex loss: 0.372342  [   80/   89]
per-ex loss: 0.561001  [   82/   89]
per-ex loss: 0.582987  [   84/   89]
per-ex loss: 0.470562  [   86/   89]
per-ex loss: 0.380018  [   88/   89]
per-ex loss: 0.586478  [   89/   89]
Train Error: Avg loss: 0.46937485
validation Error: 
 Avg loss: 0.98261047 
 F1: 0.516975 
 Precision: 0.571453 
 Recall: 0.471980
 IoU: 0.348595

test Error: 
 Avg loss: 0.98031845 
 F1: 0.535607 
 Precision: 0.594531 
 Recall: 0.487309
 IoU: 0.365753

We have finished training iteration 128
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_126_.pth
per-ex loss: 0.382377  [    2/   89]
per-ex loss: 0.435012  [    4/   89]
per-ex loss: 0.573318  [    6/   89]
per-ex loss: 0.582223  [    8/   89]
per-ex loss: 0.650891  [   10/   89]
per-ex loss: 0.435135  [   12/   89]
per-ex loss: 0.454664  [   14/   89]
per-ex loss: 0.397044  [   16/   89]
per-ex loss: 0.453902  [   18/   89]
per-ex loss: 0.382075  [   20/   89]
per-ex loss: 0.475621  [   22/   89]
per-ex loss: 0.398138  [   24/   89]
per-ex loss: 0.438799  [   26/   89]
per-ex loss: 0.583340  [   28/   89]
per-ex loss: 0.429153  [   30/   89]
per-ex loss: 0.505773  [   32/   89]
per-ex loss: 0.475792  [   34/   89]
per-ex loss: 0.592836  [   36/   89]
per-ex loss: 0.682715  [   38/   89]
per-ex loss: 0.490481  [   40/   89]
per-ex loss: 0.348165  [   42/   89]
per-ex loss: 0.356313  [   44/   89]
per-ex loss: 0.398277  [   46/   89]
per-ex loss: 0.509179  [   48/   89]
per-ex loss: 0.458122  [   50/   89]
per-ex loss: 0.476867  [   52/   89]
per-ex loss: 0.434139  [   54/   89]
per-ex loss: 0.418504  [   56/   89]
per-ex loss: 0.519312  [   58/   89]
per-ex loss: 0.527878  [   60/   89]
per-ex loss: 0.530010  [   62/   89]
per-ex loss: 0.408169  [   64/   89]
per-ex loss: 0.422952  [   66/   89]
per-ex loss: 0.403074  [   68/   89]
per-ex loss: 0.494587  [   70/   89]
per-ex loss: 0.459517  [   72/   89]
per-ex loss: 0.434195  [   74/   89]
per-ex loss: 0.428908  [   76/   89]
per-ex loss: 0.401548  [   78/   89]
per-ex loss: 0.512193  [   80/   89]
per-ex loss: 0.414939  [   82/   89]
per-ex loss: 0.547963  [   84/   89]
per-ex loss: 0.445235  [   86/   89]
per-ex loss: 0.488578  [   88/   89]
per-ex loss: 0.517233  [   89/   89]
Train Error: Avg loss: 0.47055884
validation Error: 
 Avg loss: 0.98231775 
 F1: 0.510627 
 Precision: 0.617950 
 Recall: 0.435067
 IoU: 0.342847

test Error: 
 Avg loss: 0.98039664 
 F1: 0.527635 
 Precision: 0.623352 
 Recall: 0.457401
 IoU: 0.358359

We have finished training iteration 129
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_127_.pth
per-ex loss: 0.472823  [    2/   89]
per-ex loss: 0.449776  [    4/   89]
per-ex loss: 0.577705  [    6/   89]
per-ex loss: 0.394399  [    8/   89]
per-ex loss: 0.508810  [   10/   89]
per-ex loss: 0.375980  [   12/   89]
per-ex loss: 0.519606  [   14/   89]
per-ex loss: 0.349289  [   16/   89]
per-ex loss: 0.462107  [   18/   89]
per-ex loss: 0.713460  [   20/   89]
per-ex loss: 0.613417  [   22/   89]
per-ex loss: 0.481290  [   24/   89]
per-ex loss: 0.312524  [   26/   89]
per-ex loss: 0.542205  [   28/   89]
per-ex loss: 0.446552  [   30/   89]
per-ex loss: 0.658920  [   32/   89]
per-ex loss: 0.382557  [   34/   89]
per-ex loss: 0.400326  [   36/   89]
per-ex loss: 0.371287  [   38/   89]
per-ex loss: 0.664092  [   40/   89]
per-ex loss: 0.525647  [   42/   89]
per-ex loss: 0.416217  [   44/   89]
per-ex loss: 0.493807  [   46/   89]
per-ex loss: 0.405192  [   48/   89]
per-ex loss: 0.510582  [   50/   89]
per-ex loss: 0.516660  [   52/   89]
per-ex loss: 0.368782  [   54/   89]
per-ex loss: 0.394100  [   56/   89]
per-ex loss: 0.440513  [   58/   89]
per-ex loss: 0.568302  [   60/   89]
per-ex loss: 0.401390  [   62/   89]
per-ex loss: 0.441774  [   64/   89]
per-ex loss: 0.366534  [   66/   89]
per-ex loss: 0.421192  [   68/   89]
per-ex loss: 0.429522  [   70/   89]
per-ex loss: 0.391847  [   72/   89]
per-ex loss: 0.449854  [   74/   89]
per-ex loss: 0.491787  [   76/   89]
per-ex loss: 0.442162  [   78/   89]
per-ex loss: 0.415090  [   80/   89]
per-ex loss: 0.367502  [   82/   89]
per-ex loss: 0.428069  [   84/   89]
per-ex loss: 0.423590  [   86/   89]
per-ex loss: 0.442868  [   88/   89]
per-ex loss: 0.557884  [   89/   89]
Train Error: Avg loss: 0.46239981
validation Error: 
 Avg loss: 0.98236087 
 F1: 0.516539 
 Precision: 0.585926 
 Recall: 0.461846
 IoU: 0.348199

test Error: 
 Avg loss: 0.98016798 
 F1: 0.540804 
 Precision: 0.604749 
 Recall: 0.489088
 IoU: 0.370617

We have finished training iteration 130
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_128_.pth
per-ex loss: 0.398759  [    2/   89]
per-ex loss: 0.422971  [    4/   89]
per-ex loss: 0.453683  [    6/   89]
per-ex loss: 0.489237  [    8/   89]
per-ex loss: 0.494944  [   10/   89]
per-ex loss: 0.553104  [   12/   89]
per-ex loss: 0.591759  [   14/   89]
per-ex loss: 0.566473  [   16/   89]
per-ex loss: 0.488190  [   18/   89]
per-ex loss: 0.447227  [   20/   89]
per-ex loss: 0.455334  [   22/   89]
per-ex loss: 0.436559  [   24/   89]
per-ex loss: 0.548388  [   26/   89]
per-ex loss: 0.501546  [   28/   89]
per-ex loss: 0.430205  [   30/   89]
per-ex loss: 0.345046  [   32/   89]
per-ex loss: 0.473080  [   34/   89]
per-ex loss: 0.416486  [   36/   89]
per-ex loss: 0.435164  [   38/   89]
per-ex loss: 0.373554  [   40/   89]
per-ex loss: 0.423708  [   42/   89]
per-ex loss: 0.440298  [   44/   89]
per-ex loss: 0.489224  [   46/   89]
per-ex loss: 0.426039  [   48/   89]
per-ex loss: 0.531154  [   50/   89]
per-ex loss: 0.527774  [   52/   89]
per-ex loss: 0.604661  [   54/   89]
per-ex loss: 0.450277  [   56/   89]
per-ex loss: 0.350553  [   58/   89]
per-ex loss: 0.381360  [   60/   89]
per-ex loss: 0.412462  [   62/   89]
per-ex loss: 0.390760  [   64/   89]
per-ex loss: 0.559180  [   66/   89]
per-ex loss: 0.568969  [   68/   89]
per-ex loss: 0.424468  [   70/   89]
per-ex loss: 0.465004  [   72/   89]
per-ex loss: 0.440401  [   74/   89]
per-ex loss: 0.430406  [   76/   89]
per-ex loss: 0.450388  [   78/   89]
per-ex loss: 0.528039  [   80/   89]
per-ex loss: 0.589892  [   82/   89]
per-ex loss: 0.513510  [   84/   89]
per-ex loss: 0.407636  [   86/   89]
per-ex loss: 0.420651  [   88/   89]
per-ex loss: 0.383293  [   89/   89]
Train Error: Avg loss: 0.46515146
validation Error: 
 Avg loss: 0.98261131 
 F1: 0.515137 
 Precision: 0.581962 
 Recall: 0.462079
 IoU: 0.346926

test Error: 
 Avg loss: 0.98008102 
 F1: 0.535414 
 Precision: 0.602528 
 Recall: 0.481752
 IoU: 0.365573

We have finished training iteration 131
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_129_.pth
per-ex loss: 0.548731  [    2/   89]
per-ex loss: 0.565054  [    4/   89]
per-ex loss: 0.453203  [    6/   89]
per-ex loss: 0.471560  [    8/   89]
per-ex loss: 0.464810  [   10/   89]
per-ex loss: 0.488588  [   12/   89]
per-ex loss: 0.393094  [   14/   89]
per-ex loss: 0.374668  [   16/   89]
per-ex loss: 0.461880  [   18/   89]
per-ex loss: 0.493069  [   20/   89]
per-ex loss: 0.387514  [   22/   89]
per-ex loss: 0.450809  [   24/   89]
per-ex loss: 0.459213  [   26/   89]
per-ex loss: 0.432382  [   28/   89]
per-ex loss: 0.449713  [   30/   89]
per-ex loss: 0.516436  [   32/   89]
per-ex loss: 0.623881  [   34/   89]
per-ex loss: 0.566079  [   36/   89]
per-ex loss: 0.422275  [   38/   89]
per-ex loss: 0.379820  [   40/   89]
per-ex loss: 0.475737  [   42/   89]
per-ex loss: 0.389278  [   44/   89]
per-ex loss: 0.570621  [   46/   89]
per-ex loss: 0.362324  [   48/   89]
per-ex loss: 0.357049  [   50/   89]
per-ex loss: 0.657875  [   52/   89]
per-ex loss: 0.368105  [   54/   89]
per-ex loss: 0.460328  [   56/   89]
per-ex loss: 0.401535  [   58/   89]
per-ex loss: 0.505060  [   60/   89]
per-ex loss: 0.318116  [   62/   89]
per-ex loss: 0.388162  [   64/   89]
per-ex loss: 0.457279  [   66/   89]
per-ex loss: 0.566549  [   68/   89]
per-ex loss: 0.369119  [   70/   89]
per-ex loss: 0.442220  [   72/   89]
per-ex loss: 0.367081  [   74/   89]
per-ex loss: 0.528729  [   76/   89]
per-ex loss: 0.420098  [   78/   89]
per-ex loss: 0.588218  [   80/   89]
per-ex loss: 0.461150  [   82/   89]
per-ex loss: 0.403695  [   84/   89]
per-ex loss: 0.447662  [   86/   89]
per-ex loss: 0.415056  [   88/   89]
per-ex loss: 0.596199  [   89/   89]
Train Error: Avg loss: 0.46044497
validation Error: 
 Avg loss: 0.98367577 
 F1: 0.517867 
 Precision: 0.551208 
 Recall: 0.488329
 IoU: 0.349407

test Error: 
 Avg loss: 0.98094458 
 F1: 0.541078 
 Precision: 0.574844 
 Recall: 0.511058
 IoU: 0.370875

We have finished training iteration 132
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_130_.pth
per-ex loss: 0.396015  [    2/   89]
per-ex loss: 0.510440  [    4/   89]
per-ex loss: 0.357381  [    6/   89]
per-ex loss: 0.373332  [    8/   89]
per-ex loss: 0.524395  [   10/   89]
per-ex loss: 0.372968  [   12/   89]
per-ex loss: 0.385229  [   14/   89]
per-ex loss: 0.430081  [   16/   89]
per-ex loss: 0.400636  [   18/   89]
per-ex loss: 0.423159  [   20/   89]
per-ex loss: 0.413884  [   22/   89]
per-ex loss: 0.396996  [   24/   89]
per-ex loss: 0.346721  [   26/   89]
per-ex loss: 0.585157  [   28/   89]
per-ex loss: 0.562057  [   30/   89]
per-ex loss: 0.440416  [   32/   89]
per-ex loss: 0.501704  [   34/   89]
per-ex loss: 0.424331  [   36/   89]
per-ex loss: 0.591343  [   38/   89]
per-ex loss: 0.396777  [   40/   89]
per-ex loss: 0.447104  [   42/   89]
per-ex loss: 0.467553  [   44/   89]
per-ex loss: 0.450625  [   46/   89]
per-ex loss: 0.549960  [   48/   89]
per-ex loss: 0.498891  [   50/   89]
per-ex loss: 0.550297  [   52/   89]
per-ex loss: 0.458488  [   54/   89]
per-ex loss: 0.478582  [   56/   89]
per-ex loss: 0.519741  [   58/   89]
per-ex loss: 0.526846  [   60/   89]
per-ex loss: 0.331997  [   62/   89]
per-ex loss: 0.393569  [   64/   89]
per-ex loss: 0.425994  [   66/   89]
per-ex loss: 0.418587  [   68/   89]
per-ex loss: 0.600266  [   70/   89]
per-ex loss: 0.418765  [   72/   89]
per-ex loss: 0.432796  [   74/   89]
per-ex loss: 0.550189  [   76/   89]
per-ex loss: 0.535007  [   78/   89]
per-ex loss: 0.465293  [   80/   89]
per-ex loss: 0.509323  [   82/   89]
per-ex loss: 0.399957  [   84/   89]
per-ex loss: 0.324796  [   86/   89]
per-ex loss: 0.499334  [   88/   89]
per-ex loss: 0.379624  [   89/   89]
Train Error: Avg loss: 0.45481344
validation Error: 
 Avg loss: 0.98277978 
 F1: 0.515263 
 Precision: 0.552691 
 Recall: 0.482583
 IoU: 0.347040

test Error: 
 Avg loss: 0.98154221 
 F1: 0.534025 
 Precision: 0.566685 
 Recall: 0.504924
 IoU: 0.364280

We have finished training iteration 133
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_131_.pth
per-ex loss: 0.428525  [    2/   89]
per-ex loss: 0.495041  [    4/   89]
per-ex loss: 0.523367  [    6/   89]
per-ex loss: 0.583909  [    8/   89]
per-ex loss: 0.411817  [   10/   89]
per-ex loss: 0.480139  [   12/   89]
per-ex loss: 0.380700  [   14/   89]
per-ex loss: 0.391603  [   16/   89]
per-ex loss: 0.458425  [   18/   89]
per-ex loss: 0.393557  [   20/   89]
per-ex loss: 0.380846  [   22/   89]
per-ex loss: 0.487623  [   24/   89]
per-ex loss: 0.591763  [   26/   89]
per-ex loss: 0.367480  [   28/   89]
per-ex loss: 0.476263  [   30/   89]
per-ex loss: 0.520871  [   32/   89]
per-ex loss: 0.573309  [   34/   89]
per-ex loss: 0.370965  [   36/   89]
per-ex loss: 0.515018  [   38/   89]
per-ex loss: 0.511312  [   40/   89]
per-ex loss: 0.380045  [   42/   89]
per-ex loss: 0.416133  [   44/   89]
per-ex loss: 0.370851  [   46/   89]
per-ex loss: 0.393327  [   48/   89]
per-ex loss: 0.607500  [   50/   89]
per-ex loss: 0.381318  [   52/   89]
per-ex loss: 0.452765  [   54/   89]
per-ex loss: 0.477733  [   56/   89]
per-ex loss: 0.581966  [   58/   89]
per-ex loss: 0.340612  [   60/   89]
per-ex loss: 0.647767  [   62/   89]
per-ex loss: 0.406324  [   64/   89]
per-ex loss: 0.435515  [   66/   89]
per-ex loss: 0.519175  [   68/   89]
per-ex loss: 0.393780  [   70/   89]
per-ex loss: 0.541923  [   72/   89]
per-ex loss: 0.448388  [   74/   89]
per-ex loss: 0.536338  [   76/   89]
per-ex loss: 0.430752  [   78/   89]
per-ex loss: 0.482755  [   80/   89]
per-ex loss: 0.615423  [   82/   89]
per-ex loss: 0.376226  [   84/   89]
per-ex loss: 0.476649  [   86/   89]
per-ex loss: 0.404145  [   88/   89]
per-ex loss: 0.369805  [   89/   89]
Train Error: Avg loss: 0.46288325
validation Error: 
 Avg loss: 0.98241852 
 F1: 0.513857 
 Precision: 0.605698 
 Recall: 0.446201
 IoU: 0.345766

test Error: 
 Avg loss: 0.97965846 
 F1: 0.536594 
 Precision: 0.621848 
 Recall: 0.471898
 IoU: 0.366675

We have finished training iteration 134
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_132_.pth
per-ex loss: 0.395749  [    2/   89]
per-ex loss: 0.458163  [    4/   89]
per-ex loss: 0.493945  [    6/   89]
per-ex loss: 0.576856  [    8/   89]
per-ex loss: 0.465301  [   10/   89]
per-ex loss: 0.385809  [   12/   89]
per-ex loss: 0.409411  [   14/   89]
per-ex loss: 0.414785  [   16/   89]
per-ex loss: 0.551540  [   18/   89]
per-ex loss: 0.586448  [   20/   89]
per-ex loss: 0.483439  [   22/   89]
per-ex loss: 0.393434  [   24/   89]
per-ex loss: 0.371003  [   26/   89]
per-ex loss: 0.390247  [   28/   89]
per-ex loss: 0.518016  [   30/   89]
per-ex loss: 0.440512  [   32/   89]
per-ex loss: 0.465012  [   34/   89]
per-ex loss: 0.463907  [   36/   89]
per-ex loss: 0.409861  [   38/   89]
per-ex loss: 0.570449  [   40/   89]
per-ex loss: 0.340069  [   42/   89]
per-ex loss: 0.475544  [   44/   89]
per-ex loss: 0.362781  [   46/   89]
per-ex loss: 0.450178  [   48/   89]
per-ex loss: 0.534500  [   50/   89]
per-ex loss: 0.342149  [   52/   89]
per-ex loss: 0.407131  [   54/   89]
per-ex loss: 0.538115  [   56/   89]
per-ex loss: 0.380844  [   58/   89]
per-ex loss: 0.457101  [   60/   89]
per-ex loss: 0.391997  [   62/   89]
per-ex loss: 0.544795  [   64/   89]
per-ex loss: 0.655640  [   66/   89]
per-ex loss: 0.387093  [   68/   89]
per-ex loss: 0.415378  [   70/   89]
per-ex loss: 0.411158  [   72/   89]
per-ex loss: 0.408349  [   74/   89]
per-ex loss: 0.375053  [   76/   89]
per-ex loss: 0.340529  [   78/   89]
per-ex loss: 0.551951  [   80/   89]
per-ex loss: 0.463284  [   82/   89]
per-ex loss: 0.407098  [   84/   89]
per-ex loss: 0.424898  [   86/   89]
per-ex loss: 0.433239  [   88/   89]
per-ex loss: 0.429859  [   89/   89]
Train Error: Avg loss: 0.44828042
validation Error: 
 Avg loss: 0.98387341 
 F1: 0.515575 
 Precision: 0.564984 
 Recall: 0.474112
 IoU: 0.347323

test Error: 
 Avg loss: 0.98139361 
 F1: 0.539539 
 Precision: 0.587846 
 Recall: 0.498569
 IoU: 0.369431

We have finished training iteration 135
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_133_.pth
per-ex loss: 0.441181  [    2/   89]
per-ex loss: 0.331367  [    4/   89]
per-ex loss: 0.386647  [    6/   89]
per-ex loss: 0.519530  [    8/   89]
per-ex loss: 0.725776  [   10/   89]
per-ex loss: 0.401355  [   12/   89]
per-ex loss: 0.566101  [   14/   89]
per-ex loss: 0.368740  [   16/   89]
per-ex loss: 0.403730  [   18/   89]
per-ex loss: 0.440552  [   20/   89]
per-ex loss: 0.470502  [   22/   89]
per-ex loss: 0.419583  [   24/   89]
per-ex loss: 0.451456  [   26/   89]
per-ex loss: 0.482958  [   28/   89]
per-ex loss: 0.353973  [   30/   89]
per-ex loss: 0.359135  [   32/   89]
per-ex loss: 0.583993  [   34/   89]
per-ex loss: 0.375695  [   36/   89]
per-ex loss: 0.435568  [   38/   89]
per-ex loss: 0.376068  [   40/   89]
per-ex loss: 0.457064  [   42/   89]
per-ex loss: 0.447569  [   44/   89]
per-ex loss: 0.561620  [   46/   89]
per-ex loss: 0.412253  [   48/   89]
per-ex loss: 0.425209  [   50/   89]
per-ex loss: 0.484236  [   52/   89]
per-ex loss: 0.432977  [   54/   89]
per-ex loss: 0.576943  [   56/   89]
per-ex loss: 0.392154  [   58/   89]
per-ex loss: 0.380449  [   60/   89]
per-ex loss: 0.542646  [   62/   89]
per-ex loss: 0.617943  [   64/   89]
per-ex loss: 0.400265  [   66/   89]
per-ex loss: 0.432916  [   68/   89]
per-ex loss: 0.471884  [   70/   89]
per-ex loss: 0.460262  [   72/   89]
per-ex loss: 0.521800  [   74/   89]
per-ex loss: 0.345888  [   76/   89]
per-ex loss: 0.404808  [   78/   89]
per-ex loss: 0.569397  [   80/   89]
per-ex loss: 0.446507  [   82/   89]
per-ex loss: 0.458821  [   84/   89]
per-ex loss: 0.589181  [   86/   89]
per-ex loss: 0.415109  [   88/   89]
per-ex loss: 0.663620  [   89/   89]
Train Error: Avg loss: 0.46234295
validation Error: 
 Avg loss: 0.98203877 
 F1: 0.518635 
 Precision: 0.582192 
 Recall: 0.467589
 IoU: 0.350106

test Error: 
 Avg loss: 0.98073783 
 F1: 0.537423 
 Precision: 0.595419 
 Recall: 0.489723
 IoU: 0.367450

We have finished training iteration 136
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_134_.pth
per-ex loss: 0.546663  [    2/   89]
per-ex loss: 0.465904  [    4/   89]
per-ex loss: 0.417484  [    6/   89]
per-ex loss: 0.443885  [    8/   89]
per-ex loss: 0.479301  [   10/   89]
per-ex loss: 0.470320  [   12/   89]
per-ex loss: 0.418690  [   14/   89]
per-ex loss: 0.548770  [   16/   89]
per-ex loss: 0.403141  [   18/   89]
per-ex loss: 0.572524  [   20/   89]
per-ex loss: 0.403334  [   22/   89]
per-ex loss: 0.387585  [   24/   89]
per-ex loss: 0.399974  [   26/   89]
per-ex loss: 0.452974  [   28/   89]
per-ex loss: 0.416384  [   30/   89]
per-ex loss: 0.608405  [   32/   89]
per-ex loss: 0.394623  [   34/   89]
per-ex loss: 0.359384  [   36/   89]
per-ex loss: 0.506256  [   38/   89]
per-ex loss: 0.413666  [   40/   89]
per-ex loss: 0.377686  [   42/   89]
per-ex loss: 0.417300  [   44/   89]
per-ex loss: 0.433029  [   46/   89]
per-ex loss: 0.363910  [   48/   89]
per-ex loss: 0.406380  [   50/   89]
per-ex loss: 0.676276  [   52/   89]
per-ex loss: 0.369224  [   54/   89]
per-ex loss: 0.623630  [   56/   89]
per-ex loss: 0.523024  [   58/   89]
per-ex loss: 0.438431  [   60/   89]
per-ex loss: 0.435030  [   62/   89]
per-ex loss: 0.477474  [   64/   89]
per-ex loss: 0.392981  [   66/   89]
per-ex loss: 0.453002  [   68/   89]
per-ex loss: 0.640407  [   70/   89]
per-ex loss: 0.451515  [   72/   89]
per-ex loss: 0.470745  [   74/   89]
per-ex loss: 0.453017  [   76/   89]
per-ex loss: 0.563483  [   78/   89]
per-ex loss: 0.592244  [   80/   89]
per-ex loss: 0.534314  [   82/   89]
per-ex loss: 0.394339  [   84/   89]
per-ex loss: 0.382138  [   86/   89]
per-ex loss: 0.495556  [   88/   89]
per-ex loss: 0.387870  [   89/   89]
Train Error: Avg loss: 0.46360604
validation Error: 
 Avg loss: 0.98340363 
 F1: 0.516276 
 Precision: 0.574987 
 Recall: 0.468443
 IoU: 0.347959

test Error: 
 Avg loss: 0.98084722 
 F1: 0.541289 
 Precision: 0.601186 
 Recall: 0.492246
 IoU: 0.371074

We have finished training iteration 137
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_135_.pth
per-ex loss: 0.380602  [    2/   89]
per-ex loss: 0.471745  [    4/   89]
per-ex loss: 0.483260  [    6/   89]
per-ex loss: 0.414308  [    8/   89]
per-ex loss: 0.421325  [   10/   89]
per-ex loss: 0.598590  [   12/   89]
per-ex loss: 0.492088  [   14/   89]
per-ex loss: 0.381461  [   16/   89]
per-ex loss: 0.531389  [   18/   89]
per-ex loss: 0.493954  [   20/   89]
per-ex loss: 0.577401  [   22/   89]
per-ex loss: 0.371733  [   24/   89]
per-ex loss: 0.607411  [   26/   89]
per-ex loss: 0.527969  [   28/   89]
per-ex loss: 0.409498  [   30/   89]
per-ex loss: 0.512000  [   32/   89]
per-ex loss: 0.464661  [   34/   89]
per-ex loss: 0.328183  [   36/   89]
per-ex loss: 0.421235  [   38/   89]
per-ex loss: 0.512813  [   40/   89]
per-ex loss: 0.383055  [   42/   89]
per-ex loss: 0.630452  [   44/   89]
per-ex loss: 0.534740  [   46/   89]
per-ex loss: 0.374203  [   48/   89]
per-ex loss: 0.487139  [   50/   89]
per-ex loss: 0.479370  [   52/   89]
per-ex loss: 0.534337  [   54/   89]
per-ex loss: 0.372564  [   56/   89]
per-ex loss: 0.568095  [   58/   89]
per-ex loss: 0.417760  [   60/   89]
per-ex loss: 0.574613  [   62/   89]
per-ex loss: 0.439262  [   64/   89]
per-ex loss: 0.411836  [   66/   89]
per-ex loss: 0.359489  [   68/   89]
per-ex loss: 0.376516  [   70/   89]
per-ex loss: 0.363859  [   72/   89]
per-ex loss: 0.374078  [   74/   89]
per-ex loss: 0.559634  [   76/   89]
per-ex loss: 0.529748  [   78/   89]
per-ex loss: 0.402944  [   80/   89]
per-ex loss: 0.353265  [   82/   89]
per-ex loss: 0.431557  [   84/   89]
per-ex loss: 0.415946  [   86/   89]
per-ex loss: 0.421812  [   88/   89]
per-ex loss: 0.327574  [   89/   89]
Train Error: Avg loss: 0.45612156
validation Error: 
 Avg loss: 0.98365739 
 F1: 0.518576 
 Precision: 0.566240 
 Recall: 0.478314
 IoU: 0.350053

test Error: 
 Avg loss: 0.98167424 
 F1: 0.537797 
 Precision: 0.575946 
 Recall: 0.504388
 IoU: 0.367799

We have finished training iteration 138
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_136_.pth
per-ex loss: 0.671280  [    2/   89]
per-ex loss: 0.574077  [    4/   89]
per-ex loss: 0.460067  [    6/   89]
per-ex loss: 0.429848  [    8/   89]
per-ex loss: 0.544086  [   10/   89]
per-ex loss: 0.466688  [   12/   89]
per-ex loss: 0.525634  [   14/   89]
per-ex loss: 0.390249  [   16/   89]
per-ex loss: 0.556800  [   18/   89]
per-ex loss: 0.406904  [   20/   89]
per-ex loss: 0.379436  [   22/   89]
per-ex loss: 0.446007  [   24/   89]
per-ex loss: 0.371435  [   26/   89]
per-ex loss: 0.628121  [   28/   89]
per-ex loss: 0.650618  [   30/   89]
per-ex loss: 0.576790  [   32/   89]
per-ex loss: 0.572676  [   34/   89]
per-ex loss: 0.444510  [   36/   89]
per-ex loss: 0.530874  [   38/   89]
per-ex loss: 0.406919  [   40/   89]
per-ex loss: 0.347310  [   42/   89]
per-ex loss: 0.442682  [   44/   89]
per-ex loss: 0.484050  [   46/   89]
per-ex loss: 0.531772  [   48/   89]
per-ex loss: 0.504401  [   50/   89]
per-ex loss: 0.403926  [   52/   89]
per-ex loss: 0.377876  [   54/   89]
per-ex loss: 0.462867  [   56/   89]
per-ex loss: 0.411605  [   58/   89]
per-ex loss: 0.403776  [   60/   89]
per-ex loss: 0.420134  [   62/   89]
per-ex loss: 0.471912  [   64/   89]
per-ex loss: 0.420925  [   66/   89]
per-ex loss: 0.402898  [   68/   89]
per-ex loss: 0.383289  [   70/   89]
per-ex loss: 0.566664  [   72/   89]
per-ex loss: 0.506942  [   74/   89]
per-ex loss: 0.437770  [   76/   89]
per-ex loss: 0.372893  [   78/   89]
per-ex loss: 0.453754  [   80/   89]
per-ex loss: 0.359009  [   82/   89]
per-ex loss: 0.440967  [   84/   89]
per-ex loss: 0.360609  [   86/   89]
per-ex loss: 0.430577  [   88/   89]
per-ex loss: 0.321676  [   89/   89]
Train Error: Avg loss: 0.46118447
validation Error: 
 Avg loss: 0.98283013 
 F1: 0.516017 
 Precision: 0.536876 
 Recall: 0.496719
 IoU: 0.347725

test Error: 
 Avg loss: 0.98153706 
 F1: 0.537488 
 Precision: 0.552883 
 Recall: 0.522928
 IoU: 0.367510

We have finished training iteration 139
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_137_.pth
per-ex loss: 0.530464  [    2/   89]
per-ex loss: 0.457713  [    4/   89]
per-ex loss: 0.453098  [    6/   89]
per-ex loss: 0.408318  [    8/   89]
per-ex loss: 0.448092  [   10/   89]
per-ex loss: 0.374611  [   12/   89]
per-ex loss: 0.439395  [   14/   89]
per-ex loss: 0.405983  [   16/   89]
per-ex loss: 0.397932  [   18/   89]
per-ex loss: 0.536092  [   20/   89]
per-ex loss: 0.385402  [   22/   89]
per-ex loss: 0.502640  [   24/   89]
per-ex loss: 0.406908  [   26/   89]
per-ex loss: 0.400513  [   28/   89]
per-ex loss: 0.405833  [   30/   89]
per-ex loss: 0.392593  [   32/   89]
per-ex loss: 0.459739  [   34/   89]
per-ex loss: 0.350565  [   36/   89]
per-ex loss: 0.417133  [   38/   89]
per-ex loss: 0.535950  [   40/   89]
per-ex loss: 0.445200  [   42/   89]
per-ex loss: 0.625342  [   44/   89]
per-ex loss: 0.528543  [   46/   89]
per-ex loss: 0.557283  [   48/   89]
per-ex loss: 0.673871  [   50/   89]
per-ex loss: 0.459290  [   52/   89]
per-ex loss: 0.387245  [   54/   89]
per-ex loss: 0.428186  [   56/   89]
per-ex loss: 0.401682  [   58/   89]
per-ex loss: 0.422331  [   60/   89]
per-ex loss: 0.494086  [   62/   89]
per-ex loss: 0.423179  [   64/   89]
per-ex loss: 0.540694  [   66/   89]
per-ex loss: 0.383401  [   68/   89]
per-ex loss: 0.390857  [   70/   89]
per-ex loss: 0.457741  [   72/   89]
per-ex loss: 0.394996  [   74/   89]
per-ex loss: 0.387043  [   76/   89]
per-ex loss: 0.354711  [   78/   89]
per-ex loss: 0.399272  [   80/   89]
per-ex loss: 0.493819  [   82/   89]
per-ex loss: 0.470285  [   84/   89]
per-ex loss: 0.400762  [   86/   89]
per-ex loss: 0.464440  [   88/   89]
per-ex loss: 0.496582  [   89/   89]
Train Error: Avg loss: 0.44866259
validation Error: 
 Avg loss: 0.98282845 
 F1: 0.517462 
 Precision: 0.580346 
 Recall: 0.466874
 IoU: 0.349038

test Error: 
 Avg loss: 0.98084731 
 F1: 0.537551 
 Precision: 0.588765 
 Recall: 0.494534
 IoU: 0.367569

We have finished training iteration 140
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_138_.pth
per-ex loss: 0.475070  [    2/   89]
per-ex loss: 0.441096  [    4/   89]
per-ex loss: 0.436316  [    6/   89]
per-ex loss: 0.421570  [    8/   89]
per-ex loss: 0.449449  [   10/   89]
per-ex loss: 0.400375  [   12/   89]
per-ex loss: 0.382280  [   14/   89]
per-ex loss: 0.378754  [   16/   89]
per-ex loss: 0.588296  [   18/   89]
per-ex loss: 0.581785  [   20/   89]
per-ex loss: 0.457540  [   22/   89]
per-ex loss: 0.504101  [   24/   89]
per-ex loss: 0.477296  [   26/   89]
per-ex loss: 0.492240  [   28/   89]
per-ex loss: 0.556863  [   30/   89]
per-ex loss: 0.467025  [   32/   89]
per-ex loss: 0.366811  [   34/   89]
per-ex loss: 0.443784  [   36/   89]
per-ex loss: 0.699852  [   38/   89]
per-ex loss: 0.435955  [   40/   89]
per-ex loss: 0.450373  [   42/   89]
per-ex loss: 0.341015  [   44/   89]
per-ex loss: 0.415620  [   46/   89]
per-ex loss: 0.440688  [   48/   89]
per-ex loss: 0.426645  [   50/   89]
per-ex loss: 0.585446  [   52/   89]
per-ex loss: 0.493293  [   54/   89]
per-ex loss: 0.466358  [   56/   89]
per-ex loss: 0.492429  [   58/   89]
per-ex loss: 0.396695  [   60/   89]
per-ex loss: 0.457580  [   62/   89]
per-ex loss: 0.666358  [   64/   89]
per-ex loss: 0.425221  [   66/   89]
per-ex loss: 0.468125  [   68/   89]
per-ex loss: 0.359845  [   70/   89]
per-ex loss: 0.549313  [   72/   89]
per-ex loss: 0.417794  [   74/   89]
per-ex loss: 0.340546  [   76/   89]
per-ex loss: 0.558180  [   78/   89]
per-ex loss: 0.374176  [   80/   89]
per-ex loss: 0.488653  [   82/   89]
per-ex loss: 0.543757  [   84/   89]
per-ex loss: 0.380180  [   86/   89]
per-ex loss: 0.379226  [   88/   89]
per-ex loss: 0.566835  [   89/   89]
Train Error: Avg loss: 0.46535126
validation Error: 
 Avg loss: 0.98229116 
 F1: 0.516331 
 Precision: 0.588095 
 Recall: 0.460177
 IoU: 0.348010

test Error: 
 Avg loss: 0.98007324 
 F1: 0.537084 
 Precision: 0.609681 
 Recall: 0.479937
 IoU: 0.367133

We have finished training iteration 141
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_139_.pth
per-ex loss: 0.550461  [    2/   89]
per-ex loss: 0.338115  [    4/   89]
per-ex loss: 0.380748  [    6/   89]
per-ex loss: 0.474039  [    8/   89]
per-ex loss: 0.402726  [   10/   89]
per-ex loss: 0.455110  [   12/   89]
per-ex loss: 0.541355  [   14/   89]
per-ex loss: 0.422808  [   16/   89]
per-ex loss: 0.543729  [   18/   89]
per-ex loss: 0.497279  [   20/   89]
per-ex loss: 0.338197  [   22/   89]
per-ex loss: 0.559721  [   24/   89]
per-ex loss: 0.469219  [   26/   89]
per-ex loss: 0.364005  [   28/   89]
per-ex loss: 0.440222  [   30/   89]
per-ex loss: 0.379377  [   32/   89]
per-ex loss: 0.409041  [   34/   89]
per-ex loss: 0.488949  [   36/   89]
per-ex loss: 0.386384  [   38/   89]
per-ex loss: 0.422502  [   40/   89]
per-ex loss: 0.401196  [   42/   89]
per-ex loss: 0.539166  [   44/   89]
per-ex loss: 0.496952  [   46/   89]
per-ex loss: 0.553840  [   48/   89]
per-ex loss: 0.462877  [   50/   89]
per-ex loss: 0.347141  [   52/   89]
per-ex loss: 0.490895  [   54/   89]
per-ex loss: 0.560005  [   56/   89]
per-ex loss: 0.459739  [   58/   89]
per-ex loss: 0.653096  [   60/   89]
per-ex loss: 0.494617  [   62/   89]
per-ex loss: 0.393197  [   64/   89]
per-ex loss: 0.390334  [   66/   89]
per-ex loss: 0.395718  [   68/   89]
per-ex loss: 0.499534  [   70/   89]
per-ex loss: 0.599860  [   72/   89]
per-ex loss: 0.408858  [   74/   89]
per-ex loss: 0.500468  [   76/   89]
per-ex loss: 0.492326  [   78/   89]
per-ex loss: 0.465325  [   80/   89]
per-ex loss: 0.440327  [   82/   89]
per-ex loss: 0.478797  [   84/   89]
per-ex loss: 0.465137  [   86/   89]
per-ex loss: 0.415600  [   88/   89]
per-ex loss: 0.368518  [   89/   89]
Train Error: Avg loss: 0.45861138
validation Error: 
 Avg loss: 0.98383070 
 F1: 0.515475 
 Precision: 0.552381 
 Recall: 0.483192
 IoU: 0.347232

test Error: 
 Avg loss: 0.98161717 
 F1: 0.542201 
 Precision: 0.576995 
 Recall: 0.511365
 IoU: 0.371931

We have finished training iteration 142
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_140_.pth
per-ex loss: 0.522435  [    2/   89]
per-ex loss: 0.440441  [    4/   89]
per-ex loss: 0.539242  [    6/   89]
per-ex loss: 0.500669  [    8/   89]
per-ex loss: 0.529812  [   10/   89]
per-ex loss: 0.407268  [   12/   89]
per-ex loss: 0.558892  [   14/   89]
per-ex loss: 0.465497  [   16/   89]
per-ex loss: 0.436261  [   18/   89]
per-ex loss: 0.654636  [   20/   89]
per-ex loss: 0.417102  [   22/   89]
per-ex loss: 0.375498  [   24/   89]
per-ex loss: 0.428606  [   26/   89]
per-ex loss: 0.484868  [   28/   89]
per-ex loss: 0.443492  [   30/   89]
per-ex loss: 0.400954  [   32/   89]
per-ex loss: 0.584884  [   34/   89]
per-ex loss: 0.358576  [   36/   89]
per-ex loss: 0.636808  [   38/   89]
per-ex loss: 0.415938  [   40/   89]
per-ex loss: 0.414957  [   42/   89]
per-ex loss: 0.440269  [   44/   89]
per-ex loss: 0.398573  [   46/   89]
per-ex loss: 0.408417  [   48/   89]
per-ex loss: 0.518838  [   50/   89]
per-ex loss: 0.496231  [   52/   89]
per-ex loss: 0.529281  [   54/   89]
per-ex loss: 0.415671  [   56/   89]
per-ex loss: 0.427808  [   58/   89]
per-ex loss: 0.622094  [   60/   89]
per-ex loss: 0.441712  [   62/   89]
per-ex loss: 0.512035  [   64/   89]
per-ex loss: 0.452961  [   66/   89]
per-ex loss: 0.383703  [   68/   89]
per-ex loss: 0.419970  [   70/   89]
per-ex loss: 0.436948  [   72/   89]
per-ex loss: 0.366793  [   74/   89]
per-ex loss: 0.380405  [   76/   89]
per-ex loss: 0.476059  [   78/   89]
per-ex loss: 0.377922  [   80/   89]
per-ex loss: 0.409303  [   82/   89]
per-ex loss: 0.326300  [   84/   89]
per-ex loss: 0.416503  [   86/   89]
per-ex loss: 0.330152  [   88/   89]
per-ex loss: 0.387986  [   89/   89]
Train Error: Avg loss: 0.45317263
validation Error: 
 Avg loss: 0.98275971 
 F1: 0.516125 
 Precision: 0.588141 
 Recall: 0.459821
 IoU: 0.347822

test Error: 
 Avg loss: 0.97983534 
 F1: 0.540196 
 Precision: 0.612942 
 Recall: 0.482885
 IoU: 0.370047

We have finished training iteration 143
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_141_.pth
per-ex loss: 0.414794  [    2/   89]
per-ex loss: 0.395061  [    4/   89]
per-ex loss: 0.399534  [    6/   89]
per-ex loss: 0.631230  [    8/   89]
per-ex loss: 0.449296  [   10/   89]
per-ex loss: 0.438621  [   12/   89]
per-ex loss: 0.333453  [   14/   89]
per-ex loss: 0.359560  [   16/   89]
per-ex loss: 0.441660  [   18/   89]
per-ex loss: 0.674746  [   20/   89]
per-ex loss: 0.474200  [   22/   89]
per-ex loss: 0.632540  [   24/   89]
per-ex loss: 0.414843  [   26/   89]
per-ex loss: 0.362701  [   28/   89]
per-ex loss: 0.517898  [   30/   89]
per-ex loss: 0.373929  [   32/   89]
per-ex loss: 0.402281  [   34/   89]
per-ex loss: 0.629259  [   36/   89]
per-ex loss: 0.493209  [   38/   89]
per-ex loss: 0.457798  [   40/   89]
per-ex loss: 0.414406  [   42/   89]
per-ex loss: 0.354205  [   44/   89]
per-ex loss: 0.591552  [   46/   89]
per-ex loss: 0.456494  [   48/   89]
per-ex loss: 0.577467  [   50/   89]
per-ex loss: 0.378988  [   52/   89]
per-ex loss: 0.403222  [   54/   89]
per-ex loss: 0.483095  [   56/   89]
per-ex loss: 0.547482  [   58/   89]
per-ex loss: 0.446852  [   60/   89]
per-ex loss: 0.477800  [   62/   89]
per-ex loss: 0.388977  [   64/   89]
per-ex loss: 0.505878  [   66/   89]
per-ex loss: 0.455373  [   68/   89]
per-ex loss: 0.412617  [   70/   89]
per-ex loss: 0.351518  [   72/   89]
per-ex loss: 0.636734  [   74/   89]
per-ex loss: 0.399090  [   76/   89]
per-ex loss: 0.537009  [   78/   89]
per-ex loss: 0.377610  [   80/   89]
per-ex loss: 0.428136  [   82/   89]
per-ex loss: 0.469823  [   84/   89]
per-ex loss: 0.407231  [   86/   89]
per-ex loss: 0.403294  [   88/   89]
per-ex loss: 0.542420  [   89/   89]
Train Error: Avg loss: 0.46097529
validation Error: 
 Avg loss: 0.98220657 
 F1: 0.517526 
 Precision: 0.570141 
 Recall: 0.473801
 IoU: 0.349096

test Error: 
 Avg loss: 0.98069956 
 F1: 0.539659 
 Precision: 0.589897 
 Recall: 0.497306
 IoU: 0.369543

We have finished training iteration 144
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_142_.pth
per-ex loss: 0.577273  [    2/   89]
per-ex loss: 0.582138  [    4/   89]
per-ex loss: 0.451735  [    6/   89]
per-ex loss: 0.524388  [    8/   89]
per-ex loss: 0.599395  [   10/   89]
per-ex loss: 0.654890  [   12/   89]
per-ex loss: 0.382292  [   14/   89]
per-ex loss: 0.626210  [   16/   89]
per-ex loss: 0.529158  [   18/   89]
per-ex loss: 0.507762  [   20/   89]
per-ex loss: 0.381695  [   22/   89]
per-ex loss: 0.544477  [   24/   89]
per-ex loss: 0.449580  [   26/   89]
per-ex loss: 0.464074  [   28/   89]
per-ex loss: 0.550246  [   30/   89]
per-ex loss: 0.389925  [   32/   89]
per-ex loss: 0.379622  [   34/   89]
per-ex loss: 0.515518  [   36/   89]
per-ex loss: 0.461682  [   38/   89]
per-ex loss: 0.575814  [   40/   89]
per-ex loss: 0.378840  [   42/   89]
per-ex loss: 0.327120  [   44/   89]
per-ex loss: 0.597893  [   46/   89]
per-ex loss: 0.502421  [   48/   89]
per-ex loss: 0.374954  [   50/   89]
per-ex loss: 0.660062  [   52/   89]
per-ex loss: 0.589896  [   54/   89]
per-ex loss: 0.488503  [   56/   89]
per-ex loss: 0.410084  [   58/   89]
per-ex loss: 0.448956  [   60/   89]
per-ex loss: 0.423747  [   62/   89]
per-ex loss: 0.472268  [   64/   89]
per-ex loss: 0.401308  [   66/   89]
per-ex loss: 0.374663  [   68/   89]
per-ex loss: 0.364047  [   70/   89]
per-ex loss: 0.418130  [   72/   89]
per-ex loss: 0.434955  [   74/   89]
per-ex loss: 0.434545  [   76/   89]
per-ex loss: 0.397699  [   78/   89]
per-ex loss: 0.373164  [   80/   89]
per-ex loss: 0.373879  [   82/   89]
per-ex loss: 0.368670  [   84/   89]
per-ex loss: 0.444787  [   86/   89]
per-ex loss: 0.581924  [   88/   89]
per-ex loss: 0.671336  [   89/   89]
Train Error: Avg loss: 0.47692724
validation Error: 
 Avg loss: 0.98224081 
 F1: 0.517023 
 Precision: 0.607736 
 Recall: 0.449873
 IoU: 0.348639

test Error: 
 Avg loss: 0.97971430 
 F1: 0.539214 
 Precision: 0.625932 
 Recall: 0.473600
 IoU: 0.369126

We have finished training iteration 145
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_143_.pth
Error in cropping the image to the non-zero values in the fourth channel. Returned the original image.
per-ex loss: 0.329406  [    2/   89]
per-ex loss: 0.408523  [    4/   89]
per-ex loss: 0.330600  [    6/   89]
per-ex loss: 0.380670  [    8/   89]
per-ex loss: 0.408138  [   10/   89]
per-ex loss: 0.584581  [   12/   89]
per-ex loss: 0.522004  [   14/   89]
per-ex loss: 0.573673  [   16/   89]
per-ex loss: 0.570989  [   18/   89]
per-ex loss: 0.565078  [   20/   89]
per-ex loss: 0.414144  [   22/   89]
per-ex loss: 0.397545  [   24/   89]
per-ex loss: 0.423991  [   26/   89]
per-ex loss: 0.449354  [   28/   89]
per-ex loss: 0.358262  [   30/   89]
per-ex loss: 0.523121  [   32/   89]
per-ex loss: 0.383281  [   34/   89]
per-ex loss: 0.351561  [   36/   89]
per-ex loss: 0.474166  [   38/   89]
per-ex loss: 0.409770  [   40/   89]
per-ex loss: 0.485807  [   42/   89]
per-ex loss: 0.374103  [   44/   89]
per-ex loss: 0.426776  [   46/   89]
per-ex loss: 0.531075  [   48/   89]
per-ex loss: 0.538208  [   50/   89]
per-ex loss: 0.533073  [   52/   89]
per-ex loss: 0.394850  [   54/   89]
per-ex loss: 0.444263  [   56/   89]
per-ex loss: 0.465605  [   58/   89]
per-ex loss: 0.406803  [   60/   89]
per-ex loss: 0.555552  [   62/   89]
per-ex loss: 0.533535  [   64/   89]
per-ex loss: 0.556944  [   66/   89]
per-ex loss: 0.514995  [   68/   89]
per-ex loss: 0.457976  [   70/   89]
per-ex loss: 0.451714  [   72/   89]
per-ex loss: 0.429873  [   74/   89]
per-ex loss: 0.365870  [   76/   89]
per-ex loss: 0.540755  [   78/   89]
per-ex loss: 0.372117  [   80/   89]
per-ex loss: 0.516992  [   82/   89]
per-ex loss: 0.424781  [   84/   89]
per-ex loss: 0.388594  [   86/   89]
per-ex loss: 0.401943  [   88/   89]
per-ex loss: 0.455598  [   89/   89]
Train Error: Avg loss: 0.45392572
validation Error: 
 Avg loss: 0.98239876 
 F1: 0.514054 
 Precision: 0.583143 
 Recall: 0.459601
 IoU: 0.345943

test Error: 
 Avg loss: 0.98119427 
 F1: 0.535393 
 Precision: 0.595664 
 Recall: 0.486198
 IoU: 0.365554

We have finished training iteration 146
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_144_.pth
per-ex loss: 0.613164  [    2/   89]
per-ex loss: 0.421528  [    4/   89]
per-ex loss: 0.381622  [    6/   89]
per-ex loss: 0.452685  [    8/   89]
per-ex loss: 0.417266  [   10/   89]
per-ex loss: 0.363333  [   12/   89]
per-ex loss: 0.396938  [   14/   89]
per-ex loss: 0.544075  [   16/   89]
per-ex loss: 0.500059  [   18/   89]
per-ex loss: 0.456786  [   20/   89]
per-ex loss: 0.542066  [   22/   89]
per-ex loss: 0.485657  [   24/   89]
per-ex loss: 0.582772  [   26/   89]
per-ex loss: 0.397945  [   28/   89]
per-ex loss: 0.586676  [   30/   89]
per-ex loss: 0.323895  [   32/   89]
per-ex loss: 0.360233  [   34/   89]
per-ex loss: 0.428267  [   36/   89]
per-ex loss: 0.415379  [   38/   89]
per-ex loss: 0.420182  [   40/   89]
per-ex loss: 0.520151  [   42/   89]
per-ex loss: 0.516211  [   44/   89]
per-ex loss: 0.496403  [   46/   89]
per-ex loss: 0.416301  [   48/   89]
per-ex loss: 0.560240  [   50/   89]
per-ex loss: 0.396533  [   52/   89]
per-ex loss: 0.382814  [   54/   89]
per-ex loss: 0.542830  [   56/   89]
per-ex loss: 0.355685  [   58/   89]
per-ex loss: 0.355696  [   60/   89]
per-ex loss: 0.428726  [   62/   89]
per-ex loss: 0.643974  [   64/   89]
per-ex loss: 0.497436  [   66/   89]
per-ex loss: 0.634678  [   68/   89]
per-ex loss: 0.451946  [   70/   89]
per-ex loss: 0.350287  [   72/   89]
per-ex loss: 0.360937  [   74/   89]
per-ex loss: 0.385018  [   76/   89]
per-ex loss: 0.431247  [   78/   89]
per-ex loss: 0.473155  [   80/   89]
per-ex loss: 0.485913  [   82/   89]
per-ex loss: 0.633171  [   84/   89]
per-ex loss: 0.418824  [   86/   89]
per-ex loss: 0.531758  [   88/   89]
per-ex loss: 0.535935  [   89/   89]
Train Error: Avg loss: 0.46436430
validation Error: 
 Avg loss: 0.98176619 
 F1: 0.514411 
 Precision: 0.615304 
 Recall: 0.441944
 IoU: 0.346267

test Error: 
 Avg loss: 0.97968027 
 F1: 0.533083 
 Precision: 0.632888 
 Recall: 0.460468
 IoU: 0.363404

We have finished training iteration 147
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_145_.pth
per-ex loss: 0.341045  [    2/   89]
per-ex loss: 0.510367  [    4/   89]
per-ex loss: 0.404518  [    6/   89]
per-ex loss: 0.546324  [    8/   89]
per-ex loss: 0.585722  [   10/   89]
per-ex loss: 0.449847  [   12/   89]
per-ex loss: 0.417265  [   14/   89]
per-ex loss: 0.513552  [   16/   89]
per-ex loss: 0.528369  [   18/   89]
per-ex loss: 0.410563  [   20/   89]
per-ex loss: 0.439198  [   22/   89]
per-ex loss: 0.383407  [   24/   89]
per-ex loss: 0.382044  [   26/   89]
per-ex loss: 0.437605  [   28/   89]
per-ex loss: 0.541481  [   30/   89]
per-ex loss: 0.519016  [   32/   89]
per-ex loss: 0.434868  [   34/   89]
per-ex loss: 0.482499  [   36/   89]
per-ex loss: 0.406627  [   38/   89]
per-ex loss: 0.526350  [   40/   89]
per-ex loss: 0.606823  [   42/   89]
per-ex loss: 0.457833  [   44/   89]
per-ex loss: 0.363708  [   46/   89]
per-ex loss: 0.424516  [   48/   89]
per-ex loss: 0.383860  [   50/   89]
per-ex loss: 0.426890  [   52/   89]
per-ex loss: 0.575725  [   54/   89]
per-ex loss: 0.416642  [   56/   89]
per-ex loss: 0.397018  [   58/   89]
per-ex loss: 0.332369  [   60/   89]
per-ex loss: 0.451378  [   62/   89]
per-ex loss: 0.354111  [   64/   89]
per-ex loss: 0.577108  [   66/   89]
per-ex loss: 0.382184  [   68/   89]
per-ex loss: 0.449170  [   70/   89]
per-ex loss: 0.451960  [   72/   89]
per-ex loss: 0.416049  [   74/   89]
per-ex loss: 0.498612  [   76/   89]
per-ex loss: 0.621868  [   78/   89]
per-ex loss: 0.526763  [   80/   89]
per-ex loss: 0.408727  [   82/   89]
per-ex loss: 0.405468  [   84/   89]
per-ex loss: 0.428363  [   86/   89]
per-ex loss: 0.491391  [   88/   89]
per-ex loss: 0.391197  [   89/   89]
Train Error: Avg loss: 0.45556445
validation Error: 
 Avg loss: 0.98383003 
 F1: 0.515282 
 Precision: 0.572398 
 Recall: 0.468530
 IoU: 0.347057

test Error: 
 Avg loss: 0.98124599 
 F1: 0.537874 
 Precision: 0.585214 
 Recall: 0.497619
 IoU: 0.367871

We have finished training iteration 148
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_146_.pth
per-ex loss: 0.435305  [    2/   89]
per-ex loss: 0.398390  [    4/   89]
per-ex loss: 0.427748  [    6/   89]
per-ex loss: 0.393915  [    8/   89]
per-ex loss: 0.401055  [   10/   89]
per-ex loss: 0.477230  [   12/   89]
per-ex loss: 0.412393  [   14/   89]
per-ex loss: 0.457754  [   16/   89]
per-ex loss: 0.516193  [   18/   89]
per-ex loss: 0.424031  [   20/   89]
per-ex loss: 0.410564  [   22/   89]
per-ex loss: 0.384372  [   24/   89]
per-ex loss: 0.394781  [   26/   89]
per-ex loss: 0.586374  [   28/   89]
per-ex loss: 0.414674  [   30/   89]
per-ex loss: 0.386686  [   32/   89]
per-ex loss: 0.360862  [   34/   89]
per-ex loss: 0.484992  [   36/   89]
per-ex loss: 0.411510  [   38/   89]
per-ex loss: 0.482978  [   40/   89]
per-ex loss: 0.425764  [   42/   89]
per-ex loss: 0.434861  [   44/   89]
per-ex loss: 0.402433  [   46/   89]
per-ex loss: 0.463737  [   48/   89]
per-ex loss: 0.511195  [   50/   89]
per-ex loss: 0.453358  [   52/   89]
per-ex loss: 0.381875  [   54/   89]
per-ex loss: 0.392846  [   56/   89]
per-ex loss: 0.540171  [   58/   89]
per-ex loss: 0.379260  [   60/   89]
per-ex loss: 0.554966  [   62/   89]
per-ex loss: 0.557008  [   64/   89]
per-ex loss: 0.594249  [   66/   89]
per-ex loss: 0.384084  [   68/   89]
per-ex loss: 0.401580  [   70/   89]
per-ex loss: 0.431998  [   72/   89]
per-ex loss: 0.554140  [   74/   89]
per-ex loss: 0.631952  [   76/   89]
per-ex loss: 0.451999  [   78/   89]
per-ex loss: 0.409865  [   80/   89]
per-ex loss: 0.514500  [   82/   89]
per-ex loss: 0.397754  [   84/   89]
per-ex loss: 0.473815  [   86/   89]
per-ex loss: 0.547336  [   88/   89]
per-ex loss: 0.630385  [   89/   89]
Train Error: Avg loss: 0.45739860
validation Error: 
 Avg loss: 0.98349921 
 F1: 0.517028 
 Precision: 0.566120 
 Recall: 0.475771
 IoU: 0.348643

test Error: 
 Avg loss: 0.98162633 
 F1: 0.536823 
 Precision: 0.571967 
 Recall: 0.505749
 IoU: 0.366889

We have finished training iteration 149
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_147_.pth
per-ex loss: 0.382658  [    2/   89]
per-ex loss: 0.400428  [    4/   89]
per-ex loss: 0.478079  [    6/   89]
per-ex loss: 0.364265  [    8/   89]
per-ex loss: 0.520603  [   10/   89]
per-ex loss: 0.450202  [   12/   89]
per-ex loss: 0.420458  [   14/   89]
per-ex loss: 0.412201  [   16/   89]
per-ex loss: 0.592068  [   18/   89]
per-ex loss: 0.451057  [   20/   89]
per-ex loss: 0.343335  [   22/   89]
per-ex loss: 0.427551  [   24/   89]
per-ex loss: 0.477925  [   26/   89]
per-ex loss: 0.549361  [   28/   89]
per-ex loss: 0.521182  [   30/   89]
per-ex loss: 0.362077  [   32/   89]
per-ex loss: 0.359896  [   34/   89]
per-ex loss: 0.428515  [   36/   89]
per-ex loss: 0.413328  [   38/   89]
per-ex loss: 0.554094  [   40/   89]
per-ex loss: 0.354285  [   42/   89]
per-ex loss: 0.366989  [   44/   89]
per-ex loss: 0.590151  [   46/   89]
per-ex loss: 0.393531  [   48/   89]
per-ex loss: 0.384630  [   50/   89]
per-ex loss: 0.478182  [   52/   89]
per-ex loss: 0.360871  [   54/   89]
per-ex loss: 0.444115  [   56/   89]
per-ex loss: 0.505490  [   58/   89]
per-ex loss: 0.580476  [   60/   89]
per-ex loss: 0.515620  [   62/   89]
per-ex loss: 0.503890  [   64/   89]
per-ex loss: 0.564642  [   66/   89]
per-ex loss: 0.473672  [   68/   89]
per-ex loss: 0.408236  [   70/   89]
per-ex loss: 0.584444  [   72/   89]
per-ex loss: 0.525543  [   74/   89]
per-ex loss: 0.372557  [   76/   89]
per-ex loss: 0.441793  [   78/   89]
per-ex loss: 0.401761  [   80/   89]
per-ex loss: 0.430140  [   82/   89]
per-ex loss: 0.456931  [   84/   89]
per-ex loss: 0.673836  [   86/   89]
per-ex loss: 0.427152  [   88/   89]
per-ex loss: 0.441784  [   89/   89]
Train Error: Avg loss: 0.45755568
validation Error: 
 Avg loss: 0.98233778 
 F1: 0.514818 
 Precision: 0.589814 
 Recall: 0.456742
 IoU: 0.346636

test Error: 
 Avg loss: 0.97973719 
 F1: 0.535839 
 Precision: 0.602222 
 Recall: 0.482638
 IoU: 0.365970

We have finished training iteration 150
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_148_.pth
per-ex loss: 0.402451  [    2/   89]
per-ex loss: 0.481433  [    4/   89]
per-ex loss: 0.541524  [    6/   89]
per-ex loss: 0.380622  [    8/   89]
per-ex loss: 0.479289  [   10/   89]
per-ex loss: 0.519307  [   12/   89]
per-ex loss: 0.584732  [   14/   89]
per-ex loss: 0.367689  [   16/   89]
per-ex loss: 0.432853  [   18/   89]
per-ex loss: 0.353964  [   20/   89]
per-ex loss: 0.448010  [   22/   89]
per-ex loss: 0.480005  [   24/   89]
per-ex loss: 0.635410  [   26/   89]
per-ex loss: 0.379541  [   28/   89]
per-ex loss: 0.420555  [   30/   89]
per-ex loss: 0.402489  [   32/   89]
per-ex loss: 0.393090  [   34/   89]
per-ex loss: 0.383842  [   36/   89]
per-ex loss: 0.367636  [   38/   89]
per-ex loss: 0.367475  [   40/   89]
per-ex loss: 0.443188  [   42/   89]
per-ex loss: 0.418970  [   44/   89]
per-ex loss: 0.375728  [   46/   89]
per-ex loss: 0.346608  [   48/   89]
per-ex loss: 0.472000  [   50/   89]
per-ex loss: 0.459056  [   52/   89]
per-ex loss: 0.419115  [   54/   89]
per-ex loss: 0.657641  [   56/   89]
per-ex loss: 0.460844  [   58/   89]
per-ex loss: 0.441669  [   60/   89]
per-ex loss: 0.476177  [   62/   89]
per-ex loss: 0.536608  [   64/   89]
per-ex loss: 0.399001  [   66/   89]
per-ex loss: 0.553523  [   68/   89]
per-ex loss: 0.582232  [   70/   89]
per-ex loss: 0.555543  [   72/   89]
per-ex loss: 0.406908  [   74/   89]
per-ex loss: 0.436166  [   76/   89]
per-ex loss: 0.384828  [   78/   89]
per-ex loss: 0.437900  [   80/   89]
per-ex loss: 0.650638  [   82/   89]
per-ex loss: 0.458988  [   84/   89]
per-ex loss: 0.511333  [   86/   89]
per-ex loss: 0.390669  [   88/   89]
per-ex loss: 0.598989  [   89/   89]
Train Error: Avg loss: 0.45991630
validation Error: 
 Avg loss: 0.98435641 
 F1: 0.517009 
 Precision: 0.545258 
 Recall: 0.491543
 IoU: 0.348626

test Error: 
 Avg loss: 0.98225910 
 F1: 0.543730 
 Precision: 0.563044 
 Recall: 0.525697
 IoU: 0.373371

We have finished training iteration 151
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_149_.pth
per-ex loss: 0.560861  [    2/   89]
per-ex loss: 0.575557  [    4/   89]
per-ex loss: 0.446389  [    6/   89]
per-ex loss: 0.434258  [    8/   89]
per-ex loss: 0.561208  [   10/   89]
per-ex loss: 0.464299  [   12/   89]
per-ex loss: 0.386770  [   14/   89]
per-ex loss: 0.339902  [   16/   89]
per-ex loss: 0.515930  [   18/   89]
per-ex loss: 0.426632  [   20/   89]
per-ex loss: 0.440225  [   22/   89]
per-ex loss: 0.413235  [   24/   89]
per-ex loss: 0.510596  [   26/   89]
per-ex loss: 0.378216  [   28/   89]
per-ex loss: 0.682716  [   30/   89]
per-ex loss: 0.441714  [   32/   89]
per-ex loss: 0.357163  [   34/   89]
per-ex loss: 0.518005  [   36/   89]
per-ex loss: 0.446199  [   38/   89]
per-ex loss: 0.656053  [   40/   89]
per-ex loss: 0.421624  [   42/   89]
per-ex loss: 0.408513  [   44/   89]
per-ex loss: 0.384102  [   46/   89]
per-ex loss: 0.479331  [   48/   89]
per-ex loss: 0.485695  [   50/   89]
per-ex loss: 0.368561  [   52/   89]
per-ex loss: 0.583175  [   54/   89]
per-ex loss: 0.417129  [   56/   89]
per-ex loss: 0.561883  [   58/   89]
per-ex loss: 0.369763  [   60/   89]
per-ex loss: 0.348455  [   62/   89]
per-ex loss: 0.446613  [   64/   89]
per-ex loss: 0.511238  [   66/   89]
per-ex loss: 0.434944  [   68/   89]
per-ex loss: 0.505366  [   70/   89]
per-ex loss: 0.550682  [   72/   89]
per-ex loss: 0.415150  [   74/   89]
per-ex loss: 0.569683  [   76/   89]
per-ex loss: 0.359359  [   78/   89]
per-ex loss: 0.494805  [   80/   89]
per-ex loss: 0.592131  [   82/   89]
per-ex loss: 0.388253  [   84/   89]
per-ex loss: 0.553574  [   86/   89]
per-ex loss: 0.386520  [   88/   89]
per-ex loss: 0.480786  [   89/   89]
Train Error: Avg loss: 0.46829470
validation Error: 
 Avg loss: 0.98298245 
 F1: 0.514621 
 Precision: 0.595308 
 Recall: 0.453196
 IoU: 0.346458

test Error: 
 Avg loss: 0.98098339 
 F1: 0.539978 
 Precision: 0.617520 
 Recall: 0.479738
 IoU: 0.369842

We have finished training iteration 152
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_150_.pth
per-ex loss: 0.525723  [    2/   89]
per-ex loss: 0.395737  [    4/   89]
per-ex loss: 0.403651  [    6/   89]
per-ex loss: 0.387378  [    8/   89]
per-ex loss: 0.429683  [   10/   89]
per-ex loss: 0.463663  [   12/   89]
per-ex loss: 0.416313  [   14/   89]
per-ex loss: 0.564784  [   16/   89]
per-ex loss: 0.379002  [   18/   89]
per-ex loss: 0.362659  [   20/   89]
per-ex loss: 0.444340  [   22/   89]
per-ex loss: 0.598675  [   24/   89]
per-ex loss: 0.569607  [   26/   89]
per-ex loss: 0.362466  [   28/   89]
per-ex loss: 0.494431  [   30/   89]
per-ex loss: 0.416283  [   32/   89]
per-ex loss: 0.403316  [   34/   89]
per-ex loss: 0.365873  [   36/   89]
per-ex loss: 0.541811  [   38/   89]
per-ex loss: 0.426725  [   40/   89]
per-ex loss: 0.357535  [   42/   89]
per-ex loss: 0.574087  [   44/   89]
per-ex loss: 0.332315  [   46/   89]
per-ex loss: 0.350630  [   48/   89]
per-ex loss: 0.426181  [   50/   89]
per-ex loss: 0.571587  [   52/   89]
per-ex loss: 0.377079  [   54/   89]
per-ex loss: 0.621642  [   56/   89]
per-ex loss: 0.506820  [   58/   89]
per-ex loss: 0.392913  [   60/   89]
per-ex loss: 0.531514  [   62/   89]
per-ex loss: 0.566000  [   64/   89]
per-ex loss: 0.444719  [   66/   89]
per-ex loss: 0.400622  [   68/   89]
per-ex loss: 0.421164  [   70/   89]
per-ex loss: 0.566407  [   72/   89]
per-ex loss: 0.528537  [   74/   89]
per-ex loss: 0.412240  [   76/   89]
per-ex loss: 0.455105  [   78/   89]
per-ex loss: 0.447828  [   80/   89]
per-ex loss: 0.486772  [   82/   89]
per-ex loss: 0.517363  [   84/   89]
per-ex loss: 0.391983  [   86/   89]
per-ex loss: 0.460670  [   88/   89]
per-ex loss: 0.404369  [   89/   89]
Train Error: Avg loss: 0.45551559
validation Error: 
 Avg loss: 0.98171137 
 F1: 0.516389 
 Precision: 0.588331 
 Recall: 0.460124
 IoU: 0.348062

test Error: 
 Avg loss: 0.98014749 
 F1: 0.529817 
 Precision: 0.587212 
 Recall: 0.482643
 IoU: 0.360375

We have finished training iteration 153
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_151_.pth
per-ex loss: 0.367744  [    2/   89]
per-ex loss: 0.586437  [    4/   89]
per-ex loss: 0.537046  [    6/   89]
per-ex loss: 0.442713  [    8/   89]
per-ex loss: 0.508459  [   10/   89]
per-ex loss: 0.544143  [   12/   89]
per-ex loss: 0.420697  [   14/   89]
per-ex loss: 0.529126  [   16/   89]
per-ex loss: 0.491137  [   18/   89]
per-ex loss: 0.421626  [   20/   89]
per-ex loss: 0.446287  [   22/   89]
per-ex loss: 0.371803  [   24/   89]
per-ex loss: 0.457231  [   26/   89]
per-ex loss: 0.538433  [   28/   89]
per-ex loss: 0.478020  [   30/   89]
per-ex loss: 0.387936  [   32/   89]
per-ex loss: 0.342375  [   34/   89]
per-ex loss: 0.375012  [   36/   89]
per-ex loss: 0.377784  [   38/   89]
per-ex loss: 0.416451  [   40/   89]
per-ex loss: 0.598487  [   42/   89]
per-ex loss: 0.438622  [   44/   89]
per-ex loss: 0.530787  [   46/   89]
per-ex loss: 0.538189  [   48/   89]
per-ex loss: 0.342698  [   50/   89]
per-ex loss: 0.739503  [   52/   89]
per-ex loss: 0.451846  [   54/   89]
per-ex loss: 0.470959  [   56/   89]
per-ex loss: 0.458577  [   58/   89]
per-ex loss: 0.399859  [   60/   89]
per-ex loss: 0.411427  [   62/   89]
per-ex loss: 0.379288  [   64/   89]
per-ex loss: 0.545615  [   66/   89]
per-ex loss: 0.395884  [   68/   89]
per-ex loss: 0.514884  [   70/   89]
per-ex loss: 0.459009  [   72/   89]
per-ex loss: 0.580523  [   74/   89]
per-ex loss: 0.436687  [   76/   89]
per-ex loss: 0.386799  [   78/   89]
per-ex loss: 0.504316  [   80/   89]
per-ex loss: 0.472799  [   82/   89]
per-ex loss: 0.477753  [   84/   89]
per-ex loss: 0.379493  [   86/   89]
per-ex loss: 0.428389  [   88/   89]
per-ex loss: 0.418599  [   89/   89]
Train Error: Avg loss: 0.46225455
validation Error: 
 Avg loss: 0.98358215 
 F1: 0.516448 
 Precision: 0.591304 
 Recall: 0.458415
 IoU: 0.348116

test Error: 
 Avg loss: 0.98104021 
 F1: 0.538488 
 Precision: 0.602117 
 Recall: 0.487022
 IoU: 0.368446

We have finished training iteration 154
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_152_.pth
per-ex loss: 0.544996  [    2/   89]
per-ex loss: 0.497575  [    4/   89]
per-ex loss: 0.605966  [    6/   89]
per-ex loss: 0.445988  [    8/   89]
per-ex loss: 0.653976  [   10/   89]
per-ex loss: 0.368400  [   12/   89]
per-ex loss: 0.376552  [   14/   89]
per-ex loss: 0.577290  [   16/   89]
per-ex loss: 0.449487  [   18/   89]
per-ex loss: 0.430385  [   20/   89]
per-ex loss: 0.465551  [   22/   89]
per-ex loss: 0.411171  [   24/   89]
per-ex loss: 0.622516  [   26/   89]
per-ex loss: 0.439665  [   28/   89]
per-ex loss: 0.471791  [   30/   89]
per-ex loss: 0.419835  [   32/   89]
per-ex loss: 0.505014  [   34/   89]
per-ex loss: 0.472995  [   36/   89]
per-ex loss: 0.369689  [   38/   89]
per-ex loss: 0.399064  [   40/   89]
per-ex loss: 0.476283  [   42/   89]
per-ex loss: 0.421135  [   44/   89]
per-ex loss: 0.500918  [   46/   89]
per-ex loss: 0.483192  [   48/   89]
per-ex loss: 0.479427  [   50/   89]
per-ex loss: 0.466929  [   52/   89]
per-ex loss: 0.461024  [   54/   89]
per-ex loss: 0.620130  [   56/   89]
per-ex loss: 0.374628  [   58/   89]
per-ex loss: 0.616311  [   60/   89]
per-ex loss: 0.406671  [   62/   89]
per-ex loss: 0.418747  [   64/   89]
per-ex loss: 0.441667  [   66/   89]
per-ex loss: 0.501235  [   68/   89]
per-ex loss: 0.311237  [   70/   89]
per-ex loss: 0.441906  [   72/   89]
per-ex loss: 0.408695  [   74/   89]
per-ex loss: 0.487544  [   76/   89]
per-ex loss: 0.424716  [   78/   89]
per-ex loss: 0.407534  [   80/   89]
per-ex loss: 0.362249  [   82/   89]
per-ex loss: 0.473833  [   84/   89]
per-ex loss: 0.359132  [   86/   89]
per-ex loss: 0.396372  [   88/   89]
per-ex loss: 0.330809  [   89/   89]
Train Error: Avg loss: 0.45778290
validation Error: 
 Avg loss: 0.98309525 
 F1: 0.519585 
 Precision: 0.587044 
 Recall: 0.466032
 IoU: 0.350972

test Error: 
 Avg loss: 0.98071650 
 F1: 0.544096 
 Precision: 0.599997 
 Recall: 0.497724
 IoU: 0.373717

We have finished training iteration 155
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_153_.pth
per-ex loss: 0.524500  [    2/   89]
per-ex loss: 0.395486  [    4/   89]
per-ex loss: 0.442194  [    6/   89]
per-ex loss: 0.488257  [    8/   89]
per-ex loss: 0.389559  [   10/   89]
per-ex loss: 0.546593  [   12/   89]
per-ex loss: 0.561875  [   14/   89]
per-ex loss: 0.360301  [   16/   89]
per-ex loss: 0.392231  [   18/   89]
per-ex loss: 0.489081  [   20/   89]
per-ex loss: 0.379251  [   22/   89]
per-ex loss: 0.405620  [   24/   89]
per-ex loss: 0.427127  [   26/   89]
per-ex loss: 0.385402  [   28/   89]
per-ex loss: 0.510571  [   30/   89]
per-ex loss: 0.522653  [   32/   89]
per-ex loss: 0.614223  [   34/   89]
per-ex loss: 0.490874  [   36/   89]
per-ex loss: 0.406022  [   38/   89]
per-ex loss: 0.523018  [   40/   89]
per-ex loss: 0.480213  [   42/   89]
per-ex loss: 0.389142  [   44/   89]
per-ex loss: 0.368236  [   46/   89]
per-ex loss: 0.466628  [   48/   89]
per-ex loss: 0.432809  [   50/   89]
per-ex loss: 0.485094  [   52/   89]
per-ex loss: 0.394849  [   54/   89]
per-ex loss: 0.552033  [   56/   89]
per-ex loss: 0.490813  [   58/   89]
per-ex loss: 0.451958  [   60/   89]
per-ex loss: 0.433175  [   62/   89]
per-ex loss: 0.338697  [   64/   89]
per-ex loss: 0.362589  [   66/   89]
per-ex loss: 0.518399  [   68/   89]
per-ex loss: 0.435528  [   70/   89]
per-ex loss: 0.547676  [   72/   89]
per-ex loss: 0.454043  [   74/   89]
per-ex loss: 0.602978  [   76/   89]
per-ex loss: 0.313408  [   78/   89]
per-ex loss: 0.487425  [   80/   89]
per-ex loss: 0.404808  [   82/   89]
per-ex loss: 0.432769  [   84/   89]
per-ex loss: 0.562679  [   86/   89]
per-ex loss: 0.419536  [   88/   89]
per-ex loss: 0.346128  [   89/   89]
Train Error: Avg loss: 0.45392118
validation Error: 
 Avg loss: 0.98402283 
 F1: 0.514048 
 Precision: 0.519912 
 Recall: 0.508316
 IoU: 0.345939

test Error: 
 Avg loss: 0.98298696 
 F1: 0.531743 
 Precision: 0.523104 
 Recall: 0.540673
 IoU: 0.362160

We have finished training iteration 156
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_154_.pth
per-ex loss: 0.360401  [    2/   89]
per-ex loss: 0.597065  [    4/   89]
per-ex loss: 0.378194  [    6/   89]
per-ex loss: 0.400102  [    8/   89]
per-ex loss: 0.406001  [   10/   89]
per-ex loss: 0.373045  [   12/   89]
per-ex loss: 0.409693  [   14/   89]
per-ex loss: 0.476904  [   16/   89]
per-ex loss: 0.485632  [   18/   89]
per-ex loss: 0.482428  [   20/   89]
per-ex loss: 0.412336  [   22/   89]
per-ex loss: 0.409449  [   24/   89]
per-ex loss: 0.412098  [   26/   89]
per-ex loss: 0.537235  [   28/   89]
per-ex loss: 0.390649  [   30/   89]
per-ex loss: 0.432257  [   32/   89]
per-ex loss: 0.556441  [   34/   89]
per-ex loss: 0.471011  [   36/   89]
per-ex loss: 0.525624  [   38/   89]
per-ex loss: 0.439856  [   40/   89]
per-ex loss: 0.585868  [   42/   89]
per-ex loss: 0.574152  [   44/   89]
per-ex loss: 0.397415  [   46/   89]
per-ex loss: 0.516951  [   48/   89]
per-ex loss: 0.454570  [   50/   89]
per-ex loss: 0.531334  [   52/   89]
per-ex loss: 0.553323  [   54/   89]
per-ex loss: 0.359360  [   56/   89]
per-ex loss: 0.448394  [   58/   89]
per-ex loss: 0.537647  [   60/   89]
per-ex loss: 0.450351  [   62/   89]
per-ex loss: 0.323464  [   64/   89]
per-ex loss: 0.378969  [   66/   89]
per-ex loss: 0.454109  [   68/   89]
per-ex loss: 0.530953  [   70/   89]
per-ex loss: 0.465420  [   72/   89]
per-ex loss: 0.478372  [   74/   89]
per-ex loss: 0.389628  [   76/   89]
per-ex loss: 0.493217  [   78/   89]
per-ex loss: 0.335477  [   80/   89]
per-ex loss: 0.449116  [   82/   89]
per-ex loss: 0.453990  [   84/   89]
per-ex loss: 0.441883  [   86/   89]
per-ex loss: 0.412087  [   88/   89]
per-ex loss: 0.657712  [   89/   89]
Train Error: Avg loss: 0.45844857
validation Error: 
 Avg loss: 0.98340667 
 F1: 0.520654 
 Precision: 0.590595 
 Recall: 0.465524
 IoU: 0.351949

test Error: 
 Avg loss: 0.98072419 
 F1: 0.543189 
 Precision: 0.606310 
 Recall: 0.491972
 IoU: 0.372862

We have finished training iteration 157
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_155_.pth
per-ex loss: 0.403812  [    2/   89]
per-ex loss: 0.454129  [    4/   89]
per-ex loss: 0.399141  [    6/   89]
per-ex loss: 0.428133  [    8/   89]
per-ex loss: 0.351957  [   10/   89]
per-ex loss: 0.361092  [   12/   89]
per-ex loss: 0.388020  [   14/   89]
per-ex loss: 0.541315  [   16/   89]
per-ex loss: 0.404756  [   18/   89]
per-ex loss: 0.479214  [   20/   89]
per-ex loss: 0.431681  [   22/   89]
per-ex loss: 0.419955  [   24/   89]
per-ex loss: 0.456996  [   26/   89]
per-ex loss: 0.422091  [   28/   89]
per-ex loss: 0.498620  [   30/   89]
per-ex loss: 0.706566  [   32/   89]
per-ex loss: 0.436070  [   34/   89]
per-ex loss: 0.412415  [   36/   89]
per-ex loss: 0.352302  [   38/   89]
per-ex loss: 0.406878  [   40/   89]
per-ex loss: 0.373453  [   42/   89]
per-ex loss: 0.478717  [   44/   89]
per-ex loss: 0.401078  [   46/   89]
per-ex loss: 0.455684  [   48/   89]
per-ex loss: 0.624563  [   50/   89]
per-ex loss: 0.552684  [   52/   89]
per-ex loss: 0.447767  [   54/   89]
per-ex loss: 0.341521  [   56/   89]
per-ex loss: 0.424343  [   58/   89]
per-ex loss: 0.555071  [   60/   89]
per-ex loss: 0.552091  [   62/   89]
per-ex loss: 0.560429  [   64/   89]
per-ex loss: 0.445801  [   66/   89]
per-ex loss: 0.358296  [   68/   89]
per-ex loss: 0.606272  [   70/   89]
per-ex loss: 0.357474  [   72/   89]
per-ex loss: 0.398654  [   74/   89]
per-ex loss: 0.481404  [   76/   89]
per-ex loss: 0.394817  [   78/   89]
per-ex loss: 0.712224  [   80/   89]
per-ex loss: 0.391394  [   82/   89]
per-ex loss: 0.544822  [   84/   89]
per-ex loss: 0.585815  [   86/   89]
per-ex loss: 0.395149  [   88/   89]
per-ex loss: 0.548148  [   89/   89]
Train Error: Avg loss: 0.46095143
validation Error: 
 Avg loss: 0.98301283 
 F1: 0.516216 
 Precision: 0.592960 
 Recall: 0.457061
 IoU: 0.347905

test Error: 
 Avg loss: 0.98060632 
 F1: 0.543417 
 Precision: 0.607910 
 Recall: 0.491295
 IoU: 0.373076

We have finished training iteration 158
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_156_.pth
per-ex loss: 0.319435  [    2/   89]
per-ex loss: 0.430609  [    4/   89]
per-ex loss: 0.361423  [    6/   89]
per-ex loss: 0.468414  [    8/   89]
per-ex loss: 0.400694  [   10/   89]
per-ex loss: 0.408349  [   12/   89]
per-ex loss: 0.391129  [   14/   89]
per-ex loss: 0.399437  [   16/   89]
per-ex loss: 0.555784  [   18/   89]
per-ex loss: 0.570389  [   20/   89]
per-ex loss: 0.587493  [   22/   89]
per-ex loss: 0.582911  [   24/   89]
per-ex loss: 0.417762  [   26/   89]
per-ex loss: 0.436573  [   28/   89]
per-ex loss: 0.428858  [   30/   89]
per-ex loss: 0.439750  [   32/   89]
per-ex loss: 0.402218  [   34/   89]
per-ex loss: 0.603548  [   36/   89]
per-ex loss: 0.425291  [   38/   89]
per-ex loss: 0.355541  [   40/   89]
per-ex loss: 0.426382  [   42/   89]
per-ex loss: 0.458130  [   44/   89]
per-ex loss: 0.396569  [   46/   89]
per-ex loss: 0.541396  [   48/   89]
per-ex loss: 0.430691  [   50/   89]
per-ex loss: 0.389267  [   52/   89]
per-ex loss: 0.564837  [   54/   89]
per-ex loss: 0.372944  [   56/   89]
per-ex loss: 0.447591  [   58/   89]
per-ex loss: 0.508376  [   60/   89]
per-ex loss: 0.438851  [   62/   89]
per-ex loss: 0.342652  [   64/   89]
per-ex loss: 0.349022  [   66/   89]
per-ex loss: 0.600345  [   68/   89]
per-ex loss: 0.539985  [   70/   89]
per-ex loss: 0.559737  [   72/   89]
per-ex loss: 0.549538  [   74/   89]
per-ex loss: 0.459100  [   76/   89]
per-ex loss: 0.538390  [   78/   89]
per-ex loss: 0.468558  [   80/   89]
per-ex loss: 0.439079  [   82/   89]
per-ex loss: 0.390092  [   84/   89]
per-ex loss: 0.560219  [   86/   89]
per-ex loss: 0.468603  [   88/   89]
per-ex loss: 0.364142  [   89/   89]
Train Error: Avg loss: 0.45755785
validation Error: 
 Avg loss: 0.98428336 
 F1: 0.516988 
 Precision: 0.528861 
 Recall: 0.505636
 IoU: 0.348607

test Error: 
 Avg loss: 0.98258824 
 F1: 0.530590 
 Precision: 0.530100 
 Recall: 0.531082
 IoU: 0.361091

We have finished training iteration 159
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_157_.pth
per-ex loss: 0.440549  [    2/   89]
per-ex loss: 0.393561  [    4/   89]
per-ex loss: 0.463085  [    6/   89]
per-ex loss: 0.465100  [    8/   89]
per-ex loss: 0.535021  [   10/   89]
per-ex loss: 0.465070  [   12/   89]
per-ex loss: 0.485166  [   14/   89]
per-ex loss: 0.401224  [   16/   89]
per-ex loss: 0.482837  [   18/   89]
per-ex loss: 0.411936  [   20/   89]
per-ex loss: 0.383534  [   22/   89]
per-ex loss: 0.504330  [   24/   89]
per-ex loss: 0.467914  [   26/   89]
per-ex loss: 0.361531  [   28/   89]
per-ex loss: 0.443256  [   30/   89]
per-ex loss: 0.382924  [   32/   89]
per-ex loss: 0.394601  [   34/   89]
per-ex loss: 0.433143  [   36/   89]
per-ex loss: 0.510903  [   38/   89]
per-ex loss: 0.406364  [   40/   89]
per-ex loss: 0.538696  [   42/   89]
per-ex loss: 0.418623  [   44/   89]
per-ex loss: 0.400135  [   46/   89]
per-ex loss: 0.600634  [   48/   89]
per-ex loss: 0.419401  [   50/   89]
per-ex loss: 0.400518  [   52/   89]
per-ex loss: 0.481272  [   54/   89]
per-ex loss: 0.409120  [   56/   89]
per-ex loss: 0.438109  [   58/   89]
per-ex loss: 0.537202  [   60/   89]
per-ex loss: 0.479102  [   62/   89]
per-ex loss: 0.413956  [   64/   89]
per-ex loss: 0.354865  [   66/   89]
per-ex loss: 0.623237  [   68/   89]
per-ex loss: 0.501079  [   70/   89]
per-ex loss: 0.351142  [   72/   89]
per-ex loss: 0.375933  [   74/   89]
per-ex loss: 0.421713  [   76/   89]
per-ex loss: 0.572212  [   78/   89]
per-ex loss: 0.459916  [   80/   89]
per-ex loss: 0.421642  [   82/   89]
per-ex loss: 0.379555  [   84/   89]
per-ex loss: 0.462730  [   86/   89]
per-ex loss: 0.370767  [   88/   89]
per-ex loss: 0.339383  [   89/   89]
Train Error: Avg loss: 0.44451089
validation Error: 
 Avg loss: 0.98363741 
 F1: 0.514925 
 Precision: 0.566628 
 Recall: 0.471869
 IoU: 0.346734

test Error: 
 Avg loss: 0.98153204 
 F1: 0.533299 
 Precision: 0.568098 
 Recall: 0.502518
 IoU: 0.363605

We have finished training iteration 160
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_158_.pth
per-ex loss: 0.392782  [    2/   89]
per-ex loss: 0.398314  [    4/   89]
per-ex loss: 0.384507  [    6/   89]
per-ex loss: 0.402689  [    8/   89]
per-ex loss: 0.439184  [   10/   89]
per-ex loss: 0.471062  [   12/   89]
per-ex loss: 0.407286  [   14/   89]
per-ex loss: 0.461012  [   16/   89]
per-ex loss: 0.570325  [   18/   89]
per-ex loss: 0.523809  [   20/   89]
per-ex loss: 0.444387  [   22/   89]
per-ex loss: 0.417052  [   24/   89]
per-ex loss: 0.534642  [   26/   89]
per-ex loss: 0.375890  [   28/   89]
per-ex loss: 0.527375  [   30/   89]
per-ex loss: 0.446323  [   32/   89]
per-ex loss: 0.571910  [   34/   89]
per-ex loss: 0.605716  [   36/   89]
per-ex loss: 0.641119  [   38/   89]
per-ex loss: 0.460630  [   40/   89]
per-ex loss: 0.522972  [   42/   89]
per-ex loss: 0.433097  [   44/   89]
per-ex loss: 0.510171  [   46/   89]
per-ex loss: 0.450380  [   48/   89]
per-ex loss: 0.462432  [   50/   89]
per-ex loss: 0.423682  [   52/   89]
per-ex loss: 0.363169  [   54/   89]
per-ex loss: 0.462013  [   56/   89]
per-ex loss: 0.402956  [   58/   89]
per-ex loss: 0.437894  [   60/   89]
per-ex loss: 0.519738  [   62/   89]
per-ex loss: 0.342949  [   64/   89]
per-ex loss: 0.442290  [   66/   89]
per-ex loss: 0.464047  [   68/   89]
per-ex loss: 0.416940  [   70/   89]
per-ex loss: 0.359997  [   72/   89]
per-ex loss: 0.505936  [   74/   89]
per-ex loss: 0.426562  [   76/   89]
per-ex loss: 0.427608  [   78/   89]
per-ex loss: 0.326049  [   80/   89]
per-ex loss: 0.549328  [   82/   89]
per-ex loss: 0.506091  [   84/   89]
per-ex loss: 0.502924  [   86/   89]
per-ex loss: 0.492794  [   88/   89]
per-ex loss: 0.534653  [   89/   89]
Train Error: Avg loss: 0.46139305
validation Error: 
 Avg loss: 0.98348546 
 F1: 0.518625 
 Precision: 0.568904 
 Recall: 0.476512
 IoU: 0.350097

test Error: 
 Avg loss: 0.98078959 
 F1: 0.542826 
 Precision: 0.593849 
 Recall: 0.499877
 IoU: 0.372520

We have finished training iteration 161
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_159_.pth
per-ex loss: 0.360888  [    2/   89]
per-ex loss: 0.476489  [    4/   89]
per-ex loss: 0.401579  [    6/   89]
per-ex loss: 0.418902  [    8/   89]
per-ex loss: 0.454714  [   10/   89]
per-ex loss: 0.603326  [   12/   89]
per-ex loss: 0.465198  [   14/   89]
per-ex loss: 0.376424  [   16/   89]
per-ex loss: 0.601763  [   18/   89]
per-ex loss: 0.392977  [   20/   89]
per-ex loss: 0.528839  [   22/   89]
per-ex loss: 0.366859  [   24/   89]
per-ex loss: 0.391564  [   26/   89]
per-ex loss: 0.431682  [   28/   89]
per-ex loss: 0.426464  [   30/   89]
per-ex loss: 0.528433  [   32/   89]
per-ex loss: 0.557001  [   34/   89]
per-ex loss: 0.437589  [   36/   89]
per-ex loss: 0.414133  [   38/   89]
per-ex loss: 0.563886  [   40/   89]
per-ex loss: 0.554067  [   42/   89]
per-ex loss: 0.430038  [   44/   89]
per-ex loss: 0.567266  [   46/   89]
per-ex loss: 0.382105  [   48/   89]
per-ex loss: 0.414704  [   50/   89]
per-ex loss: 0.376215  [   52/   89]
per-ex loss: 0.373568  [   54/   89]
per-ex loss: 0.429626  [   56/   89]
per-ex loss: 0.390196  [   58/   89]
per-ex loss: 0.611845  [   60/   89]
per-ex loss: 0.569602  [   62/   89]
per-ex loss: 0.567995  [   64/   89]
per-ex loss: 0.501564  [   66/   89]
per-ex loss: 0.629059  [   68/   89]
per-ex loss: 0.497645  [   70/   89]
per-ex loss: 0.534546  [   72/   89]
per-ex loss: 0.363874  [   74/   89]
per-ex loss: 0.368082  [   76/   89]
per-ex loss: 0.426661  [   78/   89]
per-ex loss: 0.354139  [   80/   89]
per-ex loss: 0.391052  [   82/   89]
per-ex loss: 0.539410  [   84/   89]
per-ex loss: 0.453524  [   86/   89]
per-ex loss: 0.581264  [   88/   89]
per-ex loss: 0.394942  [   89/   89]
Train Error: Avg loss: 0.46448223
validation Error: 
 Avg loss: 0.98437558 
 F1: 0.516210 
 Precision: 0.553573 
 Recall: 0.483571
 IoU: 0.347899

test Error: 
 Avg loss: 0.98220163 
 F1: 0.534150 
 Precision: 0.564622 
 Recall: 0.506799
 IoU: 0.364396

We have finished training iteration 162
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_160_.pth
per-ex loss: 0.394158  [    2/   89]
per-ex loss: 0.591354  [    4/   89]
per-ex loss: 0.420780  [    6/   89]
per-ex loss: 0.481908  [    8/   89]
per-ex loss: 0.388041  [   10/   89]
per-ex loss: 0.466453  [   12/   89]
per-ex loss: 0.339116  [   14/   89]
per-ex loss: 0.517499  [   16/   89]
per-ex loss: 0.394074  [   18/   89]
per-ex loss: 0.387177  [   20/   89]
per-ex loss: 0.380864  [   22/   89]
per-ex loss: 0.407034  [   24/   89]
per-ex loss: 0.635899  [   26/   89]
per-ex loss: 0.391516  [   28/   89]
per-ex loss: 0.372051  [   30/   89]
per-ex loss: 0.502771  [   32/   89]
per-ex loss: 0.558956  [   34/   89]
per-ex loss: 0.451912  [   36/   89]
per-ex loss: 0.414159  [   38/   89]
per-ex loss: 0.451070  [   40/   89]
per-ex loss: 0.579747  [   42/   89]
per-ex loss: 0.364180  [   44/   89]
per-ex loss: 0.608088  [   46/   89]
per-ex loss: 0.377364  [   48/   89]
per-ex loss: 0.469302  [   50/   89]
per-ex loss: 0.480709  [   52/   89]
per-ex loss: 0.447742  [   54/   89]
per-ex loss: 0.345575  [   56/   89]
per-ex loss: 0.403880  [   58/   89]
per-ex loss: 0.543437  [   60/   89]
per-ex loss: 0.420324  [   62/   89]
per-ex loss: 0.405208  [   64/   89]
per-ex loss: 0.557634  [   66/   89]
per-ex loss: 0.520753  [   68/   89]
per-ex loss: 0.576982  [   70/   89]
per-ex loss: 0.537226  [   72/   89]
per-ex loss: 0.361825  [   74/   89]
per-ex loss: 0.404401  [   76/   89]
per-ex loss: 0.555848  [   78/   89]
per-ex loss: 0.411107  [   80/   89]
per-ex loss: 0.381012  [   82/   89]
per-ex loss: 0.450638  [   84/   89]
per-ex loss: 0.351149  [   86/   89]
per-ex loss: 0.495985  [   88/   89]
per-ex loss: 0.494304  [   89/   89]
Train Error: Avg loss: 0.45536025
validation Error: 
 Avg loss: 0.98291957 
 F1: 0.517374 
 Precision: 0.593015 
 Recall: 0.458847
 IoU: 0.348958

test Error: 
 Avg loss: 0.98041236 
 F1: 0.542379 
 Precision: 0.607377 
 Recall: 0.489949
 IoU: 0.372099

We have finished training iteration 163
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_161_.pth
per-ex loss: 0.543654  [    2/   89]
per-ex loss: 0.440243  [    4/   89]
per-ex loss: 0.670744  [    6/   89]
per-ex loss: 0.481687  [    8/   89]
per-ex loss: 0.450447  [   10/   89]
per-ex loss: 0.611320  [   12/   89]
per-ex loss: 0.461600  [   14/   89]
per-ex loss: 0.537499  [   16/   89]
per-ex loss: 0.542398  [   18/   89]
per-ex loss: 0.622666  [   20/   89]
per-ex loss: 0.361228  [   22/   89]
per-ex loss: 0.361942  [   24/   89]
per-ex loss: 0.357711  [   26/   89]
per-ex loss: 0.434372  [   28/   89]
per-ex loss: 0.558383  [   30/   89]
per-ex loss: 0.431348  [   32/   89]
per-ex loss: 0.380922  [   34/   89]
per-ex loss: 0.412663  [   36/   89]
per-ex loss: 0.373853  [   38/   89]
per-ex loss: 0.592376  [   40/   89]
per-ex loss: 0.417270  [   42/   89]
per-ex loss: 0.473606  [   44/   89]
per-ex loss: 0.524209  [   46/   89]
per-ex loss: 0.405888  [   48/   89]
per-ex loss: 0.432032  [   50/   89]
per-ex loss: 0.459568  [   52/   89]
per-ex loss: 0.469090  [   54/   89]
per-ex loss: 0.372674  [   56/   89]
per-ex loss: 0.418255  [   58/   89]
per-ex loss: 0.380286  [   60/   89]
per-ex loss: 0.530987  [   62/   89]
per-ex loss: 0.532457  [   64/   89]
per-ex loss: 0.533509  [   66/   89]
per-ex loss: 0.387408  [   68/   89]
per-ex loss: 0.426381  [   70/   89]
per-ex loss: 0.436391  [   72/   89]
per-ex loss: 0.356314  [   74/   89]
per-ex loss: 0.640957  [   76/   89]
per-ex loss: 0.367896  [   78/   89]
per-ex loss: 0.434681  [   80/   89]
per-ex loss: 0.377391  [   82/   89]
per-ex loss: 0.552802  [   84/   89]
per-ex loss: 0.393095  [   86/   89]
per-ex loss: 0.438739  [   88/   89]
per-ex loss: 0.450491  [   89/   89]
Train Error: Avg loss: 0.46309866
validation Error: 
 Avg loss: 0.98264956 
 F1: 0.519365 
 Precision: 0.581145 
 Recall: 0.469458
 IoU: 0.350772

test Error: 
 Avg loss: 0.98042415 
 F1: 0.544979 
 Precision: 0.593657 
 Recall: 0.503680
 IoU: 0.374551

We have finished training iteration 164
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_162_.pth
Error in cropping the image to the non-zero values in the fourth channel. Returned the original image.
per-ex loss: 0.512545  [    2/   89]
per-ex loss: 0.424783  [    4/   89]
per-ex loss: 0.389867  [    6/   89]
per-ex loss: 0.458802  [    8/   89]
per-ex loss: 0.538236  [   10/   89]
per-ex loss: 0.445764  [   12/   89]
per-ex loss: 0.350071  [   14/   89]
per-ex loss: 0.442866  [   16/   89]
per-ex loss: 0.396338  [   18/   89]
per-ex loss: 0.491389  [   20/   89]
per-ex loss: 0.387078  [   22/   89]
per-ex loss: 0.637957  [   24/   89]
per-ex loss: 0.378487  [   26/   89]
per-ex loss: 0.394867  [   28/   89]
per-ex loss: 0.415277  [   30/   89]
per-ex loss: 0.465913  [   32/   89]
per-ex loss: 0.533884  [   34/   89]
per-ex loss: 0.584767  [   36/   89]
per-ex loss: 0.546254  [   38/   89]
per-ex loss: 0.551794  [   40/   89]
per-ex loss: 0.389289  [   42/   89]
per-ex loss: 0.452570  [   44/   89]
per-ex loss: 0.377600  [   46/   89]
per-ex loss: 0.565386  [   48/   89]
per-ex loss: 0.377146  [   50/   89]
per-ex loss: 0.393171  [   52/   89]
per-ex loss: 0.440662  [   54/   89]
per-ex loss: 0.516711  [   56/   89]
per-ex loss: 0.413068  [   58/   89]
per-ex loss: 0.408371  [   60/   89]
per-ex loss: 0.585460  [   62/   89]
per-ex loss: 0.532045  [   64/   89]
per-ex loss: 0.404793  [   66/   89]
per-ex loss: 0.449064  [   68/   89]
per-ex loss: 0.422476  [   70/   89]
per-ex loss: 0.553991  [   72/   89]
per-ex loss: 0.467320  [   74/   89]
per-ex loss: 0.505400  [   76/   89]
per-ex loss: 0.503646  [   78/   89]
per-ex loss: 0.514372  [   80/   89]
per-ex loss: 0.427054  [   82/   89]
per-ex loss: 0.366746  [   84/   89]
per-ex loss: 0.598490  [   86/   89]
per-ex loss: 0.494127  [   88/   89]
per-ex loss: 0.496201  [   89/   89]
Train Error: Avg loss: 0.46671334
validation Error: 
 Avg loss: 0.98183765 
 F1: 0.512554 
 Precision: 0.636264 
 Recall: 0.429119
 IoU: 0.344587

test Error: 
 Avg loss: 0.97974365 
 F1: 0.535130 
 Precision: 0.644413 
 Recall: 0.457539
 IoU: 0.365309

We have finished training iteration 165
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_163_.pth
per-ex loss: 0.498038  [    2/   89]
per-ex loss: 0.597137  [    4/   89]
per-ex loss: 0.355821  [    6/   89]
per-ex loss: 0.472881  [    8/   89]
per-ex loss: 0.450293  [   10/   89]
per-ex loss: 0.468280  [   12/   89]
per-ex loss: 0.362372  [   14/   89]
per-ex loss: 0.378201  [   16/   89]
per-ex loss: 0.383639  [   18/   89]
per-ex loss: 0.572318  [   20/   89]
per-ex loss: 0.522030  [   22/   89]
per-ex loss: 0.377134  [   24/   89]
per-ex loss: 0.392298  [   26/   89]
per-ex loss: 0.529776  [   28/   89]
per-ex loss: 0.484554  [   30/   89]
per-ex loss: 0.537969  [   32/   89]
per-ex loss: 0.559481  [   34/   89]
per-ex loss: 0.658753  [   36/   89]
per-ex loss: 0.509768  [   38/   89]
per-ex loss: 0.338379  [   40/   89]
per-ex loss: 0.438124  [   42/   89]
per-ex loss: 0.452217  [   44/   89]
per-ex loss: 0.393484  [   46/   89]
per-ex loss: 0.569508  [   48/   89]
per-ex loss: 0.685095  [   50/   89]
per-ex loss: 0.497850  [   52/   89]
per-ex loss: 0.510715  [   54/   89]
per-ex loss: 0.363447  [   56/   89]
per-ex loss: 0.344635  [   58/   89]
per-ex loss: 0.412707  [   60/   89]
per-ex loss: 0.471139  [   62/   89]
per-ex loss: 0.491235  [   64/   89]
per-ex loss: 0.343854  [   66/   89]
per-ex loss: 0.497742  [   68/   89]
per-ex loss: 0.392915  [   70/   89]
per-ex loss: 0.441954  [   72/   89]
per-ex loss: 0.410779  [   74/   89]
per-ex loss: 0.397119  [   76/   89]
per-ex loss: 0.489228  [   78/   89]
per-ex loss: 0.419639  [   80/   89]
per-ex loss: 0.504755  [   82/   89]
per-ex loss: 0.379473  [   84/   89]
per-ex loss: 0.398557  [   86/   89]
per-ex loss: 0.519989  [   88/   89]
per-ex loss: 0.541833  [   89/   89]
Train Error: Avg loss: 0.46260259
validation Error: 
 Avg loss: 0.98416378 
 F1: 0.513997 
 Precision: 0.549362 
 Recall: 0.482910
 IoU: 0.345892

test Error: 
 Avg loss: 0.98230252 
 F1: 0.533745 
 Precision: 0.560726 
 Recall: 0.509242
 IoU: 0.364020

We have finished training iteration 166
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_164_.pth
per-ex loss: 0.521932  [    2/   89]
per-ex loss: 0.469448  [    4/   89]
per-ex loss: 0.533153  [    6/   89]
per-ex loss: 0.363094  [    8/   89]
per-ex loss: 0.536921  [   10/   89]
per-ex loss: 0.526662  [   12/   89]
per-ex loss: 0.292758  [   14/   89]
per-ex loss: 0.556694  [   16/   89]
per-ex loss: 0.451643  [   18/   89]
per-ex loss: 0.617409  [   20/   89]
per-ex loss: 0.486356  [   22/   89]
per-ex loss: 0.462442  [   24/   89]
per-ex loss: 0.468197  [   26/   89]
per-ex loss: 0.520799  [   28/   89]
per-ex loss: 0.415331  [   30/   89]
per-ex loss: 0.496167  [   32/   89]
per-ex loss: 0.486537  [   34/   89]
per-ex loss: 0.435296  [   36/   89]
per-ex loss: 0.472069  [   38/   89]
per-ex loss: 0.418485  [   40/   89]
per-ex loss: 0.470464  [   42/   89]
per-ex loss: 0.432053  [   44/   89]
per-ex loss: 0.524078  [   46/   89]
per-ex loss: 0.415132  [   48/   89]
per-ex loss: 0.408070  [   50/   89]
per-ex loss: 0.470654  [   52/   89]
per-ex loss: 0.507533  [   54/   89]
per-ex loss: 0.570165  [   56/   89]
per-ex loss: 0.393035  [   58/   89]
per-ex loss: 0.419966  [   60/   89]
per-ex loss: 0.421945  [   62/   89]
per-ex loss: 0.362745  [   64/   89]
per-ex loss: 0.351651  [   66/   89]
per-ex loss: 0.481702  [   68/   89]
per-ex loss: 0.404051  [   70/   89]
per-ex loss: 0.423360  [   72/   89]
per-ex loss: 0.364531  [   74/   89]
per-ex loss: 0.372447  [   76/   89]
per-ex loss: 0.506505  [   78/   89]
per-ex loss: 0.587566  [   80/   89]
per-ex loss: 0.406180  [   82/   89]
per-ex loss: 0.522872  [   84/   89]
per-ex loss: 0.339029  [   86/   89]
per-ex loss: 0.480449  [   88/   89]
per-ex loss: 0.612598  [   89/   89]
Train Error: Avg loss: 0.46178164
validation Error: 
 Avg loss: 0.98174393 
 F1: 0.511249 
 Precision: 0.630872 
 Recall: 0.429760
 IoU: 0.343408

test Error: 
 Avg loss: 0.97924617 
 F1: 0.536574 
 Precision: 0.638021 
 Recall: 0.462963
 IoU: 0.366656

We have finished training iteration 167
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_165_.pth
per-ex loss: 0.566700  [    2/   89]
per-ex loss: 0.542397  [    4/   89]
per-ex loss: 0.462358  [    6/   89]
per-ex loss: 0.443374  [    8/   89]
per-ex loss: 0.544378  [   10/   89]
per-ex loss: 0.527059  [   12/   89]
per-ex loss: 0.378385  [   14/   89]
per-ex loss: 0.595011  [   16/   89]
per-ex loss: 0.585272  [   18/   89]
per-ex loss: 0.442613  [   20/   89]
per-ex loss: 0.606684  [   22/   89]
per-ex loss: 0.460936  [   24/   89]
per-ex loss: 0.399618  [   26/   89]
per-ex loss: 0.388789  [   28/   89]
per-ex loss: 0.493549  [   30/   89]
per-ex loss: 0.555432  [   32/   89]
per-ex loss: 0.478257  [   34/   89]
per-ex loss: 0.418784  [   36/   89]
per-ex loss: 0.457191  [   38/   89]
per-ex loss: 0.455244  [   40/   89]
per-ex loss: 0.578386  [   42/   89]
per-ex loss: 0.495546  [   44/   89]
per-ex loss: 0.357972  [   46/   89]
per-ex loss: 0.391717  [   48/   89]
per-ex loss: 0.466045  [   50/   89]
per-ex loss: 0.461292  [   52/   89]
per-ex loss: 0.366599  [   54/   89]
per-ex loss: 0.364464  [   56/   89]
per-ex loss: 0.427010  [   58/   89]
per-ex loss: 0.380797  [   60/   89]
per-ex loss: 0.376532  [   62/   89]
per-ex loss: 0.381481  [   64/   89]
per-ex loss: 0.380287  [   66/   89]
per-ex loss: 0.573686  [   68/   89]
per-ex loss: 0.347461  [   70/   89]
per-ex loss: 0.350654  [   72/   89]
per-ex loss: 0.582992  [   74/   89]
per-ex loss: 0.418993  [   76/   89]
per-ex loss: 0.381178  [   78/   89]
per-ex loss: 0.327617  [   80/   89]
per-ex loss: 0.449949  [   82/   89]
per-ex loss: 0.398838  [   84/   89]
per-ex loss: 0.392468  [   86/   89]
per-ex loss: 0.491345  [   88/   89]
per-ex loss: 0.528838  [   89/   89]
Train Error: Avg loss: 0.45498176
validation Error: 
 Avg loss: 0.98345827 
 F1: 0.520749 
 Precision: 0.561010 
 Recall: 0.485880
 IoU: 0.352036

test Error: 
 Avg loss: 0.98085013 
 F1: 0.542210 
 Precision: 0.576295 
 Recall: 0.511931
 IoU: 0.371939

We have finished training iteration 168
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_166_.pth
per-ex loss: 0.537881  [    2/   89]
per-ex loss: 0.467792  [    4/   89]
per-ex loss: 0.452198  [    6/   89]
per-ex loss: 0.428142  [    8/   89]
per-ex loss: 0.505499  [   10/   89]
per-ex loss: 0.368106  [   12/   89]
per-ex loss: 0.360984  [   14/   89]
per-ex loss: 0.554197  [   16/   89]
per-ex loss: 0.405673  [   18/   89]
per-ex loss: 0.371368  [   20/   89]
per-ex loss: 0.597633  [   22/   89]
per-ex loss: 0.399483  [   24/   89]
per-ex loss: 0.609363  [   26/   89]
per-ex loss: 0.442309  [   28/   89]
per-ex loss: 0.607167  [   30/   89]
per-ex loss: 0.428013  [   32/   89]
per-ex loss: 0.425697  [   34/   89]
per-ex loss: 0.473140  [   36/   89]
per-ex loss: 0.467840  [   38/   89]
per-ex loss: 0.415228  [   40/   89]
per-ex loss: 0.366652  [   42/   89]
per-ex loss: 0.475224  [   44/   89]
per-ex loss: 0.329898  [   46/   89]
per-ex loss: 0.388586  [   48/   89]
per-ex loss: 0.429379  [   50/   89]
per-ex loss: 0.451831  [   52/   89]
per-ex loss: 0.336305  [   54/   89]
per-ex loss: 0.389487  [   56/   89]
per-ex loss: 0.536622  [   58/   89]
per-ex loss: 0.388227  [   60/   89]
per-ex loss: 0.410305  [   62/   89]
per-ex loss: 0.428363  [   64/   89]
per-ex loss: 0.338777  [   66/   89]
per-ex loss: 0.478714  [   68/   89]
per-ex loss: 0.569426  [   70/   89]
per-ex loss: 0.477915  [   72/   89]
per-ex loss: 0.502872  [   74/   89]
per-ex loss: 0.387133  [   76/   89]
per-ex loss: 0.484701  [   78/   89]
per-ex loss: 0.554435  [   80/   89]
per-ex loss: 0.384386  [   82/   89]
per-ex loss: 0.385190  [   84/   89]
per-ex loss: 0.399428  [   86/   89]
per-ex loss: 0.417934  [   88/   89]
per-ex loss: 0.588175  [   89/   89]
Train Error: Avg loss: 0.44928177
validation Error: 
 Avg loss: 0.98363067 
 F1: 0.517865 
 Precision: 0.568162 
 Recall: 0.475749
 IoU: 0.349405

test Error: 
 Avg loss: 0.98120182 
 F1: 0.531314 
 Precision: 0.572802 
 Recall: 0.495430
 IoU: 0.361761

We have finished training iteration 169
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_167_.pth
per-ex loss: 0.449366  [    2/   89]
per-ex loss: 0.573966  [    4/   89]
per-ex loss: 0.393626  [    6/   89]
per-ex loss: 0.380567  [    8/   89]
per-ex loss: 0.318467  [   10/   89]
per-ex loss: 0.403969  [   12/   89]
per-ex loss: 0.604832  [   14/   89]
per-ex loss: 0.562779  [   16/   89]
per-ex loss: 0.681252  [   18/   89]
per-ex loss: 0.500296  [   20/   89]
per-ex loss: 0.317400  [   22/   89]
per-ex loss: 0.364475  [   24/   89]
per-ex loss: 0.387619  [   26/   89]
per-ex loss: 0.432426  [   28/   89]
per-ex loss: 0.472204  [   30/   89]
per-ex loss: 0.464008  [   32/   89]
per-ex loss: 0.357092  [   34/   89]
per-ex loss: 0.363351  [   36/   89]
per-ex loss: 0.345757  [   38/   89]
per-ex loss: 0.385280  [   40/   89]
per-ex loss: 0.595857  [   42/   89]
per-ex loss: 0.599092  [   44/   89]
per-ex loss: 0.413094  [   46/   89]
per-ex loss: 0.381501  [   48/   89]
per-ex loss: 0.580443  [   50/   89]
per-ex loss: 0.413578  [   52/   89]
per-ex loss: 0.391717  [   54/   89]
per-ex loss: 0.492231  [   56/   89]
per-ex loss: 0.377824  [   58/   89]
per-ex loss: 0.584179  [   60/   89]
per-ex loss: 0.449587  [   62/   89]
per-ex loss: 0.420369  [   64/   89]
per-ex loss: 0.574671  [   66/   89]
per-ex loss: 0.365546  [   68/   89]
per-ex loss: 0.396366  [   70/   89]
per-ex loss: 0.561373  [   72/   89]
per-ex loss: 0.385694  [   74/   89]
per-ex loss: 0.408123  [   76/   89]
per-ex loss: 0.460005  [   78/   89]
per-ex loss: 0.435683  [   80/   89]
per-ex loss: 0.488631  [   82/   89]
per-ex loss: 0.479163  [   84/   89]
per-ex loss: 0.416241  [   86/   89]
per-ex loss: 0.438178  [   88/   89]
per-ex loss: 0.579404  [   89/   89]
Train Error: Avg loss: 0.45438403
validation Error: 
 Avg loss: 0.98405943 
 F1: 0.517990 
 Precision: 0.553307 
 Recall: 0.486910
 IoU: 0.349518

test Error: 
 Avg loss: 0.98123674 
 F1: 0.540838 
 Precision: 0.568089 
 Recall: 0.516082
 IoU: 0.370650

We have finished training iteration 170
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_168_.pth
per-ex loss: 0.438545  [    2/   89]
per-ex loss: 0.406782  [    4/   89]
per-ex loss: 0.578193  [    6/   89]
per-ex loss: 0.377098  [    8/   89]
per-ex loss: 0.488560  [   10/   89]
per-ex loss: 0.513122  [   12/   89]
per-ex loss: 0.705740  [   14/   89]
per-ex loss: 0.378420  [   16/   89]
per-ex loss: 0.412032  [   18/   89]
per-ex loss: 0.375370  [   20/   89]
per-ex loss: 0.547373  [   22/   89]
per-ex loss: 0.444382  [   24/   89]
per-ex loss: 0.357994  [   26/   89]
per-ex loss: 0.439922  [   28/   89]
per-ex loss: 0.417153  [   30/   89]
per-ex loss: 0.409420  [   32/   89]
per-ex loss: 0.424923  [   34/   89]
per-ex loss: 0.334981  [   36/   89]
per-ex loss: 0.505287  [   38/   89]
per-ex loss: 0.556077  [   40/   89]
per-ex loss: 0.419459  [   42/   89]
per-ex loss: 0.448440  [   44/   89]
per-ex loss: 0.534051  [   46/   89]
per-ex loss: 0.629007  [   48/   89]
per-ex loss: 0.422870  [   50/   89]
per-ex loss: 0.381235  [   52/   89]
per-ex loss: 0.405326  [   54/   89]
per-ex loss: 0.366183  [   56/   89]
per-ex loss: 0.346621  [   58/   89]
per-ex loss: 0.453556  [   60/   89]
per-ex loss: 0.366806  [   62/   89]
per-ex loss: 0.336386  [   64/   89]
per-ex loss: 0.567765  [   66/   89]
per-ex loss: 0.507975  [   68/   89]
per-ex loss: 0.468239  [   70/   89]
per-ex loss: 0.333105  [   72/   89]
per-ex loss: 0.546185  [   74/   89]
per-ex loss: 0.442404  [   76/   89]
per-ex loss: 0.513964  [   78/   89]
per-ex loss: 0.494169  [   80/   89]
per-ex loss: 0.587202  [   82/   89]
per-ex loss: 0.446259  [   84/   89]
per-ex loss: 0.601093  [   86/   89]
per-ex loss: 0.596765  [   88/   89]
per-ex loss: 0.376107  [   89/   89]
Train Error: Avg loss: 0.46005655
validation Error: 
 Avg loss: 0.98464561 
 F1: 0.515939 
 Precision: 0.539853 
 Recall: 0.494053
 IoU: 0.347653

test Error: 
 Avg loss: 0.98203792 
 F1: 0.540341 
 Precision: 0.558190 
 Recall: 0.523598
 IoU: 0.370183

We have finished training iteration 171
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_169_.pth
per-ex loss: 0.629074  [    2/   89]
per-ex loss: 0.405840  [    4/   89]
per-ex loss: 0.485193  [    6/   89]
per-ex loss: 0.568997  [    8/   89]
per-ex loss: 0.556667  [   10/   89]
per-ex loss: 0.446507  [   12/   89]
per-ex loss: 0.732442  [   14/   89]
per-ex loss: 0.505693  [   16/   89]
per-ex loss: 0.389104  [   18/   89]
per-ex loss: 0.386230  [   20/   89]
per-ex loss: 0.500163  [   22/   89]
per-ex loss: 0.480613  [   24/   89]
per-ex loss: 0.577150  [   26/   89]
per-ex loss: 0.415005  [   28/   89]
per-ex loss: 0.434798  [   30/   89]
per-ex loss: 0.423300  [   32/   89]
per-ex loss: 0.517562  [   34/   89]
per-ex loss: 0.427445  [   36/   89]
per-ex loss: 0.362849  [   38/   89]
per-ex loss: 0.635036  [   40/   89]
per-ex loss: 0.346946  [   42/   89]
per-ex loss: 0.472793  [   44/   89]
per-ex loss: 0.378681  [   46/   89]
per-ex loss: 0.410420  [   48/   89]
per-ex loss: 0.430030  [   50/   89]
per-ex loss: 0.610102  [   52/   89]
per-ex loss: 0.359346  [   54/   89]
per-ex loss: 0.368247  [   56/   89]
per-ex loss: 0.461744  [   58/   89]
per-ex loss: 0.368544  [   60/   89]
per-ex loss: 0.365654  [   62/   89]
per-ex loss: 0.447018  [   64/   89]
per-ex loss: 0.385863  [   66/   89]
per-ex loss: 0.359273  [   68/   89]
per-ex loss: 0.533833  [   70/   89]
per-ex loss: 0.353850  [   72/   89]
per-ex loss: 0.572836  [   74/   89]
per-ex loss: 0.494364  [   76/   89]
per-ex loss: 0.332103  [   78/   89]
per-ex loss: 0.456813  [   80/   89]
per-ex loss: 0.526202  [   82/   89]
per-ex loss: 0.414762  [   84/   89]
per-ex loss: 0.364376  [   86/   89]
per-ex loss: 0.584955  [   88/   89]
per-ex loss: 0.413929  [   89/   89]
Train Error: Avg loss: 0.45983002
validation Error: 
 Avg loss: 0.98368460 
 F1: 0.518132 
 Precision: 0.554607 
 Recall: 0.486159
 IoU: 0.349648

test Error: 
 Avg loss: 0.98070111 
 F1: 0.545826 
 Precision: 0.583229 
 Recall: 0.512931
 IoU: 0.375351

We have finished training iteration 172
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_170_.pth
per-ex loss: 0.375994  [    2/   89]
per-ex loss: 0.392527  [    4/   89]
per-ex loss: 0.504762  [    6/   89]
per-ex loss: 0.411522  [    8/   89]
per-ex loss: 0.434887  [   10/   89]
per-ex loss: 0.454384  [   12/   89]
per-ex loss: 0.430061  [   14/   89]
per-ex loss: 0.514200  [   16/   89]
per-ex loss: 0.511052  [   18/   89]
per-ex loss: 0.583694  [   20/   89]
per-ex loss: 0.356675  [   22/   89]
per-ex loss: 0.464599  [   24/   89]
per-ex loss: 0.583338  [   26/   89]
per-ex loss: 0.511851  [   28/   89]
per-ex loss: 0.369260  [   30/   89]
per-ex loss: 0.419655  [   32/   89]
per-ex loss: 0.440454  [   34/   89]
per-ex loss: 0.404338  [   36/   89]
per-ex loss: 0.540708  [   38/   89]
per-ex loss: 0.400107  [   40/   89]
per-ex loss: 0.533682  [   42/   89]
per-ex loss: 0.409202  [   44/   89]
per-ex loss: 0.473649  [   46/   89]
per-ex loss: 0.444030  [   48/   89]
per-ex loss: 0.417259  [   50/   89]
per-ex loss: 0.544438  [   52/   89]
per-ex loss: 0.562548  [   54/   89]
per-ex loss: 0.613902  [   56/   89]
per-ex loss: 0.408032  [   58/   89]
per-ex loss: 0.361088  [   60/   89]
per-ex loss: 0.386925  [   62/   89]
per-ex loss: 0.451447  [   64/   89]
per-ex loss: 0.475641  [   66/   89]
per-ex loss: 0.355377  [   68/   89]
per-ex loss: 0.527589  [   70/   89]
per-ex loss: 0.456290  [   72/   89]
per-ex loss: 0.508330  [   74/   89]
per-ex loss: 0.406927  [   76/   89]
per-ex loss: 0.538060  [   78/   89]
per-ex loss: 0.406305  [   80/   89]
per-ex loss: 0.394320  [   82/   89]
per-ex loss: 0.366552  [   84/   89]
per-ex loss: 0.426495  [   86/   89]
per-ex loss: 0.372011  [   88/   89]
per-ex loss: 0.619238  [   89/   89]
Train Error: Avg loss: 0.45696458
validation Error: 
 Avg loss: 0.98205804 
 F1: 0.519705 
 Precision: 0.567974 
 Recall: 0.478998
 IoU: 0.351082

test Error: 
 Avg loss: 0.98051016 
 F1: 0.538804 
 Precision: 0.589945 
 Recall: 0.495822
 IoU: 0.368742

We have finished training iteration 173
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_171_.pth
per-ex loss: 0.358901  [    2/   89]
per-ex loss: 0.517433  [    4/   89]
per-ex loss: 0.632330  [    6/   89]
per-ex loss: 0.396724  [    8/   89]
per-ex loss: 0.579850  [   10/   89]
per-ex loss: 0.433667  [   12/   89]
per-ex loss: 0.594282  [   14/   89]
per-ex loss: 0.404622  [   16/   89]
per-ex loss: 0.408269  [   18/   89]
per-ex loss: 0.396977  [   20/   89]
per-ex loss: 0.455422  [   22/   89]
per-ex loss: 0.630340  [   24/   89]
per-ex loss: 0.450695  [   26/   89]
per-ex loss: 0.401549  [   28/   89]
per-ex loss: 0.384245  [   30/   89]
per-ex loss: 0.490936  [   32/   89]
per-ex loss: 0.406671  [   34/   89]
per-ex loss: 0.347803  [   36/   89]
per-ex loss: 0.570289  [   38/   89]
per-ex loss: 0.408614  [   40/   89]
per-ex loss: 0.608743  [   42/   89]
per-ex loss: 0.350599  [   44/   89]
per-ex loss: 0.381096  [   46/   89]
per-ex loss: 0.363502  [   48/   89]
per-ex loss: 0.412220  [   50/   89]
per-ex loss: 0.367089  [   52/   89]
per-ex loss: 0.443829  [   54/   89]
per-ex loss: 0.535646  [   56/   89]
per-ex loss: 0.419189  [   58/   89]
per-ex loss: 0.598969  [   60/   89]
per-ex loss: 0.429762  [   62/   89]
per-ex loss: 0.437376  [   64/   89]
per-ex loss: 0.430743  [   66/   89]
per-ex loss: 0.421913  [   68/   89]
per-ex loss: 0.421878  [   70/   89]
per-ex loss: 0.371877  [   72/   89]
per-ex loss: 0.436248  [   74/   89]
per-ex loss: 0.485541  [   76/   89]
per-ex loss: 0.448536  [   78/   89]
per-ex loss: 0.324699  [   80/   89]
per-ex loss: 0.571339  [   82/   89]
per-ex loss: 0.523267  [   84/   89]
per-ex loss: 0.365784  [   86/   89]
per-ex loss: 0.437803  [   88/   89]
per-ex loss: 0.372405  [   89/   89]
Train Error: Avg loss: 0.44954820
validation Error: 
 Avg loss: 0.98281965 
 F1: 0.519840 
 Precision: 0.571354 
 Recall: 0.476847
 IoU: 0.351205

test Error: 
 Avg loss: 0.98056401 
 F1: 0.543901 
 Precision: 0.594754 
 Recall: 0.501059
 IoU: 0.373533

We have finished training iteration 174
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_172_.pth
per-ex loss: 0.562827  [    2/   89]
per-ex loss: 0.553963  [    4/   89]
per-ex loss: 0.561027  [    6/   89]
per-ex loss: 0.393884  [    8/   89]
per-ex loss: 0.470039  [   10/   89]
per-ex loss: 0.400394  [   12/   89]
per-ex loss: 0.481199  [   14/   89]
per-ex loss: 0.350395  [   16/   89]
per-ex loss: 0.432632  [   18/   89]
per-ex loss: 0.519852  [   20/   89]
per-ex loss: 0.390002  [   22/   89]
per-ex loss: 0.497851  [   24/   89]
per-ex loss: 0.309262  [   26/   89]
per-ex loss: 0.554788  [   28/   89]
per-ex loss: 0.367479  [   30/   89]
per-ex loss: 0.392389  [   32/   89]
per-ex loss: 0.396951  [   34/   89]
per-ex loss: 0.400548  [   36/   89]
per-ex loss: 0.512154  [   38/   89]
per-ex loss: 0.492809  [   40/   89]
per-ex loss: 0.348643  [   42/   89]
per-ex loss: 0.332365  [   44/   89]
per-ex loss: 0.466513  [   46/   89]
per-ex loss: 0.379541  [   48/   89]
per-ex loss: 0.416174  [   50/   89]
per-ex loss: 0.359727  [   52/   89]
per-ex loss: 0.347751  [   54/   89]
per-ex loss: 0.480214  [   56/   89]
per-ex loss: 0.462534  [   58/   89]
per-ex loss: 0.463746  [   60/   89]
per-ex loss: 0.590515  [   62/   89]
per-ex loss: 0.461999  [   64/   89]
per-ex loss: 0.574385  [   66/   89]
per-ex loss: 0.454049  [   68/   89]
per-ex loss: 0.522927  [   70/   89]
per-ex loss: 0.515362  [   72/   89]
per-ex loss: 0.551521  [   74/   89]
per-ex loss: 0.425648  [   76/   89]
per-ex loss: 0.375804  [   78/   89]
per-ex loss: 0.567364  [   80/   89]
per-ex loss: 0.484941  [   82/   89]
per-ex loss: 0.434360  [   84/   89]
per-ex loss: 0.562551  [   86/   89]
per-ex loss: 0.538891  [   88/   89]
per-ex loss: 0.560446  [   89/   89]
Train Error: Avg loss: 0.46040920
validation Error: 
 Avg loss: 0.98459167 
 F1: 0.510502 
 Precision: 0.495312 
 Recall: 0.526653
 IoU: 0.342734

test Error: 
 Avg loss: 0.98384513 
 F1: 0.532377 
 Precision: 0.503662 
 Recall: 0.564565
 IoU: 0.362748

We have finished training iteration 175
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_173_.pth
per-ex loss: 0.437198  [    2/   89]
per-ex loss: 0.468753  [    4/   89]
per-ex loss: 0.448989  [    6/   89]
per-ex loss: 0.371508  [    8/   89]
per-ex loss: 0.615779  [   10/   89]
per-ex loss: 0.627118  [   12/   89]
per-ex loss: 0.455500  [   14/   89]
per-ex loss: 0.437232  [   16/   89]
per-ex loss: 0.449759  [   18/   89]
per-ex loss: 0.368046  [   20/   89]
per-ex loss: 0.383604  [   22/   89]
per-ex loss: 0.447512  [   24/   89]
per-ex loss: 0.434782  [   26/   89]
per-ex loss: 0.439770  [   28/   89]
per-ex loss: 0.422982  [   30/   89]
per-ex loss: 0.423017  [   32/   89]
per-ex loss: 0.398365  [   34/   89]
per-ex loss: 0.386042  [   36/   89]
per-ex loss: 0.442983  [   38/   89]
per-ex loss: 0.385858  [   40/   89]
per-ex loss: 0.480995  [   42/   89]
per-ex loss: 0.332074  [   44/   89]
per-ex loss: 0.375058  [   46/   89]
per-ex loss: 0.544048  [   48/   89]
per-ex loss: 0.466116  [   50/   89]
per-ex loss: 0.666344  [   52/   89]
per-ex loss: 0.528248  [   54/   89]
per-ex loss: 0.558278  [   56/   89]
per-ex loss: 0.504150  [   58/   89]
per-ex loss: 0.437347  [   60/   89]
per-ex loss: 0.453246  [   62/   89]
per-ex loss: 0.433648  [   64/   89]
per-ex loss: 0.356993  [   66/   89]
per-ex loss: 0.333152  [   68/   89]
per-ex loss: 0.586044  [   70/   89]
per-ex loss: 0.369416  [   72/   89]
per-ex loss: 0.402720  [   74/   89]
per-ex loss: 0.424668  [   76/   89]
per-ex loss: 0.499056  [   78/   89]
per-ex loss: 0.404611  [   80/   89]
per-ex loss: 0.538275  [   82/   89]
per-ex loss: 0.440483  [   84/   89]
per-ex loss: 0.421612  [   86/   89]
per-ex loss: 0.369217  [   88/   89]
per-ex loss: 0.422156  [   89/   89]
Train Error: Avg loss: 0.44872783
validation Error: 
 Avg loss: 0.98417374 
 F1: 0.518449 
 Precision: 0.548066 
 Recall: 0.491868
 IoU: 0.349936

test Error: 
 Avg loss: 0.98133682 
 F1: 0.544564 
 Precision: 0.567778 
 Recall: 0.523173
 IoU: 0.374158

We have finished training iteration 176
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_174_.pth
per-ex loss: 0.521922  [    2/   89]
per-ex loss: 0.499953  [    4/   89]
per-ex loss: 0.492667  [    6/   89]
per-ex loss: 0.429459  [    8/   89]
per-ex loss: 0.582617  [   10/   89]
per-ex loss: 0.421609  [   12/   89]
per-ex loss: 0.357083  [   14/   89]
per-ex loss: 0.439581  [   16/   89]
per-ex loss: 0.474825  [   18/   89]
per-ex loss: 0.659784  [   20/   89]
per-ex loss: 0.378089  [   22/   89]
per-ex loss: 0.369733  [   24/   89]
per-ex loss: 0.416299  [   26/   89]
per-ex loss: 0.582068  [   28/   89]
per-ex loss: 0.555717  [   30/   89]
per-ex loss: 0.505342  [   32/   89]
per-ex loss: 0.471185  [   34/   89]
per-ex loss: 0.495681  [   36/   89]
per-ex loss: 0.377932  [   38/   89]
per-ex loss: 0.490867  [   40/   89]
per-ex loss: 0.511755  [   42/   89]
per-ex loss: 0.466765  [   44/   89]
per-ex loss: 0.419277  [   46/   89]
per-ex loss: 0.515174  [   48/   89]
per-ex loss: 0.489607  [   50/   89]
per-ex loss: 0.531222  [   52/   89]
per-ex loss: 0.373956  [   54/   89]
per-ex loss: 0.435048  [   56/   89]
per-ex loss: 0.452314  [   58/   89]
per-ex loss: 0.359924  [   60/   89]
per-ex loss: 0.397102  [   62/   89]
per-ex loss: 0.376270  [   64/   89]
per-ex loss: 0.509936  [   66/   89]
per-ex loss: 0.377262  [   68/   89]
per-ex loss: 0.512189  [   70/   89]
per-ex loss: 0.383189  [   72/   89]
per-ex loss: 0.490734  [   74/   89]
per-ex loss: 0.336798  [   76/   89]
per-ex loss: 0.580637  [   78/   89]
per-ex loss: 0.432891  [   80/   89]
per-ex loss: 0.384578  [   82/   89]
per-ex loss: 0.379171  [   84/   89]
per-ex loss: 0.415576  [   86/   89]
per-ex loss: 0.346155  [   88/   89]
per-ex loss: 0.635753  [   89/   89]
Train Error: Avg loss: 0.45857108
validation Error: 
 Avg loss: 0.98246338 
 F1: 0.519685 
 Precision: 0.590662 
 Recall: 0.463936
 IoU: 0.351064

test Error: 
 Avg loss: 0.98001004 
 F1: 0.545088 
 Precision: 0.616081 
 Recall: 0.488765
 IoU: 0.374653

We have finished training iteration 177
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_175_.pth
per-ex loss: 0.419474  [    2/   89]
per-ex loss: 0.385613  [    4/   89]
per-ex loss: 0.429687  [    6/   89]
per-ex loss: 0.342574  [    8/   89]
per-ex loss: 0.384357  [   10/   89]
per-ex loss: 0.425842  [   12/   89]
per-ex loss: 0.373844  [   14/   89]
per-ex loss: 0.395769  [   16/   89]
per-ex loss: 0.458793  [   18/   89]
per-ex loss: 0.532505  [   20/   89]
per-ex loss: 0.360503  [   22/   89]
per-ex loss: 0.498387  [   24/   89]
per-ex loss: 0.522681  [   26/   89]
per-ex loss: 0.501858  [   28/   89]
per-ex loss: 0.432776  [   30/   89]
per-ex loss: 0.340593  [   32/   89]
per-ex loss: 0.552801  [   34/   89]
per-ex loss: 0.439264  [   36/   89]
per-ex loss: 0.589628  [   38/   89]
per-ex loss: 0.425677  [   40/   89]
per-ex loss: 0.455127  [   42/   89]
per-ex loss: 0.717430  [   44/   89]
per-ex loss: 0.389994  [   46/   89]
per-ex loss: 0.430991  [   48/   89]
per-ex loss: 0.482109  [   50/   89]
per-ex loss: 0.420652  [   52/   89]
per-ex loss: 0.416257  [   54/   89]
per-ex loss: 0.556032  [   56/   89]
per-ex loss: 0.371851  [   58/   89]
per-ex loss: 0.389028  [   60/   89]
per-ex loss: 0.487720  [   62/   89]
per-ex loss: 0.360281  [   64/   89]
per-ex loss: 0.374059  [   66/   89]
per-ex loss: 0.533050  [   68/   89]
per-ex loss: 0.571569  [   70/   89]
per-ex loss: 0.508992  [   72/   89]
per-ex loss: 0.526482  [   74/   89]
per-ex loss: 0.429566  [   76/   89]
per-ex loss: 0.457759  [   78/   89]
per-ex loss: 0.593810  [   80/   89]
per-ex loss: 0.420625  [   82/   89]
per-ex loss: 0.530498  [   84/   89]
per-ex loss: 0.401718  [   86/   89]
per-ex loss: 0.597287  [   88/   89]
per-ex loss: 0.359949  [   89/   89]
Train Error: Avg loss: 0.45767697
validation Error: 
 Avg loss: 0.98452758 
 F1: 0.512440 
 Precision: 0.534324 
 Recall: 0.492279
 IoU: 0.344484

test Error: 
 Avg loss: 0.98204132 
 F1: 0.531595 
 Precision: 0.542879 
 Recall: 0.520771
 IoU: 0.362022

We have finished training iteration 178
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_176_.pth
per-ex loss: 0.395510  [    2/   89]
per-ex loss: 0.366049  [    4/   89]
per-ex loss: 0.527208  [    6/   89]
per-ex loss: 0.466472  [    8/   89]
per-ex loss: 0.445870  [   10/   89]
per-ex loss: 0.362195  [   12/   89]
per-ex loss: 0.529557  [   14/   89]
per-ex loss: 0.512340  [   16/   89]
per-ex loss: 0.441548  [   18/   89]
per-ex loss: 0.453475  [   20/   89]
per-ex loss: 0.361690  [   22/   89]
per-ex loss: 0.438304  [   24/   89]
per-ex loss: 0.450103  [   26/   89]
per-ex loss: 0.600422  [   28/   89]
per-ex loss: 0.377217  [   30/   89]
per-ex loss: 0.458714  [   32/   89]
per-ex loss: 0.402619  [   34/   89]
per-ex loss: 0.561569  [   36/   89]
per-ex loss: 0.387471  [   38/   89]
per-ex loss: 0.440688  [   40/   89]
per-ex loss: 0.616038  [   42/   89]
per-ex loss: 0.471007  [   44/   89]
per-ex loss: 0.352067  [   46/   89]
per-ex loss: 0.345354  [   48/   89]
per-ex loss: 0.403760  [   50/   89]
per-ex loss: 0.370413  [   52/   89]
per-ex loss: 0.641934  [   54/   89]
per-ex loss: 0.397875  [   56/   89]
per-ex loss: 0.616369  [   58/   89]
per-ex loss: 0.408583  [   60/   89]
per-ex loss: 0.422145  [   62/   89]
per-ex loss: 0.575481  [   64/   89]
per-ex loss: 0.612453  [   66/   89]
per-ex loss: 0.407940  [   68/   89]
per-ex loss: 0.441521  [   70/   89]
per-ex loss: 0.575711  [   72/   89]
per-ex loss: 0.368198  [   74/   89]
per-ex loss: 0.511555  [   76/   89]
per-ex loss: 0.421658  [   78/   89]
per-ex loss: 0.527673  [   80/   89]
per-ex loss: 0.354687  [   82/   89]
per-ex loss: 0.453354  [   84/   89]
per-ex loss: 0.341656  [   86/   89]
per-ex loss: 0.564498  [   88/   89]
per-ex loss: 0.512892  [   89/   89]
Train Error: Avg loss: 0.45986325
validation Error: 
 Avg loss: 0.98452069 
 F1: 0.510276 
 Precision: 0.543395 
 Recall: 0.480962
 IoU: 0.342531

test Error: 
 Avg loss: 0.98277797 
 F1: 0.527843 
 Precision: 0.531682 
 Recall: 0.524059
 IoU: 0.358551

We have finished training iteration 179
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_177_.pth
per-ex loss: 0.461002  [    2/   89]
per-ex loss: 0.605320  [    4/   89]
per-ex loss: 0.538530  [    6/   89]
per-ex loss: 0.612884  [    8/   89]
per-ex loss: 0.452396  [   10/   89]
per-ex loss: 0.488044  [   12/   89]
per-ex loss: 0.361551  [   14/   89]
per-ex loss: 0.412223  [   16/   89]
per-ex loss: 0.424013  [   18/   89]
per-ex loss: 0.400222  [   20/   89]
per-ex loss: 0.549555  [   22/   89]
per-ex loss: 0.421770  [   24/   89]
per-ex loss: 0.542746  [   26/   89]
per-ex loss: 0.467113  [   28/   89]
per-ex loss: 0.521271  [   30/   89]
per-ex loss: 0.428048  [   32/   89]
per-ex loss: 0.512146  [   34/   89]
per-ex loss: 0.397717  [   36/   89]
per-ex loss: 0.380465  [   38/   89]
per-ex loss: 0.478480  [   40/   89]
per-ex loss: 0.417164  [   42/   89]
per-ex loss: 0.381709  [   44/   89]
per-ex loss: 0.406653  [   46/   89]
per-ex loss: 0.403428  [   48/   89]
per-ex loss: 0.486509  [   50/   89]
per-ex loss: 0.365025  [   52/   89]
per-ex loss: 0.404191  [   54/   89]
per-ex loss: 0.487272  [   56/   89]
per-ex loss: 0.499523  [   58/   89]
per-ex loss: 0.401164  [   60/   89]
per-ex loss: 0.599643  [   62/   89]
per-ex loss: 0.479386  [   64/   89]
per-ex loss: 0.492632  [   66/   89]
per-ex loss: 0.519119  [   68/   89]
per-ex loss: 0.403941  [   70/   89]
per-ex loss: 0.411047  [   72/   89]
per-ex loss: 0.493654  [   74/   89]
per-ex loss: 0.509794  [   76/   89]
per-ex loss: 0.357502  [   78/   89]
per-ex loss: 0.364653  [   80/   89]
per-ex loss: 0.518530  [   82/   89]
per-ex loss: 0.394838  [   84/   89]
per-ex loss: 0.578187  [   86/   89]
per-ex loss: 0.452695  [   88/   89]
per-ex loss: 0.315870  [   89/   89]
Train Error: Avg loss: 0.45776942
validation Error: 
 Avg loss: 0.98435144 
 F1: 0.518890 
 Precision: 0.545225 
 Recall: 0.494983
 IoU: 0.350339

test Error: 
 Avg loss: 0.98213171 
 F1: 0.534551 
 Precision: 0.548340 
 Recall: 0.521439
 IoU: 0.364770

We have finished training iteration 180
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_178_.pth
per-ex loss: 0.341987  [    2/   89]
per-ex loss: 0.524303  [    4/   89]
per-ex loss: 0.484340  [    6/   89]
per-ex loss: 0.373555  [    8/   89]
per-ex loss: 0.673350  [   10/   89]
per-ex loss: 0.356513  [   12/   89]
per-ex loss: 0.551632  [   14/   89]
per-ex loss: 0.368252  [   16/   89]
per-ex loss: 0.364593  [   18/   89]
per-ex loss: 0.437770  [   20/   89]
per-ex loss: 0.376019  [   22/   89]
per-ex loss: 0.381690  [   24/   89]
per-ex loss: 0.393570  [   26/   89]
per-ex loss: 0.552027  [   28/   89]
per-ex loss: 0.486446  [   30/   89]
per-ex loss: 0.435157  [   32/   89]
per-ex loss: 0.455627  [   34/   89]
per-ex loss: 0.540118  [   36/   89]
per-ex loss: 0.396951  [   38/   89]
per-ex loss: 0.375796  [   40/   89]
per-ex loss: 0.517106  [   42/   89]
per-ex loss: 0.633906  [   44/   89]
per-ex loss: 0.462471  [   46/   89]
per-ex loss: 0.554139  [   48/   89]
per-ex loss: 0.485719  [   50/   89]
per-ex loss: 0.545508  [   52/   89]
per-ex loss: 0.329392  [   54/   89]
per-ex loss: 0.377916  [   56/   89]
per-ex loss: 0.449036  [   58/   89]
per-ex loss: 0.529445  [   60/   89]
per-ex loss: 0.539573  [   62/   89]
per-ex loss: 0.370930  [   64/   89]
per-ex loss: 0.365031  [   66/   89]
per-ex loss: 0.447425  [   68/   89]
per-ex loss: 0.372176  [   70/   89]
per-ex loss: 0.648689  [   72/   89]
per-ex loss: 0.458308  [   74/   89]
per-ex loss: 0.411060  [   76/   89]
per-ex loss: 0.388288  [   78/   89]
per-ex loss: 0.575771  [   80/   89]
per-ex loss: 0.431116  [   82/   89]
per-ex loss: 0.417924  [   84/   89]
per-ex loss: 0.338691  [   86/   89]
per-ex loss: 0.393515  [   88/   89]
per-ex loss: 0.432381  [   89/   89]
Train Error: Avg loss: 0.45211578
validation Error: 
 Avg loss: 0.98457367 
 F1: 0.518109 
 Precision: 0.544474 
 Recall: 0.494181
 IoU: 0.349627

test Error: 
 Avg loss: 0.98226273 
 F1: 0.539128 
 Precision: 0.551628 
 Recall: 0.527182
 IoU: 0.369045

We have finished training iteration 181
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_179_.pth
per-ex loss: 0.536449  [    2/   89]
per-ex loss: 0.480990  [    4/   89]
per-ex loss: 0.610560  [    6/   89]
per-ex loss: 0.499984  [    8/   89]
per-ex loss: 0.415714  [   10/   89]
per-ex loss: 0.401483  [   12/   89]
per-ex loss: 0.419477  [   14/   89]
per-ex loss: 0.448183  [   16/   89]
per-ex loss: 0.468630  [   18/   89]
per-ex loss: 0.330546  [   20/   89]
per-ex loss: 0.419756  [   22/   89]
per-ex loss: 0.503939  [   24/   89]
per-ex loss: 0.350020  [   26/   89]
per-ex loss: 0.446411  [   28/   89]
per-ex loss: 0.387293  [   30/   89]
per-ex loss: 0.458788  [   32/   89]
per-ex loss: 0.402729  [   34/   89]
per-ex loss: 0.480966  [   36/   89]
per-ex loss: 0.502759  [   38/   89]
per-ex loss: 0.357868  [   40/   89]
per-ex loss: 0.522132  [   42/   89]
per-ex loss: 0.495827  [   44/   89]
per-ex loss: 0.452707  [   46/   89]
per-ex loss: 0.429815  [   48/   89]
per-ex loss: 0.427496  [   50/   89]
per-ex loss: 0.370103  [   52/   89]
per-ex loss: 0.510782  [   54/   89]
per-ex loss: 0.427077  [   56/   89]
per-ex loss: 0.486251  [   58/   89]
per-ex loss: 0.538409  [   60/   89]
per-ex loss: 0.400018  [   62/   89]
per-ex loss: 0.396598  [   64/   89]
per-ex loss: 0.483366  [   66/   89]
per-ex loss: 0.425111  [   68/   89]
per-ex loss: 0.390632  [   70/   89]
per-ex loss: 0.369066  [   72/   89]
per-ex loss: 0.411505  [   74/   89]
per-ex loss: 0.554383  [   76/   89]
per-ex loss: 0.595912  [   78/   89]
per-ex loss: 0.534776  [   80/   89]
per-ex loss: 0.462696  [   82/   89]
per-ex loss: 0.367674  [   84/   89]
per-ex loss: 0.393665  [   86/   89]
per-ex loss: 0.371798  [   88/   89]
per-ex loss: 0.400189  [   89/   89]
Train Error: Avg loss: 0.44756746
validation Error: 
 Avg loss: 0.98158696 
 F1: 0.517707 
 Precision: 0.586757 
 Recall: 0.463198
 IoU: 0.349261

test Error: 
 Avg loss: 0.98029948 
 F1: 0.541018 
 Precision: 0.607175 
 Recall: 0.487861
 IoU: 0.370819

We have finished training iteration 182
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_180_.pth
per-ex loss: 0.400124  [    2/   89]
per-ex loss: 0.510943  [    4/   89]
per-ex loss: 0.375971  [    6/   89]
per-ex loss: 0.452089  [    8/   89]
per-ex loss: 0.376559  [   10/   89]
per-ex loss: 0.427197  [   12/   89]
per-ex loss: 0.381886  [   14/   89]
per-ex loss: 0.475168  [   16/   89]
per-ex loss: 0.372139  [   18/   89]
per-ex loss: 0.638628  [   20/   89]
per-ex loss: 0.355448  [   22/   89]
per-ex loss: 0.503027  [   24/   89]
per-ex loss: 0.476269  [   26/   89]
per-ex loss: 0.399888  [   28/   89]
per-ex loss: 0.546115  [   30/   89]
per-ex loss: 0.510109  [   32/   89]
per-ex loss: 0.406747  [   34/   89]
per-ex loss: 0.405244  [   36/   89]
per-ex loss: 0.406636  [   38/   89]
per-ex loss: 0.473087  [   40/   89]
per-ex loss: 0.558526  [   42/   89]
per-ex loss: 0.477454  [   44/   89]
per-ex loss: 0.398031  [   46/   89]
per-ex loss: 0.344414  [   48/   89]
per-ex loss: 0.575654  [   50/   89]
per-ex loss: 0.479455  [   52/   89]
per-ex loss: 0.378014  [   54/   89]
per-ex loss: 0.432091  [   56/   89]
per-ex loss: 0.556438  [   58/   89]
per-ex loss: 0.440446  [   60/   89]
per-ex loss: 0.553307  [   62/   89]
per-ex loss: 0.392640  [   64/   89]
per-ex loss: 0.310728  [   66/   89]
per-ex loss: 0.587119  [   68/   89]
per-ex loss: 0.510767  [   70/   89]
per-ex loss: 0.490817  [   72/   89]
per-ex loss: 0.461214  [   74/   89]
per-ex loss: 0.461612  [   76/   89]
per-ex loss: 0.416518  [   78/   89]
per-ex loss: 0.355530  [   80/   89]
per-ex loss: 0.500353  [   82/   89]
per-ex loss: 0.448362  [   84/   89]
per-ex loss: 0.353743  [   86/   89]
per-ex loss: 0.404835  [   88/   89]
per-ex loss: 0.454913  [   89/   89]
Train Error: Avg loss: 0.44969466
validation Error: 
 Avg loss: 0.98332614 
 F1: 0.518076 
 Precision: 0.586464 
 Recall: 0.463972
 IoU: 0.349597

test Error: 
 Avg loss: 0.98055586 
 F1: 0.541066 
 Precision: 0.601155 
 Recall: 0.491897
 IoU: 0.370863

We have finished training iteration 183
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_181_.pth
per-ex loss: 0.499870  [    2/   89]
per-ex loss: 0.483314  [    4/   89]
per-ex loss: 0.377006  [    6/   89]
per-ex loss: 0.510311  [    8/   89]
per-ex loss: 0.470286  [   10/   89]
per-ex loss: 0.671916  [   12/   89]
per-ex loss: 0.423240  [   14/   89]
per-ex loss: 0.468102  [   16/   89]
per-ex loss: 0.551476  [   18/   89]
per-ex loss: 0.536863  [   20/   89]
per-ex loss: 0.451572  [   22/   89]
per-ex loss: 0.529174  [   24/   89]
per-ex loss: 0.500498  [   26/   89]
per-ex loss: 0.556692  [   28/   89]
per-ex loss: 0.373409  [   30/   89]
per-ex loss: 0.364965  [   32/   89]
per-ex loss: 0.347515  [   34/   89]
per-ex loss: 0.371888  [   36/   89]
per-ex loss: 0.457106  [   38/   89]
per-ex loss: 0.413679  [   40/   89]
per-ex loss: 0.320449  [   42/   89]
per-ex loss: 0.561382  [   44/   89]
per-ex loss: 0.309981  [   46/   89]
per-ex loss: 0.453013  [   48/   89]
per-ex loss: 0.368900  [   50/   89]
per-ex loss: 0.378818  [   52/   89]
per-ex loss: 0.420473  [   54/   89]
per-ex loss: 0.421733  [   56/   89]
per-ex loss: 0.432645  [   58/   89]
per-ex loss: 0.470577  [   60/   89]
per-ex loss: 0.390585  [   62/   89]
per-ex loss: 0.490046  [   64/   89]
per-ex loss: 0.423276  [   66/   89]
per-ex loss: 0.443386  [   68/   89]
per-ex loss: 0.630841  [   70/   89]
per-ex loss: 0.505981  [   72/   89]
per-ex loss: 0.400907  [   74/   89]
per-ex loss: 0.589408  [   76/   89]
per-ex loss: 0.395249  [   78/   89]
per-ex loss: 0.615507  [   80/   89]
per-ex loss: 0.438318  [   82/   89]
per-ex loss: 0.385031  [   84/   89]
per-ex loss: 0.398201  [   86/   89]
per-ex loss: 0.376018  [   88/   89]
per-ex loss: 0.772665  [   89/   89]
Train Error: Avg loss: 0.46116164
validation Error: 
 Avg loss: 0.98368567 
 F1: 0.515331 
 Precision: 0.588367 
 Recall: 0.458425
 IoU: 0.347101

test Error: 
 Avg loss: 0.98093348 
 F1: 0.542230 
 Precision: 0.605243 
 Recall: 0.491101
 IoU: 0.371959

We have finished training iteration 184
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_182_.pth
per-ex loss: 0.562903  [    2/   89]
per-ex loss: 0.401325  [    4/   89]
per-ex loss: 0.544570  [    6/   89]
per-ex loss: 0.437586  [    8/   89]
per-ex loss: 0.396172  [   10/   89]
per-ex loss: 0.363630  [   12/   89]
per-ex loss: 0.373690  [   14/   89]
per-ex loss: 0.372826  [   16/   89]
per-ex loss: 0.413656  [   18/   89]
per-ex loss: 0.330117  [   20/   89]
per-ex loss: 0.530125  [   22/   89]
per-ex loss: 0.348608  [   24/   89]
per-ex loss: 0.409777  [   26/   89]
per-ex loss: 0.466810  [   28/   89]
per-ex loss: 0.434294  [   30/   89]
per-ex loss: 0.374214  [   32/   89]
per-ex loss: 0.442095  [   34/   89]
per-ex loss: 0.439152  [   36/   89]
per-ex loss: 0.545811  [   38/   89]
per-ex loss: 0.393841  [   40/   89]
per-ex loss: 0.367060  [   42/   89]
per-ex loss: 0.431949  [   44/   89]
per-ex loss: 0.462272  [   46/   89]
per-ex loss: 0.589735  [   48/   89]
per-ex loss: 0.490496  [   50/   89]
per-ex loss: 0.387158  [   52/   89]
per-ex loss: 0.428248  [   54/   89]
per-ex loss: 0.382084  [   56/   89]
per-ex loss: 0.405842  [   58/   89]
per-ex loss: 0.437303  [   60/   89]
per-ex loss: 0.403654  [   62/   89]
per-ex loss: 0.463055  [   64/   89]
per-ex loss: 0.565124  [   66/   89]
per-ex loss: 0.471039  [   68/   89]
per-ex loss: 0.587395  [   70/   89]
per-ex loss: 0.369681  [   72/   89]
per-ex loss: 0.441053  [   74/   89]
per-ex loss: 0.433426  [   76/   89]
per-ex loss: 0.594668  [   78/   89]
per-ex loss: 0.414445  [   80/   89]
per-ex loss: 0.430999  [   82/   89]
per-ex loss: 0.473877  [   84/   89]
per-ex loss: 0.476148  [   86/   89]
per-ex loss: 0.324919  [   88/   89]
per-ex loss: 0.379171  [   89/   89]
Train Error: Avg loss: 0.43982224
validation Error: 
 Avg loss: 0.98313213 
 F1: 0.520920 
 Precision: 0.582702 
 Recall: 0.470983
 IoU: 0.352192

test Error: 
 Avg loss: 0.98015916 
 F1: 0.547996 
 Precision: 0.601535 
 Recall: 0.503208
 IoU: 0.377406

We have finished training iteration 185
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_183_.pth
per-ex loss: 0.486264  [    2/   89]
per-ex loss: 0.567106  [    4/   89]
per-ex loss: 0.488939  [    6/   89]
per-ex loss: 0.472964  [    8/   89]
per-ex loss: 0.374385  [   10/   89]
per-ex loss: 0.410181  [   12/   89]
per-ex loss: 0.385195  [   14/   89]
per-ex loss: 0.419890  [   16/   89]
per-ex loss: 0.349503  [   18/   89]
per-ex loss: 0.398485  [   20/   89]
per-ex loss: 0.566857  [   22/   89]
per-ex loss: 0.416166  [   24/   89]
per-ex loss: 0.522198  [   26/   89]
per-ex loss: 0.473993  [   28/   89]
per-ex loss: 0.591539  [   30/   89]
per-ex loss: 0.522902  [   32/   89]
per-ex loss: 0.374090  [   34/   89]
per-ex loss: 0.367851  [   36/   89]
per-ex loss: 0.568722  [   38/   89]
per-ex loss: 0.539516  [   40/   89]
per-ex loss: 0.470048  [   42/   89]
per-ex loss: 0.578151  [   44/   89]
per-ex loss: 0.517313  [   46/   89]
per-ex loss: 0.450562  [   48/   89]
per-ex loss: 0.458769  [   50/   89]
per-ex loss: 0.411772  [   52/   89]
per-ex loss: 0.378467  [   54/   89]
per-ex loss: 0.397644  [   56/   89]
per-ex loss: 0.379905  [   58/   89]
per-ex loss: 0.492020  [   60/   89]
per-ex loss: 0.463365  [   62/   89]
per-ex loss: 0.330685  [   64/   89]
per-ex loss: 0.469850  [   66/   89]
per-ex loss: 0.651109  [   68/   89]
per-ex loss: 0.538567  [   70/   89]
per-ex loss: 0.430302  [   72/   89]
per-ex loss: 0.439785  [   74/   89]
per-ex loss: 0.442218  [   76/   89]
per-ex loss: 0.522564  [   78/   89]
per-ex loss: 0.486818  [   80/   89]
per-ex loss: 0.443349  [   82/   89]
per-ex loss: 0.318827  [   84/   89]
per-ex loss: 0.479192  [   86/   89]
per-ex loss: 0.398155  [   88/   89]
per-ex loss: 0.470739  [   89/   89]
Train Error: Avg loss: 0.46037608
validation Error: 
 Avg loss: 0.98224541 
 F1: 0.512837 
 Precision: 0.618764 
 Recall: 0.437876
 IoU: 0.344842

test Error: 
 Avg loss: 0.97924064 
 F1: 0.534945 
 Precision: 0.651775 
 Recall: 0.453631
 IoU: 0.365136

We have finished training iteration 186
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_184_.pth
per-ex loss: 0.535393  [    2/   89]
per-ex loss: 0.392462  [    4/   89]
per-ex loss: 0.417878  [    6/   89]
per-ex loss: 0.376470  [    8/   89]
per-ex loss: 0.684367  [   10/   89]
per-ex loss: 0.558946  [   12/   89]
per-ex loss: 0.420526  [   14/   89]
per-ex loss: 0.447452  [   16/   89]
per-ex loss: 0.398611  [   18/   89]
per-ex loss: 0.391187  [   20/   89]
per-ex loss: 0.460056  [   22/   89]
per-ex loss: 0.623895  [   24/   89]
per-ex loss: 0.498339  [   26/   89]
per-ex loss: 0.371874  [   28/   89]
per-ex loss: 0.433709  [   30/   89]
per-ex loss: 0.421813  [   32/   89]
per-ex loss: 0.344717  [   34/   89]
per-ex loss: 0.385733  [   36/   89]
per-ex loss: 0.593335  [   38/   89]
per-ex loss: 0.508234  [   40/   89]
per-ex loss: 0.582794  [   42/   89]
per-ex loss: 0.465975  [   44/   89]
per-ex loss: 0.535520  [   46/   89]
per-ex loss: 0.387669  [   48/   89]
per-ex loss: 0.388739  [   50/   89]
per-ex loss: 0.429404  [   52/   89]
per-ex loss: 0.368404  [   54/   89]
per-ex loss: 0.320183  [   56/   89]
per-ex loss: 0.432900  [   58/   89]
per-ex loss: 0.520950  [   60/   89]
per-ex loss: 0.453889  [   62/   89]
per-ex loss: 0.592828  [   64/   89]
per-ex loss: 0.361123  [   66/   89]
per-ex loss: 0.453562  [   68/   89]
per-ex loss: 0.458703  [   70/   89]
per-ex loss: 0.401946  [   72/   89]
per-ex loss: 0.402553  [   74/   89]
per-ex loss: 0.304596  [   76/   89]
per-ex loss: 0.469633  [   78/   89]
per-ex loss: 0.407453  [   80/   89]
per-ex loss: 0.468600  [   82/   89]
per-ex loss: 0.578530  [   84/   89]
per-ex loss: 0.379217  [   86/   89]
per-ex loss: 0.433213  [   88/   89]
per-ex loss: 0.418719  [   89/   89]
Train Error: Avg loss: 0.45071332
validation Error: 
 Avg loss: 0.98361706 
 F1: 0.519062 
 Precision: 0.560147 
 Recall: 0.483593
 IoU: 0.350496

test Error: 
 Avg loss: 0.98161588 
 F1: 0.542095 
 Precision: 0.578818 
 Recall: 0.509753
 IoU: 0.371831

We have finished training iteration 187
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_185_.pth
Error in cropping the image to the non-zero values in the fourth channel. Returned the original image.
per-ex loss: 0.476710  [    2/   89]
per-ex loss: 0.399555  [    4/   89]
per-ex loss: 0.349602  [    6/   89]
per-ex loss: 0.449618  [    8/   89]
per-ex loss: 0.373343  [   10/   89]
per-ex loss: 0.392061  [   12/   89]
per-ex loss: 0.375430  [   14/   89]
per-ex loss: 0.567013  [   16/   89]
per-ex loss: 0.453943  [   18/   89]
per-ex loss: 0.460304  [   20/   89]
per-ex loss: 0.322664  [   22/   89]
per-ex loss: 0.353030  [   24/   89]
per-ex loss: 0.439176  [   26/   89]
per-ex loss: 0.438325  [   28/   89]
per-ex loss: 0.486573  [   30/   89]
per-ex loss: 0.451371  [   32/   89]
per-ex loss: 0.532512  [   34/   89]
per-ex loss: 0.475494  [   36/   89]
per-ex loss: 0.505524  [   38/   89]
per-ex loss: 0.557605  [   40/   89]
per-ex loss: 0.454933  [   42/   89]
per-ex loss: 0.388032  [   44/   89]
per-ex loss: 0.420198  [   46/   89]
per-ex loss: 0.464339  [   48/   89]
per-ex loss: 0.585585  [   50/   89]
per-ex loss: 0.414321  [   52/   89]
per-ex loss: 0.360779  [   54/   89]
per-ex loss: 0.394884  [   56/   89]
per-ex loss: 0.376470  [   58/   89]
per-ex loss: 0.384869  [   60/   89]
per-ex loss: 0.553619  [   62/   89]
per-ex loss: 0.517732  [   64/   89]
per-ex loss: 0.461590  [   66/   89]
per-ex loss: 0.461292  [   68/   89]
per-ex loss: 0.529754  [   70/   89]
per-ex loss: 0.340046  [   72/   89]
per-ex loss: 0.515325  [   74/   89]
per-ex loss: 0.380747  [   76/   89]
per-ex loss: 0.489892  [   78/   89]
per-ex loss: 0.366968  [   80/   89]
per-ex loss: 0.448704  [   82/   89]
per-ex loss: 0.541771  [   84/   89]
per-ex loss: 0.445262  [   86/   89]
per-ex loss: 0.367374  [   88/   89]
per-ex loss: 0.464198  [   89/   89]
Train Error: Avg loss: 0.44418968
validation Error: 
 Avg loss: 0.98385300 
 F1: 0.516281 
 Precision: 0.592869 
 Recall: 0.457217
 IoU: 0.347964

test Error: 
 Avg loss: 0.98167980 
 F1: 0.537663 
 Precision: 0.602384 
 Recall: 0.485500
 IoU: 0.367673

We have finished training iteration 188
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_186_.pth
per-ex loss: 0.485474  [    2/   89]
per-ex loss: 0.328545  [    4/   89]
per-ex loss: 0.400150  [    6/   89]
per-ex loss: 0.527833  [    8/   89]
per-ex loss: 0.434680  [   10/   89]
per-ex loss: 0.376086  [   12/   89]
per-ex loss: 0.404058  [   14/   89]
per-ex loss: 0.522266  [   16/   89]
per-ex loss: 0.333539  [   18/   89]
per-ex loss: 0.375114  [   20/   89]
per-ex loss: 0.438113  [   22/   89]
per-ex loss: 0.446399  [   24/   89]
per-ex loss: 0.367765  [   26/   89]
per-ex loss: 0.637233  [   28/   89]
per-ex loss: 0.363565  [   30/   89]
per-ex loss: 0.415476  [   32/   89]
per-ex loss: 0.425106  [   34/   89]
per-ex loss: 0.399794  [   36/   89]
per-ex loss: 0.488677  [   38/   89]
per-ex loss: 0.544794  [   40/   89]
per-ex loss: 0.474114  [   42/   89]
per-ex loss: 0.543240  [   44/   89]
per-ex loss: 0.379055  [   46/   89]
per-ex loss: 0.405246  [   48/   89]
per-ex loss: 0.538382  [   50/   89]
per-ex loss: 0.529893  [   52/   89]
per-ex loss: 0.543878  [   54/   89]
per-ex loss: 0.371298  [   56/   89]
per-ex loss: 0.587654  [   58/   89]
per-ex loss: 0.464481  [   60/   89]
per-ex loss: 0.411792  [   62/   89]
per-ex loss: 0.369146  [   64/   89]
per-ex loss: 0.405380  [   66/   89]
per-ex loss: 0.595747  [   68/   89]
per-ex loss: 0.421648  [   70/   89]
per-ex loss: 0.466855  [   72/   89]
per-ex loss: 0.541119  [   74/   89]
per-ex loss: 0.446540  [   76/   89]
per-ex loss: 0.451860  [   78/   89]
per-ex loss: 0.377165  [   80/   89]
per-ex loss: 0.559408  [   82/   89]
per-ex loss: 0.411800  [   84/   89]
per-ex loss: 0.397528  [   86/   89]
per-ex loss: 0.451924  [   88/   89]
per-ex loss: 0.593297  [   89/   89]
Train Error: Avg loss: 0.45451369
validation Error: 
 Avg loss: 0.98121720 
 F1: 0.511471 
 Precision: 0.619403 
 Recall: 0.435572
 IoU: 0.343608

test Error: 
 Avg loss: 0.97975559 
 F1: 0.537355 
 Precision: 0.644601 
 Recall: 0.460706
 IoU: 0.367386

We have finished training iteration 189
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_187_.pth
per-ex loss: 0.389166  [    2/   89]
per-ex loss: 0.511149  [    4/   89]
per-ex loss: 0.370469  [    6/   89]
per-ex loss: 0.392328  [    8/   89]
per-ex loss: 0.405830  [   10/   89]
per-ex loss: 0.534610  [   12/   89]
per-ex loss: 0.383609  [   14/   89]
per-ex loss: 0.446250  [   16/   89]
per-ex loss: 0.638312  [   18/   89]
per-ex loss: 0.383251  [   20/   89]
per-ex loss: 0.524635  [   22/   89]
per-ex loss: 0.366795  [   24/   89]
per-ex loss: 0.443203  [   26/   89]
per-ex loss: 0.393333  [   28/   89]
per-ex loss: 0.454700  [   30/   89]
per-ex loss: 0.511271  [   32/   89]
per-ex loss: 0.435188  [   34/   89]
per-ex loss: 0.308985  [   36/   89]
per-ex loss: 0.382504  [   38/   89]
per-ex loss: 0.478633  [   40/   89]
per-ex loss: 0.510951  [   42/   89]
per-ex loss: 0.477131  [   44/   89]
per-ex loss: 0.383718  [   46/   89]
per-ex loss: 0.333492  [   48/   89]
per-ex loss: 0.543988  [   50/   89]
per-ex loss: 0.461291  [   52/   89]
per-ex loss: 0.337996  [   54/   89]
per-ex loss: 0.452720  [   56/   89]
per-ex loss: 0.456830  [   58/   89]
per-ex loss: 0.479157  [   60/   89]
per-ex loss: 0.609320  [   62/   89]
per-ex loss: 0.574059  [   64/   89]
per-ex loss: 0.437260  [   66/   89]
per-ex loss: 0.506291  [   68/   89]
per-ex loss: 0.566618  [   70/   89]
per-ex loss: 0.395013  [   72/   89]
per-ex loss: 0.405544  [   74/   89]
per-ex loss: 0.488916  [   76/   89]
per-ex loss: 0.466249  [   78/   89]
per-ex loss: 0.366838  [   80/   89]
per-ex loss: 0.403639  [   82/   89]
per-ex loss: 0.519142  [   84/   89]
per-ex loss: 0.452340  [   86/   89]
per-ex loss: 0.394301  [   88/   89]
per-ex loss: 0.543667  [   89/   89]
Train Error: Avg loss: 0.45157092
validation Error: 
 Avg loss: 0.98366700 
 F1: 0.520497 
 Precision: 0.559769 
 Recall: 0.486374
 IoU: 0.351805

test Error: 
 Avg loss: 0.98147593 
 F1: 0.544943 
 Precision: 0.570673 
 Recall: 0.521432
 IoU: 0.374516

We have finished training iteration 190
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_188_.pth
per-ex loss: 0.462651  [    2/   89]
per-ex loss: 0.440673  [    4/   89]
per-ex loss: 0.464982  [    6/   89]
per-ex loss: 0.390314  [    8/   89]
per-ex loss: 0.457723  [   10/   89]
per-ex loss: 0.497229  [   12/   89]
per-ex loss: 0.328096  [   14/   89]
per-ex loss: 0.354469  [   16/   89]
per-ex loss: 0.538870  [   18/   89]
per-ex loss: 0.461025  [   20/   89]
per-ex loss: 0.379576  [   22/   89]
per-ex loss: 0.481216  [   24/   89]
per-ex loss: 0.506566  [   26/   89]
per-ex loss: 0.497837  [   28/   89]
per-ex loss: 0.363242  [   30/   89]
per-ex loss: 0.421814  [   32/   89]
per-ex loss: 0.402024  [   34/   89]
per-ex loss: 0.356100  [   36/   89]
per-ex loss: 0.500831  [   38/   89]
per-ex loss: 0.416586  [   40/   89]
per-ex loss: 0.675907  [   42/   89]
per-ex loss: 0.503943  [   44/   89]
per-ex loss: 0.380764  [   46/   89]
per-ex loss: 0.406808  [   48/   89]
per-ex loss: 0.294699  [   50/   89]
per-ex loss: 0.651323  [   52/   89]
per-ex loss: 0.496148  [   54/   89]
per-ex loss: 0.520349  [   56/   89]
per-ex loss: 0.526308  [   58/   89]
per-ex loss: 0.440075  [   60/   89]
per-ex loss: 0.416312  [   62/   89]
per-ex loss: 0.421633  [   64/   89]
per-ex loss: 0.484576  [   66/   89]
per-ex loss: 0.613577  [   68/   89]
per-ex loss: 0.482980  [   70/   89]
per-ex loss: 0.351935  [   72/   89]
per-ex loss: 0.458552  [   74/   89]
per-ex loss: 0.396895  [   76/   89]
per-ex loss: 0.451069  [   78/   89]
per-ex loss: 0.390803  [   80/   89]
per-ex loss: 0.397100  [   82/   89]
per-ex loss: 0.477026  [   84/   89]
per-ex loss: 0.401236  [   86/   89]
per-ex loss: 0.651310  [   88/   89]
per-ex loss: 0.346244  [   89/   89]
Train Error: Avg loss: 0.45243102
validation Error: 
 Avg loss: 0.98371454 
 F1: 0.518826 
 Precision: 0.567603 
 Recall: 0.477769
 IoU: 0.350280

test Error: 
 Avg loss: 0.98172012 
 F1: 0.541433 
 Precision: 0.584003 
 Recall: 0.504647
 IoU: 0.371209

We have finished training iteration 191
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_189_.pth
per-ex loss: 0.369019  [    2/   89]
per-ex loss: 0.466232  [    4/   89]
per-ex loss: 0.603761  [    6/   89]
per-ex loss: 0.516221  [    8/   89]
per-ex loss: 0.418538  [   10/   89]
per-ex loss: 0.383553  [   12/   89]
per-ex loss: 0.416588  [   14/   89]
per-ex loss: 0.538113  [   16/   89]
per-ex loss: 0.481383  [   18/   89]
per-ex loss: 0.415094  [   20/   89]
per-ex loss: 0.428293  [   22/   89]
per-ex loss: 0.384451  [   24/   89]
per-ex loss: 0.362137  [   26/   89]
per-ex loss: 0.367057  [   28/   89]
per-ex loss: 0.450793  [   30/   89]
per-ex loss: 0.357049  [   32/   89]
per-ex loss: 0.575345  [   34/   89]
per-ex loss: 0.504114  [   36/   89]
per-ex loss: 0.369083  [   38/   89]
per-ex loss: 0.548529  [   40/   89]
per-ex loss: 0.629569  [   42/   89]
per-ex loss: 0.475166  [   44/   89]
per-ex loss: 0.401001  [   46/   89]
per-ex loss: 0.445643  [   48/   89]
per-ex loss: 0.333938  [   50/   89]
per-ex loss: 0.394014  [   52/   89]
per-ex loss: 0.329957  [   54/   89]
per-ex loss: 0.441121  [   56/   89]
per-ex loss: 0.486959  [   58/   89]
per-ex loss: 0.609579  [   60/   89]
per-ex loss: 0.482456  [   62/   89]
per-ex loss: 0.542471  [   64/   89]
per-ex loss: 0.623317  [   66/   89]
per-ex loss: 0.641768  [   68/   89]
per-ex loss: 0.463212  [   70/   89]
per-ex loss: 0.412349  [   72/   89]
per-ex loss: 0.464358  [   74/   89]
per-ex loss: 0.400514  [   76/   89]
per-ex loss: 0.399682  [   78/   89]
per-ex loss: 0.389701  [   80/   89]
per-ex loss: 0.363500  [   82/   89]
per-ex loss: 0.437175  [   84/   89]
per-ex loss: 0.585976  [   86/   89]
per-ex loss: 0.392310  [   88/   89]
per-ex loss: 0.525736  [   89/   89]
Train Error: Avg loss: 0.45837381
validation Error: 
 Avg loss: 0.98317194 
 F1: 0.516004 
 Precision: 0.583736 
 Recall: 0.462355
 IoU: 0.347712

test Error: 
 Avg loss: 0.98044236 
 F1: 0.543673 
 Precision: 0.600373 
 Recall: 0.496759
 IoU: 0.373318

We have finished training iteration 192
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_190_.pth
Error in cropping the image to the non-zero values in the fourth channel. Returned the original image.
per-ex loss: 0.426365  [    2/   89]
per-ex loss: 0.411309  [    4/   89]
per-ex loss: 0.554488  [    6/   89]
per-ex loss: 0.387521  [    8/   89]
per-ex loss: 0.379939  [   10/   89]
per-ex loss: 0.544285  [   12/   89]
per-ex loss: 0.396834  [   14/   89]
per-ex loss: 0.397118  [   16/   89]
per-ex loss: 0.402681  [   18/   89]
per-ex loss: 0.400503  [   20/   89]
per-ex loss: 0.644727  [   22/   89]
per-ex loss: 0.382898  [   24/   89]
per-ex loss: 0.449318  [   26/   89]
per-ex loss: 0.378468  [   28/   89]
per-ex loss: 0.585488  [   30/   89]
per-ex loss: 0.486958  [   32/   89]
per-ex loss: 0.419628  [   34/   89]
per-ex loss: 0.536565  [   36/   89]
per-ex loss: 0.416616  [   38/   89]
per-ex loss: 0.554504  [   40/   89]
per-ex loss: 0.399905  [   42/   89]
per-ex loss: 0.429159  [   44/   89]
per-ex loss: 0.333514  [   46/   89]
per-ex loss: 0.422547  [   48/   89]
per-ex loss: 0.382231  [   50/   89]
per-ex loss: 0.452535  [   52/   89]
per-ex loss: 0.315846  [   54/   89]
per-ex loss: 0.356709  [   56/   89]
per-ex loss: 0.621451  [   58/   89]
per-ex loss: 0.464444  [   60/   89]
per-ex loss: 0.413567  [   62/   89]
per-ex loss: 0.381655  [   64/   89]
per-ex loss: 0.428639  [   66/   89]
per-ex loss: 0.544602  [   68/   89]
per-ex loss: 0.429470  [   70/   89]
per-ex loss: 0.435297  [   72/   89]
per-ex loss: 0.541193  [   74/   89]
per-ex loss: 0.422158  [   76/   89]
per-ex loss: 0.662675  [   78/   89]
per-ex loss: 0.406675  [   80/   89]
per-ex loss: 0.367142  [   82/   89]
per-ex loss: 0.407349  [   84/   89]
per-ex loss: 0.382547  [   86/   89]
per-ex loss: 0.625337  [   88/   89]
per-ex loss: 0.335086  [   89/   89]
Train Error: Avg loss: 0.44706546
validation Error: 
 Avg loss: 0.98482700 
 F1: 0.516174 
 Precision: 0.543562 
 Recall: 0.491414
 IoU: 0.347867

test Error: 
 Avg loss: 0.98222086 
 F1: 0.539245 
 Precision: 0.557893 
 Recall: 0.521804
 IoU: 0.369155

We have finished training iteration 193
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_191_.pth
per-ex loss: 0.582530  [    2/   89]
per-ex loss: 0.505083  [    4/   89]
per-ex loss: 0.454784  [    6/   89]
per-ex loss: 0.372653  [    8/   89]
per-ex loss: 0.372522  [   10/   89]
per-ex loss: 0.400683  [   12/   89]
per-ex loss: 0.427844  [   14/   89]
per-ex loss: 0.481965  [   16/   89]
per-ex loss: 0.484100  [   18/   89]
per-ex loss: 0.448806  [   20/   89]
per-ex loss: 0.467023  [   22/   89]
per-ex loss: 0.417574  [   24/   89]
per-ex loss: 0.358749  [   26/   89]
per-ex loss: 0.566312  [   28/   89]
per-ex loss: 0.445758  [   30/   89]
per-ex loss: 0.514103  [   32/   89]
per-ex loss: 0.574683  [   34/   89]
per-ex loss: 0.416539  [   36/   89]
per-ex loss: 0.360677  [   38/   89]
per-ex loss: 0.433871  [   40/   89]
per-ex loss: 0.456212  [   42/   89]
per-ex loss: 0.352209  [   44/   89]
per-ex loss: 0.426120  [   46/   89]
per-ex loss: 0.559180  [   48/   89]
per-ex loss: 0.449059  [   50/   89]
per-ex loss: 0.454362  [   52/   89]
per-ex loss: 0.409065  [   54/   89]
per-ex loss: 0.383089  [   56/   89]
per-ex loss: 0.362109  [   58/   89]
per-ex loss: 0.425849  [   60/   89]
per-ex loss: 0.612718  [   62/   89]
per-ex loss: 0.394798  [   64/   89]
per-ex loss: 0.590001  [   66/   89]
per-ex loss: 0.556746  [   68/   89]
per-ex loss: 0.418286  [   70/   89]
per-ex loss: 0.470311  [   72/   89]
per-ex loss: 0.464578  [   74/   89]
per-ex loss: 0.383655  [   76/   89]
per-ex loss: 0.410549  [   78/   89]
per-ex loss: 0.403719  [   80/   89]
per-ex loss: 0.405572  [   82/   89]
per-ex loss: 0.370531  [   84/   89]
per-ex loss: 0.356789  [   86/   89]
per-ex loss: 0.480567  [   88/   89]
per-ex loss: 0.521172  [   89/   89]
Train Error: Avg loss: 0.44896672
validation Error: 
 Avg loss: 0.98275286 
 F1: 0.513537 
 Precision: 0.565274 
 Recall: 0.470477
 IoU: 0.345476

test Error: 
 Avg loss: 0.98092401 
 F1: 0.528915 
 Precision: 0.572059 
 Recall: 0.491823
 IoU: 0.359541

We have finished training iteration 194
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_192_.pth
per-ex loss: 0.550309  [    2/   89]
per-ex loss: 0.424016  [    4/   89]
per-ex loss: 0.406826  [    6/   89]
per-ex loss: 0.403306  [    8/   89]
per-ex loss: 0.505372  [   10/   89]
per-ex loss: 0.417684  [   12/   89]
per-ex loss: 0.525465  [   14/   89]
per-ex loss: 0.525010  [   16/   89]
per-ex loss: 0.425929  [   18/   89]
per-ex loss: 0.524832  [   20/   89]
per-ex loss: 0.434919  [   22/   89]
per-ex loss: 0.452626  [   24/   89]
per-ex loss: 0.419507  [   26/   89]
per-ex loss: 0.377449  [   28/   89]
per-ex loss: 0.482206  [   30/   89]
per-ex loss: 0.380461  [   32/   89]
per-ex loss: 0.442914  [   34/   89]
per-ex loss: 0.510438  [   36/   89]
per-ex loss: 0.530844  [   38/   89]
per-ex loss: 0.399400  [   40/   89]
per-ex loss: 0.476065  [   42/   89]
per-ex loss: 0.360451  [   44/   89]
per-ex loss: 0.355696  [   46/   89]
per-ex loss: 0.378134  [   48/   89]
per-ex loss: 0.508891  [   50/   89]
per-ex loss: 0.497718  [   52/   89]
per-ex loss: 0.351612  [   54/   89]
per-ex loss: 0.556184  [   56/   89]
per-ex loss: 0.563096  [   58/   89]
per-ex loss: 0.540092  [   60/   89]
per-ex loss: 0.400363  [   62/   89]
per-ex loss: 0.435493  [   64/   89]
per-ex loss: 0.409778  [   66/   89]
per-ex loss: 0.483845  [   68/   89]
per-ex loss: 0.608901  [   70/   89]
per-ex loss: 0.466384  [   72/   89]
per-ex loss: 0.312482  [   74/   89]
per-ex loss: 0.605053  [   76/   89]
per-ex loss: 0.538170  [   78/   89]
per-ex loss: 0.405904  [   80/   89]
per-ex loss: 0.499448  [   82/   89]
per-ex loss: 0.414611  [   84/   89]
per-ex loss: 0.389524  [   86/   89]
per-ex loss: 0.441008  [   88/   89]
per-ex loss: 0.341975  [   89/   89]
Train Error: Avg loss: 0.45511981
validation Error: 
 Avg loss: 0.98558308 
 F1: 0.509033 
 Precision: 0.505945 
 Recall: 0.512158
 IoU: 0.341411

test Error: 
 Avg loss: 0.98370773 
 F1: 0.522376 
 Precision: 0.506329 
 Recall: 0.539475
 IoU: 0.353525

We have finished training iteration 195
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_193_.pth
per-ex loss: 0.362423  [    2/   89]
per-ex loss: 0.367999  [    4/   89]
per-ex loss: 0.630325  [    6/   89]
per-ex loss: 0.456990  [    8/   89]
per-ex loss: 0.482736  [   10/   89]
per-ex loss: 0.438572  [   12/   89]
per-ex loss: 0.361888  [   14/   89]
per-ex loss: 0.578086  [   16/   89]
per-ex loss: 0.646513  [   18/   89]
per-ex loss: 0.467297  [   20/   89]
per-ex loss: 0.410080  [   22/   89]
per-ex loss: 0.333279  [   24/   89]
per-ex loss: 0.542120  [   26/   89]
per-ex loss: 0.515318  [   28/   89]
per-ex loss: 0.513291  [   30/   89]
per-ex loss: 0.429223  [   32/   89]
per-ex loss: 0.486064  [   34/   89]
per-ex loss: 0.585341  [   36/   89]
per-ex loss: 0.419217  [   38/   89]
per-ex loss: 0.428818  [   40/   89]
per-ex loss: 0.421321  [   42/   89]
per-ex loss: 0.587020  [   44/   89]
per-ex loss: 0.349353  [   46/   89]
per-ex loss: 0.400725  [   48/   89]
per-ex loss: 0.462944  [   50/   89]
per-ex loss: 0.377391  [   52/   89]
per-ex loss: 0.343098  [   54/   89]
per-ex loss: 0.406958  [   56/   89]
per-ex loss: 0.461249  [   58/   89]
per-ex loss: 0.476495  [   60/   89]
per-ex loss: 0.349158  [   62/   89]
per-ex loss: 0.430066  [   64/   89]
per-ex loss: 0.405428  [   66/   89]
per-ex loss: 0.405202  [   68/   89]
per-ex loss: 0.314285  [   70/   89]
per-ex loss: 0.438931  [   72/   89]
per-ex loss: 0.403562  [   74/   89]
per-ex loss: 0.408634  [   76/   89]
per-ex loss: 0.454694  [   78/   89]
per-ex loss: 0.508408  [   80/   89]
per-ex loss: 0.374804  [   82/   89]
per-ex loss: 0.609675  [   84/   89]
per-ex loss: 0.583959  [   86/   89]
per-ex loss: 0.440623  [   88/   89]
per-ex loss: 0.358283  [   89/   89]
Train Error: Avg loss: 0.44950769
validation Error: 
 Avg loss: 0.98430694 
 F1: 0.520057 
 Precision: 0.560626 
 Recall: 0.484964
 IoU: 0.351404

test Error: 
 Avg loss: 0.98192717 
 F1: 0.542036 
 Precision: 0.564980 
 Recall: 0.520882
 IoU: 0.371776

We have finished training iteration 196
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_194_.pth
per-ex loss: 0.654709  [    2/   89]
per-ex loss: 0.530887  [    4/   89]
per-ex loss: 0.432241  [    6/   89]
per-ex loss: 0.312103  [    8/   89]
per-ex loss: 0.532424  [   10/   89]
per-ex loss: 0.419743  [   12/   89]
per-ex loss: 0.539958  [   14/   89]
per-ex loss: 0.574387  [   16/   89]
per-ex loss: 0.384037  [   18/   89]
per-ex loss: 0.608484  [   20/   89]
per-ex loss: 0.412316  [   22/   89]
per-ex loss: 0.542405  [   24/   89]
per-ex loss: 0.394218  [   26/   89]
per-ex loss: 0.484715  [   28/   89]
per-ex loss: 0.455203  [   30/   89]
per-ex loss: 0.355005  [   32/   89]
per-ex loss: 0.360196  [   34/   89]
per-ex loss: 0.338282  [   36/   89]
per-ex loss: 0.390276  [   38/   89]
per-ex loss: 0.343137  [   40/   89]
per-ex loss: 0.375772  [   42/   89]
per-ex loss: 0.398390  [   44/   89]
per-ex loss: 0.426153  [   46/   89]
per-ex loss: 0.449785  [   48/   89]
per-ex loss: 0.458297  [   50/   89]
per-ex loss: 0.439864  [   52/   89]
per-ex loss: 0.595682  [   54/   89]
per-ex loss: 0.547668  [   56/   89]
per-ex loss: 0.384587  [   58/   89]
per-ex loss: 0.432982  [   60/   89]
per-ex loss: 0.407071  [   62/   89]
per-ex loss: 0.425573  [   64/   89]
per-ex loss: 0.427000  [   66/   89]
per-ex loss: 0.520927  [   68/   89]
per-ex loss: 0.475093  [   70/   89]
per-ex loss: 0.507261  [   72/   89]
per-ex loss: 0.364002  [   74/   89]
per-ex loss: 0.385810  [   76/   89]
per-ex loss: 0.400943  [   78/   89]
per-ex loss: 0.496805  [   80/   89]
per-ex loss: 0.659319  [   82/   89]
per-ex loss: 0.397831  [   84/   89]
per-ex loss: 0.432450  [   86/   89]
per-ex loss: 0.381006  [   88/   89]
per-ex loss: 0.377315  [   89/   89]
Train Error: Avg loss: 0.44960697
validation Error: 
 Avg loss: 0.98447110 
 F1: 0.518029 
 Precision: 0.547497 
 Recall: 0.491572
 IoU: 0.349554

test Error: 
 Avg loss: 0.98240621 
 F1: 0.537609 
 Precision: 0.557670 
 Recall: 0.518941
 IoU: 0.367623

We have finished training iteration 197
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_195_.pth
per-ex loss: 0.389469  [    2/   89]
per-ex loss: 0.509872  [    4/   89]
per-ex loss: 0.533969  [    6/   89]
per-ex loss: 0.470320  [    8/   89]
per-ex loss: 0.370077  [   10/   89]
per-ex loss: 0.452064  [   12/   89]
per-ex loss: 0.507224  [   14/   89]
per-ex loss: 0.504494  [   16/   89]
per-ex loss: 0.436366  [   18/   89]
per-ex loss: 0.456657  [   20/   89]
per-ex loss: 0.418351  [   22/   89]
per-ex loss: 0.417292  [   24/   89]
per-ex loss: 0.404026  [   26/   89]
per-ex loss: 0.332800  [   28/   89]
per-ex loss: 0.512464  [   30/   89]
per-ex loss: 0.385905  [   32/   89]
per-ex loss: 0.414915  [   34/   89]
per-ex loss: 0.344973  [   36/   89]
per-ex loss: 0.676442  [   38/   89]
per-ex loss: 0.429467  [   40/   89]
per-ex loss: 0.358757  [   42/   89]
per-ex loss: 0.464690  [   44/   89]
per-ex loss: 0.332654  [   46/   89]
per-ex loss: 0.355028  [   48/   89]
per-ex loss: 0.531975  [   50/   89]
per-ex loss: 0.384170  [   52/   89]
per-ex loss: 0.439990  [   54/   89]
per-ex loss: 0.513910  [   56/   89]
per-ex loss: 0.384500  [   58/   89]
per-ex loss: 0.423280  [   60/   89]
per-ex loss: 0.439964  [   62/   89]
per-ex loss: 0.450720  [   64/   89]
per-ex loss: 0.604952  [   66/   89]
per-ex loss: 0.467748  [   68/   89]
per-ex loss: 0.542452  [   70/   89]
per-ex loss: 0.453586  [   72/   89]
per-ex loss: 0.390787  [   74/   89]
per-ex loss: 0.387695  [   76/   89]
per-ex loss: 0.365070  [   78/   89]
per-ex loss: 0.562256  [   80/   89]
per-ex loss: 0.443699  [   82/   89]
per-ex loss: 0.430342  [   84/   89]
per-ex loss: 0.395885  [   86/   89]
per-ex loss: 0.672794  [   88/   89]
per-ex loss: 0.493076  [   89/   89]
Train Error: Avg loss: 0.45015841
validation Error: 
 Avg loss: 0.98267181 
 F1: 0.517022 
 Precision: 0.618766 
 Recall: 0.444013
 IoU: 0.348638

test Error: 
 Avg loss: 0.98004793 
 F1: 0.542306 
 Precision: 0.636250 
 Recall: 0.472534
 IoU: 0.372030

We have finished training iteration 198
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_196_.pth
per-ex loss: 0.413997  [    2/   89]
per-ex loss: 0.523779  [    4/   89]
per-ex loss: 0.384357  [    6/   89]
per-ex loss: 0.419193  [    8/   89]
per-ex loss: 0.573755  [   10/   89]
per-ex loss: 0.597303  [   12/   89]
per-ex loss: 0.369347  [   14/   89]
per-ex loss: 0.470831  [   16/   89]
per-ex loss: 0.478355  [   18/   89]
per-ex loss: 0.472919  [   20/   89]
per-ex loss: 0.390007  [   22/   89]
per-ex loss: 0.413652  [   24/   89]
per-ex loss: 0.449000  [   26/   89]
per-ex loss: 0.358883  [   28/   89]
per-ex loss: 0.534701  [   30/   89]
per-ex loss: 0.395493  [   32/   89]
per-ex loss: 0.339175  [   34/   89]
per-ex loss: 0.504257  [   36/   89]
per-ex loss: 0.402221  [   38/   89]
per-ex loss: 0.385759  [   40/   89]
per-ex loss: 0.340247  [   42/   89]
per-ex loss: 0.490410  [   44/   89]
per-ex loss: 0.408615  [   46/   89]
per-ex loss: 0.717876  [   48/   89]
per-ex loss: 0.434307  [   50/   89]
per-ex loss: 0.443667  [   52/   89]
per-ex loss: 0.374859  [   54/   89]
per-ex loss: 0.419571  [   56/   89]
per-ex loss: 0.388919  [   58/   89]
per-ex loss: 0.456701  [   60/   89]
per-ex loss: 0.397040  [   62/   89]
per-ex loss: 0.550528  [   64/   89]
per-ex loss: 0.336094  [   66/   89]
per-ex loss: 0.371087  [   68/   89]
per-ex loss: 0.383864  [   70/   89]
per-ex loss: 0.606634  [   72/   89]
per-ex loss: 0.487924  [   74/   89]
per-ex loss: 0.565262  [   76/   89]
per-ex loss: 0.364815  [   78/   89]
per-ex loss: 0.392550  [   80/   89]
per-ex loss: 0.504821  [   82/   89]
per-ex loss: 0.533051  [   84/   89]
per-ex loss: 0.442809  [   86/   89]
per-ex loss: 0.353758  [   88/   89]
per-ex loss: 0.437050  [   89/   89]
Train Error: Avg loss: 0.44620982
validation Error: 
 Avg loss: 0.98398685 
 F1: 0.515879 
 Precision: 0.562575 
 Recall: 0.476341
 IoU: 0.347599

test Error: 
 Avg loss: 0.98170899 
 F1: 0.539823 
 Precision: 0.576199 
 Recall: 0.507767
 IoU: 0.369697

We have finished training iteration 199
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_197_.pth
per-ex loss: 0.356420  [    2/   89]
per-ex loss: 0.530653  [    4/   89]
per-ex loss: 0.455853  [    6/   89]
per-ex loss: 0.443730  [    8/   89]
per-ex loss: 0.417205  [   10/   89]
per-ex loss: 0.533033  [   12/   89]
per-ex loss: 0.565132  [   14/   89]
per-ex loss: 0.611236  [   16/   89]
per-ex loss: 0.454845  [   18/   89]
per-ex loss: 0.397051  [   20/   89]
per-ex loss: 0.457241  [   22/   89]
per-ex loss: 0.372934  [   24/   89]
per-ex loss: 0.631657  [   26/   89]
per-ex loss: 0.580225  [   28/   89]
per-ex loss: 0.402994  [   30/   89]
per-ex loss: 0.419638  [   32/   89]
per-ex loss: 0.452814  [   34/   89]
per-ex loss: 0.504861  [   36/   89]
per-ex loss: 0.427941  [   38/   89]
per-ex loss: 0.526673  [   40/   89]
per-ex loss: 0.451311  [   42/   89]
per-ex loss: 0.398538  [   44/   89]
per-ex loss: 0.336180  [   46/   89]
per-ex loss: 0.537128  [   48/   89]
per-ex loss: 0.451650  [   50/   89]
per-ex loss: 0.377129  [   52/   89]
per-ex loss: 0.354517  [   54/   89]
per-ex loss: 0.477482  [   56/   89]
per-ex loss: 0.425136  [   58/   89]
per-ex loss: 0.492826  [   60/   89]
per-ex loss: 0.469025  [   62/   89]
per-ex loss: 0.389059  [   64/   89]
per-ex loss: 0.414195  [   66/   89]
per-ex loss: 0.458529  [   68/   89]
per-ex loss: 0.384014  [   70/   89]
per-ex loss: 0.421215  [   72/   89]
per-ex loss: 0.386677  [   74/   89]
per-ex loss: 0.429427  [   76/   89]
per-ex loss: 0.382668  [   78/   89]
per-ex loss: 0.374795  [   80/   89]
per-ex loss: 0.462313  [   82/   89]
per-ex loss: 0.467511  [   84/   89]
per-ex loss: 0.361879  [   86/   89]
per-ex loss: 0.340460  [   88/   89]
per-ex loss: 0.502460  [   89/   89]
Train Error: Avg loss: 0.44640579
validation Error: 
 Avg loss: 0.98198393 
 F1: 0.512517 
 Precision: 0.603958 
 Recall: 0.445124
 IoU: 0.344553

test Error: 
 Avg loss: 0.98062701 
 F1: 0.532576 
 Precision: 0.591462 
 Recall: 0.484354
 IoU: 0.362933

We have finished training iteration 200
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_198_.pth
per-ex loss: 0.487306  [    2/   89]
per-ex loss: 0.361996  [    4/   89]
per-ex loss: 0.598974  [    6/   89]
per-ex loss: 0.613025  [    8/   89]
per-ex loss: 0.410397  [   10/   89]
per-ex loss: 0.369846  [   12/   89]
per-ex loss: 0.459188  [   14/   89]
per-ex loss: 0.405967  [   16/   89]
per-ex loss: 0.555257  [   18/   89]
per-ex loss: 0.442410  [   20/   89]
per-ex loss: 0.579497  [   22/   89]
per-ex loss: 0.363704  [   24/   89]
per-ex loss: 0.416132  [   26/   89]
per-ex loss: 0.345613  [   28/   89]
per-ex loss: 0.465012  [   30/   89]
per-ex loss: 0.424023  [   32/   89]
per-ex loss: 0.374641  [   34/   89]
per-ex loss: 0.443930  [   36/   89]
per-ex loss: 0.435771  [   38/   89]
per-ex loss: 0.370268  [   40/   89]
per-ex loss: 0.420170  [   42/   89]
per-ex loss: 0.460200  [   44/   89]
per-ex loss: 0.474224  [   46/   89]
per-ex loss: 0.467200  [   48/   89]
per-ex loss: 0.430252  [   50/   89]
per-ex loss: 0.422133  [   52/   89]
per-ex loss: 0.396804  [   54/   89]
per-ex loss: 0.584481  [   56/   89]
per-ex loss: 0.462461  [   58/   89]
per-ex loss: 0.429245  [   60/   89]
per-ex loss: 0.567704  [   62/   89]
per-ex loss: 0.416431  [   64/   89]
per-ex loss: 0.527761  [   66/   89]
per-ex loss: 0.507810  [   68/   89]
per-ex loss: 0.588085  [   70/   89]
per-ex loss: 0.397003  [   72/   89]
per-ex loss: 0.691221  [   74/   89]
per-ex loss: 0.435957  [   76/   89]
per-ex loss: 0.577913  [   78/   89]
per-ex loss: 0.547588  [   80/   89]
per-ex loss: 0.438861  [   82/   89]
per-ex loss: 0.567790  [   84/   89]
per-ex loss: 0.666044  [   86/   89]
per-ex loss: 0.354066  [   88/   89]
per-ex loss: 0.363643  [   89/   89]
Train Error: Avg loss: 0.46928897
validation Error: 
 Avg loss: 0.98399785 
 F1: 0.515581 
 Precision: 0.563560 
 Recall: 0.475129
 IoU: 0.347328

test Error: 
 Avg loss: 0.98216462 
 F1: 0.535814 
 Precision: 0.569580 
 Recall: 0.505828
 IoU: 0.365947

We have finished training iteration 201
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_199_.pth
per-ex loss: 0.563989  [    2/   89]
per-ex loss: 0.409365  [    4/   89]
per-ex loss: 0.461824  [    6/   89]
per-ex loss: 0.500802  [    8/   89]
per-ex loss: 0.467313  [   10/   89]
per-ex loss: 0.459814  [   12/   89]
per-ex loss: 0.498728  [   14/   89]
per-ex loss: 0.471525  [   16/   89]
per-ex loss: 0.372622  [   18/   89]
per-ex loss: 0.407122  [   20/   89]
per-ex loss: 0.475147  [   22/   89]
per-ex loss: 0.359621  [   24/   89]
per-ex loss: 0.340938  [   26/   89]
per-ex loss: 0.404622  [   28/   89]
per-ex loss: 0.402564  [   30/   89]
per-ex loss: 0.537376  [   32/   89]
per-ex loss: 0.581642  [   34/   89]
per-ex loss: 0.518694  [   36/   89]
per-ex loss: 0.666929  [   38/   89]
per-ex loss: 0.347454  [   40/   89]
per-ex loss: 0.401168  [   42/   89]
per-ex loss: 0.620721  [   44/   89]
per-ex loss: 0.392744  [   46/   89]
per-ex loss: 0.402440  [   48/   89]
per-ex loss: 0.442653  [   50/   89]
per-ex loss: 0.545483  [   52/   89]
per-ex loss: 0.367081  [   54/   89]
per-ex loss: 0.411120  [   56/   89]
per-ex loss: 0.426560  [   58/   89]
per-ex loss: 0.417536  [   60/   89]
per-ex loss: 0.368641  [   62/   89]
per-ex loss: 0.405149  [   64/   89]
per-ex loss: 0.549379  [   66/   89]
per-ex loss: 0.522718  [   68/   89]
per-ex loss: 0.422885  [   70/   89]
per-ex loss: 0.438566  [   72/   89]
per-ex loss: 0.315135  [   74/   89]
per-ex loss: 0.499823  [   76/   89]
per-ex loss: 0.424099  [   78/   89]
per-ex loss: 0.394776  [   80/   89]
per-ex loss: 0.565483  [   82/   89]
per-ex loss: 0.365043  [   84/   89]
per-ex loss: 0.408186  [   86/   89]
per-ex loss: 0.419081  [   88/   89]
per-ex loss: 0.531389  [   89/   89]
Train Error: Avg loss: 0.45124331
validation Error: 
 Avg loss: 0.98304070 
 F1: 0.512327 
 Precision: 0.598238 
 Recall: 0.447992
 IoU: 0.344381

test Error: 
 Avg loss: 0.98008982 
 F1: 0.539233 
 Precision: 0.617769 
 Recall: 0.478414
 IoU: 0.369144

We have finished training iteration 202
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_200_.pth
per-ex loss: 0.453172  [    2/   89]
per-ex loss: 0.334638  [    4/   89]
per-ex loss: 0.426452  [    6/   89]
per-ex loss: 0.372371  [    8/   89]
per-ex loss: 0.390239  [   10/   89]
per-ex loss: 0.557309  [   12/   89]
per-ex loss: 0.433285  [   14/   89]
per-ex loss: 0.346682  [   16/   89]
per-ex loss: 0.382093  [   18/   89]
per-ex loss: 0.552026  [   20/   89]
per-ex loss: 0.544049  [   22/   89]
per-ex loss: 0.513719  [   24/   89]
per-ex loss: 0.494743  [   26/   89]
per-ex loss: 0.390573  [   28/   89]
per-ex loss: 0.383733  [   30/   89]
per-ex loss: 0.336256  [   32/   89]
per-ex loss: 0.430240  [   34/   89]
per-ex loss: 0.605533  [   36/   89]
per-ex loss: 0.497492  [   38/   89]
per-ex loss: 0.340048  [   40/   89]
per-ex loss: 0.477974  [   42/   89]
per-ex loss: 0.450425  [   44/   89]
per-ex loss: 0.502625  [   46/   89]
per-ex loss: 0.385681  [   48/   89]
per-ex loss: 0.366566  [   50/   89]
per-ex loss: 0.627300  [   52/   89]
per-ex loss: 0.504527  [   54/   89]
per-ex loss: 0.360036  [   56/   89]
per-ex loss: 0.475204  [   58/   89]
per-ex loss: 0.435025  [   60/   89]
per-ex loss: 0.355487  [   62/   89]
per-ex loss: 0.547375  [   64/   89]
per-ex loss: 0.427882  [   66/   89]
per-ex loss: 0.554620  [   68/   89]
per-ex loss: 0.383387  [   70/   89]
per-ex loss: 0.569539  [   72/   89]
per-ex loss: 0.484164  [   74/   89]
per-ex loss: 0.565502  [   76/   89]
per-ex loss: 0.471960  [   78/   89]
per-ex loss: 0.374948  [   80/   89]
per-ex loss: 0.438371  [   82/   89]
per-ex loss: 0.492378  [   84/   89]
per-ex loss: 0.450809  [   86/   89]
per-ex loss: 0.388426  [   88/   89]
per-ex loss: 0.406306  [   89/   89]
Train Error: Avg loss: 0.45069264
validation Error: 
 Avg loss: 0.98448467 
 F1: 0.516653 
 Precision: 0.591677 
 Recall: 0.458514
 IoU: 0.348303

test Error: 
 Avg loss: 0.98223907 
 F1: 0.542582 
 Precision: 0.594999 
 Recall: 0.498653
 IoU: 0.372290

We have finished training iteration 203
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_201_.pth
per-ex loss: 0.400416  [    2/   89]
per-ex loss: 0.435930  [    4/   89]
per-ex loss: 0.595027  [    6/   89]
per-ex loss: 0.375453  [    8/   89]
per-ex loss: 0.410318  [   10/   89]
per-ex loss: 0.381207  [   12/   89]
per-ex loss: 0.518205  [   14/   89]
per-ex loss: 0.403837  [   16/   89]
per-ex loss: 0.647898  [   18/   89]
per-ex loss: 0.497582  [   20/   89]
per-ex loss: 0.326664  [   22/   89]
per-ex loss: 0.443622  [   24/   89]
per-ex loss: 0.426384  [   26/   89]
per-ex loss: 0.390166  [   28/   89]
per-ex loss: 0.453435  [   30/   89]
per-ex loss: 0.451142  [   32/   89]
per-ex loss: 0.468969  [   34/   89]
per-ex loss: 0.423023  [   36/   89]
per-ex loss: 0.581204  [   38/   89]
per-ex loss: 0.363327  [   40/   89]
per-ex loss: 0.579248  [   42/   89]
per-ex loss: 0.395571  [   44/   89]
per-ex loss: 0.465149  [   46/   89]
per-ex loss: 0.481813  [   48/   89]
per-ex loss: 0.372448  [   50/   89]
per-ex loss: 0.479303  [   52/   89]
per-ex loss: 0.416595  [   54/   89]
per-ex loss: 0.524316  [   56/   89]
per-ex loss: 0.396405  [   58/   89]
per-ex loss: 0.498249  [   60/   89]
per-ex loss: 0.402301  [   62/   89]
per-ex loss: 0.413048  [   64/   89]
per-ex loss: 0.653967  [   66/   89]
per-ex loss: 0.385555  [   68/   89]
per-ex loss: 0.387402  [   70/   89]
per-ex loss: 0.487991  [   72/   89]
per-ex loss: 0.386645  [   74/   89]
per-ex loss: 0.411910  [   76/   89]
per-ex loss: 0.460887  [   78/   89]
per-ex loss: 0.435589  [   80/   89]
per-ex loss: 0.385187  [   82/   89]
per-ex loss: 0.400491  [   84/   89]
per-ex loss: 0.376750  [   86/   89]
per-ex loss: 0.435998  [   88/   89]
per-ex loss: 0.358954  [   89/   89]
Train Error: Avg loss: 0.44412407
validation Error: 
 Avg loss: 0.98359746 
 F1: 0.515311 
 Precision: 0.562482 
 Recall: 0.475440
 IoU: 0.347084

test Error: 
 Avg loss: 0.98089412 
 F1: 0.539337 
 Precision: 0.576470 
 Recall: 0.506698
 IoU: 0.369241

We have finished training iteration 204
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_202_.pth
per-ex loss: 0.389305  [    2/   89]
per-ex loss: 0.468365  [    4/   89]
per-ex loss: 0.594538  [    6/   89]
per-ex loss: 0.329243  [    8/   89]
per-ex loss: 0.357399  [   10/   89]
per-ex loss: 0.452764  [   12/   89]
per-ex loss: 0.378909  [   14/   89]
per-ex loss: 0.398139  [   16/   89]
per-ex loss: 0.449641  [   18/   89]
per-ex loss: 0.664843  [   20/   89]
per-ex loss: 0.430172  [   22/   89]
per-ex loss: 0.492459  [   24/   89]
per-ex loss: 0.372189  [   26/   89]
per-ex loss: 0.509731  [   28/   89]
per-ex loss: 0.457073  [   30/   89]
per-ex loss: 0.386798  [   32/   89]
per-ex loss: 0.496531  [   34/   89]
per-ex loss: 0.524936  [   36/   89]
per-ex loss: 0.362810  [   38/   89]
per-ex loss: 0.405534  [   40/   89]
per-ex loss: 0.497448  [   42/   89]
per-ex loss: 0.570318  [   44/   89]
per-ex loss: 0.367078  [   46/   89]
per-ex loss: 0.515094  [   48/   89]
per-ex loss: 0.376177  [   50/   89]
per-ex loss: 0.433044  [   52/   89]
per-ex loss: 0.466249  [   54/   89]
per-ex loss: 0.371310  [   56/   89]
per-ex loss: 0.382359  [   58/   89]
per-ex loss: 0.449911  [   60/   89]
per-ex loss: 0.354181  [   62/   89]
per-ex loss: 0.607496  [   64/   89]
per-ex loss: 0.400719  [   66/   89]
per-ex loss: 0.483433  [   68/   89]
per-ex loss: 0.505410  [   70/   89]
per-ex loss: 0.395406  [   72/   89]
per-ex loss: 0.552777  [   74/   89]
per-ex loss: 0.399765  [   76/   89]
per-ex loss: 0.539047  [   78/   89]
per-ex loss: 0.487096  [   80/   89]
per-ex loss: 0.451873  [   82/   89]
per-ex loss: 0.417824  [   84/   89]
per-ex loss: 0.491029  [   86/   89]
per-ex loss: 0.473290  [   88/   89]
per-ex loss: 0.672244  [   89/   89]
Train Error: Avg loss: 0.45737687
validation Error: 
 Avg loss: 0.98389177 
 F1: 0.516972 
 Precision: 0.580354 
 Recall: 0.466071
 IoU: 0.348592

test Error: 
 Avg loss: 0.98122324 
 F1: 0.543333 
 Precision: 0.604049 
 Recall: 0.493707
 IoU: 0.372997

We have finished training iteration 205
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_203_.pth
per-ex loss: 0.389296  [    2/   89]
per-ex loss: 0.452307  [    4/   89]
per-ex loss: 0.392270  [    6/   89]
per-ex loss: 0.424218  [    8/   89]
per-ex loss: 0.508852  [   10/   89]
per-ex loss: 0.585011  [   12/   89]
per-ex loss: 0.539587  [   14/   89]
per-ex loss: 0.438844  [   16/   89]
per-ex loss: 0.375255  [   18/   89]
per-ex loss: 0.550804  [   20/   89]
per-ex loss: 0.346263  [   22/   89]
per-ex loss: 0.366331  [   24/   89]
per-ex loss: 0.412382  [   26/   89]
per-ex loss: 0.705443  [   28/   89]
per-ex loss: 0.408157  [   30/   89]
per-ex loss: 0.333597  [   32/   89]
per-ex loss: 0.405468  [   34/   89]
per-ex loss: 0.384508  [   36/   89]
per-ex loss: 0.472947  [   38/   89]
per-ex loss: 0.543007  [   40/   89]
per-ex loss: 0.391181  [   42/   89]
per-ex loss: 0.480290  [   44/   89]
per-ex loss: 0.449679  [   46/   89]
per-ex loss: 0.425306  [   48/   89]
per-ex loss: 0.334560  [   50/   89]
per-ex loss: 0.448830  [   52/   89]
per-ex loss: 0.482034  [   54/   89]
per-ex loss: 0.534176  [   56/   89]
per-ex loss: 0.529974  [   58/   89]
per-ex loss: 0.391839  [   60/   89]
per-ex loss: 0.538041  [   62/   89]
per-ex loss: 0.469289  [   64/   89]
per-ex loss: 0.530797  [   66/   89]
per-ex loss: 0.479230  [   68/   89]
per-ex loss: 0.482778  [   70/   89]
per-ex loss: 0.376808  [   72/   89]
per-ex loss: 0.421192  [   74/   89]
per-ex loss: 0.496288  [   76/   89]
per-ex loss: 0.481814  [   78/   89]
per-ex loss: 0.411629  [   80/   89]
per-ex loss: 0.340660  [   82/   89]
per-ex loss: 0.421324  [   84/   89]
per-ex loss: 0.486312  [   86/   89]
per-ex loss: 0.360965  [   88/   89]
per-ex loss: 0.557142  [   89/   89]
Train Error: Avg loss: 0.45237077
validation Error: 
 Avg loss: 0.98579306 
 F1: 0.512442 
 Precision: 0.517393 
 Recall: 0.507586
 IoU: 0.344486

test Error: 
 Avg loss: 0.98344818 
 F1: 0.531391 
 Precision: 0.525356 
 Recall: 0.537566
 IoU: 0.361833

We have finished training iteration 206
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_204_.pth
per-ex loss: 0.436730  [    2/   89]
per-ex loss: 0.375484  [    4/   89]
per-ex loss: 0.427313  [    6/   89]
per-ex loss: 0.427830  [    8/   89]
per-ex loss: 0.470289  [   10/   89]
per-ex loss: 0.494666  [   12/   89]
per-ex loss: 0.437885  [   14/   89]
per-ex loss: 0.530646  [   16/   89]
per-ex loss: 0.419475  [   18/   89]
per-ex loss: 0.450504  [   20/   89]
per-ex loss: 0.373176  [   22/   89]
per-ex loss: 0.434399  [   24/   89]
per-ex loss: 0.328211  [   26/   89]
per-ex loss: 0.564235  [   28/   89]
per-ex loss: 0.508874  [   30/   89]
per-ex loss: 0.361074  [   32/   89]
per-ex loss: 0.436196  [   34/   89]
per-ex loss: 0.519742  [   36/   89]
per-ex loss: 0.409551  [   38/   89]
per-ex loss: 0.434891  [   40/   89]
per-ex loss: 0.468786  [   42/   89]
per-ex loss: 0.427916  [   44/   89]
per-ex loss: 0.463673  [   46/   89]
per-ex loss: 0.421322  [   48/   89]
per-ex loss: 0.509785  [   50/   89]
per-ex loss: 0.396825  [   52/   89]
per-ex loss: 0.364327  [   54/   89]
per-ex loss: 0.326943  [   56/   89]
per-ex loss: 0.557654  [   58/   89]
per-ex loss: 0.397364  [   60/   89]
per-ex loss: 0.415041  [   62/   89]
per-ex loss: 0.348100  [   64/   89]
per-ex loss: 0.378358  [   66/   89]
per-ex loss: 0.487203  [   68/   89]
per-ex loss: 0.411656  [   70/   89]
per-ex loss: 0.472105  [   72/   89]
per-ex loss: 0.381502  [   74/   89]
per-ex loss: 0.520702  [   76/   89]
per-ex loss: 0.424651  [   78/   89]
per-ex loss: 0.358796  [   80/   89]
per-ex loss: 0.455788  [   82/   89]
per-ex loss: 0.550162  [   84/   89]
per-ex loss: 0.368311  [   86/   89]
per-ex loss: 0.451594  [   88/   89]
per-ex loss: 0.436860  [   89/   89]
Train Error: Avg loss: 0.43636879
validation Error: 
 Avg loss: 0.98388719 
 F1: 0.519499 
 Precision: 0.550579 
 Recall: 0.491740
 IoU: 0.350894

test Error: 
 Avg loss: 0.98195282 
 F1: 0.540425 
 Precision: 0.551029 
 Recall: 0.530221
 IoU: 0.370262

We have finished training iteration 207
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_205_.pth
per-ex loss: 0.492356  [    2/   89]
per-ex loss: 0.389813  [    4/   89]
per-ex loss: 0.515121  [    6/   89]
per-ex loss: 0.426768  [    8/   89]
per-ex loss: 0.432426  [   10/   89]
per-ex loss: 0.415488  [   12/   89]
per-ex loss: 0.512080  [   14/   89]
per-ex loss: 0.404319  [   16/   89]
per-ex loss: 0.346542  [   18/   89]
per-ex loss: 0.380635  [   20/   89]
per-ex loss: 0.352045  [   22/   89]
per-ex loss: 0.445128  [   24/   89]
per-ex loss: 0.626664  [   26/   89]
per-ex loss: 0.439126  [   28/   89]
per-ex loss: 0.449756  [   30/   89]
per-ex loss: 0.424717  [   32/   89]
per-ex loss: 0.417824  [   34/   89]
per-ex loss: 0.658196  [   36/   89]
per-ex loss: 0.420495  [   38/   89]
per-ex loss: 0.585241  [   40/   89]
per-ex loss: 0.402633  [   42/   89]
per-ex loss: 0.412354  [   44/   89]
per-ex loss: 0.399639  [   46/   89]
per-ex loss: 0.388964  [   48/   89]
per-ex loss: 0.408759  [   50/   89]
per-ex loss: 0.395096  [   52/   89]
per-ex loss: 0.440670  [   54/   89]
per-ex loss: 0.402971  [   56/   89]
per-ex loss: 0.608408  [   58/   89]
per-ex loss: 0.388649  [   60/   89]
per-ex loss: 0.551494  [   62/   89]
per-ex loss: 0.524003  [   64/   89]
per-ex loss: 0.449920  [   66/   89]
per-ex loss: 0.415768  [   68/   89]
per-ex loss: 0.633468  [   70/   89]
per-ex loss: 0.392022  [   72/   89]
per-ex loss: 0.474130  [   74/   89]
per-ex loss: 0.404134  [   76/   89]
per-ex loss: 0.344553  [   78/   89]
per-ex loss: 0.516051  [   80/   89]
per-ex loss: 0.406848  [   82/   89]
per-ex loss: 0.568325  [   84/   89]
per-ex loss: 0.339668  [   86/   89]
per-ex loss: 0.394363  [   88/   89]
per-ex loss: 0.406510  [   89/   89]
Train Error: Avg loss: 0.44898088
validation Error: 
 Avg loss: 0.98376831 
 F1: 0.517955 
 Precision: 0.568820 
 Recall: 0.475440
 IoU: 0.349487

test Error: 
 Avg loss: 0.98110739 
 F1: 0.544619 
 Precision: 0.578175 
 Recall: 0.514745
 IoU: 0.374211

We have finished training iteration 208
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_206_.pth
per-ex loss: 0.413127  [    2/   89]
per-ex loss: 0.427618  [    4/   89]
per-ex loss: 0.354464  [    6/   89]
per-ex loss: 0.538006  [    8/   89]
per-ex loss: 0.496568  [   10/   89]
per-ex loss: 0.532172  [   12/   89]
per-ex loss: 0.503581  [   14/   89]
per-ex loss: 0.395646  [   16/   89]
per-ex loss: 0.512483  [   18/   89]
per-ex loss: 0.410876  [   20/   89]
per-ex loss: 0.399638  [   22/   89]
per-ex loss: 0.539966  [   24/   89]
per-ex loss: 0.445460  [   26/   89]
per-ex loss: 0.384594  [   28/   89]
per-ex loss: 0.432075  [   30/   89]
per-ex loss: 0.467130  [   32/   89]
per-ex loss: 0.361570  [   34/   89]
per-ex loss: 0.418894  [   36/   89]
per-ex loss: 0.372297  [   38/   89]
per-ex loss: 0.382001  [   40/   89]
per-ex loss: 0.383264  [   42/   89]
per-ex loss: 0.465139  [   44/   89]
per-ex loss: 0.375587  [   46/   89]
per-ex loss: 0.582471  [   48/   89]
per-ex loss: 0.418030  [   50/   89]
per-ex loss: 0.407664  [   52/   89]
per-ex loss: 0.456131  [   54/   89]
per-ex loss: 0.415640  [   56/   89]
per-ex loss: 0.665465  [   58/   89]
per-ex loss: 0.304762  [   60/   89]
per-ex loss: 0.641101  [   62/   89]
per-ex loss: 0.367390  [   64/   89]
per-ex loss: 0.429143  [   66/   89]
per-ex loss: 0.451392  [   68/   89]
per-ex loss: 0.509481  [   70/   89]
per-ex loss: 0.358533  [   72/   89]
per-ex loss: 0.373782  [   74/   89]
per-ex loss: 0.444233  [   76/   89]
per-ex loss: 0.375646  [   78/   89]
per-ex loss: 0.406607  [   80/   89]
per-ex loss: 0.504095  [   82/   89]
per-ex loss: 0.385406  [   84/   89]
per-ex loss: 0.481872  [   86/   89]
per-ex loss: 0.609999  [   88/   89]
per-ex loss: 0.467558  [   89/   89]
Train Error: Avg loss: 0.44596793
validation Error: 
 Avg loss: 0.98341408 
 F1: 0.517880 
 Precision: 0.588453 
 Recall: 0.462422
 IoU: 0.349419

test Error: 
 Avg loss: 0.98088891 
 F1: 0.545433 
 Precision: 0.599188 
 Recall: 0.500530
 IoU: 0.374980

We have finished training iteration 209
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_207_.pth
per-ex loss: 0.356608  [    2/   89]
per-ex loss: 0.400194  [    4/   89]
per-ex loss: 0.354941  [    6/   89]
per-ex loss: 0.577936  [    8/   89]
per-ex loss: 0.518851  [   10/   89]
per-ex loss: 0.446585  [   12/   89]
per-ex loss: 0.477313  [   14/   89]
per-ex loss: 0.448330  [   16/   89]
per-ex loss: 0.495747  [   18/   89]
per-ex loss: 0.417138  [   20/   89]
per-ex loss: 0.329105  [   22/   89]
per-ex loss: 0.315666  [   24/   89]
per-ex loss: 0.351742  [   26/   89]
per-ex loss: 0.438064  [   28/   89]
per-ex loss: 0.527898  [   30/   89]
per-ex loss: 0.404952  [   32/   89]
per-ex loss: 0.379579  [   34/   89]
per-ex loss: 0.369844  [   36/   89]
per-ex loss: 0.436851  [   38/   89]
per-ex loss: 0.415226  [   40/   89]
per-ex loss: 0.614048  [   42/   89]
per-ex loss: 0.375242  [   44/   89]
per-ex loss: 0.591216  [   46/   89]
per-ex loss: 0.523824  [   48/   89]
per-ex loss: 0.468327  [   50/   89]
per-ex loss: 0.373576  [   52/   89]
per-ex loss: 0.533421  [   54/   89]
per-ex loss: 0.660686  [   56/   89]
per-ex loss: 0.395162  [   58/   89]
per-ex loss: 0.426066  [   60/   89]
per-ex loss: 0.550600  [   62/   89]
per-ex loss: 0.420130  [   64/   89]
per-ex loss: 0.335641  [   66/   89]
per-ex loss: 0.447008  [   68/   89]
per-ex loss: 0.576854  [   70/   89]
per-ex loss: 0.380185  [   72/   89]
per-ex loss: 0.519761  [   74/   89]
per-ex loss: 0.412944  [   76/   89]
per-ex loss: 0.360903  [   78/   89]
per-ex loss: 0.430576  [   80/   89]
per-ex loss: 0.387444  [   82/   89]
per-ex loss: 0.605720  [   84/   89]
per-ex loss: 0.619752  [   86/   89]
per-ex loss: 0.407199  [   88/   89]
per-ex loss: 0.382199  [   89/   89]
Train Error: Avg loss: 0.45024563
validation Error: 
 Avg loss: 0.98262070 
 F1: 0.518239 
 Precision: 0.596219 
 Recall: 0.458298
 IoU: 0.349745

test Error: 
 Avg loss: 0.98099002 
 F1: 0.542740 
 Precision: 0.608478 
 Recall: 0.489822
 IoU: 0.372439

We have finished training iteration 210
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_208_.pth
per-ex loss: 0.611171  [    2/   89]
per-ex loss: 0.355670  [    4/   89]
per-ex loss: 0.537994  [    6/   89]
per-ex loss: 0.355234  [    8/   89]
per-ex loss: 0.398120  [   10/   89]
per-ex loss: 0.474049  [   12/   89]
per-ex loss: 0.514150  [   14/   89]
per-ex loss: 0.406206  [   16/   89]
per-ex loss: 0.395552  [   18/   89]
per-ex loss: 0.379665  [   20/   89]
per-ex loss: 0.317671  [   22/   89]
per-ex loss: 0.475936  [   24/   89]
per-ex loss: 0.554429  [   26/   89]
per-ex loss: 0.518258  [   28/   89]
per-ex loss: 0.560728  [   30/   89]
per-ex loss: 0.456942  [   32/   89]
per-ex loss: 0.357626  [   34/   89]
per-ex loss: 0.520171  [   36/   89]
per-ex loss: 0.497604  [   38/   89]
per-ex loss: 0.360806  [   40/   89]
per-ex loss: 0.450147  [   42/   89]
per-ex loss: 0.390910  [   44/   89]
per-ex loss: 0.450962  [   46/   89]
per-ex loss: 0.407252  [   48/   89]
per-ex loss: 0.431427  [   50/   89]
per-ex loss: 0.467346  [   52/   89]
per-ex loss: 0.363795  [   54/   89]
per-ex loss: 0.405378  [   56/   89]
per-ex loss: 0.376513  [   58/   89]
per-ex loss: 0.394785  [   60/   89]
per-ex loss: 0.576504  [   62/   89]
per-ex loss: 0.423122  [   64/   89]
per-ex loss: 0.551454  [   66/   89]
per-ex loss: 0.404625  [   68/   89]
per-ex loss: 0.464042  [   70/   89]
per-ex loss: 0.403578  [   72/   89]
per-ex loss: 0.504946  [   74/   89]
per-ex loss: 0.414103  [   76/   89]
per-ex loss: 0.551079  [   78/   89]
per-ex loss: 0.466782  [   80/   89]
per-ex loss: 0.541386  [   82/   89]
per-ex loss: 0.511774  [   84/   89]
per-ex loss: 0.412304  [   86/   89]
per-ex loss: 0.354598  [   88/   89]
per-ex loss: 0.419118  [   89/   89]
Train Error: Avg loss: 0.44857573
validation Error: 
 Avg loss: 0.98244919 
 F1: 0.517507 
 Precision: 0.607781 
 Recall: 0.450582
 IoU: 0.349079

test Error: 
 Avg loss: 0.98019935 
 F1: 0.538656 
 Precision: 0.600504 
 Recall: 0.488359
 IoU: 0.368603

We have finished training iteration 211
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_209_.pth
per-ex loss: 0.527130  [    2/   89]
per-ex loss: 0.347800  [    4/   89]
per-ex loss: 0.326034  [    6/   89]
per-ex loss: 0.383675  [    8/   89]
per-ex loss: 0.488705  [   10/   89]
per-ex loss: 0.421147  [   12/   89]
per-ex loss: 0.507566  [   14/   89]
per-ex loss: 0.553337  [   16/   89]
per-ex loss: 0.494939  [   18/   89]
per-ex loss: 0.451951  [   20/   89]
per-ex loss: 0.464758  [   22/   89]
per-ex loss: 0.404520  [   24/   89]
per-ex loss: 0.551775  [   26/   89]
per-ex loss: 0.417154  [   28/   89]
per-ex loss: 0.373545  [   30/   89]
per-ex loss: 0.402465  [   32/   89]
per-ex loss: 0.377566  [   34/   89]
per-ex loss: 0.572580  [   36/   89]
per-ex loss: 0.363619  [   38/   89]
per-ex loss: 0.479749  [   40/   89]
per-ex loss: 0.682558  [   42/   89]
per-ex loss: 0.486164  [   44/   89]
per-ex loss: 0.393078  [   46/   89]
per-ex loss: 0.474534  [   48/   89]
per-ex loss: 0.570982  [   50/   89]
per-ex loss: 0.414599  [   52/   89]
per-ex loss: 0.430654  [   54/   89]
per-ex loss: 0.415036  [   56/   89]
per-ex loss: 0.377597  [   58/   89]
per-ex loss: 0.557470  [   60/   89]
per-ex loss: 0.439692  [   62/   89]
per-ex loss: 0.329967  [   64/   89]
per-ex loss: 0.375504  [   66/   89]
per-ex loss: 0.387964  [   68/   89]
per-ex loss: 0.426261  [   70/   89]
per-ex loss: 0.507231  [   72/   89]
per-ex loss: 0.454276  [   74/   89]
per-ex loss: 0.566652  [   76/   89]
per-ex loss: 0.370954  [   78/   89]
per-ex loss: 0.516958  [   80/   89]
per-ex loss: 0.613943  [   82/   89]
per-ex loss: 0.385354  [   84/   89]
per-ex loss: 0.510143  [   86/   89]
per-ex loss: 0.300789  [   88/   89]
per-ex loss: 0.324073  [   89/   89]
Train Error: Avg loss: 0.44938775
validation Error: 
 Avg loss: 0.98582785 
 F1: 0.516277 
 Precision: 0.524602 
 Recall: 0.508213
 IoU: 0.347961

test Error: 
 Avg loss: 0.98379956 
 F1: 0.533691 
 Precision: 0.529426 
 Recall: 0.538024
 IoU: 0.363969

We have finished training iteration 212
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_210_.pth
per-ex loss: 0.490626  [    2/   89]
per-ex loss: 0.464536  [    4/   89]
per-ex loss: 0.581146  [    6/   89]
per-ex loss: 0.371098  [    8/   89]
per-ex loss: 0.374115  [   10/   89]
per-ex loss: 0.418079  [   12/   89]
per-ex loss: 0.359983  [   14/   89]
per-ex loss: 0.507571  [   16/   89]
per-ex loss: 0.485177  [   18/   89]
per-ex loss: 0.434517  [   20/   89]
per-ex loss: 0.366812  [   22/   89]
per-ex loss: 0.422690  [   24/   89]
per-ex loss: 0.453586  [   26/   89]
per-ex loss: 0.666820  [   28/   89]
per-ex loss: 0.564834  [   30/   89]
per-ex loss: 0.345857  [   32/   89]
per-ex loss: 0.441776  [   34/   89]
per-ex loss: 0.364192  [   36/   89]
per-ex loss: 0.365247  [   38/   89]
per-ex loss: 0.434802  [   40/   89]
per-ex loss: 0.540315  [   42/   89]
per-ex loss: 0.419754  [   44/   89]
per-ex loss: 0.363730  [   46/   89]
per-ex loss: 0.379533  [   48/   89]
per-ex loss: 0.383960  [   50/   89]
per-ex loss: 0.427002  [   52/   89]
per-ex loss: 0.456244  [   54/   89]
per-ex loss: 0.512970  [   56/   89]
per-ex loss: 0.382758  [   58/   89]
per-ex loss: 0.438732  [   60/   89]
per-ex loss: 0.465134  [   62/   89]
per-ex loss: 0.405755  [   64/   89]
per-ex loss: 0.465468  [   66/   89]
per-ex loss: 0.401479  [   68/   89]
per-ex loss: 0.361363  [   70/   89]
per-ex loss: 0.407073  [   72/   89]
per-ex loss: 0.338182  [   74/   89]
per-ex loss: 0.383480  [   76/   89]
per-ex loss: 0.543648  [   78/   89]
per-ex loss: 0.615774  [   80/   89]
per-ex loss: 0.362501  [   82/   89]
per-ex loss: 0.498682  [   84/   89]
per-ex loss: 0.526154  [   86/   89]
per-ex loss: 0.428781  [   88/   89]
per-ex loss: 0.533178  [   89/   89]
Train Error: Avg loss: 0.44344710
validation Error: 
 Avg loss: 0.98229395 
 F1: 0.517679 
 Precision: 0.608433 
 Recall: 0.450484
 IoU: 0.349235

test Error: 
 Avg loss: 0.98092297 
 F1: 0.538665 
 Precision: 0.619824 
 Recall: 0.476299
 IoU: 0.368612

We have finished training iteration 213
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_211_.pth
per-ex loss: 0.437161  [    2/   89]
per-ex loss: 0.501047  [    4/   89]
per-ex loss: 0.389770  [    6/   89]
per-ex loss: 0.388247  [    8/   89]
per-ex loss: 0.396589  [   10/   89]
per-ex loss: 0.445875  [   12/   89]
per-ex loss: 0.360862  [   14/   89]
per-ex loss: 0.532074  [   16/   89]
per-ex loss: 0.427686  [   18/   89]
per-ex loss: 0.541572  [   20/   89]
per-ex loss: 0.456022  [   22/   89]
per-ex loss: 0.431733  [   24/   89]
per-ex loss: 0.595016  [   26/   89]
per-ex loss: 0.602059  [   28/   89]
per-ex loss: 0.627332  [   30/   89]
per-ex loss: 0.398460  [   32/   89]
per-ex loss: 0.418311  [   34/   89]
per-ex loss: 0.399490  [   36/   89]
per-ex loss: 0.567732  [   38/   89]
per-ex loss: 0.515124  [   40/   89]
per-ex loss: 0.382385  [   42/   89]
per-ex loss: 0.343110  [   44/   89]
per-ex loss: 0.424973  [   46/   89]
per-ex loss: 0.383995  [   48/   89]
per-ex loss: 0.414703  [   50/   89]
per-ex loss: 0.485223  [   52/   89]
per-ex loss: 0.463549  [   54/   89]
per-ex loss: 0.467235  [   56/   89]
per-ex loss: 0.370107  [   58/   89]
per-ex loss: 0.402287  [   60/   89]
per-ex loss: 0.513697  [   62/   89]
per-ex loss: 0.458677  [   64/   89]
per-ex loss: 0.537821  [   66/   89]
per-ex loss: 0.571266  [   68/   89]
per-ex loss: 0.578777  [   70/   89]
per-ex loss: 0.371545  [   72/   89]
per-ex loss: 0.328911  [   74/   89]
per-ex loss: 0.379167  [   76/   89]
per-ex loss: 0.393439  [   78/   89]
per-ex loss: 0.406545  [   80/   89]
per-ex loss: 0.368364  [   82/   89]
per-ex loss: 0.400556  [   84/   89]
per-ex loss: 0.466558  [   86/   89]
per-ex loss: 0.361456  [   88/   89]
per-ex loss: 0.328896  [   89/   89]
Train Error: Avg loss: 0.44523128
validation Error: 
 Avg loss: 0.98265801 
 F1: 0.519153 
 Precision: 0.578643 
 Recall: 0.470755
 IoU: 0.350578

test Error: 
 Avg loss: 0.98076066 
 F1: 0.547703 
 Precision: 0.585516 
 Recall: 0.514477
 IoU: 0.377129

We have finished training iteration 214
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_212_.pth
per-ex loss: 0.414532  [    2/   89]
per-ex loss: 0.454243  [    4/   89]
per-ex loss: 0.437708  [    6/   89]
per-ex loss: 0.310406  [    8/   89]
per-ex loss: 0.447196  [   10/   89]
per-ex loss: 0.430002  [   12/   89]
per-ex loss: 0.321657  [   14/   89]
per-ex loss: 0.532429  [   16/   89]
per-ex loss: 0.363784  [   18/   89]
per-ex loss: 0.390708  [   20/   89]
per-ex loss: 0.379725  [   22/   89]
per-ex loss: 0.567514  [   24/   89]
per-ex loss: 0.397131  [   26/   89]
per-ex loss: 0.404747  [   28/   89]
per-ex loss: 0.360696  [   30/   89]
per-ex loss: 0.427980  [   32/   89]
per-ex loss: 0.482962  [   34/   89]
per-ex loss: 0.368748  [   36/   89]
per-ex loss: 0.459691  [   38/   89]
per-ex loss: 0.452805  [   40/   89]
per-ex loss: 0.507451  [   42/   89]
per-ex loss: 0.598667  [   44/   89]
per-ex loss: 0.595963  [   46/   89]
per-ex loss: 0.480578  [   48/   89]
per-ex loss: 0.464335  [   50/   89]
per-ex loss: 0.402663  [   52/   89]
per-ex loss: 0.623246  [   54/   89]
per-ex loss: 0.543064  [   56/   89]
per-ex loss: 0.413880  [   58/   89]
per-ex loss: 0.410423  [   60/   89]
per-ex loss: 0.554291  [   62/   89]
per-ex loss: 0.353750  [   64/   89]
per-ex loss: 0.524734  [   66/   89]
per-ex loss: 0.361570  [   68/   89]
per-ex loss: 0.369837  [   70/   89]
per-ex loss: 0.402892  [   72/   89]
per-ex loss: 0.590322  [   74/   89]
per-ex loss: 0.464786  [   76/   89]
per-ex loss: 0.338234  [   78/   89]
per-ex loss: 0.392412  [   80/   89]
per-ex loss: 0.417281  [   82/   89]
per-ex loss: 0.386034  [   84/   89]
per-ex loss: 0.589385  [   86/   89]
per-ex loss: 0.543000  [   88/   89]
per-ex loss: 0.376312  [   89/   89]
Train Error: Avg loss: 0.44688384
validation Error: 
 Avg loss: 0.98313313 
 F1: 0.516932 
 Precision: 0.587706 
 Recall: 0.461372
 IoU: 0.348556

test Error: 
 Avg loss: 0.98048751 
 F1: 0.544702 
 Precision: 0.609825 
 Recall: 0.492146
 IoU: 0.374289

We have finished training iteration 215
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_213_.pth
per-ex loss: 0.559767  [    2/   89]
per-ex loss: 0.410248  [    4/   89]
per-ex loss: 0.382426  [    6/   89]
per-ex loss: 0.382596  [    8/   89]
per-ex loss: 0.354845  [   10/   89]
per-ex loss: 0.766300  [   12/   89]
per-ex loss: 0.336645  [   14/   89]
per-ex loss: 0.418596  [   16/   89]
per-ex loss: 0.436964  [   18/   89]
per-ex loss: 0.475911  [   20/   89]
per-ex loss: 0.506916  [   22/   89]
per-ex loss: 0.415812  [   24/   89]
per-ex loss: 0.470454  [   26/   89]
per-ex loss: 0.401176  [   28/   89]
per-ex loss: 0.398421  [   30/   89]
per-ex loss: 0.558436  [   32/   89]
per-ex loss: 0.376881  [   34/   89]
per-ex loss: 0.431084  [   36/   89]
per-ex loss: 0.536464  [   38/   89]
per-ex loss: 0.456243  [   40/   89]
per-ex loss: 0.571187  [   42/   89]
per-ex loss: 0.486561  [   44/   89]
per-ex loss: 0.640727  [   46/   89]
per-ex loss: 0.391441  [   48/   89]
per-ex loss: 0.309226  [   50/   89]
per-ex loss: 0.466631  [   52/   89]
per-ex loss: 0.414138  [   54/   89]
per-ex loss: 0.338236  [   56/   89]
per-ex loss: 0.403375  [   58/   89]
per-ex loss: 0.503964  [   60/   89]
per-ex loss: 0.544777  [   62/   89]
per-ex loss: 0.424832  [   64/   89]
per-ex loss: 0.478927  [   66/   89]
per-ex loss: 0.496078  [   68/   89]
per-ex loss: 0.454532  [   70/   89]
per-ex loss: 0.391202  [   72/   89]
per-ex loss: 0.552824  [   74/   89]
per-ex loss: 0.457948  [   76/   89]
per-ex loss: 0.503379  [   78/   89]
per-ex loss: 0.487512  [   80/   89]
per-ex loss: 0.559730  [   82/   89]
per-ex loss: 0.414227  [   84/   89]
per-ex loss: 0.625139  [   86/   89]
per-ex loss: 0.375943  [   88/   89]
per-ex loss: 0.588724  [   89/   89]
Train Error: Avg loss: 0.46572105
validation Error: 
 Avg loss: 0.98407664 
 F1: 0.515978 
 Precision: 0.571706 
 Recall: 0.470149
 IoU: 0.347689

test Error: 
 Avg loss: 0.98167826 
 F1: 0.539630 
 Precision: 0.571936 
 Recall: 0.510779
 IoU: 0.369516

We have finished training iteration 216
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_214_.pth
per-ex loss: 0.362551  [    2/   89]
per-ex loss: 0.514481  [    4/   89]
per-ex loss: 0.472593  [    6/   89]
per-ex loss: 0.419670  [    8/   89]
per-ex loss: 0.468198  [   10/   89]
per-ex loss: 0.330587  [   12/   89]
per-ex loss: 0.384046  [   14/   89]
per-ex loss: 0.420456  [   16/   89]
per-ex loss: 0.396823  [   18/   89]
per-ex loss: 0.709300  [   20/   89]
per-ex loss: 0.425288  [   22/   89]
per-ex loss: 0.500182  [   24/   89]
per-ex loss: 0.445961  [   26/   89]
per-ex loss: 0.358002  [   28/   89]
per-ex loss: 0.583464  [   30/   89]
per-ex loss: 0.463262  [   32/   89]
per-ex loss: 0.502991  [   34/   89]
per-ex loss: 0.398864  [   36/   89]
per-ex loss: 0.369989  [   38/   89]
per-ex loss: 0.384238  [   40/   89]
per-ex loss: 0.412264  [   42/   89]
per-ex loss: 0.424142  [   44/   89]
per-ex loss: 0.461318  [   46/   89]
per-ex loss: 0.345853  [   48/   89]
per-ex loss: 0.306462  [   50/   89]
per-ex loss: 0.433293  [   52/   89]
per-ex loss: 0.496206  [   54/   89]
per-ex loss: 0.401725  [   56/   89]
per-ex loss: 0.558128  [   58/   89]
per-ex loss: 0.478838  [   60/   89]
per-ex loss: 0.476617  [   62/   89]
per-ex loss: 0.543388  [   64/   89]
per-ex loss: 0.324746  [   66/   89]
per-ex loss: 0.454127  [   68/   89]
per-ex loss: 0.487533  [   70/   89]
per-ex loss: 0.424326  [   72/   89]
per-ex loss: 0.468926  [   74/   89]
per-ex loss: 0.436546  [   76/   89]
per-ex loss: 0.467316  [   78/   89]
per-ex loss: 0.435321  [   80/   89]
per-ex loss: 0.369357  [   82/   89]
per-ex loss: 0.398791  [   84/   89]
per-ex loss: 0.428275  [   86/   89]
per-ex loss: 0.386618  [   88/   89]
per-ex loss: 0.603218  [   89/   89]
Train Error: Avg loss: 0.44298403
validation Error: 
 Avg loss: 0.98432750 
 F1: 0.517028 
 Precision: 0.555478 
 Recall: 0.483557
 IoU: 0.348643

test Error: 
 Avg loss: 0.98198006 
 F1: 0.544471 
 Precision: 0.558204 
 Recall: 0.531397
 IoU: 0.374070

We have finished training iteration 217
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_215_.pth
per-ex loss: 0.417184  [    2/   89]
per-ex loss: 0.407978  [    4/   89]
per-ex loss: 0.406346  [    6/   89]
per-ex loss: 0.443864  [    8/   89]
per-ex loss: 0.402838  [   10/   89]
per-ex loss: 0.705422  [   12/   89]
per-ex loss: 0.348072  [   14/   89]
per-ex loss: 0.397234  [   16/   89]
per-ex loss: 0.347163  [   18/   89]
per-ex loss: 0.448739  [   20/   89]
per-ex loss: 0.467594  [   22/   89]
per-ex loss: 0.587218  [   24/   89]
per-ex loss: 0.413184  [   26/   89]
per-ex loss: 0.482191  [   28/   89]
per-ex loss: 0.582431  [   30/   89]
per-ex loss: 0.367996  [   32/   89]
per-ex loss: 0.315074  [   34/   89]
per-ex loss: 0.547960  [   36/   89]
per-ex loss: 0.393250  [   38/   89]
per-ex loss: 0.504513  [   40/   89]
per-ex loss: 0.596585  [   42/   89]
per-ex loss: 0.407094  [   44/   89]
per-ex loss: 0.358063  [   46/   89]
per-ex loss: 0.435245  [   48/   89]
per-ex loss: 0.350808  [   50/   89]
per-ex loss: 0.406103  [   52/   89]
per-ex loss: 0.375257  [   54/   89]
per-ex loss: 0.412403  [   56/   89]
per-ex loss: 0.426666  [   58/   89]
per-ex loss: 0.436989  [   60/   89]
per-ex loss: 0.471576  [   62/   89]
per-ex loss: 0.343299  [   64/   89]
per-ex loss: 0.577821  [   66/   89]
per-ex loss: 0.499700  [   68/   89]
per-ex loss: 0.410341  [   70/   89]
per-ex loss: 0.363072  [   72/   89]
per-ex loss: 0.466624  [   74/   89]
per-ex loss: 0.440185  [   76/   89]
per-ex loss: 0.469325  [   78/   89]
per-ex loss: 0.565695  [   80/   89]
per-ex loss: 0.412279  [   82/   89]
per-ex loss: 0.396207  [   84/   89]
per-ex loss: 0.409147  [   86/   89]
per-ex loss: 0.369700  [   88/   89]
per-ex loss: 0.547042  [   89/   89]
Train Error: Avg loss: 0.44296613
validation Error: 
 Avg loss: 0.98485124 
 F1: 0.517573 
 Precision: 0.542473 
 Recall: 0.494859
 IoU: 0.349139

test Error: 
 Avg loss: 0.98278620 
 F1: 0.536965 
 Precision: 0.539421 
 Recall: 0.534532
 IoU: 0.367022

We have finished training iteration 218
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_216_.pth
per-ex loss: 0.594839  [    2/   89]
per-ex loss: 0.384355  [    4/   89]
per-ex loss: 0.466672  [    6/   89]
per-ex loss: 0.493894  [    8/   89]
per-ex loss: 0.555764  [   10/   89]
per-ex loss: 0.397457  [   12/   89]
per-ex loss: 0.385982  [   14/   89]
per-ex loss: 0.447909  [   16/   89]
per-ex loss: 0.550552  [   18/   89]
per-ex loss: 0.461506  [   20/   89]
per-ex loss: 0.352331  [   22/   89]
per-ex loss: 0.499008  [   24/   89]
per-ex loss: 0.447203  [   26/   89]
per-ex loss: 0.449204  [   28/   89]
per-ex loss: 0.377795  [   30/   89]
per-ex loss: 0.652124  [   32/   89]
per-ex loss: 0.418939  [   34/   89]
per-ex loss: 0.508174  [   36/   89]
per-ex loss: 0.421256  [   38/   89]
per-ex loss: 0.397789  [   40/   89]
per-ex loss: 0.411830  [   42/   89]
per-ex loss: 0.364892  [   44/   89]
per-ex loss: 0.385602  [   46/   89]
per-ex loss: 0.538472  [   48/   89]
per-ex loss: 0.368265  [   50/   89]
per-ex loss: 0.327780  [   52/   89]
per-ex loss: 0.490579  [   54/   89]
per-ex loss: 0.579645  [   56/   89]
per-ex loss: 0.370574  [   58/   89]
per-ex loss: 0.406530  [   60/   89]
per-ex loss: 0.623891  [   62/   89]
per-ex loss: 0.440291  [   64/   89]
per-ex loss: 0.432303  [   66/   89]
per-ex loss: 0.411408  [   68/   89]
per-ex loss: 0.390112  [   70/   89]
per-ex loss: 0.534373  [   72/   89]
per-ex loss: 0.437390  [   74/   89]
per-ex loss: 0.553002  [   76/   89]
per-ex loss: 0.475114  [   78/   89]
per-ex loss: 0.485077  [   80/   89]
per-ex loss: 0.580454  [   82/   89]
per-ex loss: 0.487990  [   84/   89]
per-ex loss: 0.441847  [   86/   89]
per-ex loss: 0.312696  [   88/   89]
per-ex loss: 0.311523  [   89/   89]
Train Error: Avg loss: 0.45387543
validation Error: 
 Avg loss: 0.98515794 
 F1: 0.500494 
 Precision: 0.485363 
 Recall: 0.516599
 IoU: 0.333772

test Error: 
 Avg loss: 0.98349321 
 F1: 0.511551 
 Precision: 0.476056 
 Recall: 0.552766
 IoU: 0.343681

We have finished training iteration 219
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_217_.pth
per-ex loss: 0.434000  [    2/   89]
per-ex loss: 0.680626  [    4/   89]
per-ex loss: 0.548053  [    6/   89]
per-ex loss: 0.372342  [    8/   89]
per-ex loss: 0.380968  [   10/   89]
per-ex loss: 0.512727  [   12/   89]
per-ex loss: 0.553727  [   14/   89]
per-ex loss: 0.441115  [   16/   89]
per-ex loss: 0.428957  [   18/   89]
per-ex loss: 0.384407  [   20/   89]
per-ex loss: 0.376836  [   22/   89]
per-ex loss: 0.314038  [   24/   89]
per-ex loss: 0.381472  [   26/   89]
per-ex loss: 0.548826  [   28/   89]
per-ex loss: 0.462106  [   30/   89]
per-ex loss: 0.539759  [   32/   89]
per-ex loss: 0.477356  [   34/   89]
per-ex loss: 0.410842  [   36/   89]
per-ex loss: 0.406298  [   38/   89]
per-ex loss: 0.603141  [   40/   89]
per-ex loss: 0.381448  [   42/   89]
per-ex loss: 0.382118  [   44/   89]
per-ex loss: 0.401033  [   46/   89]
per-ex loss: 0.449398  [   48/   89]
per-ex loss: 0.442479  [   50/   89]
per-ex loss: 0.401576  [   52/   89]
per-ex loss: 0.408719  [   54/   89]
per-ex loss: 0.581446  [   56/   89]
per-ex loss: 0.450439  [   58/   89]
per-ex loss: 0.351074  [   60/   89]
per-ex loss: 0.381258  [   62/   89]
per-ex loss: 0.427701  [   64/   89]
per-ex loss: 0.409124  [   66/   89]
per-ex loss: 0.551611  [   68/   89]
per-ex loss: 0.398470  [   70/   89]
per-ex loss: 0.393046  [   72/   89]
per-ex loss: 0.673466  [   74/   89]
per-ex loss: 0.578839  [   76/   89]
per-ex loss: 0.691198  [   78/   89]
per-ex loss: 0.387711  [   80/   89]
per-ex loss: 0.412194  [   82/   89]
per-ex loss: 0.382746  [   84/   89]
per-ex loss: 0.346855  [   86/   89]
per-ex loss: 0.379781  [   88/   89]
per-ex loss: 0.608680  [   89/   89]
Train Error: Avg loss: 0.45622245
validation Error: 
 Avg loss: 0.98325749 
 F1: 0.514311 
 Precision: 0.615853 
 Recall: 0.441514
 IoU: 0.346176

test Error: 
 Avg loss: 0.98076032 
 F1: 0.543360 
 Precision: 0.624690 
 Recall: 0.480767
 IoU: 0.373022

We have finished training iteration 220
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_218_.pth
per-ex loss: 0.428403  [    2/   89]
per-ex loss: 0.414473  [    4/   89]
per-ex loss: 0.473256  [    6/   89]
per-ex loss: 0.411363  [    8/   89]
per-ex loss: 0.590803  [   10/   89]
per-ex loss: 0.386475  [   12/   89]
per-ex loss: 0.441888  [   14/   89]
per-ex loss: 0.533133  [   16/   89]
per-ex loss: 0.366089  [   18/   89]
per-ex loss: 0.630766  [   20/   89]
per-ex loss: 0.413305  [   22/   89]
per-ex loss: 0.406338  [   24/   89]
per-ex loss: 0.587370  [   26/   89]
per-ex loss: 0.408955  [   28/   89]
per-ex loss: 0.400149  [   30/   89]
per-ex loss: 0.591837  [   32/   89]
per-ex loss: 0.428930  [   34/   89]
per-ex loss: 0.339783  [   36/   89]
per-ex loss: 0.378535  [   38/   89]
per-ex loss: 0.475805  [   40/   89]
per-ex loss: 0.444216  [   42/   89]
per-ex loss: 0.295119  [   44/   89]
per-ex loss: 0.313523  [   46/   89]
per-ex loss: 0.393844  [   48/   89]
per-ex loss: 0.421094  [   50/   89]
per-ex loss: 0.437163  [   52/   89]
per-ex loss: 0.416616  [   54/   89]
per-ex loss: 0.597552  [   56/   89]
per-ex loss: 0.380699  [   58/   89]
per-ex loss: 0.435570  [   60/   89]
per-ex loss: 0.387584  [   62/   89]
per-ex loss: 0.420025  [   64/   89]
per-ex loss: 0.603046  [   66/   89]
per-ex loss: 0.400073  [   68/   89]
per-ex loss: 0.635414  [   70/   89]
per-ex loss: 0.407259  [   72/   89]
per-ex loss: 0.383349  [   74/   89]
per-ex loss: 0.413212  [   76/   89]
per-ex loss: 0.476333  [   78/   89]
per-ex loss: 0.529419  [   80/   89]
per-ex loss: 0.437025  [   82/   89]
per-ex loss: 0.430674  [   84/   89]
per-ex loss: 0.366117  [   86/   89]
per-ex loss: 0.505825  [   88/   89]
per-ex loss: 0.424000  [   89/   89]
Train Error: Avg loss: 0.44583129
validation Error: 
 Avg loss: 0.98166469 
 F1: 0.508564 
 Precision: 0.632203 
 Recall: 0.425374
 IoU: 0.340989

test Error: 
 Avg loss: 0.97867251 
 F1: 0.537218 
 Precision: 0.652274 
 Recall: 0.456666
 IoU: 0.367258

We have finished training iteration 221
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_219_.pth
per-ex loss: 0.381066  [    2/   89]
per-ex loss: 0.383128  [    4/   89]
per-ex loss: 0.588538  [    6/   89]
per-ex loss: 0.398820  [    8/   89]
per-ex loss: 0.584127  [   10/   89]
per-ex loss: 0.451975  [   12/   89]
per-ex loss: 0.444479  [   14/   89]
per-ex loss: 0.371774  [   16/   89]
per-ex loss: 0.513178  [   18/   89]
per-ex loss: 0.361620  [   20/   89]
per-ex loss: 0.448847  [   22/   89]
per-ex loss: 0.575446  [   24/   89]
per-ex loss: 0.341779  [   26/   89]
per-ex loss: 0.365481  [   28/   89]
per-ex loss: 0.547663  [   30/   89]
per-ex loss: 0.419782  [   32/   89]
per-ex loss: 0.465819  [   34/   89]
per-ex loss: 0.368095  [   36/   89]
per-ex loss: 0.417068  [   38/   89]
per-ex loss: 0.378895  [   40/   89]
per-ex loss: 0.386661  [   42/   89]
per-ex loss: 0.359571  [   44/   89]
per-ex loss: 0.456460  [   46/   89]
per-ex loss: 0.506552  [   48/   89]
per-ex loss: 0.299473  [   50/   89]
per-ex loss: 0.414280  [   52/   89]
per-ex loss: 0.522202  [   54/   89]
per-ex loss: 0.517966  [   56/   89]
per-ex loss: 0.353294  [   58/   89]
per-ex loss: 0.408682  [   60/   89]
per-ex loss: 0.481159  [   62/   89]
per-ex loss: 0.369458  [   64/   89]
per-ex loss: 0.560879  [   66/   89]
per-ex loss: 0.468497  [   68/   89]
per-ex loss: 0.414353  [   70/   89]
per-ex loss: 0.536240  [   72/   89]
per-ex loss: 0.438067  [   74/   89]
per-ex loss: 0.628378  [   76/   89]
per-ex loss: 0.530589  [   78/   89]
per-ex loss: 0.348586  [   80/   89]
per-ex loss: 0.405466  [   82/   89]
per-ex loss: 0.416743  [   84/   89]
per-ex loss: 0.413525  [   86/   89]
per-ex loss: 0.402361  [   88/   89]
per-ex loss: 0.422749  [   89/   89]
Train Error: Avg loss: 0.44155045
validation Error: 
 Avg loss: 0.98610162 
 F1: 0.514321 
 Precision: 0.514724 
 Recall: 0.513919
 IoU: 0.346186

test Error: 
 Avg loss: 0.98375195 
 F1: 0.539247 
 Precision: 0.522790 
 Recall: 0.556774
 IoU: 0.369157

We have finished training iteration 222
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_220_.pth
per-ex loss: 0.388478  [    2/   89]
per-ex loss: 0.378775  [    4/   89]
per-ex loss: 0.559266  [    6/   89]
per-ex loss: 0.549043  [    8/   89]
per-ex loss: 0.416385  [   10/   89]
per-ex loss: 0.369097  [   12/   89]
per-ex loss: 0.346444  [   14/   89]
per-ex loss: 0.443274  [   16/   89]
per-ex loss: 0.451674  [   18/   89]
per-ex loss: 0.487415  [   20/   89]
per-ex loss: 0.339379  [   22/   89]
per-ex loss: 0.402270  [   24/   89]
per-ex loss: 0.349847  [   26/   89]
per-ex loss: 0.559750  [   28/   89]
per-ex loss: 0.326866  [   30/   89]
per-ex loss: 0.392506  [   32/   89]
per-ex loss: 0.428596  [   34/   89]
per-ex loss: 0.573862  [   36/   89]
per-ex loss: 0.414500  [   38/   89]
per-ex loss: 0.491180  [   40/   89]
per-ex loss: 0.474470  [   42/   89]
per-ex loss: 0.396229  [   44/   89]
per-ex loss: 0.363102  [   46/   89]
per-ex loss: 0.491631  [   48/   89]
per-ex loss: 0.419488  [   50/   89]
per-ex loss: 0.402356  [   52/   89]
per-ex loss: 0.554364  [   54/   89]
per-ex loss: 0.363323  [   56/   89]
per-ex loss: 0.478652  [   58/   89]
per-ex loss: 0.433310  [   60/   89]
per-ex loss: 0.447254  [   62/   89]
per-ex loss: 0.354030  [   64/   89]
per-ex loss: 0.589475  [   66/   89]
per-ex loss: 0.540538  [   68/   89]
per-ex loss: 0.611466  [   70/   89]
per-ex loss: 0.508181  [   72/   89]
per-ex loss: 0.435092  [   74/   89]
per-ex loss: 0.366779  [   76/   89]
per-ex loss: 0.404601  [   78/   89]
per-ex loss: 0.341207  [   80/   89]
per-ex loss: 0.497351  [   82/   89]
per-ex loss: 0.522719  [   84/   89]
per-ex loss: 0.339112  [   86/   89]
per-ex loss: 0.445320  [   88/   89]
per-ex loss: 0.382350  [   89/   89]
Train Error: Avg loss: 0.44068910
validation Error: 
 Avg loss: 0.98393896 
 F1: 0.517743 
 Precision: 0.570955 
 Recall: 0.473604
 IoU: 0.349293

test Error: 
 Avg loss: 0.98121253 
 F1: 0.546577 
 Precision: 0.586614 
 Recall: 0.511656
 IoU: 0.376062

We have finished training iteration 223
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_221_.pth
Error in cropping the image to the non-zero values in the fourth channel. Returned the original image.
per-ex loss: 0.383701  [    2/   89]
per-ex loss: 0.357003  [    4/   89]
per-ex loss: 0.336304  [    6/   89]
per-ex loss: 0.543322  [    8/   89]
per-ex loss: 0.397106  [   10/   89]
per-ex loss: 0.432335  [   12/   89]
per-ex loss: 0.536207  [   14/   89]
per-ex loss: 0.446752  [   16/   89]
per-ex loss: 0.472395  [   18/   89]
per-ex loss: 0.466769  [   20/   89]
per-ex loss: 0.408154  [   22/   89]
per-ex loss: 0.460418  [   24/   89]
per-ex loss: 0.484518  [   26/   89]
per-ex loss: 0.327472  [   28/   89]
per-ex loss: 0.601978  [   30/   89]
per-ex loss: 0.667802  [   32/   89]
per-ex loss: 0.415787  [   34/   89]
per-ex loss: 0.415966  [   36/   89]
per-ex loss: 0.419830  [   38/   89]
per-ex loss: 0.397762  [   40/   89]
per-ex loss: 0.368111  [   42/   89]
per-ex loss: 0.590178  [   44/   89]
per-ex loss: 0.474942  [   46/   89]
per-ex loss: 0.345604  [   48/   89]
per-ex loss: 0.373589  [   50/   89]
per-ex loss: 0.415769  [   52/   89]
per-ex loss: 0.379606  [   54/   89]
per-ex loss: 0.510288  [   56/   89]
per-ex loss: 0.396267  [   58/   89]
per-ex loss: 0.362575  [   60/   89]
per-ex loss: 0.555758  [   62/   89]
per-ex loss: 0.401814  [   64/   89]
per-ex loss: 0.524001  [   66/   89]
per-ex loss: 0.400944  [   68/   89]
per-ex loss: 0.625296  [   70/   89]
per-ex loss: 0.423690  [   72/   89]
per-ex loss: 0.407739  [   74/   89]
per-ex loss: 0.456265  [   76/   89]
per-ex loss: 0.390865  [   78/   89]
per-ex loss: 0.428346  [   80/   89]
per-ex loss: 0.444737  [   82/   89]
per-ex loss: 0.367733  [   84/   89]
per-ex loss: 0.447272  [   86/   89]
per-ex loss: 0.490276  [   88/   89]
per-ex loss: 0.429685  [   89/   89]
Train Error: Avg loss: 0.44406515
validation Error: 
 Avg loss: 0.98558635 
 F1: 0.514657 
 Precision: 0.527743 
 Recall: 0.502204
 IoU: 0.346490

test Error: 
 Avg loss: 0.98368678 
 F1: 0.535418 
 Precision: 0.522121 
 Recall: 0.549411
 IoU: 0.365577

We have finished training iteration 224
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_222_.pth
per-ex loss: 0.532261  [    2/   89]
per-ex loss: 0.544739  [    4/   89]
per-ex loss: 0.562316  [    6/   89]
per-ex loss: 0.512596  [    8/   89]
per-ex loss: 0.547283  [   10/   89]
per-ex loss: 0.394191  [   12/   89]
per-ex loss: 0.346504  [   14/   89]
per-ex loss: 0.515153  [   16/   89]
per-ex loss: 0.490009  [   18/   89]
per-ex loss: 0.365748  [   20/   89]
per-ex loss: 0.390863  [   22/   89]
per-ex loss: 0.382664  [   24/   89]
per-ex loss: 0.550260  [   26/   89]
per-ex loss: 0.543112  [   28/   89]
per-ex loss: 0.383072  [   30/   89]
per-ex loss: 0.635056  [   32/   89]
per-ex loss: 0.359031  [   34/   89]
per-ex loss: 0.357518  [   36/   89]
per-ex loss: 0.424762  [   38/   89]
per-ex loss: 0.405031  [   40/   89]
per-ex loss: 0.442133  [   42/   89]
per-ex loss: 0.408598  [   44/   89]
per-ex loss: 0.371164  [   46/   89]
per-ex loss: 0.337776  [   48/   89]
per-ex loss: 0.369716  [   50/   89]
per-ex loss: 0.621739  [   52/   89]
per-ex loss: 0.415588  [   54/   89]
per-ex loss: 0.474761  [   56/   89]
per-ex loss: 0.426219  [   58/   89]
per-ex loss: 0.534500  [   60/   89]
per-ex loss: 0.502202  [   62/   89]
per-ex loss: 0.371668  [   64/   89]
per-ex loss: 0.415117  [   66/   89]
per-ex loss: 0.510740  [   68/   89]
per-ex loss: 0.377903  [   70/   89]
per-ex loss: 0.399636  [   72/   89]
per-ex loss: 0.398635  [   74/   89]
per-ex loss: 0.387784  [   76/   89]
per-ex loss: 0.332900  [   78/   89]
per-ex loss: 0.406607  [   80/   89]
per-ex loss: 0.438410  [   82/   89]
per-ex loss: 0.558832  [   84/   89]
per-ex loss: 0.417251  [   86/   89]
per-ex loss: 0.383854  [   88/   89]
per-ex loss: 0.620652  [   89/   89]
Train Error: Avg loss: 0.44814565
validation Error: 
 Avg loss: 0.98236451 
 F1: 0.518371 
 Precision: 0.607663 
 Recall: 0.451959
 IoU: 0.349865

test Error: 
 Avg loss: 0.97952668 
 F1: 0.548344 
 Precision: 0.618823 
 Recall: 0.492277
 IoU: 0.377737

We have finished training iteration 225
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_223_.pth
per-ex loss: 0.377378  [    2/   89]
per-ex loss: 0.582316  [    4/   89]
per-ex loss: 0.570518  [    6/   89]
per-ex loss: 0.533094  [    8/   89]
per-ex loss: 0.335450  [   10/   89]
per-ex loss: 0.381340  [   12/   89]
per-ex loss: 0.492097  [   14/   89]
per-ex loss: 0.342467  [   16/   89]
per-ex loss: 0.424261  [   18/   89]
per-ex loss: 0.618609  [   20/   89]
per-ex loss: 0.381846  [   22/   89]
per-ex loss: 0.580870  [   24/   89]
per-ex loss: 0.506532  [   26/   89]
per-ex loss: 0.390510  [   28/   89]
per-ex loss: 0.580456  [   30/   89]
per-ex loss: 0.522699  [   32/   89]
per-ex loss: 0.436711  [   34/   89]
per-ex loss: 0.405774  [   36/   89]
per-ex loss: 0.418254  [   38/   89]
per-ex loss: 0.325477  [   40/   89]
per-ex loss: 0.412437  [   42/   89]
per-ex loss: 0.424156  [   44/   89]
per-ex loss: 0.510788  [   46/   89]
per-ex loss: 0.657624  [   48/   89]
per-ex loss: 0.574424  [   50/   89]
per-ex loss: 0.466442  [   52/   89]
per-ex loss: 0.407711  [   54/   89]
per-ex loss: 0.380204  [   56/   89]
per-ex loss: 0.393175  [   58/   89]
per-ex loss: 0.535683  [   60/   89]
per-ex loss: 0.349344  [   62/   89]
per-ex loss: 0.358448  [   64/   89]
per-ex loss: 0.501209  [   66/   89]
per-ex loss: 0.490024  [   68/   89]
per-ex loss: 0.482995  [   70/   89]
per-ex loss: 0.538126  [   72/   89]
per-ex loss: 0.420779  [   74/   89]
per-ex loss: 0.490582  [   76/   89]
per-ex loss: 0.353691  [   78/   89]
per-ex loss: 0.358031  [   80/   89]
per-ex loss: 0.477384  [   82/   89]
per-ex loss: 0.350685  [   84/   89]
per-ex loss: 0.490745  [   86/   89]
per-ex loss: 0.386919  [   88/   89]
per-ex loss: 0.404896  [   89/   89]
Train Error: Avg loss: 0.45384808
validation Error: 
 Avg loss: 0.98369372 
 F1: 0.518388 
 Precision: 0.593850 
 Recall: 0.459942
 IoU: 0.349881

test Error: 
 Avg loss: 0.98093142 
 F1: 0.548538 
 Precision: 0.611963 
 Recall: 0.497026
 IoU: 0.377921

We have finished training iteration 226
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_224_.pth
per-ex loss: 0.420333  [    2/   89]
per-ex loss: 0.356855  [    4/   89]
per-ex loss: 0.434575  [    6/   89]
per-ex loss: 0.361094  [    8/   89]
per-ex loss: 0.483018  [   10/   89]
per-ex loss: 0.400072  [   12/   89]
per-ex loss: 0.447468  [   14/   89]
per-ex loss: 0.560733  [   16/   89]
per-ex loss: 0.515561  [   18/   89]
per-ex loss: 0.367109  [   20/   89]
per-ex loss: 0.536358  [   22/   89]
per-ex loss: 0.496018  [   24/   89]
per-ex loss: 0.515048  [   26/   89]
per-ex loss: 0.424370  [   28/   89]
per-ex loss: 0.507542  [   30/   89]
per-ex loss: 0.310880  [   32/   89]
per-ex loss: 0.355505  [   34/   89]
per-ex loss: 0.396620  [   36/   89]
per-ex loss: 0.351563  [   38/   89]
per-ex loss: 0.495169  [   40/   89]
per-ex loss: 0.641695  [   42/   89]
per-ex loss: 0.460451  [   44/   89]
per-ex loss: 0.547898  [   46/   89]
per-ex loss: 0.480302  [   48/   89]
per-ex loss: 0.417877  [   50/   89]
per-ex loss: 0.450819  [   52/   89]
per-ex loss: 0.569761  [   54/   89]
per-ex loss: 0.363524  [   56/   89]
per-ex loss: 0.378924  [   58/   89]
per-ex loss: 0.461859  [   60/   89]
per-ex loss: 0.459257  [   62/   89]
per-ex loss: 0.466258  [   64/   89]
per-ex loss: 0.626727  [   66/   89]
per-ex loss: 0.366445  [   68/   89]
per-ex loss: 0.598493  [   70/   89]
per-ex loss: 0.401661  [   72/   89]
per-ex loss: 0.359480  [   74/   89]
per-ex loss: 0.419285  [   76/   89]
per-ex loss: 0.414644  [   78/   89]
per-ex loss: 0.460965  [   80/   89]
per-ex loss: 0.509051  [   82/   89]
per-ex loss: 0.402203  [   84/   89]
per-ex loss: 0.352496  [   86/   89]
per-ex loss: 0.372598  [   88/   89]
per-ex loss: 0.429750  [   89/   89]
Train Error: Avg loss: 0.44774033
validation Error: 
 Avg loss: 0.98319849 
 F1: 0.516222 
 Precision: 0.603673 
 Recall: 0.450902
 IoU: 0.347910

test Error: 
 Avg loss: 0.98023196 
 F1: 0.548315 
 Precision: 0.616925 
 Recall: 0.493438
 IoU: 0.377709

We have finished training iteration 227
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_225_.pth
per-ex loss: 0.597452  [    2/   89]
per-ex loss: 0.428591  [    4/   89]
per-ex loss: 0.584721  [    6/   89]
per-ex loss: 0.353767  [    8/   89]
per-ex loss: 0.448129  [   10/   89]
per-ex loss: 0.411126  [   12/   89]
per-ex loss: 0.335124  [   14/   89]
per-ex loss: 0.456549  [   16/   89]
per-ex loss: 0.541859  [   18/   89]
per-ex loss: 0.591321  [   20/   89]
per-ex loss: 0.561554  [   22/   89]
per-ex loss: 0.396004  [   24/   89]
per-ex loss: 0.418183  [   26/   89]
per-ex loss: 0.320738  [   28/   89]
per-ex loss: 0.646900  [   30/   89]
per-ex loss: 0.445671  [   32/   89]
per-ex loss: 0.497640  [   34/   89]
per-ex loss: 0.375796  [   36/   89]
per-ex loss: 0.529849  [   38/   89]
per-ex loss: 0.482789  [   40/   89]
per-ex loss: 0.377821  [   42/   89]
per-ex loss: 0.503115  [   44/   89]
per-ex loss: 0.416140  [   46/   89]
per-ex loss: 0.587085  [   48/   89]
per-ex loss: 0.406517  [   50/   89]
per-ex loss: 0.531202  [   52/   89]
per-ex loss: 0.471464  [   54/   89]
per-ex loss: 0.570202  [   56/   89]
per-ex loss: 0.370364  [   58/   89]
per-ex loss: 0.373595  [   60/   89]
per-ex loss: 0.383339  [   62/   89]
per-ex loss: 0.382938  [   64/   89]
per-ex loss: 0.320449  [   66/   89]
per-ex loss: 0.565423  [   68/   89]
per-ex loss: 0.367361  [   70/   89]
per-ex loss: 0.377925  [   72/   89]
per-ex loss: 0.346482  [   74/   89]
per-ex loss: 0.532717  [   76/   89]
per-ex loss: 0.375660  [   78/   89]
per-ex loss: 0.546492  [   80/   89]
per-ex loss: 0.403205  [   82/   89]
per-ex loss: 0.368224  [   84/   89]
per-ex loss: 0.533698  [   86/   89]
per-ex loss: 0.449704  [   88/   89]
per-ex loss: 0.331817  [   89/   89]
Train Error: Avg loss: 0.45148218
validation Error: 
 Avg loss: 0.98320444 
 F1: 0.517816 
 Precision: 0.612772 
 Recall: 0.448340
 IoU: 0.349360

test Error: 
 Avg loss: 0.98070049 
 F1: 0.550136 
 Precision: 0.623037 
 Recall: 0.492507
 IoU: 0.379439

We have finished training iteration 228
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_226_.pth
Error in cropping the image to the non-zero values in the fourth channel. Returned the original image.
per-ex loss: 0.454671  [    2/   89]
per-ex loss: 0.471355  [    4/   89]
per-ex loss: 0.388645  [    6/   89]
per-ex loss: 0.478173  [    8/   89]
per-ex loss: 0.411800  [   10/   89]
per-ex loss: 0.323520  [   12/   89]
per-ex loss: 0.337157  [   14/   89]
per-ex loss: 0.502580  [   16/   89]
per-ex loss: 0.363694  [   18/   89]
per-ex loss: 0.437337  [   20/   89]
per-ex loss: 0.400317  [   22/   89]
per-ex loss: 0.412583  [   24/   89]
per-ex loss: 0.550867  [   26/   89]
per-ex loss: 0.356198  [   28/   89]
per-ex loss: 0.620504  [   30/   89]
per-ex loss: 0.364910  [   32/   89]
per-ex loss: 0.486169  [   34/   89]
per-ex loss: 0.382300  [   36/   89]
per-ex loss: 0.546757  [   38/   89]
per-ex loss: 0.556445  [   40/   89]
per-ex loss: 0.396205  [   42/   89]
per-ex loss: 0.416747  [   44/   89]
per-ex loss: 0.396800  [   46/   89]
per-ex loss: 0.376496  [   48/   89]
per-ex loss: 0.407645  [   50/   89]
per-ex loss: 0.367904  [   52/   89]
per-ex loss: 0.405395  [   54/   89]
per-ex loss: 0.370073  [   56/   89]
per-ex loss: 0.655147  [   58/   89]
per-ex loss: 0.554123  [   60/   89]
per-ex loss: 0.500222  [   62/   89]
per-ex loss: 0.679604  [   64/   89]
per-ex loss: 0.401333  [   66/   89]
per-ex loss: 0.352865  [   68/   89]
per-ex loss: 0.388200  [   70/   89]
per-ex loss: 0.515581  [   72/   89]
per-ex loss: 0.422296  [   74/   89]
per-ex loss: 0.410261  [   76/   89]
per-ex loss: 0.422945  [   78/   89]
per-ex loss: 0.623886  [   80/   89]
per-ex loss: 0.486499  [   82/   89]
per-ex loss: 0.360521  [   84/   89]
per-ex loss: 0.478789  [   86/   89]
per-ex loss: 0.522226  [   88/   89]
per-ex loss: 0.341382  [   89/   89]
Train Error: Avg loss: 0.44664727
validation Error: 
 Avg loss: 0.98151505 
 F1: 0.519817 
 Precision: 0.612302 
 Recall: 0.451605
 IoU: 0.351184

test Error: 
 Avg loss: 0.97996923 
 F1: 0.546692 
 Precision: 0.624419 
 Recall: 0.486174
 IoU: 0.376171

We have finished training iteration 229
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_227_.pth
per-ex loss: 0.557001  [    2/   89]
per-ex loss: 0.422476  [    4/   89]
per-ex loss: 0.530571  [    6/   89]
per-ex loss: 0.511927  [    8/   89]
per-ex loss: 0.346217  [   10/   89]
per-ex loss: 0.358909  [   12/   89]
per-ex loss: 0.469420  [   14/   89]
per-ex loss: 0.364484  [   16/   89]
per-ex loss: 0.330367  [   18/   89]
per-ex loss: 0.418177  [   20/   89]
per-ex loss: 0.328551  [   22/   89]
per-ex loss: 0.423324  [   24/   89]
per-ex loss: 0.378620  [   26/   89]
per-ex loss: 0.458150  [   28/   89]
per-ex loss: 0.511236  [   30/   89]
per-ex loss: 0.602915  [   32/   89]
per-ex loss: 0.408177  [   34/   89]
per-ex loss: 0.396613  [   36/   89]
per-ex loss: 0.378740  [   38/   89]
per-ex loss: 0.412002  [   40/   89]
per-ex loss: 0.453206  [   42/   89]
per-ex loss: 0.456483  [   44/   89]
per-ex loss: 0.341118  [   46/   89]
per-ex loss: 0.621641  [   48/   89]
per-ex loss: 0.527655  [   50/   89]
per-ex loss: 0.506751  [   52/   89]
per-ex loss: 0.370409  [   54/   89]
per-ex loss: 0.399972  [   56/   89]
per-ex loss: 0.430259  [   58/   89]
per-ex loss: 0.603325  [   60/   89]
per-ex loss: 0.374085  [   62/   89]
per-ex loss: 0.366983  [   64/   89]
per-ex loss: 0.474961  [   66/   89]
per-ex loss: 0.397229  [   68/   89]
per-ex loss: 0.597589  [   70/   89]
per-ex loss: 0.493743  [   72/   89]
per-ex loss: 0.617804  [   74/   89]
per-ex loss: 0.673517  [   76/   89]
per-ex loss: 0.482816  [   78/   89]
per-ex loss: 0.420824  [   80/   89]
per-ex loss: 0.333380  [   82/   89]
per-ex loss: 0.349634  [   84/   89]
per-ex loss: 0.522153  [   86/   89]
per-ex loss: 0.355799  [   88/   89]
per-ex loss: 0.338418  [   89/   89]
Train Error: Avg loss: 0.44705846
validation Error: 
 Avg loss: 0.98452871 
 F1: 0.517893 
 Precision: 0.538551 
 Recall: 0.498761
 IoU: 0.349430

test Error: 
 Avg loss: 0.98200678 
 F1: 0.541740 
 Precision: 0.547234 
 Recall: 0.536356
 IoU: 0.371498

We have finished training iteration 230
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_228_.pth
per-ex loss: 0.379281  [    2/   89]
per-ex loss: 0.548476  [    4/   89]
per-ex loss: 0.389649  [    6/   89]
per-ex loss: 0.392941  [    8/   89]
per-ex loss: 0.369596  [   10/   89]
per-ex loss: 0.391557  [   12/   89]
per-ex loss: 0.421924  [   14/   89]
per-ex loss: 0.386737  [   16/   89]
per-ex loss: 0.411107  [   18/   89]
per-ex loss: 0.454678  [   20/   89]
per-ex loss: 0.305826  [   22/   89]
per-ex loss: 0.621562  [   24/   89]
per-ex loss: 0.438581  [   26/   89]
per-ex loss: 0.374177  [   28/   89]
per-ex loss: 0.480458  [   30/   89]
per-ex loss: 0.416822  [   32/   89]
per-ex loss: 0.352046  [   34/   89]
per-ex loss: 0.510696  [   36/   89]
per-ex loss: 0.455986  [   38/   89]
per-ex loss: 0.455879  [   40/   89]
per-ex loss: 0.402595  [   42/   89]
per-ex loss: 0.454312  [   44/   89]
per-ex loss: 0.498633  [   46/   89]
per-ex loss: 0.504796  [   48/   89]
per-ex loss: 0.375647  [   50/   89]
per-ex loss: 0.449576  [   52/   89]
per-ex loss: 0.353280  [   54/   89]
per-ex loss: 0.382547  [   56/   89]
per-ex loss: 0.538528  [   58/   89]
per-ex loss: 0.380730  [   60/   89]
per-ex loss: 0.334205  [   62/   89]
per-ex loss: 0.459642  [   64/   89]
per-ex loss: 0.448299  [   66/   89]
per-ex loss: 0.405015  [   68/   89]
per-ex loss: 0.414199  [   70/   89]
per-ex loss: 0.482044  [   72/   89]
per-ex loss: 0.410039  [   74/   89]
per-ex loss: 0.450444  [   76/   89]
per-ex loss: 0.644264  [   78/   89]
per-ex loss: 0.539186  [   80/   89]
per-ex loss: 0.417218  [   82/   89]
per-ex loss: 0.308990  [   84/   89]
per-ex loss: 0.458405  [   86/   89]
per-ex loss: 0.388143  [   88/   89]
per-ex loss: 0.386653  [   89/   89]
Train Error: Avg loss: 0.43211930
validation Error: 
 Avg loss: 0.98503662 
 F1: 0.512261 
 Precision: 0.538389 
 Recall: 0.488552
 IoU: 0.344322

test Error: 
 Avg loss: 0.98267495 
 F1: 0.536819 
 Precision: 0.541629 
 Recall: 0.532093
 IoU: 0.366885

We have finished training iteration 231
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_229_.pth
Error in cropping the image to the non-zero values in the fourth channel. Returned the original image.
per-ex loss: 0.368546  [    2/   89]
per-ex loss: 0.364087  [    4/   89]
per-ex loss: 0.378449  [    6/   89]
per-ex loss: 0.373565  [    8/   89]
per-ex loss: 0.388079  [   10/   89]
per-ex loss: 0.493027  [   12/   89]
per-ex loss: 0.548216  [   14/   89]
per-ex loss: 0.389341  [   16/   89]
per-ex loss: 0.370546  [   18/   89]
per-ex loss: 0.522365  [   20/   89]
per-ex loss: 0.384558  [   22/   89]
per-ex loss: 0.449552  [   24/   89]
per-ex loss: 0.339824  [   26/   89]
per-ex loss: 0.554711  [   28/   89]
per-ex loss: 0.360867  [   30/   89]
per-ex loss: 0.356265  [   32/   89]
per-ex loss: 0.397421  [   34/   89]
per-ex loss: 0.496530  [   36/   89]
per-ex loss: 0.382489  [   38/   89]
per-ex loss: 0.355775  [   40/   89]
per-ex loss: 0.484683  [   42/   89]
per-ex loss: 0.406023  [   44/   89]
per-ex loss: 0.463702  [   46/   89]
per-ex loss: 0.377920  [   48/   89]
per-ex loss: 0.525419  [   50/   89]
per-ex loss: 0.480084  [   52/   89]
per-ex loss: 0.420806  [   54/   89]
per-ex loss: 0.492867  [   56/   89]
per-ex loss: 0.440255  [   58/   89]
per-ex loss: 0.648331  [   60/   89]
per-ex loss: 0.419305  [   62/   89]
per-ex loss: 0.359140  [   64/   89]
per-ex loss: 0.331755  [   66/   89]
per-ex loss: 0.436082  [   68/   89]
per-ex loss: 0.424478  [   70/   89]
per-ex loss: 0.467590  [   72/   89]
per-ex loss: 0.581861  [   74/   89]
per-ex loss: 0.420051  [   76/   89]
per-ex loss: 0.362750  [   78/   89]
per-ex loss: 0.365995  [   80/   89]
per-ex loss: 0.394420  [   82/   89]
per-ex loss: 0.350662  [   84/   89]
per-ex loss: 0.553247  [   86/   89]
per-ex loss: 0.356025  [   88/   89]
per-ex loss: 0.402928  [   89/   89]
Train Error: Avg loss: 0.42756868
validation Error: 
 Avg loss: 0.98321026 
 F1: 0.515231 
 Precision: 0.596570 
 Recall: 0.453411
 IoU: 0.347011

test Error: 
 Avg loss: 0.98037888 
 F1: 0.544706 
 Precision: 0.613117 
 Recall: 0.490029
 IoU: 0.374293

We have finished training iteration 232
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_230_.pth
per-ex loss: 0.512516  [    2/   89]
per-ex loss: 0.343250  [    4/   89]
per-ex loss: 0.463295  [    6/   89]
per-ex loss: 0.291658  [    8/   89]
per-ex loss: 0.423766  [   10/   89]
per-ex loss: 0.470359  [   12/   89]
per-ex loss: 0.579456  [   14/   89]
per-ex loss: 0.554052  [   16/   89]
per-ex loss: 0.610536  [   18/   89]
per-ex loss: 0.423340  [   20/   89]
per-ex loss: 0.557522  [   22/   89]
per-ex loss: 0.602005  [   24/   89]
per-ex loss: 0.577876  [   26/   89]
per-ex loss: 0.501636  [   28/   89]
per-ex loss: 0.373748  [   30/   89]
per-ex loss: 0.369673  [   32/   89]
per-ex loss: 0.567324  [   34/   89]
per-ex loss: 0.442485  [   36/   89]
per-ex loss: 0.399600  [   38/   89]
per-ex loss: 0.484400  [   40/   89]
per-ex loss: 0.537162  [   42/   89]
per-ex loss: 0.480127  [   44/   89]
per-ex loss: 0.360759  [   46/   89]
per-ex loss: 0.438681  [   48/   89]
per-ex loss: 0.396837  [   50/   89]
per-ex loss: 0.365763  [   52/   89]
per-ex loss: 0.385379  [   54/   89]
per-ex loss: 0.385956  [   56/   89]
per-ex loss: 0.339571  [   58/   89]
per-ex loss: 0.370589  [   60/   89]
per-ex loss: 0.373484  [   62/   89]
per-ex loss: 0.627268  [   64/   89]
per-ex loss: 0.398135  [   66/   89]
per-ex loss: 0.348943  [   68/   89]
per-ex loss: 0.457435  [   70/   89]
per-ex loss: 0.404823  [   72/   89]
per-ex loss: 0.441927  [   74/   89]
per-ex loss: 0.424443  [   76/   89]
per-ex loss: 0.354601  [   78/   89]
per-ex loss: 0.546674  [   80/   89]
per-ex loss: 0.454428  [   82/   89]
per-ex loss: 0.489385  [   84/   89]
per-ex loss: 0.404952  [   86/   89]
per-ex loss: 0.554653  [   88/   89]
per-ex loss: 0.323444  [   89/   89]
Train Error: Avg loss: 0.44919820
validation Error: 
 Avg loss: 0.98275689 
 F1: 0.516726 
 Precision: 0.617429 
 Recall: 0.444267
 IoU: 0.348369

test Error: 
 Avg loss: 0.98046420 
 F1: 0.545113 
 Precision: 0.625967 
 Recall: 0.482756
 IoU: 0.374677

We have finished training iteration 233
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_231_.pth
Error in cropping the image to the non-zero values in the fourth channel. Returned the original image.
per-ex loss: 0.494550  [    2/   89]
per-ex loss: 0.617703  [    4/   89]
per-ex loss: 0.301268  [    6/   89]
per-ex loss: 0.498928  [    8/   89]
per-ex loss: 0.540546  [   10/   89]
per-ex loss: 0.593525  [   12/   89]
per-ex loss: 0.367856  [   14/   89]
per-ex loss: 0.404671  [   16/   89]
per-ex loss: 0.502194  [   18/   89]
per-ex loss: 0.426891  [   20/   89]
per-ex loss: 0.417941  [   22/   89]
per-ex loss: 0.397227  [   24/   89]
per-ex loss: 0.491711  [   26/   89]
per-ex loss: 0.431826  [   28/   89]
per-ex loss: 0.523250  [   30/   89]
per-ex loss: 0.370806  [   32/   89]
per-ex loss: 0.443820  [   34/   89]
per-ex loss: 0.420082  [   36/   89]
per-ex loss: 0.390940  [   38/   89]
per-ex loss: 0.366948  [   40/   89]
per-ex loss: 0.385099  [   42/   89]
per-ex loss: 0.382911  [   44/   89]
per-ex loss: 0.406628  [   46/   89]
per-ex loss: 0.569517  [   48/   89]
per-ex loss: 0.476199  [   50/   89]
per-ex loss: 0.355874  [   52/   89]
per-ex loss: 0.560250  [   54/   89]
per-ex loss: 0.365589  [   56/   89]
per-ex loss: 0.396248  [   58/   89]
per-ex loss: 0.452179  [   60/   89]
per-ex loss: 0.618589  [   62/   89]
per-ex loss: 0.555605  [   64/   89]
per-ex loss: 0.366969  [   66/   89]
per-ex loss: 0.433895  [   68/   89]
per-ex loss: 0.542660  [   70/   89]
per-ex loss: 0.461037  [   72/   89]
per-ex loss: 0.345693  [   74/   89]
per-ex loss: 0.519060  [   76/   89]
per-ex loss: 0.387744  [   78/   89]
per-ex loss: 0.470695  [   80/   89]
per-ex loss: 0.324542  [   82/   89]
per-ex loss: 0.407888  [   84/   89]
per-ex loss: 0.390338  [   86/   89]
per-ex loss: 0.376552  [   88/   89]
per-ex loss: 0.364191  [   89/   89]
Train Error: Avg loss: 0.44263637
validation Error: 
 Avg loss: 0.98464203 
 F1: 0.518996 
 Precision: 0.567058 
 Recall: 0.478444
 IoU: 0.350435

test Error: 
 Avg loss: 0.98254200 
 F1: 0.542849 
 Precision: 0.575220 
 Recall: 0.513928
 IoU: 0.372541

We have finished training iteration 234
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_232_.pth
Error in cropping the image to the non-zero values in the fourth channel. Returned the original image.
per-ex loss: 0.415888  [    2/   89]
per-ex loss: 0.418792  [    4/   89]
per-ex loss: 0.509109  [    6/   89]
per-ex loss: 0.428920  [    8/   89]
per-ex loss: 0.502108  [   10/   89]
per-ex loss: 0.558306  [   12/   89]
per-ex loss: 0.492580  [   14/   89]
per-ex loss: 0.547967  [   16/   89]
per-ex loss: 0.373133  [   18/   89]
per-ex loss: 0.470094  [   20/   89]
per-ex loss: 0.353513  [   22/   89]
per-ex loss: 0.480606  [   24/   89]
per-ex loss: 0.469369  [   26/   89]
per-ex loss: 0.459980  [   28/   89]
per-ex loss: 0.399164  [   30/   89]
per-ex loss: 0.352397  [   32/   89]
per-ex loss: 0.581189  [   34/   89]
per-ex loss: 0.391673  [   36/   89]
per-ex loss: 0.338588  [   38/   89]
per-ex loss: 0.400384  [   40/   89]
per-ex loss: 0.472015  [   42/   89]
per-ex loss: 0.389882  [   44/   89]
per-ex loss: 0.402996  [   46/   89]
per-ex loss: 0.531609  [   48/   89]
per-ex loss: 0.363439  [   50/   89]
per-ex loss: 0.538678  [   52/   89]
per-ex loss: 0.370410  [   54/   89]
per-ex loss: 0.400415  [   56/   89]
per-ex loss: 0.512154  [   58/   89]
per-ex loss: 0.358365  [   60/   89]
per-ex loss: 0.423309  [   62/   89]
per-ex loss: 0.422976  [   64/   89]
per-ex loss: 0.389894  [   66/   89]
per-ex loss: 0.377116  [   68/   89]
per-ex loss: 0.375974  [   70/   89]
per-ex loss: 0.541586  [   72/   89]
per-ex loss: 0.484886  [   74/   89]
per-ex loss: 0.394580  [   76/   89]
per-ex loss: 0.364428  [   78/   89]
per-ex loss: 0.502547  [   80/   89]
per-ex loss: 0.494984  [   82/   89]
per-ex loss: 0.383100  [   84/   89]
per-ex loss: 0.476718  [   86/   89]
per-ex loss: 0.631795  [   88/   89]
per-ex loss: 0.299006  [   89/   89]
Train Error: Avg loss: 0.44103605
validation Error: 
 Avg loss: 0.98267946 
 F1: 0.516418 
 Precision: 0.594561 
 Recall: 0.456429
 IoU: 0.348089

test Error: 
 Avg loss: 0.97940009 
 F1: 0.548343 
 Precision: 0.617358 
 Recall: 0.493206
 IoU: 0.377736

We have finished training iteration 235
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_233_.pth
per-ex loss: 0.500944  [    2/   89]
per-ex loss: 0.400580  [    4/   89]
per-ex loss: 0.607043  [    6/   89]
per-ex loss: 0.347762  [    8/   89]
per-ex loss: 0.408145  [   10/   89]
per-ex loss: 0.378007  [   12/   89]
per-ex loss: 0.385398  [   14/   89]
per-ex loss: 0.396230  [   16/   89]
per-ex loss: 0.534166  [   18/   89]
per-ex loss: 0.343732  [   20/   89]
per-ex loss: 0.426248  [   22/   89]
per-ex loss: 0.489189  [   24/   89]
per-ex loss: 0.562050  [   26/   89]
per-ex loss: 0.432194  [   28/   89]
per-ex loss: 0.397004  [   30/   89]
per-ex loss: 0.390959  [   32/   89]
per-ex loss: 0.441961  [   34/   89]
per-ex loss: 0.369188  [   36/   89]
per-ex loss: 0.510843  [   38/   89]
per-ex loss: 0.409293  [   40/   89]
per-ex loss: 0.391202  [   42/   89]
per-ex loss: 0.374583  [   44/   89]
per-ex loss: 0.506257  [   46/   89]
per-ex loss: 0.424887  [   48/   89]
per-ex loss: 0.471431  [   50/   89]
per-ex loss: 0.548351  [   52/   89]
per-ex loss: 0.331072  [   54/   89]
per-ex loss: 0.418989  [   56/   89]
per-ex loss: 0.415883  [   58/   89]
per-ex loss: 0.394351  [   60/   89]
per-ex loss: 0.317512  [   62/   89]
per-ex loss: 0.381466  [   64/   89]
per-ex loss: 0.420789  [   66/   89]
per-ex loss: 0.399744  [   68/   89]
per-ex loss: 0.421168  [   70/   89]
per-ex loss: 0.319745  [   72/   89]
per-ex loss: 0.536811  [   74/   89]
per-ex loss: 0.509207  [   76/   89]
per-ex loss: 0.354252  [   78/   89]
per-ex loss: 0.457425  [   80/   89]
per-ex loss: 0.554635  [   82/   89]
per-ex loss: 0.345216  [   84/   89]
per-ex loss: 0.415862  [   86/   89]
per-ex loss: 0.562392  [   88/   89]
per-ex loss: 0.374443  [   89/   89]
Train Error: Avg loss: 0.43063578
validation Error: 
 Avg loss: 0.98419266 
 F1: 0.519309 
 Precision: 0.535648 
 Recall: 0.503937
 IoU: 0.350721

test Error: 
 Avg loss: 0.98206936 
 F1: 0.542634 
 Precision: 0.547947 
 Recall: 0.537422
 IoU: 0.372338

We have finished training iteration 236
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_234_.pth
per-ex loss: 0.416276  [    2/   89]
per-ex loss: 0.497468  [    4/   89]
per-ex loss: 0.403611  [    6/   89]
per-ex loss: 0.384884  [    8/   89]
per-ex loss: 0.369793  [   10/   89]
per-ex loss: 0.332934  [   12/   89]
per-ex loss: 0.424016  [   14/   89]
per-ex loss: 0.468528  [   16/   89]
per-ex loss: 0.537389  [   18/   89]
per-ex loss: 0.413811  [   20/   89]
per-ex loss: 0.360944  [   22/   89]
per-ex loss: 0.443147  [   24/   89]
per-ex loss: 0.574468  [   26/   89]
per-ex loss: 0.404329  [   28/   89]
per-ex loss: 0.357294  [   30/   89]
per-ex loss: 0.449869  [   32/   89]
per-ex loss: 0.363951  [   34/   89]
per-ex loss: 0.541059  [   36/   89]
per-ex loss: 0.453733  [   38/   89]
per-ex loss: 0.339638  [   40/   89]
per-ex loss: 0.482319  [   42/   89]
per-ex loss: 0.513303  [   44/   89]
per-ex loss: 0.409004  [   46/   89]
per-ex loss: 0.441299  [   48/   89]
per-ex loss: 0.598052  [   50/   89]
per-ex loss: 0.397767  [   52/   89]
per-ex loss: 0.360403  [   54/   89]
per-ex loss: 0.475811  [   56/   89]
per-ex loss: 0.368253  [   58/   89]
per-ex loss: 0.560078  [   60/   89]
per-ex loss: 0.662606  [   62/   89]
per-ex loss: 0.307699  [   64/   89]
per-ex loss: 0.506571  [   66/   89]
per-ex loss: 0.607846  [   68/   89]
per-ex loss: 0.368674  [   70/   89]
per-ex loss: 0.571968  [   72/   89]
per-ex loss: 0.347970  [   74/   89]
per-ex loss: 0.384303  [   76/   89]
per-ex loss: 0.453786  [   78/   89]
per-ex loss: 0.351792  [   80/   89]
per-ex loss: 0.606275  [   82/   89]
per-ex loss: 0.592651  [   84/   89]
per-ex loss: 0.397267  [   86/   89]
per-ex loss: 0.356264  [   88/   89]
per-ex loss: 0.460231  [   89/   89]
Train Error: Avg loss: 0.44709634
validation Error: 
 Avg loss: 0.98390495 
 F1: 0.518046 
 Precision: 0.577757 
 Recall: 0.469522
 IoU: 0.349570

test Error: 
 Avg loss: 0.98100864 
 F1: 0.546228 
 Precision: 0.596805 
 Recall: 0.503554
 IoU: 0.375732

We have finished training iteration 237
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_235_.pth
per-ex loss: 0.450090  [    2/   89]
per-ex loss: 0.536344  [    4/   89]
per-ex loss: 0.381524  [    6/   89]
per-ex loss: 0.370166  [    8/   89]
per-ex loss: 0.446771  [   10/   89]
per-ex loss: 0.386262  [   12/   89]
per-ex loss: 0.437713  [   14/   89]
per-ex loss: 0.476167  [   16/   89]
per-ex loss: 0.415997  [   18/   89]
per-ex loss: 0.603513  [   20/   89]
per-ex loss: 0.425197  [   22/   89]
per-ex loss: 0.493041  [   24/   89]
per-ex loss: 0.349008  [   26/   89]
per-ex loss: 0.462258  [   28/   89]
per-ex loss: 0.372675  [   30/   89]
per-ex loss: 0.344422  [   32/   89]
per-ex loss: 0.416854  [   34/   89]
per-ex loss: 0.387019  [   36/   89]
per-ex loss: 0.397454  [   38/   89]
per-ex loss: 0.490667  [   40/   89]
per-ex loss: 0.381800  [   42/   89]
per-ex loss: 0.539033  [   44/   89]
per-ex loss: 0.416493  [   46/   89]
per-ex loss: 0.523443  [   48/   89]
per-ex loss: 0.478934  [   50/   89]
per-ex loss: 0.371225  [   52/   89]
per-ex loss: 0.381753  [   54/   89]
per-ex loss: 0.403287  [   56/   89]
per-ex loss: 0.625808  [   58/   89]
per-ex loss: 0.385275  [   60/   89]
per-ex loss: 0.377934  [   62/   89]
per-ex loss: 0.396100  [   64/   89]
per-ex loss: 0.358168  [   66/   89]
per-ex loss: 0.580587  [   68/   89]
per-ex loss: 0.382285  [   70/   89]
per-ex loss: 0.366278  [   72/   89]
per-ex loss: 0.419589  [   74/   89]
per-ex loss: 0.604677  [   76/   89]
per-ex loss: 0.420786  [   78/   89]
per-ex loss: 0.380800  [   80/   89]
per-ex loss: 0.560109  [   82/   89]
per-ex loss: 0.451330  [   84/   89]
per-ex loss: 0.477258  [   86/   89]
per-ex loss: 0.563605  [   88/   89]
per-ex loss: 0.347447  [   89/   89]
Train Error: Avg loss: 0.44082546
validation Error: 
 Avg loss: 0.98519806 
 F1: 0.514088 
 Precision: 0.521591 
 Recall: 0.506799
 IoU: 0.345975

test Error: 
 Avg loss: 0.98310954 
 F1: 0.532594 
 Precision: 0.521430 
 Recall: 0.544247
 IoU: 0.362949

We have finished training iteration 238
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_236_.pth
per-ex loss: 0.324449  [    2/   89]
per-ex loss: 0.407020  [    4/   89]
per-ex loss: 0.504134  [    6/   89]
per-ex loss: 0.351776  [    8/   89]
per-ex loss: 0.438029  [   10/   89]
per-ex loss: 0.351194  [   12/   89]
per-ex loss: 0.349935  [   14/   89]
per-ex loss: 0.485471  [   16/   89]
per-ex loss: 0.361952  [   18/   89]
per-ex loss: 0.386010  [   20/   89]
per-ex loss: 0.750634  [   22/   89]
per-ex loss: 0.381787  [   24/   89]
per-ex loss: 0.353053  [   26/   89]
per-ex loss: 0.466072  [   28/   89]
per-ex loss: 0.394799  [   30/   89]
per-ex loss: 0.451544  [   32/   89]
per-ex loss: 0.389913  [   34/   89]
per-ex loss: 0.480867  [   36/   89]
per-ex loss: 0.466380  [   38/   89]
per-ex loss: 0.387474  [   40/   89]
per-ex loss: 0.472523  [   42/   89]
per-ex loss: 0.574591  [   44/   89]
per-ex loss: 0.552233  [   46/   89]
per-ex loss: 0.588884  [   48/   89]
per-ex loss: 0.543801  [   50/   89]
per-ex loss: 0.500313  [   52/   89]
per-ex loss: 0.418904  [   54/   89]
per-ex loss: 0.455535  [   56/   89]
per-ex loss: 0.387243  [   58/   89]
per-ex loss: 0.527764  [   60/   89]
per-ex loss: 0.376575  [   62/   89]
per-ex loss: 0.547790  [   64/   89]
per-ex loss: 0.491902  [   66/   89]
per-ex loss: 0.375749  [   68/   89]
per-ex loss: 0.445651  [   70/   89]
per-ex loss: 0.533592  [   72/   89]
per-ex loss: 0.476346  [   74/   89]
per-ex loss: 0.320693  [   76/   89]
per-ex loss: 0.377324  [   78/   89]
per-ex loss: 0.346742  [   80/   89]
per-ex loss: 0.331563  [   82/   89]
per-ex loss: 0.407339  [   84/   89]
per-ex loss: 0.533191  [   86/   89]
per-ex loss: 0.393964  [   88/   89]
per-ex loss: 0.481320  [   89/   89]
Train Error: Avg loss: 0.44320066
validation Error: 
 Avg loss: 0.98261300 
 F1: 0.516791 
 Precision: 0.608717 
 Recall: 0.448986
 IoU: 0.348427

test Error: 
 Avg loss: 0.97993978 
 F1: 0.536132 
 Precision: 0.614787 
 Recall: 0.475321
 IoU: 0.366244

We have finished training iteration 239
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_237_.pth
per-ex loss: 0.415611  [    2/   89]
per-ex loss: 0.390565  [    4/   89]
per-ex loss: 0.490593  [    6/   89]
per-ex loss: 0.431296  [    8/   89]
per-ex loss: 0.531511  [   10/   89]
per-ex loss: 0.394683  [   12/   89]
per-ex loss: 0.350874  [   14/   89]
per-ex loss: 0.504513  [   16/   89]
per-ex loss: 0.547862  [   18/   89]
per-ex loss: 0.456649  [   20/   89]
per-ex loss: 0.377812  [   22/   89]
per-ex loss: 0.338358  [   24/   89]
per-ex loss: 0.371846  [   26/   89]
per-ex loss: 0.429215  [   28/   89]
per-ex loss: 0.329206  [   30/   89]
per-ex loss: 0.370714  [   32/   89]
per-ex loss: 0.436611  [   34/   89]
per-ex loss: 0.420458  [   36/   89]
per-ex loss: 0.493378  [   38/   89]
per-ex loss: 0.351975  [   40/   89]
per-ex loss: 0.573782  [   42/   89]
per-ex loss: 0.420584  [   44/   89]
per-ex loss: 0.389818  [   46/   89]
per-ex loss: 0.404369  [   48/   89]
per-ex loss: 0.412383  [   50/   89]
per-ex loss: 0.338925  [   52/   89]
per-ex loss: 0.510113  [   54/   89]
per-ex loss: 0.343386  [   56/   89]
per-ex loss: 0.515056  [   58/   89]
per-ex loss: 0.389020  [   60/   89]
per-ex loss: 0.486331  [   62/   89]
per-ex loss: 0.431151  [   64/   89]
per-ex loss: 0.538412  [   66/   89]
per-ex loss: 0.411530  [   68/   89]
per-ex loss: 0.414406  [   70/   89]
per-ex loss: 0.529633  [   72/   89]
per-ex loss: 0.424262  [   74/   89]
per-ex loss: 0.324681  [   76/   89]
per-ex loss: 0.538866  [   78/   89]
per-ex loss: 0.337094  [   80/   89]
per-ex loss: 0.545284  [   82/   89]
per-ex loss: 0.463943  [   84/   89]
per-ex loss: 0.439000  [   86/   89]
per-ex loss: 0.537247  [   88/   89]
per-ex loss: 0.348961  [   89/   89]
Train Error: Avg loss: 0.43337705
validation Error: 
 Avg loss: 0.98395876 
 F1: 0.515408 
 Precision: 0.562508 
 Recall: 0.475586
 IoU: 0.347171

test Error: 
 Avg loss: 0.98169528 
 F1: 0.539052 
 Precision: 0.566908 
 Recall: 0.513806
 IoU: 0.368974

We have finished training iteration 240
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_238_.pth
per-ex loss: 0.404777  [    2/   89]
per-ex loss: 0.438332  [    4/   89]
per-ex loss: 0.415003  [    6/   89]
per-ex loss: 0.590746  [    8/   89]
per-ex loss: 0.529622  [   10/   89]
per-ex loss: 0.417383  [   12/   89]
per-ex loss: 0.468134  [   14/   89]
per-ex loss: 0.430323  [   16/   89]
per-ex loss: 0.456893  [   18/   89]
per-ex loss: 0.404561  [   20/   89]
per-ex loss: 0.418040  [   22/   89]
per-ex loss: 0.501695  [   24/   89]
per-ex loss: 0.366097  [   26/   89]
per-ex loss: 0.553639  [   28/   89]
per-ex loss: 0.441407  [   30/   89]
per-ex loss: 0.354084  [   32/   89]
per-ex loss: 0.518649  [   34/   89]
per-ex loss: 0.364363  [   36/   89]
per-ex loss: 0.555081  [   38/   89]
per-ex loss: 0.409068  [   40/   89]
per-ex loss: 0.603379  [   42/   89]
per-ex loss: 0.318435  [   44/   89]
per-ex loss: 0.452422  [   46/   89]
per-ex loss: 0.402570  [   48/   89]
per-ex loss: 0.510072  [   50/   89]
per-ex loss: 0.408233  [   52/   89]
per-ex loss: 0.349773  [   54/   89]
per-ex loss: 0.610481  [   56/   89]
per-ex loss: 0.472254  [   58/   89]
per-ex loss: 0.370275  [   60/   89]
per-ex loss: 0.574633  [   62/   89]
per-ex loss: 0.442122  [   64/   89]
per-ex loss: 0.384643  [   66/   89]
per-ex loss: 0.450450  [   68/   89]
per-ex loss: 0.369348  [   70/   89]
per-ex loss: 0.529841  [   72/   89]
per-ex loss: 0.393454  [   74/   89]
per-ex loss: 0.353350  [   76/   89]
per-ex loss: 0.446221  [   78/   89]
per-ex loss: 0.512176  [   80/   89]
per-ex loss: 0.512923  [   82/   89]
per-ex loss: 0.397607  [   84/   89]
per-ex loss: 0.444232  [   86/   89]
per-ex loss: 0.380173  [   88/   89]
per-ex loss: 0.519868  [   89/   89]
Train Error: Avg loss: 0.44992960
validation Error: 
 Avg loss: 0.98306608 
 F1: 0.513035 
 Precision: 0.631627 
 Recall: 0.431936
 IoU: 0.345021

test Error: 
 Avg loss: 0.98075791 
 F1: 0.539532 
 Precision: 0.633631 
 Recall: 0.469767
 IoU: 0.369424

We have finished training iteration 241
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_239_.pth
per-ex loss: 0.531228  [    2/   89]
per-ex loss: 0.428238  [    4/   89]
per-ex loss: 0.432765  [    6/   89]
per-ex loss: 0.368490  [    8/   89]
per-ex loss: 0.441802  [   10/   89]
per-ex loss: 0.370091  [   12/   89]
per-ex loss: 0.421109  [   14/   89]
per-ex loss: 0.459115  [   16/   89]
per-ex loss: 0.518761  [   18/   89]
per-ex loss: 0.559004  [   20/   89]
per-ex loss: 0.383118  [   22/   89]
per-ex loss: 0.602418  [   24/   89]
per-ex loss: 0.386346  [   26/   89]
per-ex loss: 0.490369  [   28/   89]
per-ex loss: 0.411277  [   30/   89]
per-ex loss: 0.344383  [   32/   89]
per-ex loss: 0.409301  [   34/   89]
per-ex loss: 0.570428  [   36/   89]
per-ex loss: 0.374841  [   38/   89]
per-ex loss: 0.404619  [   40/   89]
per-ex loss: 0.430470  [   42/   89]
per-ex loss: 0.383384  [   44/   89]
per-ex loss: 0.348208  [   46/   89]
per-ex loss: 0.438506  [   48/   89]
per-ex loss: 0.414279  [   50/   89]
per-ex loss: 0.401833  [   52/   89]
per-ex loss: 0.515555  [   54/   89]
per-ex loss: 0.523210  [   56/   89]
per-ex loss: 0.357869  [   58/   89]
per-ex loss: 0.415495  [   60/   89]
per-ex loss: 0.436249  [   62/   89]
per-ex loss: 0.590387  [   64/   89]
per-ex loss: 0.598522  [   66/   89]
per-ex loss: 0.462534  [   68/   89]
per-ex loss: 0.435857  [   70/   89]
per-ex loss: 0.466831  [   72/   89]
per-ex loss: 0.594454  [   74/   89]
per-ex loss: 0.341290  [   76/   89]
per-ex loss: 0.496947  [   78/   89]
per-ex loss: 0.431001  [   80/   89]
per-ex loss: 0.393656  [   82/   89]
per-ex loss: 0.491253  [   84/   89]
per-ex loss: 0.393188  [   86/   89]
per-ex loss: 0.445598  [   88/   89]
per-ex loss: 0.369155  [   89/   89]
Train Error: Avg loss: 0.44629854
validation Error: 
 Avg loss: 0.98577708 
 F1: 0.506989 
 Precision: 0.483042 
 Recall: 0.533434
 IoU: 0.339575

test Error: 
 Avg loss: 0.98351561 
 F1: 0.524738 
 Precision: 0.487196 
 Recall: 0.568547
 IoU: 0.355691

We have finished training iteration 242
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_240_.pth
per-ex loss: 0.443252  [    2/   89]
per-ex loss: 0.399236  [    4/   89]
per-ex loss: 0.421056  [    6/   89]
per-ex loss: 0.332343  [    8/   89]
per-ex loss: 0.339997  [   10/   89]
per-ex loss: 0.589504  [   12/   89]
per-ex loss: 0.407144  [   14/   89]
per-ex loss: 0.388020  [   16/   89]
per-ex loss: 0.422673  [   18/   89]
per-ex loss: 0.379053  [   20/   89]
per-ex loss: 0.370544  [   22/   89]
per-ex loss: 0.404787  [   24/   89]
per-ex loss: 0.359193  [   26/   89]
per-ex loss: 0.478017  [   28/   89]
per-ex loss: 0.431332  [   30/   89]
per-ex loss: 0.520094  [   32/   89]
per-ex loss: 0.380929  [   34/   89]
per-ex loss: 0.481883  [   36/   89]
per-ex loss: 0.440286  [   38/   89]
per-ex loss: 0.384517  [   40/   89]
per-ex loss: 0.447329  [   42/   89]
per-ex loss: 0.505850  [   44/   89]
per-ex loss: 0.385301  [   46/   89]
per-ex loss: 0.464472  [   48/   89]
per-ex loss: 0.369115  [   50/   89]
per-ex loss: 0.454690  [   52/   89]
per-ex loss: 0.349339  [   54/   89]
per-ex loss: 0.499307  [   56/   89]
per-ex loss: 0.347866  [   58/   89]
per-ex loss: 0.559021  [   60/   89]
per-ex loss: 0.469321  [   62/   89]
per-ex loss: 0.423286  [   64/   89]
per-ex loss: 0.407772  [   66/   89]
per-ex loss: 0.378311  [   68/   89]
per-ex loss: 0.538204  [   70/   89]
per-ex loss: 0.428619  [   72/   89]
per-ex loss: 0.362394  [   74/   89]
per-ex loss: 0.434574  [   76/   89]
per-ex loss: 0.394741  [   78/   89]
per-ex loss: 0.400122  [   80/   89]
per-ex loss: 0.479573  [   82/   89]
per-ex loss: 0.428668  [   84/   89]
per-ex loss: 0.449417  [   86/   89]
per-ex loss: 0.400230  [   88/   89]
per-ex loss: 0.557634  [   89/   89]
Train Error: Avg loss: 0.42908923
validation Error: 
 Avg loss: 0.98386538 
 F1: 0.522718 
 Precision: 0.570628 
 Recall: 0.482230
 IoU: 0.353838

test Error: 
 Avg loss: 0.98179714 
 F1: 0.543196 
 Precision: 0.575762 
 Recall: 0.514117
 IoU: 0.372868

We have finished training iteration 243
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_241_.pth
per-ex loss: 0.475098  [    2/   89]
per-ex loss: 0.504414  [    4/   89]
per-ex loss: 0.401011  [    6/   89]
per-ex loss: 0.420373  [    8/   89]
per-ex loss: 0.364473  [   10/   89]
per-ex loss: 0.479326  [   12/   89]
per-ex loss: 0.497453  [   14/   89]
per-ex loss: 0.600549  [   16/   89]
per-ex loss: 0.565723  [   18/   89]
per-ex loss: 0.521860  [   20/   89]
per-ex loss: 0.458305  [   22/   89]
per-ex loss: 0.356334  [   24/   89]
per-ex loss: 0.351631  [   26/   89]
per-ex loss: 0.430816  [   28/   89]
per-ex loss: 0.344833  [   30/   89]
per-ex loss: 0.511853  [   32/   89]
per-ex loss: 0.585130  [   34/   89]
per-ex loss: 0.387686  [   36/   89]
per-ex loss: 0.558520  [   38/   89]
per-ex loss: 0.550187  [   40/   89]
per-ex loss: 0.630134  [   42/   89]
per-ex loss: 0.519644  [   44/   89]
per-ex loss: 0.470358  [   46/   89]
per-ex loss: 0.333719  [   48/   89]
per-ex loss: 0.336292  [   50/   89]
per-ex loss: 0.494651  [   52/   89]
per-ex loss: 0.371280  [   54/   89]
per-ex loss: 0.437802  [   56/   89]
per-ex loss: 0.505696  [   58/   89]
per-ex loss: 0.394823  [   60/   89]
per-ex loss: 0.607158  [   62/   89]
per-ex loss: 0.470177  [   64/   89]
per-ex loss: 0.365804  [   66/   89]
per-ex loss: 0.390437  [   68/   89]
per-ex loss: 0.390100  [   70/   89]
per-ex loss: 0.393556  [   72/   89]
per-ex loss: 0.300678  [   74/   89]
per-ex loss: 0.329160  [   76/   89]
per-ex loss: 0.374028  [   78/   89]
per-ex loss: 0.523268  [   80/   89]
per-ex loss: 0.395414  [   82/   89]
per-ex loss: 0.405064  [   84/   89]
per-ex loss: 0.407266  [   86/   89]
per-ex loss: 0.369594  [   88/   89]
per-ex loss: 0.624014  [   89/   89]
Train Error: Avg loss: 0.44901539
validation Error: 
 Avg loss: 0.98273335 
 F1: 0.518265 
 Precision: 0.600378 
 Recall: 0.455911
 IoU: 0.349769

test Error: 
 Avg loss: 0.98004402 
 F1: 0.544549 
 Precision: 0.606166 
 Recall: 0.494303
 IoU: 0.374144

We have finished training iteration 244
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_242_.pth
per-ex loss: 0.581687  [    2/   89]
per-ex loss: 0.418390  [    4/   89]
per-ex loss: 0.498202  [    6/   89]
per-ex loss: 0.369902  [    8/   89]
per-ex loss: 0.574637  [   10/   89]
per-ex loss: 0.480855  [   12/   89]
per-ex loss: 0.536320  [   14/   89]
per-ex loss: 0.352665  [   16/   89]
per-ex loss: 0.408664  [   18/   89]
per-ex loss: 0.366416  [   20/   89]
per-ex loss: 0.393540  [   22/   89]
per-ex loss: 0.398004  [   24/   89]
per-ex loss: 0.313544  [   26/   89]
per-ex loss: 0.459408  [   28/   89]
per-ex loss: 0.450947  [   30/   89]
per-ex loss: 0.561488  [   32/   89]
per-ex loss: 0.560244  [   34/   89]
per-ex loss: 0.487254  [   36/   89]
per-ex loss: 0.621432  [   38/   89]
per-ex loss: 0.318920  [   40/   89]
per-ex loss: 0.359420  [   42/   89]
per-ex loss: 0.400116  [   44/   89]
per-ex loss: 0.487573  [   46/   89]
per-ex loss: 0.404565  [   48/   89]
per-ex loss: 0.397697  [   50/   89]
per-ex loss: 0.400984  [   52/   89]
per-ex loss: 0.397900  [   54/   89]
per-ex loss: 0.407255  [   56/   89]
per-ex loss: 0.459966  [   58/   89]
per-ex loss: 0.513286  [   60/   89]
per-ex loss: 0.366258  [   62/   89]
per-ex loss: 0.442523  [   64/   89]
per-ex loss: 0.512695  [   66/   89]
per-ex loss: 0.391391  [   68/   89]
per-ex loss: 0.389453  [   70/   89]
per-ex loss: 0.361218  [   72/   89]
per-ex loss: 0.434901  [   74/   89]
per-ex loss: 0.368261  [   76/   89]
per-ex loss: 0.378699  [   78/   89]
per-ex loss: 0.367399  [   80/   89]
per-ex loss: 0.391460  [   82/   89]
per-ex loss: 0.402199  [   84/   89]
per-ex loss: 0.488789  [   86/   89]
per-ex loss: 0.534736  [   88/   89]
per-ex loss: 0.433012  [   89/   89]
Train Error: Avg loss: 0.43653948
validation Error: 
 Avg loss: 0.98563932 
 F1: 0.515674 
 Precision: 0.509426 
 Recall: 0.522078
 IoU: 0.347413

test Error: 
 Avg loss: 0.98334721 
 F1: 0.540753 
 Precision: 0.520175 
 Recall: 0.563027
 IoU: 0.370570

We have finished training iteration 245
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_243_.pth
per-ex loss: 0.463874  [    2/   89]
per-ex loss: 0.392722  [    4/   89]
per-ex loss: 0.365769  [    6/   89]
per-ex loss: 0.510716  [    8/   89]
per-ex loss: 0.440407  [   10/   89]
per-ex loss: 0.563132  [   12/   89]
per-ex loss: 0.468202  [   14/   89]
per-ex loss: 0.464947  [   16/   89]
per-ex loss: 0.348080  [   18/   89]
per-ex loss: 0.504457  [   20/   89]
per-ex loss: 0.412128  [   22/   89]
per-ex loss: 0.370554  [   24/   89]
per-ex loss: 0.449198  [   26/   89]
per-ex loss: 0.405553  [   28/   89]
per-ex loss: 0.372578  [   30/   89]
per-ex loss: 0.386369  [   32/   89]
per-ex loss: 0.372702  [   34/   89]
per-ex loss: 0.346330  [   36/   89]
per-ex loss: 0.392663  [   38/   89]
per-ex loss: 0.573961  [   40/   89]
per-ex loss: 0.532523  [   42/   89]
per-ex loss: 0.451855  [   44/   89]
per-ex loss: 0.491862  [   46/   89]
per-ex loss: 0.492824  [   48/   89]
per-ex loss: 0.395350  [   50/   89]
per-ex loss: 0.384051  [   52/   89]
per-ex loss: 0.451326  [   54/   89]
per-ex loss: 0.355943  [   56/   89]
per-ex loss: 0.530163  [   58/   89]
per-ex loss: 0.379348  [   60/   89]
per-ex loss: 0.402794  [   62/   89]
per-ex loss: 0.609081  [   64/   89]
per-ex loss: 0.361674  [   66/   89]
per-ex loss: 0.444369  [   68/   89]
per-ex loss: 0.365558  [   70/   89]
per-ex loss: 0.501728  [   72/   89]
per-ex loss: 0.372550  [   74/   89]
per-ex loss: 0.402288  [   76/   89]
per-ex loss: 0.476279  [   78/   89]
per-ex loss: 0.354359  [   80/   89]
per-ex loss: 0.417451  [   82/   89]
per-ex loss: 0.526074  [   84/   89]
per-ex loss: 0.394558  [   86/   89]
per-ex loss: 0.434713  [   88/   89]
per-ex loss: 0.525489  [   89/   89]
Train Error: Avg loss: 0.43685670
validation Error: 
 Avg loss: 0.98393212 
 F1: 0.517773 
 Precision: 0.610561 
 Recall: 0.449466
 IoU: 0.349321

test Error: 
 Avg loss: 0.98131484 
 F1: 0.544331 
 Precision: 0.623365 
 Recall: 0.483083
 IoU: 0.373939

We have finished training iteration 246
Deleting model ./unet_zscwzo_train/saved_model_wrapper/models/UNet_244_.pth
Max training iterations reached: 200. Train_iter: 246, Initial_train_iter: 46
